<!DOCTYPE html>
<html>









  <head>
    <meta charset="utf-8">
    <title>Protein Structure Analysis</title>
    
    <link rel="stylesheet" href="/assets/css/slides.css">
    <link rel="stylesheet" href="/assets/css/font-awesome.css" id="theme">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />

    
    
    
    
    <meta name="description" content="Analyzing the protein structure of your protein-of-intere..." />
    <meta property="og:title" content="VIB Bioinformatics Training: Protein Structure Analysis" />
    <meta property="og:description" content="Analyzing the protein structure of your protein-of-intere..." />
    <meta property="og:image" content="/assets/images/bioinformatics_core_rgb_neg.png" />
    <script type="application/ld+json">
       


{
  "@context": "http://schema.org",
  "@type": "Course",
  "accessMode": [
    "textual",
    "visual"
  ],
  "accessModeSufficient": [
    "textual",
    "visual"
  ],
  "accessibilityControl": [
    "fullKeyboardControl",
    "fullMouseControl"
  ],
  "accessibilityFeature": [
    "alternativeText",
    "tableOfContents"
  ],
  "accessibilitySummary": "Short descriptions are present but long descriptions will be needed for non-visual users",
  "audience": {
    "@type": "EducationalAudience",
    "educationalRole": "students"
  },
  "copyrightHolder": {
    "@type": "Organization",
    "email": "bits@vib.be",
    "name": "VIB Bioinformatics Core",
    "url": "https://www.bits.vib.be"
  },
  "headline": "Protein Structure Analysis",
  "inLanguage": {
    "@type": "Language",
    "name": "English",
    "alternateName": "en"
  },
  "interactivityType": "mixed",
  "isAccessibleForFree": true,
  "license": "/blob//LICENSE.md",
  "producer": {
    "@type": "Organization",
    "email": "bits@vib.be",
    "name": "VIB Bioinformatics Core",
    "url": "https://www.bits.vib.be"
  },
  "provider": {
    "@type": "Organization",
    "email": "bits@vib.be",
    "name": "VIB Bioinformatics Core",
    "url": "https://www.bits.vib.be"
  },
  "sourceOrganization": {
    "@type": "Organization",
    "email": "bits@vib.be",
    "name": "VIB Bioinformatics Core",
    "url": "https://www.bits.vib.be"
  },
  "courseCode": "protein-structure-analysis / introduction / introduction.html",
  "isPartOf": {
    "@type": "CreativeWork",
    "name": "Protein Structure Analysis",
    "description": "Analyzing the protein structure of your protein-of-interest can be advantageous in multiple ways. It can help you discover regions which are good candidates to interact with other proteins. It can help you discover new domains. It can help with identifying differences with homologuous proteins and a lot more.",
    "url": "https://vibbits.github.io//topics/protein-structure-analysis/"
  },
  "learningResourceType": "slides",
  "name": "Introduction to 'Protein Structure Analysis'",
  "url": "https://vibbits.github.io//topics/protein-structure-analysis/slides/introduction.html",
  "description": "Protein Structure Analysis",
  "hasPart": [

  ],
  "mentions": [

  ],
  "author": [
    {
      "@type": "Person",
      "name": "Alexander Botzki"
    },
    {
      "@type": "Person",
      "name": "Joost Van Durme"
    },
    {
      "@type": "Person",
      "name": "Janick Mathys"
    }
  ],
  "contributor": [
    {
      "@type": "Person",
      "name": "Alexander Botzki"
    },
    {
      "@type": "Person",
      "name": "Joost Van Durme"
    },
    {
      "@type": "Person",
      "name": "Janick Mathys"
    }
  ],
  "about": [
    {
      "@type": "CreativeWork",
      "name": "Protein Structure Analysis",
      "description": "Analyzing the protein structure of your protein-of-interest can be advantageous in multiple ways. It can help you discover regions which are good candidates to interact with other proteins. It can help you discover new domains. It can help with identifying differences with homologuous proteins and a lot more.",
      "url": "https://vibbits.github.io//topics/protein-structure-analysis/"
    }
  ]
}
    </script>
  </head>
  <body>
         <pre>
              site: {&quot;tags&quot;:{},&quot;posts&quot;:[],&quot;time&quot;:&quot;2019-12-19 11:57:01 -0600&quot;,&quot;categories&quot;:{},&quot;static_files&quot;:[{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;.nojekyll&quot;,&quot;basename&quot;:&quot;.nojekyll&quot;,&quot;extname&quot;:&quot;&quot;,&quot;path&quot;:&quot;/.nojekyll&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;.nojekyll&quot;,&quot;basename&quot;:&quot;.nojekyll&quot;,&quot;extname&quot;:&quot;&quot;,&quot;path&quot;:&quot;/.nojekyll&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;404.html&quot;,&quot;basename&quot;:&quot;404&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/404.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;CNAME&quot;,&quot;basename&quot;:&quot;CNAME&quot;,&quot;extname&quot;:&quot;&quot;,&quot;path&quot;:&quot;/CNAME&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;CODEOWNERS&quot;,&quot;basename&quot;:&quot;CODEOWNERS&quot;,&quot;extname&quot;:&quot;&quot;,&quot;path&quot;:&quot;/CODEOWNERS&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;CODE_OF_CONDUCT.md&quot;,&quot;basename&quot;:&quot;CODE_OF_CONDUCT&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/CODE_OF_CONDUCT.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Procfile&quot;,&quot;basename&quot;:&quot;Procfile&quot;,&quot;extname&quot;:&quot;&quot;,&quot;path&quot;:&quot;/Procfile&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;app.json&quot;,&quot;basename&quot;:&quot;app&quot;,&quot;extname&quot;:&quot;.json&quot;,&quot;path&quot;:&quot;/app.json&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;VIB.css&quot;,&quot;basename&quot;:&quot;VIB&quot;,&quot;extname&quot;:&quot;.css&quot;,&quot;path&quot;:&quot;/assets/css/VIB.css&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;academicons.css&quot;,&quot;basename&quot;:&quot;academicons&quot;,&quot;extname&quot;:&quot;.css&quot;,&quot;path&quot;:&quot;/assets/css/academicons.css&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bootstrap-theme.css&quot;,&quot;basename&quot;:&quot;bootstrap-theme&quot;,&quot;extname&quot;:&quot;.css&quot;,&quot;path&quot;:&quot;/assets/css/bootstrap-theme.css&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bootstrap-theme.min.css&quot;,&quot;basename&quot;:&quot;bootstrap-theme.min&quot;,&quot;extname&quot;:&quot;.css&quot;,&quot;path&quot;:&quot;/assets/css/bootstrap-theme.min.css&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bootstrap-toc.min.css&quot;,&quot;basename&quot;:&quot;bootstrap-toc.min&quot;,&quot;extname&quot;:&quot;.css&quot;,&quot;path&quot;:&quot;/assets/css/bootstrap-toc.min.css&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bootstrap.css&quot;,&quot;basename&quot;:&quot;bootstrap&quot;,&quot;extname&quot;:&quot;.css&quot;,&quot;path&quot;:&quot;/assets/css/bootstrap.css&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bootstrap.min.css&quot;,&quot;basename&quot;:&quot;bootstrap.min&quot;,&quot;extname&quot;:&quot;.css&quot;,&quot;path&quot;:&quot;/assets/css/bootstrap.min.css&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;font-awesome.css&quot;,&quot;basename&quot;:&quot;font-awesome&quot;,&quot;extname&quot;:&quot;.css&quot;,&quot;path&quot;:&quot;/assets/css/font-awesome.css&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;main.css&quot;,&quot;basename&quot;:&quot;main&quot;,&quot;extname&quot;:&quot;.css&quot;,&quot;path&quot;:&quot;/assets/css/main.css&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;slides.css&quot;,&quot;basename&quot;:&quot;slides&quot;,&quot;extname&quot;:&quot;.css&quot;,&quot;path&quot;:&quot;/assets/css/slides.css&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;syntax_highlighting.css&quot;,&quot;basename&quot;:&quot;syntax_highlighting&quot;,&quot;extname&quot;:&quot;.css&quot;,&quot;path&quot;:&quot;/assets/css/syntax_highlighting.css&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Dense-Regular.otf&quot;,&quot;basename&quot;:&quot;Dense-Regular&quot;,&quot;extname&quot;:&quot;.otf&quot;,&quot;path&quot;:&quot;/assets/fonts/Dense-Regular.otf&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Dense-Regular.ttf&quot;,&quot;basename&quot;:&quot;Dense-Regular&quot;,&quot;extname&quot;:&quot;.ttf&quot;,&quot;path&quot;:&quot;/assets/fonts/Dense-Regular.ttf&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;FontAwesome.otf&quot;,&quot;basename&quot;:&quot;FontAwesome&quot;,&quot;extname&quot;:&quot;.otf&quot;,&quot;path&quot;:&quot;/assets/fonts/FontAwesome.otf&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;MaterialIcons.woff&quot;,&quot;basename&quot;:&quot;MaterialIcons&quot;,&quot;extname&quot;:&quot;.woff&quot;,&quot;path&quot;:&quot;/assets/fonts/MaterialIcons.woff&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;MaterialIcons.woff2&quot;,&quot;basename&quot;:&quot;MaterialIcons&quot;,&quot;extname&quot;:&quot;.woff2&quot;,&quot;path&quot;:&quot;/assets/fonts/MaterialIcons.woff2&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;OpenSans.otf&quot;,&quot;basename&quot;:&quot;OpenSans&quot;,&quot;extname&quot;:&quot;.otf&quot;,&quot;path&quot;:&quot;/assets/fonts/OpenSans.otf&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;OpenSans.woff&quot;,&quot;basename&quot;:&quot;OpenSans&quot;,&quot;extname&quot;:&quot;.woff&quot;,&quot;path&quot;:&quot;/assets/fonts/OpenSans.woff&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;OpenSans.woff2&quot;,&quot;basename&quot;:&quot;OpenSans&quot;,&quot;extname&quot;:&quot;.woff2&quot;,&quot;path&quot;:&quot;/assets/fonts/OpenSans.woff2&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;academicons.eot&quot;,&quot;basename&quot;:&quot;academicons&quot;,&quot;extname&quot;:&quot;.eot&quot;,&quot;path&quot;:&quot;/assets/fonts/academicons.eot&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;academicons.svg&quot;,&quot;basename&quot;:&quot;academicons&quot;,&quot;extname&quot;:&quot;.svg&quot;,&quot;path&quot;:&quot;/assets/fonts/academicons.svg&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;academicons.ttf&quot;,&quot;basename&quot;:&quot;academicons&quot;,&quot;extname&quot;:&quot;.ttf&quot;,&quot;path&quot;:&quot;/assets/fonts/academicons.ttf&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;academicons.woff&quot;,&quot;basename&quot;:&quot;academicons&quot;,&quot;extname&quot;:&quot;.woff&quot;,&quot;path&quot;:&quot;/assets/fonts/academicons.woff&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;fontawesome-webfont.eot&quot;,&quot;basename&quot;:&quot;fontawesome-webfont&quot;,&quot;extname&quot;:&quot;.eot&quot;,&quot;path&quot;:&quot;/assets/fonts/fontawesome-webfont.eot&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;fontawesome-webfont.svg&quot;,&quot;basename&quot;:&quot;fontawesome-webfont&quot;,&quot;extname&quot;:&quot;.svg&quot;,&quot;path&quot;:&quot;/assets/fonts/fontawesome-webfont.svg&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;fontawesome-webfont.ttf&quot;,&quot;basename&quot;:&quot;fontawesome-webfont&quot;,&quot;extname&quot;:&quot;.ttf&quot;,&quot;path&quot;:&quot;/assets/fonts/fontawesome-webfont.ttf&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;fontawesome-webfont.woff&quot;,&quot;basename&quot;:&quot;fontawesome-webfont&quot;,&quot;extname&quot;:&quot;.woff&quot;,&quot;path&quot;:&quot;/assets/fonts/fontawesome-webfont.woff&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;fontawesome-webfont.woff2&quot;,&quot;basename&quot;:&quot;fontawesome-webfont&quot;,&quot;extname&quot;:&quot;.woff2&quot;,&quot;path&quot;:&quot;/assets/fonts/fontawesome-webfont.woff2&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;glyphicons-halflings-regular.eot&quot;,&quot;basename&quot;:&quot;glyphicons-halflings-regular&quot;,&quot;extname&quot;:&quot;.eot&quot;,&quot;path&quot;:&quot;/assets/fonts/glyphicons-halflings-regular.eot&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;glyphicons-halflings-regular.svg&quot;,&quot;basename&quot;:&quot;glyphicons-halflings-regular&quot;,&quot;extname&quot;:&quot;.svg&quot;,&quot;path&quot;:&quot;/assets/fonts/glyphicons-halflings-regular.svg&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;glyphicons-halflings-regular.ttf&quot;,&quot;basename&quot;:&quot;glyphicons-halflings-regular&quot;,&quot;extname&quot;:&quot;.ttf&quot;,&quot;path&quot;:&quot;/assets/fonts/glyphicons-halflings-regular.ttf&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;glyphicons-halflings-regular.woff&quot;,&quot;basename&quot;:&quot;glyphicons-halflings-regular&quot;,&quot;extname&quot;:&quot;.woff&quot;,&quot;path&quot;:&quot;/assets/fonts/glyphicons-halflings-regular.woff&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;glyphicons-halflings-regular.woff2&quot;,&quot;basename&quot;:&quot;glyphicons-halflings-regular&quot;,&quot;extname&quot;:&quot;.woff2&quot;,&quot;path&quot;:&quot;/assets/fonts/glyphicons-halflings-regular.woff2&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;GTN-60px.png&quot;,&quot;basename&quot;:&quot;GTN-60px&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/assets/images/GTN-60px.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;GTN.png&quot;,&quot;basename&quot;:&quot;GTN&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/assets/images/GTN.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;GTNLogo1000.png&quot;,&quot;basename&quot;:&quot;GTNLogo1000&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/assets/images/GTNLogo1000.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bioinformatics_core_rgb_neg.png&quot;,&quot;basename&quot;:&quot;bioinformatics_core_rgb_neg&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/assets/images/bioinformatics_core_rgb_neg.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;introblockheader.jpg&quot;,&quot;basename&quot;:&quot;introblockheader&quot;,&quot;extname&quot;:&quot;.jpg&quot;,&quot;path&quot;:&quot;/assets/images/introblockheader.jpg&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;logo.svg&quot;,&quot;basename&quot;:&quot;logo&quot;,&quot;extname&quot;:&quot;.svg&quot;,&quot;path&quot;:&quot;/assets/images/logo.svg&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;qr-gtn-black-logo.png&quot;,&quot;basename&quot;:&quot;qr-gtn-black-logo&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/assets/images/qr-gtn-black-logo.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;qr-gtn-black.png&quot;,&quot;basename&quot;:&quot;qr-gtn-black&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/assets/images/qr-gtn-black.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;qr-gtn-darkblue-logo.png&quot;,&quot;basename&quot;:&quot;qr-gtn-darkblue-logo&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/assets/images/qr-gtn-darkblue-logo.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;qr-gtn-darkblue.png&quot;,&quot;basename&quot;:&quot;qr-gtn-darkblue&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/assets/images/qr-gtn-darkblue.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;qr-gtn-darkgrey-logo.png&quot;,&quot;basename&quot;:&quot;qr-gtn-darkgrey-logo&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/assets/images/qr-gtn-darkgrey-logo.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;qr-gtn-darkgrey.png&quot;,&quot;basename&quot;:&quot;qr-gtn-darkgrey&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/assets/images/qr-gtn-darkgrey.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;qr-gtn-logo.xcf&quot;,&quot;basename&quot;:&quot;qr-gtn-logo&quot;,&quot;extname&quot;:&quot;.xcf&quot;,&quot;path&quot;:&quot;/assets/images/qr-gtn-logo.xcf&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;qr-gtn-white-logo.png&quot;,&quot;basename&quot;:&quot;qr-gtn-white-logo&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/assets/images/qr-gtn-white-logo.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;qr-gtn-white.png&quot;,&quot;basename&quot;:&quot;qr-gtn-white&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/assets/images/qr-gtn-white.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;qr-gtn.xcf&quot;,&quot;basename&quot;:&quot;qr-gtn&quot;,&quot;extname&quot;:&quot;.xcf&quot;,&quot;path&quot;:&quot;/assets/images/qr-gtn.xcf&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;search.svg&quot;,&quot;basename&quot;:&quot;search&quot;,&quot;extname&quot;:&quot;.svg&quot;,&quot;path&quot;:&quot;/assets/images/search.svg&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;vib_notag_neg_rgb.jpg&quot;,&quot;basename&quot;:&quot;vib_notag_neg_rgb&quot;,&quot;extname&quot;:&quot;.jpg&quot;,&quot;path&quot;:&quot;/assets/images/vib_notag_neg_rgb.jpg&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bootstrap-toc.min.js&quot;,&quot;basename&quot;:&quot;bootstrap-toc.min&quot;,&quot;extname&quot;:&quot;.js&quot;,&quot;path&quot;:&quot;/assets/js/bootstrap-toc.min.js&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bootstrap.js&quot;,&quot;basename&quot;:&quot;bootstrap&quot;,&quot;extname&quot;:&quot;.js&quot;,&quot;path&quot;:&quot;/assets/js/bootstrap.js&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bootstrap.min.js&quot;,&quot;basename&quot;:&quot;bootstrap.min&quot;,&quot;extname&quot;:&quot;.js&quot;,&quot;path&quot;:&quot;/assets/js/bootstrap.min.js&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;clipboard.min.js&quot;,&quot;basename&quot;:&quot;clipboard.min&quot;,&quot;extname&quot;:&quot;.js&quot;,&quot;path&quot;:&quot;/assets/js/clipboard.min.js&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;details-element-polyfill.js&quot;,&quot;basename&quot;:&quot;details-element-polyfill&quot;,&quot;extname&quot;:&quot;.js&quot;,&quot;path&quot;:&quot;/assets/js/details-element-polyfill.js&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;jquery.slim.min.js&quot;,&quot;basename&quot;:&quot;jquery.slim.min&quot;,&quot;extname&quot;:&quot;.js&quot;,&quot;path&quot;:&quot;/assets/js/jquery.slim.min.js&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;main.js&quot;,&quot;basename&quot;:&quot;main&quot;,&quot;extname&quot;:&quot;.js&quot;,&quot;path&quot;:&quot;/assets/js/main.js&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;popper.min.js&quot;,&quot;basename&quot;:&quot;popper.min&quot;,&quot;extname&quot;:&quot;.js&quot;,&quot;path&quot;:&quot;/assets/js/popper.min.js&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;remark-latest.min.js&quot;,&quot;basename&quot;:&quot;remark-latest.min&quot;,&quot;extname&quot;:&quot;.js&quot;,&quot;path&quot;:&quot;/assets/js/remark-latest.min.js&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;index.html&quot;,&quot;basename&quot;:&quot;index&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/badges/index.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;faq.html&quot;,&quot;basename&quot;:&quot;faq&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/faq.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;favicon.ico&quot;,&quot;basename&quot;:&quot;favicon&quot;,&quot;extname&quot;:&quot;.ico&quot;,&quot;path&quot;:&quot;/favicon.ico&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;feed.xml&quot;,&quot;basename&quot;:&quot;feed&quot;,&quot;extname&quot;:&quot;.xml&quot;,&quot;path&quot;:&quot;/feed.xml&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;galaxy_instances.yaml&quot;,&quot;basename&quot;:&quot;galaxy_instances&quot;,&quot;extname&quot;:&quot;.yaml&quot;,&quot;path&quot;:&quot;/galaxy_instances.yaml&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;hall-of-fame.html&quot;,&quot;basename&quot;:&quot;hall-of-fame&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/hall-of-fame.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;index.html&quot;,&quot;basename&quot;:&quot;index&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/index.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;LICENSE.txt&quot;,&quot;basename&quot;:&quot;LICENSE&quot;,&quot;extname&quot;:&quot;.txt&quot;,&quot;path&quot;:&quot;/shared/fonts/NotoSans/LICENSE.txt&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;NotoSans-Bold.ttf&quot;,&quot;basename&quot;:&quot;NotoSans-Bold&quot;,&quot;extname&quot;:&quot;.ttf&quot;,&quot;path&quot;:&quot;/shared/fonts/NotoSans/NotoSans-Bold.ttf&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;NotoSans-BoldItalic.ttf&quot;,&quot;basename&quot;:&quot;NotoSans-BoldItalic&quot;,&quot;extname&quot;:&quot;.ttf&quot;,&quot;path&quot;:&quot;/shared/fonts/NotoSans/NotoSans-BoldItalic.ttf&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;NotoSans-Italic.ttf&quot;,&quot;basename&quot;:&quot;NotoSans-Italic&quot;,&quot;extname&quot;:&quot;.ttf&quot;,&quot;path&quot;:&quot;/shared/fonts/NotoSans/NotoSans-Italic.ttf&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;NotoSans-Regular.ttf&quot;,&quot;basename&quot;:&quot;NotoSans-Regular&quot;,&quot;extname&quot;:&quot;.ttf&quot;,&quot;path&quot;:&quot;/shared/fonts/NotoSans/NotoSans-Regular.ttf&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Excelerate_whitebackground.png&quot;,&quot;basename&quot;:&quot;Excelerate_whitebackground&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/Excelerate_whitebackground.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;FreeBayes_settings.png&quot;,&quot;basename&quot;:&quot;FreeBayes_settings&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/FreeBayes_settings.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;GTNLogo1000.png&quot;,&quot;basename&quot;:&quot;GTNLogo1000&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/GTNLogo1000.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;MA_plot.png&quot;,&quot;basename&quot;:&quot;MA_plot&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/MA_plot.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;RNAseq_histiry_image.key&quot;,&quot;basename&quot;:&quot;RNAseq_histiry_image&quot;,&quot;extname&quot;:&quot;.key&quot;,&quot;path&quot;:&quot;/shared/images/RNAseq_histiry_image.key&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rarithmetic_operators.png&quot;,&quot;basename&quot;:&quot;Rarithmetic_operators&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/Rarithmetic_operators.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rautocompletion.png&quot;,&quot;basename&quot;:&quot;Rautocompletion&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/Rautocompletion.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rcomment_uncomment.png&quot;,&quot;basename&quot;:&quot;Rcomment_uncomment&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/Rcomment_uncomment.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rexport_plot.png&quot;,&quot;basename&quot;:&quot;Rexport_plot&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/Rexport_plot.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rfile_imported.png&quot;,&quot;basename&quot;:&quot;Rfile_imported&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/Rfile_imported.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rgeneral_functions.png&quot;,&quot;basename&quot;:&quot;Rgeneral_functions&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/Rgeneral_functions.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rinstall_zip.png&quot;,&quot;basename&quot;:&quot;Rinstall_zip&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/Rinstall_zip.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rlogic_operators.png&quot;,&quot;basename&quot;:&quot;Rlogic_operators&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/Rlogic_operators.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rnew_script.png&quot;,&quot;basename&quot;:&quot;Rnew_script&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/Rnew_script.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rrefresh_button.png&quot;,&quot;basename&quot;:&quot;Rrefresh_button&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/Rrefresh_button.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rsave_script.png&quot;,&quot;basename&quot;:&quot;Rsave_script&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/Rsave_script.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rsection_headings.png&quot;,&quot;basename&quot;:&quot;Rsection_headings&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/Rsection_headings.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rtable_function.png&quot;,&quot;basename&quot;:&quot;Rtable_function&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/Rtable_function.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rview_file.png&quot;,&quot;basename&quot;:&quot;Rview_file&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/Rview_file.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Screen Shot 2016-04-21 at 3.55.19 PM.png&quot;,&quot;basename&quot;:&quot;Screen Shot 2016-04-21 at 3.55.19 PM&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/Screen Shot 2016-04-21 at 3.55.19 PM.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Screen Shot 2016-12-06 at 18.14.25.png&quot;,&quot;basename&quot;:&quot;Screen Shot 2016-12-06 at 18.14.25&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/Screen Shot 2016-12-06 at 18.14.25.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;accepted_hits_1.png&quot;,&quot;basename&quot;:&quot;accepted_hits_1&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/accepted_hits_1.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;accepted_hits_2.png&quot;,&quot;basename&quot;:&quot;accepted_hits_2&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/accepted_hits_2.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;ansible_logo.png&quot;,&quot;basename&quot;:&quot;ansible_logo&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/ansible_logo.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;arrow_white_left.svg&quot;,&quot;basename&quot;:&quot;arrow_white_left&quot;,&quot;extname&quot;:&quot;.svg&quot;,&quot;path&quot;:&quot;/shared/images/arrow_white_left.svg&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bioconda_logo.png&quot;,&quot;basename&quot;:&quot;bioconda_logo&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/bioconda_logo.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bw.png&quot;,&quot;basename&quot;:&quot;bw&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/bw.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bw_b_rank.png&quot;,&quot;basename&quot;:&quot;bw_b_rank&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/bw_b_rank.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bwt_q1.png&quot;,&quot;basename&quot;:&quot;bwt_q1&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/bwt_q1.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bwt_q2.png&quot;,&quot;basename&quot;:&quot;bwt_q2&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/bwt_q2.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bwt_q3.png&quot;,&quot;basename&quot;:&quot;bwt_q3&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/bwt_q3.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bwt_q4.png&quot;,&quot;basename&quot;:&quot;bwt_q4&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/bwt_q4.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bwt_q5.png&quot;,&quot;basename&quot;:&quot;bwt_q5&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/bwt_q5.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bwt_rev.png&quot;,&quot;basename&quot;:&quot;bwt_rev&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/bwt_rev.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;bwt_rev2.png&quot;,&quot;basename&quot;:&quot;bwt_rev2&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/bwt_rev2.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;cloudman_based_server_landing_page.png&quot;,&quot;basename&quot;:&quot;cloudman_based_server_landing_page&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/cloudman_based_server_landing_page.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;cloudman_management_console_showing_autoscaled_w_1_worker.png&quot;,&quot;basename&quot;:&quot;cloudman_management_console_showing_autoscaled_w_1_worker&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/cloudman_management_console_showing_autoscaled_w_1_worker.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;collections_video.png&quot;,&quot;basename&quot;:&quot;collections_video&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/collections_video.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;conda_logo.png&quot;,&quot;basename&quot;:&quot;conda_logo&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/conda_logo.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;create_index.png&quot;,&quot;basename&quot;:&quot;create_index&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/create_index.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;dT_random.png&quot;,&quot;basename&quot;:&quot;dT_random&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/dT_random.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;deNBI.png&quot;,&quot;basename&quot;:&quot;deNBI&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/deNBI.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;deseq2_interface.png&quot;,&quot;basename&quot;:&quot;deseq2_interface&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/deseq2_interface.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;deseq2_output.png&quot;,&quot;basename&quot;:&quot;deseq2_output&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/deseq2_output.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;development_process.png&quot;,&quot;basename&quot;:&quot;development_process&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/development_process.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;diff.png&quot;,&quot;basename&quot;:&quot;diff&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/diff.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;dispersion.png&quot;,&quot;basename&quot;:&quot;dispersion&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/dispersion.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;dna_rna.png&quot;,&quot;basename&quot;:&quot;dna_rna&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/dna_rna.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;docker_logo.png&quot;,&quot;basename&quot;:&quot;docker_logo&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/docker_logo.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;dotplot.gif&quot;,&quot;basename&quot;:&quot;dotplot&quot;,&quot;extname&quot;:&quot;.gif&quot;,&quot;path&quot;:&quot;/shared/images/dotplot.gif&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;elixir.png&quot;,&quot;basename&quot;:&quot;elixir&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/elixir.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;em.png&quot;,&quot;basename&quot;:&quot;em&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/em.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;euc_dist.png&quot;,&quot;basename&quot;:&quot;euc_dist&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/euc_dist.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;everything_connected.png&quot;,&quot;basename&quot;:&quot;everything_connected&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/everything_connected.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;f_from_l.png&quot;,&quot;basename&quot;:&quot;f_from_l&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/f_from_l.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;filter_gtf.png&quot;,&quot;basename&quot;:&quot;filter_gtf&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/filter_gtf.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;forward_index.png&quot;,&quot;basename&quot;:&quot;forward_index&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/forward_index.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;freebayes.png&quot;,&quot;basename&quot;:&quot;freebayes&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/freebayes.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;freebayes_gq.png&quot;,&quot;basename&quot;:&quot;freebayes_gq&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/freebayes_gq.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;galaxy_command.png&quot;,&quot;basename&quot;:&quot;galaxy_command&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/galaxy_command.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;galaxy_logo.png&quot;,&quot;basename&quot;:&quot;galaxy_logo&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/galaxy_logo.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;galaxy_logo_25percent_transparent.png&quot;,&quot;basename&quot;:&quot;galaxy_logo_25percent_transparent&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/galaxy_logo_25percent_transparent.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;gemini_command.png&quot;,&quot;basename&quot;:&quot;gemini_command&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/gemini_command.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;gemini_db_info.png&quot;,&quot;basename&quot;:&quot;gemini_db_info&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/gemini_db_info.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;gemini_load.png&quot;,&quot;basename&quot;:&quot;gemini_load&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/gemini_load.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;gemini_query1.png&quot;,&quot;basename&quot;:&quot;gemini_query1&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/gemini_query1.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;gemini_query2.png&quot;,&quot;basename&quot;:&quot;gemini_query2&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/gemini_query2.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;goblet.png&quot;,&quot;basename&quot;:&quot;goblet&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/goblet.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;hash.png&quot;,&quot;basename&quot;:&quot;hash&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/hash.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;hisat.png&quot;,&quot;basename&quot;:&quot;hisat&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/hisat.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;history_menu_buttons2.png&quot;,&quot;basename&quot;:&quot;history_menu_buttons2&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/history_menu_buttons2.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;history_menu_extract_workflow.png&quot;,&quot;basename&quot;:&quot;history_menu_extract_workflow&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/history_menu_extract_workflow.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;history_options_menu.png&quot;,&quot;basename&quot;:&quot;history_options_menu&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/history_options_menu.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;htseq_count.png&quot;,&quot;basename&quot;:&quot;htseq_count&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/htseq_count.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;htseq_count_interface.png&quot;,&quot;basename&quot;:&quot;htseq_count_interface&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/htseq_count_interface.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;igv_tophat.png&quot;,&quot;basename&quot;:&quot;igv_tophat&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/igv_tophat.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;import_history.png&quot;,&quot;basename&quot;:&quot;import_history&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/import_history.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;interactive_training.png&quot;,&quot;basename&quot;:&quot;interactive_training&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/interactive_training.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;introblockheader.jpg&quot;,&quot;basename&quot;:&quot;introblockheader&quot;,&quot;extname&quot;:&quot;.jpg&quot;,&quot;path&quot;:&quot;/shared/images/introblockheader.jpg&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;inverted_index.png&quot;,&quot;basename&quot;:&quot;inverted_index&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/inverted_index.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;kallisto.png&quot;,&quot;basename&quot;:&quot;kallisto&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/kallisto.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;landing_page.png&quot;,&quot;basename&quot;:&quot;landing_page&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/landing_page.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;lcs.png&quot;,&quot;basename&quot;:&quot;lcs&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/lcs.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;lf_a.png&quot;,&quot;basename&quot;:&quot;lf_a&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/lf_a.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;lf_b.png&quot;,&quot;basename&quot;:&quot;lf_b&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/lf_b.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;lib_type.png&quot;,&quot;basename&quot;:&quot;lib_type&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/lib_type.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;library_import.png&quot;,&quot;basename&quot;:&quot;library_import&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/library_import.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;library_import_complete.png&quot;,&quot;basename&quot;:&quot;library_import_complete&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/library_import_complete.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;logo.svg&quot;,&quot;basename&quot;:&quot;logo&quot;,&quot;extname&quot;:&quot;.svg&quot;,&quot;path&quot;:&quot;/shared/images/logo.svg&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;map.png&quot;,&quot;basename&quot;:&quot;map&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/map.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;mum.png&quot;,&quot;basename&quot;:&quot;mum&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/mum.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;nih.png&quot;,&quot;basename&quot;:&quot;nih&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/nih.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;nsf.gif&quot;,&quot;basename&quot;:&quot;nsf&quot;,&quot;extname&quot;:&quot;.gif&quot;,&quot;path&quot;:&quot;/shared/images/nsf.gif&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;pA.png&quot;,&quot;basename&quot;:&quot;pA&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/pA.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;pAB.png&quot;,&quot;basename&quot;:&quot;pAB&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/pAB.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;pB.png&quot;,&quot;basename&quot;:&quot;pB&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/pB.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;p_val_hist.png&quot;,&quot;basename&quot;:&quot;p_val_hist&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/p_val_hist.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;pca.png&quot;,&quot;basename&quot;:&quot;pca&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/pca.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;pcr-duplicates.png&quot;,&quot;basename&quot;:&quot;pcr-duplicates&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/pcr-duplicates.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;phinch_overviewpage.png&quot;,&quot;basename&quot;:&quot;phinch_overviewpage&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/phinch_overviewpage.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;psu.png&quot;,&quot;basename&quot;:&quot;psu&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/psu.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;quasi_aln.png&quot;,&quot;basename&quot;:&quot;quasi_aln&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/quasi_aln.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;rename_history.png&quot;,&quot;basename&quot;:&quot;rename_history&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/rename_history.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;repo_organization.png&quot;,&quot;basename&quot;:&quot;repo_organization&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/repo_organization.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;repo_organization.svg&quot;,&quot;basename&quot;:&quot;repo_organization&quot;,&quot;extname&quot;:&quot;.svg&quot;,&quot;path&quot;:&quot;/shared/images/repo_organization.svg&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;rnaseq_comparison.png&quot;,&quot;basename&quot;:&quot;rnaseq_comparison&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/rnaseq_comparison.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;rnaseq_data_in_history.png&quot;,&quot;basename&quot;:&quot;rnaseq_data_in_history&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/rnaseq_data_in_history.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;rnaseq_library.png&quot;,&quot;basename&quot;:&quot;rnaseq_library&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/rnaseq_library.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;sa.png&quot;,&quot;basename&quot;:&quot;sa&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/sa.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;sailfish.png&quot;,&quot;basename&quot;:&quot;sailfish&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/sailfish.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;salmon.png&quot;,&quot;basename&quot;:&quot;salmon&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/salmon.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;sampling-bias.png&quot;,&quot;basename&quot;:&quot;sampling-bias&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/sampling-bias.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;sashimi.png&quot;,&quot;basename&quot;:&quot;sashimi&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/sashimi.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;search_index.png&quot;,&quot;basename&quot;:&quot;search_index&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/search_index.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;side-by-side.png&quot;,&quot;basename&quot;:&quot;side-by-side&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/side-by-side.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;snpeff.png&quot;,&quot;basename&quot;:&quot;snpeff&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/snpeff.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;snpeff_chart.png&quot;,&quot;basename&quot;:&quot;snpeff_chart&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/snpeff_chart.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;snpeff_codons.png&quot;,&quot;basename&quot;:&quot;snpeff_codons&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/snpeff_codons.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;sorted_list.png&quot;,&quot;basename&quot;:&quot;sorted_list&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/sorted_list.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;specificity.png&quot;,&quot;basename&quot;:&quot;specificity&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/specificity.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;star.png&quot;,&quot;basename&quot;:&quot;star&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/star.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;stranded_protocols.png&quot;,&quot;basename&quot;:&quot;stranded_protocols&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/stranded_protocols.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;stranded_result.png&quot;,&quot;basename&quot;:&quot;stranded_result&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/stranded_result.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;stringtie1.png&quot;,&quot;basename&quot;:&quot;stringtie1&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/stringtie1.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;stringtie2.png&quot;,&quot;basename&quot;:&quot;stringtie2&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/stringtie2.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;substring_trie.png&quot;,&quot;basename&quot;:&quot;substring_trie&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/substring_trie.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;suffix_tree_1.png&quot;,&quot;basename&quot;:&quot;suffix_tree_1&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/suffix_tree_1.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;suffix_tree_2.png&quot;,&quot;basename&quot;:&quot;suffix_tree_2&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/suffix_tree_2.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;suffix_tree_3.png&quot;,&quot;basename&quot;:&quot;suffix_tree_3&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/suffix_tree_3.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;suffix_tree_4.png&quot;,&quot;basename&quot;:&quot;suffix_tree_4&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/suffix_tree_4.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;suffix_tree_5.png&quot;,&quot;basename&quot;:&quot;suffix_tree_5&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/suffix_tree_5.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;suffix_trie_1.png&quot;,&quot;basename&quot;:&quot;suffix_trie_1&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/suffix_trie_1.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;suffix_trie_2.png&quot;,&quot;basename&quot;:&quot;suffix_trie_2&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/suffix_trie_2.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;suffix_trie_3.png&quot;,&quot;basename&quot;:&quot;suffix_trie_3&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/suffix_trie_3.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;suffix_trie_4.png&quot;,&quot;basename&quot;:&quot;suffix_trie_4&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/suffix_trie_4.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;suffix_trie_5.png&quot;,&quot;basename&quot;:&quot;suffix_trie_5&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/suffix_trie_5.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;suffix_trie_6.png&quot;,&quot;basename&quot;:&quot;suffix_trie_6&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/suffix_trie_6.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;suffix_trie_7.png&quot;,&quot;basename&quot;:&quot;suffix_trie_7&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/suffix_trie_7.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;suffix_trie_8.png&quot;,&quot;basename&quot;:&quot;suffix_trie_8&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/suffix_trie_8.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;suffix_trie_9.png&quot;,&quot;basename&quot;:&quot;suffix_trie_9&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/suffix_trie_9.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tools_collection_input.png&quot;,&quot;basename&quot;:&quot;tools_collection_input&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/tools_collection_input.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tophat.png&quot;,&quot;basename&quot;:&quot;tophat&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/tophat.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tophat2.png&quot;,&quot;basename&quot;:&quot;tophat2&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/tophat2.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tophat_interface.png&quot;,&quot;basename&quot;:&quot;tophat_interface&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/tophat_interface.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tophat_output.png&quot;,&quot;basename&quot;:&quot;tophat_output&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/tophat_output.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;training_infra.svg&quot;,&quot;basename&quot;:&quot;training_infra&quot;,&quot;extname&quot;:&quot;.svg&quot;,&quot;path&quot;:&quot;/shared/images/training_infra.svg&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;trie.png&quot;,&quot;basename&quot;:&quot;trie&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/trie.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;trie_no_end.png&quot;,&quot;basename&quot;:&quot;trie_no_end&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/trie_no_end.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial_footer.png&quot;,&quot;basename&quot;:&quot;tutorial_footer&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/tutorial_footer.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial_footer.svg&quot;,&quot;basename&quot;:&quot;tutorial_footer&quot;,&quot;extname&quot;:&quot;.svg&quot;,&quot;path&quot;:&quot;/shared/images/tutorial_footer.svg&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial_header.png&quot;,&quot;basename&quot;:&quot;tutorial_header&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/tutorial_header.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial_introduction.png&quot;,&quot;basename&quot;:&quot;tutorial_introduction&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/tutorial_introduction.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial_introduction.svg&quot;,&quot;basename&quot;:&quot;tutorial_introduction&quot;,&quot;extname&quot;:&quot;.svg&quot;,&quot;path&quot;:&quot;/shared/images/tutorial_introduction.svg&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial_part.png&quot;,&quot;basename&quot;:&quot;tutorial_part&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/tutorial_part.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial_part.svg&quot;,&quot;basename&quot;:&quot;tutorial_part&quot;,&quot;extname&quot;:&quot;.svg&quot;,&quot;path&quot;:&quot;/shared/images/tutorial_part.svg&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;ucsc_dm3.png&quot;,&quot;basename&quot;:&quot;ucsc_dm3&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/ucsc_dm3.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;unification_scheme.graphml&quot;,&quot;basename&quot;:&quot;unification_scheme&quot;,&quot;extname&quot;:&quot;.graphml&quot;,&quot;path&quot;:&quot;/shared/images/unification_scheme.graphml&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;unification_scheme.png&quot;,&quot;basename&quot;:&quot;unification_scheme&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/unification_scheme.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;vcfallelicprimitives.png&quot;,&quot;basename&quot;:&quot;vcfallelicprimitives&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/vcfallelicprimitives.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;vib_logo_white.svg&quot;,&quot;basename&quot;:&quot;vib_logo_white&quot;,&quot;extname&quot;:&quot;.svg&quot;,&quot;path&quot;:&quot;/shared/images/vib_logo_white.svg&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;viewatphinch.png&quot;,&quot;basename&quot;:&quot;viewatphinch&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/viewatphinch.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;we_need_you.jpg&quot;,&quot;basename&quot;:&quot;we_need_you&quot;,&quot;extname&quot;:&quot;.jpg&quot;,&quot;path&quot;:&quot;/shared/images/we_need_you.jpg&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;within_norm.png&quot;,&quot;basename&quot;:&quot;within_norm&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/within_norm.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;workflow_editor_mark_output.png&quot;,&quot;basename&quot;:&quot;workflow_editor_mark_output&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/workflow_editor_mark_output.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;workflow_editor_save.png&quot;,&quot;basename&quot;:&quot;workflow_editor_save&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/shared/images/workflow_editor_save.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;literature.md&quot;,&quot;basename&quot;:&quot;literature&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/shared/literature.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;add_custom_build.md&quot;,&quot;basename&quot;:&quot;add_custom_build&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/add_custom_build.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;add_tag.md&quot;,&quot;basename&quot;:&quot;add_tag&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/add_tag.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;ansible_local.md&quot;,&quot;basename&quot;:&quot;ansible_local&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/ansible_local.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;build_dataset_list.md&quot;,&quot;basename&quot;:&quot;build_dataset_list&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/build_dataset_list.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;build_list_collection.md&quot;,&quot;basename&quot;:&quot;build_list_collection&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/build_list_collection.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;change_datatype.md&quot;,&quot;basename&quot;:&quot;change_datatype&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/change_datatype.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;change_dbkey.md&quot;,&quot;basename&quot;:&quot;change_dbkey&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/change_dbkey.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;create_dataset_collection.md&quot;,&quot;basename&quot;:&quot;create_dataset_collection&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/create_dataset_collection.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;create_new_file.md&quot;,&quot;basename&quot;:&quot;create_new_file&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/create_new_file.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;create_new_history.md&quot;,&quot;basename&quot;:&quot;create_new_history&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/create_new_history.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;display_extra_training.md&quot;,&quot;basename&quot;:&quot;display_extra_training&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/display_extra_training.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;display_extra_training_slides.md&quot;,&quot;basename&quot;:&quot;display_extra_training_slides&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/display_extra_training_slides.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;extra_protein.md&quot;,&quot;basename&quot;:&quot;extra_protein&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/extra_protein.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;extract_workflow.md&quot;,&quot;basename&quot;:&quot;extract_workflow&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/extract_workflow.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;history_create_new.md&quot;,&quot;basename&quot;:&quot;history_create_new&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/history_create_new.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;import_from_data_library.md&quot;,&quot;basename&quot;:&quot;import_from_data_library&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/import_from_data_library.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;import_via_link.md&quot;,&quot;basename&quot;:&quot;import_via_link&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/import_via_link.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;import_workflow.md&quot;,&quot;basename&quot;:&quot;import_workflow&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/import_workflow.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;rename_dataset.md&quot;,&quot;basename&quot;:&quot;rename_dataset&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/rename_dataset.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;rename_history.md&quot;,&quot;basename&quot;:&quot;rename_history&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/rename_history.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;run_workflow.md&quot;,&quot;basename&quot;:&quot;run_workflow&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/run_workflow.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;select_collection.md&quot;,&quot;basename&quot;:&quot;select_collection&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/select_collection.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;select_multiple_datasets.md&quot;,&quot;basename&quot;:&quot;select_multiple_datasets&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/select_multiple_datasets.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;use_scratchbook.md&quot;,&quot;basename&quot;:&quot;use_scratchbook&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/use_scratchbook.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;warning_results_may_vary.md&quot;,&quot;basename&quot;:&quot;warning_results_may_vary&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/snippets/warning_results_may_vary.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;RNAseq_histiry_image.key&quot;,&quot;basename&quot;:&quot;RNAseq_histiry_image&quot;,&quot;extname&quot;:&quot;.key&quot;,&quot;path&quot;:&quot;/topics/R/images/RNAseq_histiry_image.key&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rarithmetic_operators.png&quot;,&quot;basename&quot;:&quot;Rarithmetic_operators&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/R/images/Rarithmetic_operators.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rautocompletion.png&quot;,&quot;basename&quot;:&quot;Rautocompletion&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/R/images/Rautocompletion.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rcomment_uncomment.png&quot;,&quot;basename&quot;:&quot;Rcomment_uncomment&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/R/images/Rcomment_uncomment.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rexport_plot.png&quot;,&quot;basename&quot;:&quot;Rexport_plot&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/R/images/Rexport_plot.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rfile_imported.png&quot;,&quot;basename&quot;:&quot;Rfile_imported&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/R/images/Rfile_imported.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rgeneral_functions.png&quot;,&quot;basename&quot;:&quot;Rgeneral_functions&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/R/images/Rgeneral_functions.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rinstall_zip.png&quot;,&quot;basename&quot;:&quot;Rinstall_zip&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/R/images/Rinstall_zip.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rlogic_operators.png&quot;,&quot;basename&quot;:&quot;Rlogic_operators&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/R/images/Rlogic_operators.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rnew_script.png&quot;,&quot;basename&quot;:&quot;Rnew_script&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/R/images/Rnew_script.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rrefresh_button.png&quot;,&quot;basename&quot;:&quot;Rrefresh_button&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/R/images/Rrefresh_button.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rsave_script.png&quot;,&quot;basename&quot;:&quot;Rsave_script&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/R/images/Rsave_script.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rsection_headings.png&quot;,&quot;basename&quot;:&quot;Rsection_headings&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/R/images/Rsection_headings.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rtable_function.png&quot;,&quot;basename&quot;:&quot;Rtable_function&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/R/images/Rtable_function.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rview_file.png&quot;,&quot;basename&quot;:&quot;Rview_file&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/R/images/Rview_file.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;index.html&quot;,&quot;basename&quot;:&quot;index&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/R/index.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial.html&quot;,&quot;basename&quot;:&quot;tutorial&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/R/tutorials/Functions/tutorial.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial.html&quot;,&quot;basename&quot;:&quot;tutorial&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/R/tutorials/Matrices_Dataframes_Lists/tutorial.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial.html&quot;,&quot;basename&quot;:&quot;tutorial&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/R/tutorials/Rbasics/tutorial.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial.html&quot;,&quot;basename&quot;:&quot;tutorial&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/R/tutorials/Reading_Writing/tutorial.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial.html&quot;,&quot;basename&quot;:&quot;tutorial&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/R/tutorials/Vectors_Factors/tutorial.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;index.html&quot;,&quot;basename&quot;:&quot;index&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/basic-bioinformatics/index.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial.html&quot;,&quot;basename&quot;:&quot;tutorial&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/basic-bioinformatics/tutorials/general-introduction/tutorial.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;assembly-general-introduction.ga&quot;,&quot;basename&quot;:&quot;assembly-general-introduction&quot;,&quot;extname&quot;:&quot;.ga&quot;,&quot;path&quot;:&quot;/topics/basic-bioinformatics/tutorials/general-introduction/workflows/assembly-general-introduction.ga&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;FunTopp_NF.png&quot;,&quot;basename&quot;:&quot;FunTopp_NF&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/functional_analysis/images/FunTopp_NF.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;FunTopp_Results.png&quot;,&quot;basename&quot;:&quot;FunTopp_Results&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/functional_analysis/images/FunTopp_Results.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;FunWebG_Results1.png&quot;,&quot;basename&quot;:&quot;FunWebG_Results1&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/functional_analysis/images/FunWebG_Results1.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;FunWebG_Results2.png&quot;,&quot;basename&quot;:&quot;FunWebG_Results2&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/functional_analysis/images/FunWebG_Results2.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;FungP_Interface.png&quot;,&quot;basename&quot;:&quot;FungP_Interface&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/functional_analysis/images/FungP_Interface.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;FungP_Ranked.png&quot;,&quot;basename&quot;:&quot;FungP_Ranked&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/functional_analysis/images/FungP_Ranked.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;FungP_Results.png&quot;,&quot;basename&quot;:&quot;FungP_Results&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/functional_analysis/images/FungP_Results.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;RNAseq_histiry_image.key&quot;,&quot;basename&quot;:&quot;RNAseq_histiry_image&quot;,&quot;extname&quot;:&quot;.key&quot;,&quot;path&quot;:&quot;/topics/metagenomics/images/RNAseq_histiry_image.key&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rarithmetic_operators.png&quot;,&quot;basename&quot;:&quot;Rarithmetic_operators&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/metagenomics/images/Rarithmetic_operators.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rautocompletion.png&quot;,&quot;basename&quot;:&quot;Rautocompletion&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/metagenomics/images/Rautocompletion.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rcomment_uncomment.png&quot;,&quot;basename&quot;:&quot;Rcomment_uncomment&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/metagenomics/images/Rcomment_uncomment.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rexport_plot.png&quot;,&quot;basename&quot;:&quot;Rexport_plot&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/metagenomics/images/Rexport_plot.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rfile_imported.png&quot;,&quot;basename&quot;:&quot;Rfile_imported&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/metagenomics/images/Rfile_imported.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rgeneral_functions.png&quot;,&quot;basename&quot;:&quot;Rgeneral_functions&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/metagenomics/images/Rgeneral_functions.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rinstall_zip.png&quot;,&quot;basename&quot;:&quot;Rinstall_zip&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/metagenomics/images/Rinstall_zip.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rlogic_operators.png&quot;,&quot;basename&quot;:&quot;Rlogic_operators&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/metagenomics/images/Rlogic_operators.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rnew_script.png&quot;,&quot;basename&quot;:&quot;Rnew_script&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/metagenomics/images/Rnew_script.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rrefresh_button.png&quot;,&quot;basename&quot;:&quot;Rrefresh_button&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/metagenomics/images/Rrefresh_button.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rsave_script.png&quot;,&quot;basename&quot;:&quot;Rsave_script&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/metagenomics/images/Rsave_script.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rsection_headings.png&quot;,&quot;basename&quot;:&quot;Rsection_headings&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/metagenomics/images/Rsection_headings.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rtable_function.png&quot;,&quot;basename&quot;:&quot;Rtable_function&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/metagenomics/images/Rtable_function.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Rview_file.png&quot;,&quot;basename&quot;:&quot;Rview_file&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/metagenomics/images/Rview_file.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;index.html&quot;,&quot;basename&quot;:&quot;index&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/metagenomics/index.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial.html&quot;,&quot;basename&quot;:&quot;tutorial&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/metagenomics/tutorials/Ecology_Analysis_using_vegan/tutorial.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial.html&quot;,&quot;basename&quot;:&quot;tutorial&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/metagenomics/tutorials/Introduction/tutorial.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial.html&quot;,&quot;basename&quot;:&quot;tutorial&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/metagenomics/tutorials/OTU_creation/tutorial.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Blastpdb.png&quot;,&quot;basename&quot;:&quot;Blastpdb&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Blastpdb.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Mol_desc_1DKX.png&quot;,&quot;basename&quot;:&quot;Mol_desc_1DKX&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Mol_desc_1DKX.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Pdb_expdetails_1dkx.png&quot;,&quot;basename&quot;:&quot;Pdb_expdetails_1dkx&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Pdb_expdetails_1dkx.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Pdb_firstresiduesmissing_1dkx.png&quot;,&quot;basename&quot;:&quot;Pdb_firstresiduesmissing_1dkx&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Pdb_firstresiduesmissing_1dkx.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Pdb_seqtab.png&quot;,&quot;basename&quot;:&quot;Pdb_seqtab&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Pdb_seqtab.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Pdbdownloadfile1.png&quot;,&quot;basename&quot;:&quot;Pdbdownloadfile1&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Pdbdownloadfile1.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Pdbsearchbox_RCSB.png&quot;,&quot;basename&quot;:&quot;Pdbsearchbox_RCSB&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Pdbsearchbox_RCSB.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Pdf_uniprotview_button.png&quot;,&quot;basename&quot;:&quot;Pdf_uniprotview_button&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Pdf_uniprotview_button.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Seqselector.png&quot;,&quot;basename&quot;:&quot;Seqselector&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Seqselector.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Training_1.png&quot;,&quot;basename&quot;:&quot;Training_1&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Training_1.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Training_10.png&quot;,&quot;basename&quot;:&quot;Training_10&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Training_10.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Training_11.png&quot;,&quot;basename&quot;:&quot;Training_11&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Training_11.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Training_12.png&quot;,&quot;basename&quot;:&quot;Training_12&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Training_12.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Training_2.png&quot;,&quot;basename&quot;:&quot;Training_2&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Training_2.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Training_3.png&quot;,&quot;basename&quot;:&quot;Training_3&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Training_3.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Training_4.png&quot;,&quot;basename&quot;:&quot;Training_4&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Training_4.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Training_5.png&quot;,&quot;basename&quot;:&quot;Training_5&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Training_5.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Training_6.png&quot;,&quot;basename&quot;:&quot;Training_6&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Training_6.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Training_7.png&quot;,&quot;basename&quot;:&quot;Training_7&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Training_7.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Training_8.png&quot;,&quot;basename&quot;:&quot;Training_8&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Training_8.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Training_9.png&quot;,&quot;basename&quot;:&quot;Training_9&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/Training_9.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;amino-acids.cdx&quot;,&quot;basename&quot;:&quot;amino-acids&quot;,&quot;extname&quot;:&quot;.cdx&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/amino-acids.cdx&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;amino-acids.png&quot;,&quot;basename&quot;:&quot;amino-acids&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/amino-acids.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;blastpdb.png&quot;,&quot;basename&quot;:&quot;blastpdb&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/blastpdb.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;diffraction-pattern.png&quot;,&quot;basename&quot;:&quot;diffraction-pattern&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/diffraction-pattern.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;electron-density.png&quot;,&quot;basename&quot;:&quot;electron-density&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/electron-density.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;hemoglobin.png&quot;,&quot;basename&quot;:&quot;hemoglobin&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/hemoglobin.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;nmr-model-example.png&quot;,&quot;basename&quot;:&quot;nmr-model-example&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/nmr-model-example.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;nmr-noe.jpg&quot;,&quot;basename&quot;:&quot;nmr-noe&quot;,&quot;extname&quot;:&quot;.jpg&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/nmr-noe.jpg&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;nmr-peaks-to-structure.png&quot;,&quot;basename&quot;:&quot;nmr-peaks-to-structure&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/nmr-peaks-to-structure.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;occupancy.png&quot;,&quot;basename&quot;:&quot;occupancy&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/occupancy.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;pdb-file-format.png&quot;,&quot;basename&quot;:&quot;pdb-file-format&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/pdb-file-format.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;pdb-logo.png&quot;,&quot;basename&quot;:&quot;pdb-logo&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/pdb-logo.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;pdbdownloadfile1.png&quot;,&quot;basename&quot;:&quot;pdbdownloadfile1&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/pdbdownloadfile1.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;pdbsearchbox_RCSB.png&quot;,&quot;basename&quot;:&quot;pdbsearchbox_RCSB&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/pdbsearchbox_RCSB.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;saxs.png&quot;,&quot;basename&quot;:&quot;saxs&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/saxs.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;uniprot-logo.png&quot;,&quot;basename&quot;:&quot;uniprot-logo&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/uniprot-logo.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;uniprotsearchbox.png&quot;,&quot;basename&quot;:&quot;uniprotsearchbox&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/uniprotsearchbox.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;wwpdb-welcome-page.png&quot;,&quot;basename&quot;:&quot;wwpdb-welcome-page&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/wwpdb-welcome-page.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;xray-tech-setup.png&quot;,&quot;basename&quot;:&quot;xray-tech-setup&quot;,&quot;extname&quot;:&quot;.png&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/images/xray-tech-setup.png&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;index.html&quot;,&quot;basename&quot;:&quot;index&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/index.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;Visualizing_protein_structures_with_YASARA_exercises.md&quot;,&quot;basename&quot;:&quot;Visualizing_protein_structures_with_YASARA_exercises&quot;,&quot;extname&quot;:&quot;.md&quot;,&quot;path&quot;:&quot;/topics/protein-structure-analysis/tutorials/visualise-structures/Visualizing_protein_structures_with_YASARA_exercises.md&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;index.html&quot;,&quot;basename&quot;:&quot;index&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/qbase-plus/index.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial.html&quot;,&quot;basename&quot;:&quot;tutorial&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/qbase-plus/tutorials/experiment-design/tutorial.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial.html&quot;,&quot;basename&quot;:&quot;tutorial&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/qbase-plus/tutorials/gene-expression/tutorial.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial.html&quot;,&quot;basename&quot;:&quot;tutorial&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/qbase-plus/tutorials/multiple-experiments/tutorial.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial.html&quot;,&quot;basename&quot;:&quot;tutorial&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/qbase-plus/tutorials/primer-design/tutorial.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial.html&quot;,&quot;basename&quot;:&quot;tutorial&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/qbase-plus/tutorials/qbaseplus-introduction/tutorial.html&quot;,&quot;collection&quot;:null},{&quot;modified_time&quot;:&quot;2019-12-19 11:52:41 -0600&quot;,&quot;name&quot;:&quot;tutorial.html&quot;,&quot;basename&quot;:&quot;tutorial&quot;,&quot;extname&quot;:&quot;.html&quot;,&quot;path&quot;:&quot;/topics/qbase-plus/tutorials/reference-genes/tutorial.html&quot;,&quot;collection&quot;:null}],&quot;html_pages&quot;:[&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;&lt;ol id=\&quot;markdown-toc\&quot;&gt;\n  &lt;li&gt;&lt;a href=\&quot;#overview-questions\&quot; id=\&quot;markdown-toc-overview-questions\&quot;&gt;Overview Questions&lt;/a&gt;    &lt;ol&gt;\n      &lt;li&gt;&lt;a href=\&quot;#what-is-this-website\&quot; id=\&quot;markdown-toc-what-is-this-website\&quot;&gt;What is this website?&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=\&quot;#what-are-the-tutorials-for\&quot; id=\&quot;markdown-toc-what-are-the-tutorials-for\&quot;&gt;What are the tutorials for?&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=\&quot;#what-audiences-are-the-tutorials-for\&quot; id=\&quot;markdown-toc-what-audiences-are-the-tutorials-for\&quot;&gt;What audiences are the tutorials for?&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=\&quot;#how-is-the-content-licensed\&quot; id=\&quot;markdown-toc-how-is-the-content-licensed\&quot;&gt;How is the content licensed?&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=\&quot;#how-can-i-advertise-the-training-materials-on-my-posters\&quot; id=\&quot;markdown-toc-how-can-i-advertise-the-training-materials-on-my-posters\&quot;&gt;How can I advertise the training materials on my posters?&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=\&quot;#how-do-i-use-this-material\&quot; id=\&quot;markdown-toc-how-do-i-use-this-material\&quot;&gt;How do I use this material?&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=\&quot;#how-can-i-get-help\&quot; id=\&quot;markdown-toc-how-can-i-get-help\&quot;&gt;How can I get help?&lt;/a&gt;&lt;/li&gt;\n    &lt;/ol&gt;\n  &lt;/li&gt;\n  &lt;li&gt;&lt;a href=\&quot;#for-instructors\&quot; id=\&quot;markdown-toc-for-instructors\&quot;&gt;For Instructors&lt;/a&gt;    &lt;ol&gt;\n      &lt;li&gt;&lt;a href=\&quot;#where-do-i-start\&quot; id=\&quot;markdown-toc-where-do-i-start\&quot;&gt;Where do I start?&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=\&quot;#how-can-i-fix-mistakes-or-expand-an-existing-tutorial-using-the-github-interface\&quot; id=\&quot;markdown-toc-how-can-i-fix-mistakes-or-expand-an-existing-tutorial-using-the-github-interface\&quot;&gt;How can I fix mistakes or expand an existing tutorial using the GitHub interface?&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=\&quot;#sustainability-of-the-training-material-and-metadata\&quot; id=\&quot;markdown-toc-sustainability-of-the-training-material-and-metadata\&quot;&gt;Sustainability of the training-material and metadata&lt;/a&gt;&lt;/li&gt;\n    &lt;/ol&gt;\n  &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1 id=\&quot;overview-questions\&quot;&gt;Overview Questions&lt;/h1&gt;\n\n&lt;h2 id=\&quot;what-is-this-website\&quot;&gt;What is this website?&lt;/h2&gt;\n\n&lt;p&gt;This website is a collection of hands-on tutorials that are designed to be interactive.&lt;/p&gt;\n\n&lt;p&gt;This material is developed and maintained by the &lt;a href=\&quot;https://www.bits.vib.be/\&quot;&gt;VIB Bioinformatics Core&lt;/a&gt;.&lt;/p&gt;\n\n&lt;h2 id=\&quot;what-are-the-tutorials-for\&quot;&gt;What are the tutorials for?&lt;/h2&gt;\n\n&lt;p&gt;These tutorials can be used for learning and teaching how for general data analysis, and for learning/teaching specific domains such as metagenomcis and differential gene expression analysis with RNA-Seq data.&lt;/p&gt;\n\n&lt;h2 id=\&quot;what-audiences-are-the-tutorials-for\&quot;&gt;What audiences are the tutorials for?&lt;/h2&gt;\n\n&lt;p&gt;There are two distinct audiences for these materials.&lt;/p&gt;\n\n&lt;ol&gt;\n  &lt;li&gt;&lt;strong&gt;Self-paced individual learners.&lt;/strong&gt; These tutorials provide everything you need to learn a topic, from explanations of concepts to detailed hands-on exercises.&lt;/li&gt;\n  &lt;li&gt;&lt;strong&gt;Instructors.&lt;/strong&gt; They are also designed to be used by instructors in teaching/training settings. Slides, and detailed tutorials are provided.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h2 id=\&quot;how-is-the-content-licensed\&quot;&gt;How is the content licensed?&lt;/h2&gt;\n\n&lt;p&gt;The content of this website is licensed under the &lt;a href=\&quot;https://creativecommons.org/licenses/by/4.0/\&quot;&gt;Creative Commons Attribution 4.0 License&lt;/a&gt;.&lt;/p&gt;\n\n&lt;h2 id=\&quot;how-can-i-advertise-the-training-materials-on-my-posters\&quot;&gt;How can I advertise the training materials on my posters?&lt;/h2&gt;\n\n&lt;p&gt;We provide some QR codes and logos in the &lt;a href=\&quot;https://github.com/vibbits/training-material/tree/master/assets/images\&quot;&gt;images folder&lt;/a&gt;.&lt;/p&gt;\n\n&lt;h2 id=\&quot;how-do-i-use-this-material\&quot;&gt;How do I use this material?&lt;/h2&gt;\n\n&lt;p&gt;Many topics include slide decks and if the topic you are interested in has slides then start there.  These will introduce the topic and important concepts.&lt;/p&gt;\n\n&lt;h2 id=\&quot;how-can-i-get-help\&quot;&gt;How can I get help?&lt;/h2&gt;\n\n&lt;p&gt;If you have questions about this training material, you can reach us sending an email to bits@vib.be.&lt;/p&gt;\n\n&lt;h1 id=\&quot;for-instructors\&quot;&gt;For Instructors&lt;/h1&gt;\n\n&lt;p&gt;This material can also be used to teach the content in a group setting to students and researchers.&lt;/p&gt;\n\n&lt;h2 id=\&quot;where-do-i-start\&quot;&gt;Where do I start?&lt;/h2&gt;\n\n&lt;p&gt;Spend some time exploring the different tutorials and the different resources that are available. Become familiar with the structure of the tutorials and think about how you might use them in your teaching.&lt;/p&gt;\n\n&lt;h2 id=\&quot;how-can-i-fix-mistakes-or-expand-an-existing-tutorial-using-the-github-interface\&quot;&gt;How can I fix mistakes or expand an existing tutorial using the GitHub interface?&lt;/h2&gt;\n\n&lt;p&gt;Please submit an issue via github.&lt;/p&gt;\n\n&lt;h2 id=\&quot;sustainability-of-the-training-material-and-metadata\&quot;&gt;Sustainability of the training-material and metadata&lt;/h2&gt;\n\n&lt;p&gt;This repository is hosted on &lt;a href=\&quot;https://github.com/\&quot;&gt;GitHub&lt;/a&gt; using git as a &lt;a href=\&quot;https://en.wikipedia.org/wiki/Distributed_version_control\&quot;&gt;DVCS&lt;/a&gt;. Therefore the community is hosting backups of this repository in a decentralised way. The repository is self-contained and contains all needed content and all metadata.&lt;/p&gt;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;### How to fill the slide decks?\n\nPlease follow our\n[tutorial to learn how to fill the slides](/topics/contributing/tutorials/create-new-tutorial-slides/slides.html)\n&quot;,&quot;### Protein Structure Analysis ###\n\n- Sequences, structures and databases\n- Experimental methods (X-rays, electrons and NMR)\n- Finding and visualising structures from the  Protein Data Bank\n- Comparing structures\n- Modelling mutations\n- Creating homology models\n\n---\n### Sequences and Structures ###\n\nadd one slide over transcription / translation / \n\n---\n\n### Amino acids and peptide structure\n\n![](/topics/protein-structure-analysis/images/amino-acids.png)\n\n---\n\n### The Structure-Function Connection ###\n\n.pull-left[\n- Folded proteins provide a well-defined 3D arrangement of functional groups, creating microenvironments and active sites.\n- Structural changes  are often involved in functional  mechanisms  (motor proteins, ...)\n]\n.image-90[![](/topics/protein-structure-analysis/images/hemoglobin.png)]\n\n\n---\n\n### Databases\n\n.pull-left[\n**Uniprot** approx. 1100,000 sequences\n\n- mainly determined by large-scale DNA sequencing of individual genes or whole genomes\n- increasingly automated annotation\n\n**Protein Data Bank** approx. 141,000 \nexperimentally determined structures\n\n- Mainly determined by X-ray crystallography and high-resolution NMR spectroscopy\n- Automation is increasing, but there are still significant limitations in the rate of solving new structures\n]\n\n\n]\n.pull-right[ .image-50[![](/topics/protein-structure-analysis/images/uniprot-logo.png)]\n             .image-50[![](/topics/protein-structure-analysis/images/pdb-logo.png)]\n]\n\n---\n\n### X-Ray Crystallography ###\n\n![](/topics/protein-structure-analysis/images/xray-tech-setup.png)\n\n.pull-left[\n\n.left[In a crystal, a large number  of macromolecules are  packed together in a regular grid, with consistent  orientations and relative  distances. \nWhen exposed  to an X-ray beam, this  arrangement gives rise to\ndiffracted rays in specific directions,  resulting in discrete spots on the planar\ndetector. By rotating the crystal, a series  of images is obtained. From these, the\nintensities of all the diffracted rays of the  crystal can be derived.]\n\n]\n.pull-right[ .image-90[![](/topics/protein-structure-analysis/images/diffraction-pattern.png)]\n]\n\n\n---\n\n### X-Ray Crystallography ###\n\n.pull-left[\n.image-50[![](/topics/protein-structure-analysis/images/diffraction-pattern.png)]\n]\n.pull-right[.image-50[![](/topics/protein-structure-analysis/images/electron-density.png)]]\n\n|              |          |               |\n|:-------------|:--------:|--------------:|\n| Diffraction Spot Intensities and Phases $$F_{obs}(h,k,l)$$ and $$\\phi_{obs}(h,k,l)$$ | $$R_{cryst} = \\frac{\\sum_{h,k,l}F_{obs}-F_{calc}}{\\sum_{h,k,l}F_{obs}}$$ | Electron density $$\\rho(x,y,z)$$ |\n\n\n---\n\n### The Protein Databank ###\n\n.pull-left[ .image-80[![](/topics/protein-structure-analysis/images/wwpdb-welcome-page.png)] \n\n\n.pull-right[ \n.left[ [http://www.wwpdb.org](http://www.wwpdb.org) ]\n- contains structures of  proteins, nucleic acids  and complexes,  determined by X-ray  crystallography, NMR  spectroscopy\n- No purely theoretical  or ab initio models  (since 2006)\n- Also stores supporting  experimental data\n- Full deposition now  required by all peer-reviewed journals\n]\n]\n\n---\n\n### Exercise 1: Search the PDB ###\n\n- Use the UniProt site to search for dnak.  \n- Use the PDB site to search for dnak.\n - Compare the UniProt and PDB result lists.\n- Use the sequence search function to see if there are structures with sequences similar to that of the  DnaK C-terminal domain.\n- Look at the summary pages of a number of  structures and note some interesting properties.\n- Select a number of structures and create a report  page.\n\n---\n\n### PDB File Format ###\n\n![](/topics/protein-structure-analysis/images/pdb-file-format.png)\n\n---\n\n### Occupancy ###\n\n![](/topics/protein-structure-analysis/images/occupancy.png)\n\n\n---\n\n### Related Web sites ###\n\n- Nucleic Acid Database: DNA and RNA structures\n\n.left[[http://ndbserver.rutgers.edu/](http://ndbserver.rutgers.edu/)]\n\n- PDB-REDO: automatically re-refined deposited  structures, using the latest methods\n\n.left[[http://www.cmbi.ru.nl/pdb_redo/](http://www.cmbi.ru.nl/pdb_redo)]\n\n- EBI: many online tools for structure analysis\n\n[http://www.ebi.ac.uk/Tools/structure/](http://www.ebi.ac.uk/Tools/structure/).left[]]\n\n- Replaced Electron Density Server: convenient overview of  quality parameters for crystal structures\n\n.left[[http://www.ebi.ac.uk/pdbe/litemol](http://www.ebi.ac.uk/pdbe/litemol)]\n\n---\n\n### High-Resolution NMR Spectrometry ###\n\n.left[Many atomic nuclei, including the ubiquitous hydrogen nuclei,  resonate at specific radio frequencies when placed in a  strong, uniform magnetic field. The chemical environment of each individual atom slightly modulates its exact resonance  frequency.]\n\n.image-80[![](/topics/protein-structure-analysis/images/nmr-peaks-to-structure.png)]\n\n.left[In macromolecules with thousands of atoms, many different  effects combine to generate an extremely complicated pattern of chemical shifts, \nwhich therefore more or less uniquely  identify each atom. Multidimensional spectra allow these  frequencies to be assigned to specific atoms.]\n---\n\n### High-Resolution NMR Spectroscopy ###\n\n.left[When two atoms are near each other in 3D space, they can exchange magnetization, giving rise to crosspeaks at the  intersection of their respective frequencies.]\n\n.image-50[![](/topics/protein-structure-analysis/images/nmr-noe.jpg)]\n\n.left[This nuclear Overhauser effect (NOE) is used to effectively measure the distances between pairs of atoms, at least  qualitatively.]\n\n---\n\n### High-Resolution NMR Spectroscopy ###\n\n.left[After identification of the atoms by means of their unique chemical shifts, distance restraints are derived from the  Overhauser crosspeaks. An extended model of the protein  is  generated,  \nand  then  condensed  into  a  shape  that  is consistent with as many of distance restraints as possible.]\n\n.image-50[![](/topics/protein-structure-analysis/images/nmr-model-example.png)]\n\n---\n\n### Other methods ###\n\n\n- Electron microscopy (and especially Cryo-electron microscopy): Electron crystallography and single particle reconstruction\r\n-Small-angle X-ray and neutron scattering (SAXS and SANS)\n\n\n.image-80[![](/topics/protein-structure-analysis/images/saxs.png)]\n\n---\n\n### Related Web sites ###\n\n- BioMagResBank: experimental data for NMR-  derived structures (lists of distance restraints  and other experimentally derived properties)\n\n.left[[http://www.bmrb.wisc.edu/](http://www.bmrb.wisc.edu/)]\n\n- BioIsis: database of SAXS-derived structures\n\n.left[[http://www.bioisis.net](http://www.bioisis.net)]\n\n- EMBL database of SAXS-derived structures\n\n.left[[http://www.sasbdb.org](http://www.sasbdb.org)]\n\n- EM Databank for cryo-EM structures\n\n[http://www.emdatabank.org](http://www.emdatabank.org.left[)]\n\n---\n\n### Assessing Structure Quality ###\n\nGeneral geometric properties (bond lengths and angles, Ramachandran distribution, ): MolProbity  [Link](http://molprobity.biochem.duke.edu/)\n\n.left[ **Crystal Structures** ]\n- Diffraction data resolution and completeness (PDB)\n- Final $$ R_{cryst} $$ and $$ R_{free} $$ factors (PDB)\n- Local correspondence to electron density (EDS)\n\n.left[**NMR Structures**]\n- Number of distance restraints and additional experimental data sources (BMRB)\n- Local restraint density (on-line NMR constraint analyser)\n[link](http://molsim.sci.univr.it/bioinfo/tools/constraint/index.html)\n\n.left[**Other techniques**]\n- Difficult to generalise: carefully read and consider the  published protocol\n\n---\n\n### Molecular Graphics Software ###\n\n- [PyMOL](http://www.pymol.org/): high-quality output,  good examples on [Wiki](http://www.pymolwiki.org/)\n- [Chimera](http://www.cgl.ucsf.edu/chimera/): good  documentation on website\n- [VMD](http://www.ks.uiuc.edu/Research/vmd/):  excellent for the analysis of MD trajectories\n- [Yasara](http://www.yasara.org)  \n- [SwissPDBViewer](http://spdbv.vital-it.ch/)\n\n---\n\n### YASARA ###\n\n.left[\nYasara View is freely available and provides  basic visualisation functions.\n\nYasara Model, Dynamics and Structure provide  additional functionality.\n\nAn add-on module for NMR structures is  available.\n\nThe program can be combined with the WHAT-  IF program for structure validation, and with  FoldX for energy calculations.]\n\n---\n\n### Exercise 2: show a structure ###\n\n.left[\nLoad PDB entry 1TRZ using the File menu.\n\nCompare the default representations (F1-F8)  and use the various controls to change the view  of the protein.\n\nExplore the Edit and View menus to change  various aspects of the graphical representation  of the structure.\n\nExamine the hydrogen bonding patterns.  Display a molecular surface.\n\nCreate an interesting view of the molecule and  save it as a high-resolution image.\n]\n---\n\n### Protein folds are the structures of domains ###\n\n.left[\nSimilarities in assembly of secondary structure elements\n\nSo not based on sequence like motifs but on 3D structure\n\nFolds represent the shapes of protein domains!\n]\n\nExamples: TODO (add images e.g. alpha solenoid, DNA clamp, thioredoxin fold)\n\n---\n\n### Databases of protein folds ###\n\n- SCOP (http://scop.mrc-lmb.cam.ac.uk/scop/)\n- CATH (http://www.cathdb.info/)\n\n\n---\n\n### check on slides from course Wim Vranken ###\n\nsee also (http://www.ii.uib.no/~slars/bioinfocourse/PDFs/structpred_tutorial.pdf)\n\n---\n\n### Structure Superposition ###\n\n.left[\nStructures can be superimposed to achieve the best  possible match between corresponding atoms. It is  possible to consider all atoms, or only a subset  (such as the C atoms).\n\nWhen the structures are very similar, determining  which atoms should be matched to each other is  trivial. When there are larger differences, it takes  more preparation.\n\nDifferent algorithms use different combinations of  sequence- and secondary of tertiary structure-based information.\n]\n\n---\n\n### Exercise 3: Compare Structures ###\n\n.left[\nDownload the five provided PDB files and open  them in Yasara.\n\nUse the `Analyze|Align|Objects` with MUSTANG  function to align the four last objects with the first one.\n\nUse the space bar to open the text console and  see the reported root mean square deviations as well as the number of residues matched.\n]\n\n$$ rmsd = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}R_{i}^{2}} $$ \n\n.left[\nColor all structures by B factor and compare the  distribution to the local variability of the structures.\n]\n---\n\n### PDB File Surprises ###\n\n- Missing atoms, residues and loops  \n- Multiple molecules in the asymmetric unit\n- Incomplete oligomers due to coincident crystal and  oligomer symmetry\n- C-only models  lternate conformations\n- Multiple models, especially for NMR ensembles\n- Use of B factors to represent other properties  ther non-standard extensions (PDBQT, ...)\n\n---\n\n### Force Fields ###\n\n- Energy terms representing physical interactions\n\n - Covalent bond lengths and angles\n - Dihedral angles and van der Waals forces (steric effects)\n - Electrostatic interactions and hydrogen bonds\n\n\n- Energy can be minimized, and forces can literally be derived from the potential function.\n\n- Consistency and careful consideration of the  properties to be simulated are essential.\n\n---\n\n### Force Field Terms ###\n\n.left[Each energy term has a functional form, which includes one or more parameters:]\n\n- Covalent bond energy term\n To do: add formula\n- Van der Waals contact energy term\n\n.left[The parameters are collectively optimized to  reproduce a chosen set of experimentally observed parameters.\n\nA given force field should be used as a  consistent system, and can only be used to predict properties that are covered by the  training set.\n]\n\n---\n\n### FoldX ###\n\n\n.left[\nIs designed for quantitative modelling of the contribution of structural interactions to the stability of proteins and protein complexes. It also supports  protein/DNA complexes.\n\nThe force field describes the different interactions in a  protein structure or complex in analytical terms. It has  been calibrated using a set of experimentally determined  stabilities.\n\nApplications include the optimisation of structures, the calculation of the stability of complexes, and predicting  the effect of amino-acid or base-pair mutations on these  properties.\n]\n\n---\n\n### The FoldX Plugin for Yasara\t###\n\n.left[\nIn order to make FoldX more accessible and  integrate its functions into Yasara, dr. Joost van  Durme (SWITCH laboratory) made a Yasara plugin  module that can apply FoldX functions to structures  that are loaded as Yasara objects.\n\nThis greatly simplifies the use of FoldX, and allows  for a quick visual analysis of the resulting changes  in the structures.\n\nMore information can be found at [wiki](http://foldxyasara.switchlab.org/index.php/) [FoldX](http://foldxsuite.crg.eu/)\n]\n\n---\n\n### Exercise 4a: Repair a PDB File ###\n\n- Load the 1CRN PDB file.\n- Use the Repair object option in the Analysis |  FoldX menu to activate the corresponding FoldX  function.\n- Select the object to repair.\n\n.left[This exports the object as a temporary PDB file,  starts FoldX with the appropriate options, and loads  the repaired PDB file as a new object in Yasara.]\n\n- Compare the original and repaired objects.  \n- Describe the changes that were introduced.\n\n---\n\n### Exercise 4b: Model a Mutation ###\n\n- Load the 2AC0.sce Yasara scene file.\n- Set an appropriate structure representation.\n- Locate residue Ala159 using the sequence view,  and right-click to access the `FoldX|Mutate` residue function. Change it to a Trp residue.\n- Look at the effect of the substitution on the  structure, and use the space bar to open the text  console and read the output of the FoldX  calculation.\n- Mutate Arg273 to an alanine side chain. Discuss  the effects of this substitution.\n\n---\n\n### Homology Modelling ###\n\n- When a structure is available for a protein with a  similar sequences, it is possible to predict the  structure of a new sequence with varying degrees of  confidence.\n- Use PSI-BLAST/DELTA-BLAST to detect sequences with similar structures.\n- All homology modelling procedures start from an  alignment of the template and target sequences.  The quality of this alignment will have a major  impact on the resulting model.\n- Available applications include stand-alone programs  (Modeller, FoldX, ) and web-based services (such as SwissModel).\n\n \n\n---\n\n### Exercise 5: Make a Homology  Model using Swiss Model ###\n\nsee []()\n\n---\n\n### Predict protein structures by fold recognition ###\n\n1. Search SCOP/CATH for protein with same fold and known 3D structure\n2. Align each amino acid of query sequence to a position in the template structure\n3. Evaluate how well the sequence fits the fold and select best-fit fold\n4. Build structural model of query based on alignment with selected fold\n\n- Phyre (http://www.sbg.bio.ic.ac.uk/phyre2/html/page.cgi?id=index)\n- HHpred (http://toolkit.lmb.uni-muenchen.de/hhpred)\n- DescFold (http://202.112.170.199/DescFold/)\n\n.left[Works because:\n- Number of different folds in nature is fairly small (approximately 1300)\n- 90% of new submissions in PDB have similar folds to those already in PDB\n- Not always accurate\n]\n\n---\n\n### Guidelines to improve fold recognition results ###\n\n- Run as many methods as you can\n- Run each method on many sequences from your homologous protein family\n- After all of these runs, build up a consensus picture of the likely fold\n- Compare function of your protein to function of the proteins with the likely fold\n- Compare secondary structure of your protein to that of the likely fold\n\n\n---\n\n### Similarity searches based on 3D structure ###\n\n.left[\nSimilarity on structural level: aligning 3D structures\n\nStructure of query protein is known and aligned to PDB structures\n- VAST+ (https://www.ncbi.nlm.nih.gov/Structure/vastplus/vastplus.cgi)\n- DALI (http://ekhidna.biocenter.helsinki.fi/dali_server/)\n\nCompare proteins with low sequence similarity:\nsimilar structure implies homology -&gt; same function\n\nCan help to find active sites\n]\n\n---\n\n### Exercise 6: Study Protein-Ligand Interactions ###\n\nsee []()\n\n---\n\n### On-Line References ###\n\n- Crystallography 101 (Bernhard Rupp):  (http://www.ruppweb.org/Xray/101index.html)\n- Protein NMR, A Practical Guide (Vicky Higman) (http://www.protein-nmr.org.uk/)\n- Model validation course  (http://xray.bmc.uu.se/gerard/embo2001/modval/index.html)\n- Assessing model quality (http://spdbv.vital-it.ch/TheMolecularLevel/ModQual/)\n\n- Lectures by Burkhard Rost on protein structure  prediction (https://www.youtube.com/channel/UCU6j8BG4RbEtTgyIZJ6Vpow)\n\n---\n&quot;,&quot;&quot;,&quot;.enlarge120[\n\n# ***De novo* Genome Assembly**\n\n]\n\n#### With thanks to T Seemann, D Bulach, I Cooke and Simon Gladman\n---\n.enlarge120[\n\n# ***De novo* assembly**\n\n]\n\n.pull-left[\n\n**The process of reconstructing the original DNA sequence from the fragment reads alone.**\n\n* Instinctively like a jigsaw puzzle\n\n  * Find reads which \&quot;fit together\&quot; (overlap)\n  * Could be missing pieces (sequencing bias)\n  * Some pieces will be dirty (sequencing errors)\n\n]\n\n.pull-right[ ![](../../images/Humpty.jpg) ]\n\n---\n\n# **Another View**\n\n![](../../images/newspaper.png)\n\n---\n\n# **Assembly: An Example**\n\n---\n\n# **A small \&quot;genome\&quot;**\n\n![](../../images/shakespear1.png)\n\n---\n\n# **Shakespearomics**\n\n![](../../images/shakespear2.png)\n\n---\n\n# **Shakespearomics**\n\n![](../../images/shakespear3.png)\n\n---\n\n# **Shakespearomics**\n\n![](../../images/shakespear4.png)\n\n---\n\n# **So far, so good!**\n\n---\n\n# **The Awful Truth**\n\n![](../../images/notsimply.png)\n\n## \&quot;Genome assembly is impossible.\&quot; - A/Prof. Mihai Pop\n\n---\n.enlarge120[\n\n# **Why is it so hard?**\n\n]\n\n.pull-left[\n* Millions of pieces\n  * Much, much shorter than the genome\n  * Lots of them look similar\n* Missing pieces\n  * Some parts can&#39;t be sequenced easily\n* Dirty Pieces\n  * Lots of errors in reads\n]\n\n.pull-right[ ![](../../images/worlds_hardest.png) ]\n\n---\n\n# **Assembly recipe**\n\n* Find all overlaps between reads\n  * Hmm, sounds like a lot of work..\n* Build a graph\n  * A picture of the read connections\n* Simplify the graph\n  * Sequencing errors will mess it up a lot\n* Traverse the graph\n  * Trace a sensible path to produce a consensus\n\n---\n\n![](../../images/olc_pic.png)\n\n---\n\n# **A more realistic graph**\n\n![](../../images/real_graph.png)\n\n---\n\n# .image-15[![](../../images/nofun.png)] **What ruins the graph?**\n\n* Read errors\n  * Introduces false edges and nodes\n\n* Non haploid organisms\n  * Heterozygosity causes lots of detours\n\n* Repeats\n  * If they are longer than the read length\n  * Causes nodes to be shared, locality confusion.\n\n---\n\n# **Repeats**\n\n---\n.enlarge120[\n# **What is a repeat?**\n]\n\n.pull-left[\n\n#### ***A segment of DNA which occurs more than once in the genome sequence***\n\n* Very common\n  * Transposons (self replicating genes)\n  * Satellites (repetitive adjacent patterns)\n  * Gene duplications (paralogs)\n\n]\n\n.pull-right[\n\n![](../../images/triplets.png)\n\n]\n\n---\n\n# **Effect on Assembly**\n\n![](../../images/repeat_effect.png)\n\n---\n.enlarge120[\n# **The law of repeats** .image-15[![](../../images/repeatafterme.png)]\n]\n\n## **It is impossible to resolve repeats of length S unless you have reads longer than S**\n\n## **It is impossible to resolve repeats of length S unless you have reads longer than S**\n\n---\n\n# **Scaffolding**\n\n---\n.enlarge120[\n# **Beyond contigs**\n]\n\n.pull-left[\n\nContig sizes are limited by:\n\n* the length of the repeats in your genome\n  * Can&#39;t change this\n\n\n* the length (or \&quot;span\&quot;) of the reads\n  * Use long read technology\n  * Use tricks with other technology\n\n]\n\n---\n.enlarge120[\n# **Types of reads**\n]\n\n.pull-left[.enlarge120[**Example fragment**]]\n\n\n.remark-code[.enlarge120[atcgtatgatcttgagattctctcttcccttatagctgctata]]\n\n.pull-left[.enlarge120[**\&quot;Single-end\&quot; read**]]\n\n\n.remark-code[.enlarge120[**atcgtatg**atcttgagattctctcttcccttatagctgctata]]\n\nsequence *one* end of the fragment\n\n.pull-left[.enlarge120[**\&quot;Paired-end\&quot; read**]]\n\n\n.remark-code[.enlarge120[**atcgtatg**atcttgagattctctcttcccttatag**ctgctata**]]\n\nsequence both ends of the same fragment\n\n**We can exploit this information!**\n---\n\n.enlarge120[# **Scaffolding**]\n\n* **Paired end reads**\n  * Known sequences at each end of fragment\n  * Roughly known fragment length\n\n* **Most ends will occur in same contig**\n\n* **Some will occur in different contigs**\n  * ***evidence that these contigs are linked***\n---\n\n.enlarge120[# **Contigs to Scaffolds**]\n\n![](../../images/scaffolding.png)\n\n---\n\n.enlarge120[# **Assessing assemblies**]\n\n* We desire\n  * Total length similar to genome size\n  * Fewer, larger contigs\n  * Correct contigs\n\n* Metrics\n  * No generally useful measure. (No real prior information)\n  * Longest contigs, total base pairs in contigs, **N50**, ...\n\n---\n\n.enlarge120[# **The \&quot;N50\&quot;**]\n\n.enlarge120[***The length of that contig from which 50% of the bases are in it and shorter contigs***]\n\n* Imagine we have 7 contigs with lengths:\n  * 1, 1, 3, 5, 8, 12, 20\n\n* Total\n  * 1+1+3+5+8+12+20 = 50\n\n* N50 is the \&quot;halfway sum\&quot; = 25\n  * 1+1+3+5+8+**12** = 30 (&gt;25) so **N50 is 12**\n\n---\n\n.enlarge120[# **2 levels of assembly**]\n\n* Draft assembly\n  * Will contain a number of non-linked scaffolds with gaps of unknown sequence\n  * Fairly easy to get to\n\n* Closed (finished) assembly\n  * One sequence for each chromosome\n  * Takes a **lot** more work\n  * Small genomes are becoming easier with long read tech\n  * Large genomes are the province of big consortia (e.g. Human Genome Consortium)\n\n---\n.enlarge120[# **How do I do it?**]\n---\n.enlarge120[\n# **Example**\n\n* Culture your bacterium\n\n\n* Extract your genomic DNA\n\n\n* Send it to your sequencing centre for Illumina sequencing\n  * 250bp paired end\n\n\n* Get back 2 files\n  * .remark-code[MRSA_R1.fastq.gz]\n  * .remark-code[MRSA_R2.fastq.gz]\n\n\n* ***Now what?***\n]\n\n---\n.enlarge120[# **Assembly tools**\n\n* **Genome**\n  * **Velvet, Velvet Optimizer, Spades,** Abyss, MIRA, Newbler, SGA, AllPaths, Ray, SOAPdenovo, ...\n\n\n* Meta-genome\n  * Meta Velvet, SGA, custom scripts + above\n\n\n* Transcriptome\n  * Trinity, Oases, Trans-abyss\n\n***And many, many others...***\n\n]\n\n---\n.enlarge120[\n# **Assembly Exercise #1**\n\n* We will do a simple assembly using **Velvet** in **Galaxy**\n* We can do a number of different assemblies and compare some assembly metrics.\n\n]\n&quot;,&quot;# Ecology Analysis using vegan \n{:.no_toc}\n\nIn this exercise we will look at a data matrix of 16S rRNA counts in 74 samples.\n\nThis dataset is the microbiota composition of 74 mice from 5 different mice strains. The original research aim was to define the effect that the mouse genome has on the microbiota and what the effect of living in the same cage would be. However, we found much stronger trends in the data, and these we will look at in this exercise.\n\nThe 454 data was already compiled into a matrix with genus abundance per sample in a previous step. This matrix is called a feature abundance matrix, or abundance matrix for short. We will do an ecology-oriented analysis of the data, in later steps also taking metadata (experimental, environmental or clinical data that was collected for each sample, independent of the DNA) into account. The aim of this tutorial is to get an idea of the very basic steps of ecological data analysis using the programming language R.\n\nThe gene abundance table (Genus.txt) can be found in the folder /home/VIBTrainingX/NGS/metagenomics/higherLvl folder on the server. Those who are working on their own laptop can download it [from the lotus website](http://psbweb05.psb.ugent.be/lotus/data/LotuStutorial.tar.gz).\n\n1. Set the folder with the provided files as your working directory in R using `setw`. This way required files can be easily loaded. To find out how to use this command, you can type ?setwd() to open the help. If there are other R-commands that you want to know more about, you can open the R-help for that command by entering in the R-prompt `?command`. This will be very useful when working with R, make sure to use this a lot as you can only learn more :o). \n\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 1 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to set the working directory in R \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; setwd(dir_to_data) \n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\n2. Load the provided data into the matrix M (Genus.txt, actual genus abundance data), using the read.delim command, saving the loaded table as `M`. Make sure, the row names are correctly read in. As R reads the matrix as an object of class data.frame, we convert M from a data.frame to a matrix `M=as.matrix(M)`. This is important for some of the following calculations, where we need a `matrix` class object. \n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 1 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to read in data as matrix ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # read in data as matrix\n&gt;  &gt; &gt; M = read.delim(file=\&quot;Genus.txt\&quot;,row.names=1)\n&gt;  &gt; &gt; M = as.matrix(M) \n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nThe matrix you loaded represents the number of 16S sequences assignable to each genus, which we could find in the samples. Also note that not all genera are real genera, but partly assigned unknown sequences. With these groups we do not know if this is a single genus or in fact several genera or in extreme cases even several classes, that just all fall under the same phylum tag. What are the advantages and disadvantages of keeping such undefined groups in the data?\nUse the function `edit(M)` to better view the abundance matrix.\n\n3. Lets look at some  basic features of the abundance matrix. The `summary(M)` command is a good start, but also look at total row and column counts (`colSums`, `rowSums` command). To see how the genera are distributed within each sample, we will plot a sample-wise density plot.We will be using a combination of the `density`, `lines` and `lapply` functions, to draw the densities of values found in each sample. Lets start with looking at the density of the first sample. In R you can access specific columns by writing the matrix coordinates in square brackets. For example `M[1,]` shows the first row of a matrix, `M[,7]` shows the 7th column etc:\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 3 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to estimate density of first sample ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # estimate density of first sample\n&gt;  &gt; &gt; densityOfSample1 = density(M[,1])\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\n\nLook at the object densityOfSample1 by simply entering the object name into the command prompt. Next try to visualize it with `plot(densityOfSample1)`. In this plot you see that most genera are at 0 abundance, some genera have an abundance &lt;10 and some rare genera actually occur with a higher frequency, one genus even having ~1100 16S reads assigned to it. Which genus is this?\n\nAlternatively you can also use the function `hist`, to plot a histogram of the abundances. Try to do this now.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 4 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to plot histogram of abundances ?\n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # plot histogram of abundances\n&gt;  &gt; &gt; hist(M[,1], nclass = 50)\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nWe can use the `apply` command, to apply the density command to every column of M, which will return a list of density objects. The second argument to the `apply` function is the `margin` and is set to 2, which tells the `apply` function that we want to work on columns (margin = 2) and not on rows (margin = 1). Save this into object  `S_densities`.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 5 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to estimate densities of all samples ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # estimate densities of all samples\n&gt;  &gt; &gt; S_densities = apply(M,2,density)\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\n\n\nTo plot this start with:\n```\n# open a new plot window and set range of x and y axis\nplot(1,1,type=\&quot;n\&quot;,ylim=c(0,3),xlim=c(0,5000)) \n```\n\nThis will open a new plotting window, already set to the range of x and y coordinates (xlim, ylim) we will need in this example. In this case we just want to plot a blank space, this is done with the `type=n` argument. Try to replace the argument by `type=p`, to actually see that point! S_densities is a list, so we use `lapply` (list apply), in combination with the `lines` function, try this now to plot all the density lines into the open plot window.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 6 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to plot density distributions of all samples ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # plot density distributions of all samples\n&gt;  &gt; &gt; lapply(S_densities,lines)\n&gt; &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\n\nWhat you should see now in the plot window is the density distribution of all samples. The lines function is adding new lines, while a plot function makes a completely new plot. Try to replace the `lines` with `plot` to see this (its very fast, so keep a close eye on your plot). How are these lines already telling us something about the differences between the communities of each sample?\n\n4. Maybe you noticed that the `colSums` command showed that the totals are not equal. What does this mean? In this state the data is actually not comparable among each other. One way to `correct` the data for this shortcoming is to normalize the matrix. In this step we will normalize the abundance matrix into variable M1: \n\n```\n# normalize matrix: divide each column by the total of that column\nM1 = sweep(M,2,colSums(M),\&quot;/\&quot;)\n```\n\nThe `sweep` command is extremely useful, as it will apply a simple arithmetic operation (like divide) in a matrix column- or row-wise with a vector of your choice. So it is very similar to `apply`, but takes more basic functions. In this case we will divide each column by the sum of the column, this is called normalization.\n\nNow we will compare these matrices using the `barplot` function. For this we need to open another graphical window, using the `X11` function:\n```\n# create barplot of original and normalized data\nbarplot(M)\nX11()\nbarplot(M1)\n```\n\nWhat do you notice about the sample composition? What does the graph mean? Discuss where you would want to normalize the data (and where not).\n\nClose all open plots.\n\nNow replot the sample-wise density plot (as you did in step 3), but start the plot with these adapted x and y ranges. Additionally we will this time label the x- and y-axis:\n\n```\n# open a new plot and define ranges and titles of x and y axis\nplot(1,1,type=\&quot;n\&quot;,ylim=c(0,80),xlim=c(0,1),xlab=\&quot;relative genus abundance\&quot;, ylab=\&quot;Frequency of genera\&quot;) \n``` \n\nYou will notice that the graph looks different from you previous plot. What changed due to the normalization? Are the samples more similar to each other using M or M1? \n\nIf you spot a difference in species abundance between two samples using matrix M, is this difference real, does it have scientific value?\n\nFor the next step the R-library vegan is required. It is a set of functions specifically designed for ecological data analysis. The package has been installed on the bits laptops. If you were to install the package, you could do so using the command: `install.packages(vegan)`. More details on the [vegan web site ](http://cc.oulu.fi/~jarioksa/softhelp/vegan.html). Load vegan, using the `library` command.\n\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 7 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to load the vegan package ?\n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # load vegan package\n&gt;  &gt; &gt; library(vegan)\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\n\nLets try to put the differences we observed in sample density into numbers. To do this, ecologists rely on the concept of diversity. Diversity describes the evenness of species distributions as well as the richness of species that are observed in a given ecological system. We will first calculate the Shannon diversity, using vegans `diversity` command. Try to do this per sample, using the `apply` function again. Save the result in object `div`.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 8 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to calculate Shannon diversity index for each sample using the normalized data ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # calculate Shannon diversity index for each sample using the normalized data \n&gt;  &gt; &gt; div = apply(M1,2,diversity,index=\&quot;shannon\&quot;)\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nNow we can see in action what these indices are actually doing for us. Plot the density of the sample with the lowest and highest diversity in red and blue on your previous density plot of M1, this you do by first finding out which diversity indexes are the maximum and minimum values using the `which.max` and `which.min` functions on the object `div`. Dont forget to have the last density plot still open (or replot it from step 4 on M1), than add the lowest samples as a blue line and the highest sample as a red line, using the `lines` command. \n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 9 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; Find samples with lowest and highest Shannon diversity index and add them to the density plot ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # find samples with lowest and highest Shannon diversity index and add them to the density plot\n&gt;  &gt; &gt; which.min(div) #should be bl16\n&gt;  &gt; &gt; which.max(div) #should be bl48\n&gt;  &gt; &gt; lines(density(M1[,\&quot;bl16\&quot;],adjust =0.5),col=\&quot;blue\&quot;)\n&gt;  &gt; &gt; lines(density(M1[,\&quot;bl48\&quot;],adjust =0.5),col=\&quot;red\&quot;)&amp;\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nYou can now readjust the window by changing the `ylim` and `xlim` attribute in the plot function, if necessary (tip, try to rerun using `ylim=c(0,180)`). Try to explain why the colored samples have the highest &amp; lowest diversity. What does this tell about an ecosystem (remember that these are genus abundances).\nRaise your hand if you reached this step.\n\nA different way to normalize the data is to sample exactly equal amounts of 16S rDNA for each sample in this experiment. Of course in practice this is impossible to do, but we can simulate this, by randomly selecting a subset of 16S rDNA. This is called rarefaction. Rarefy your original abundance matrix (M) into M2, using 1000 reads per sample, using the `rrarefy` function of vegan. Note that you need to transpose (command `t()`) the matrix, before giving it to `rrarefy`. Transform the matrix back and save it as `M2`.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 10 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to normalize via rarefaction ?\n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # Alternative way of normalization\n&gt;  &gt; &gt; M2 = t(rrarefy(t(M),sample=2000))  #vegan needs transformed matrix, and we need it back-transformed\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nUse `colSums(M2)` to check if the rarefaction worked. The main use of rarefaction is in calculating diversity and richness correctly, for this we will look in the following step at observed richness.\n\nThe concept of observed richness within a sample is pretty simple (but useful): richness describes the number of different species that occur at least once in a sample. This can be calculated in two steps:\n\n```\n# Species present in sample: TRUE or 1 if species is present, FALSE or 0 if species is absent\nOnceOrMoreOftenPresent = M1&gt;0\n``` \n\nThe sum of each column in this matrix will tell us how many species were detected in total within the respective sample, use the `apply` and `sum` functions , saving the result in `rich1`.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 11 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to calculate the sum of each column ?\n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # Calculate sum of each column\n&gt;  &gt; &gt; rich1 = apply(OnceOrMoreOftenPresent,2,sum)\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\n\nCompare the richness values in `rich1` to the richness obtained on the rarefied matrix `M2`, calculated with a shortened command:\n\n```\n# Calculate number of present species in each sample using the rarefied data\nrich2 = apply(M2&gt;0,2,sum)\n``` \n\nCompare rich1 and rich2 in a matrix value by value. We use the `cbind` command to bind two vectors column wise together, so we get a matrix with 2 columns. Order this matrix by the richness values in rich1, using the `order` command and accessing the vector representation with `[]` square brackets.\n\n```\n# Create new matrix with two columns: rich1 and rich2 and order rows according to rich1 values\ncbind(rich1,rich2)[order(rich1),]\n```\n\nWhat does the second part of the formula do? What happens if you change that to order(rich2)?\n\nDiscuss which richness values have the highest value to the researcher and why the order is very different between these two richness estimates. Is one way clearly wrong?\n\nWhy did we choose 1000 as cutoff for the sequences per sample? What is the maximum value we could choose? \n\nFirst samples are clustered to see underlying data structures. For this tutorial we will choose a hierarchical clustering, based on a bray-curtis distance between samples, using the function `vegdist`. Make  sure the distances are calculated between Samples and not Genera.\n\nNext, use the function `hclust` on the distance matrix, saving the output in variable `cluster`, and subsequently plot the clustering of the samples (using `plot`).\nTake a guess of how many groups there might be in this clustering?\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 11 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to cluster samples and plot results ?\n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # cluster samples and plot results\n&gt;  &gt; &gt; BCD = vegdist(t(M1), dist=\&quot;bray\&quot;)\n&gt;  &gt; &gt; cluster = hclust(BCD)\n&gt;  &gt; &gt; plot(cluster)\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nTo visualize the samples and their relatedness to each other in a two-dimensional space, we can use an ordination to visualize the data in a low dimensional space. The dimensionality of the original matrix (73 genera=73 dimensions) is reduced to two dimensions. If you know what a PCA (Principal component analysis) is, this step will use a conceptually similar, but methodologically quite different technique to perform an ordination of the data, NMDS (non-metric multidimensional scaling).\n\nStart by calculating a 2-dimensional NMDS of the data using M1, using the Bray-Curtis distance in the function `metaMDS`, saving the result to `nmds`. Again, make sure that samples are being ordinated and not Genera.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 11 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to calculate the NMDS ?\n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # calculate NMDS\n&gt;  &gt; &gt; nmds = metaMDS(t(M1),distance = \&quot;bray\&quot;) #actual NMDS command, matrix needs to be transformed to conform with vegans standards\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nTake a look at the `nmds` object and explore some of its features (e.g. type `str(nmds)` to see what variables are stored within the NMDS object). Try to find out what the `stress` of your ordination is. What does stress stand for (tip: go to the R help on metaMDS)? Next we can visualize the NMDS, similar to what you get out of PCAs, displaying samples only:\n```\n# plot NMDS\nplot(nmds,display =\&quot;sites\&quot;)\n```\n\nThe important difference of NMDS compared to PCA is, that NMDS works with any kind of distance metric, while PCA can only use Euclidean distances between samples. A second important feature of NMDS is, that this method finds non-parametric, monotonic relationships between objects; in short: it doesnt assume a specific data distribution. Why might these two features be important for ecologists? \n\nYou might have noticed that you see two clusters, similar to the hierarchical clustering of the data. We can get for each sample the identity within the two clusters using the `cutree` commands, specifying k=2 (2 clusters). This can be plotted into the NMDS with the following command:\n\n```\n# identify clusters\nmemb = cutree(cluster, k = 2)\nordispider(nmds,memb)\n```\n\nCongratulations, you have just visualized the mouse enterotypes. Next we are going to look closer at these. If you want to know the exact methods to detect enterotypes in your data visit [http://enterotype.embl.de/enterotypes.html http://enterotype.embl.de/enterotypes.html]\n\nIn the last step, we will test for all the genera in the matrix whether they show significant differences between two clusters. The scientific question we are posing here is: what are the significant differences in the gut microbiota of between enterotypes? We will use a non-parametric test (kruskal-wallis) to do the tests, as ecological data is in most cases not normally distributed. This test is very similar to the student t-test, and the interpretation works just the same way. Use the function `kruskal.test` to test the first genera (M[1,]) for significant differences between the two cluster groups (in object `memb`). Save the output of this command in variable `Kt`.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 12 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to test if there is a difference between the two clusters for the first genus ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # Test if there is a difference between the two clusters for the first genus\n&gt;  &gt; &gt; Kt = kruskal.test(M1[1,],memb)\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\n\nLook at the output of this function. This will show you a human readable summary of the test and the result. You can access elements of a list (`Kt` is a list in this case) using the `$` operator. Try to extract the p-value from the `Kt` object.\n\nOnce you know how, we can start to calculate the significance for every genus in the M1 matrix,. These p-values we will store in a newly created vector `pvals`. Lets add the first 2 p-values to the vector:\n\n```\n# Test if there is a difference between the two clusters for the first and second genera. Store p-values in a vector.\npvals = c()\npvals[1] = kruskal.test(M1[1,], memb)$p.value\npvals[2] = kruskal.test(M1[2,], memb)$p.value\n```\n\nSince doing this 73 times takes a long time, we will be using a for-loop to `loop` over the matrix and do this for us. We could as well use the apply function, but the syntax would get a little more complicated, since we are only interested in a subpart of the result, the $p.value part. Try to write a for-loop, to calculate the p-value 73 times.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 13 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to test if there is a difference between the two clusters for all genera ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # Test if there is a difference between the two clusters for all genera\n&gt;  &gt; &gt; for (i in 1:dim(M1)[1])\n&gt;  &gt; &gt; {\n&gt;  &gt; &gt;         pvals[i] = kruskal.test(M1[i,], memb)$p.value\n&gt;  &gt; &gt; }\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nAs an additional help, you can add the name of the taxa to the pvals vector using the names command (that will name a vector):\n\n```\n# Add names to the vector\nnames(pvals) = dimnames(M1)[[1]] \n```\n\nWhich taxa are significantly different?\n\nIn this case we will use the normalized M1 matrix, can you explain why we do not use the M or M2 matrix? Would either be wrong to use?\n\nIn total we were testing in 73 genera, if their p-value was below a threshold of 0.05. What is the chance of observing data with a p-value &gt;0.05 by random chance? How many genera do you expect to be below this threshold by random chance? \n\nTo avoid statistical errors of this kind, we will use a Benjamini-Hochberg multiple testing correction, implemented in the R function `p.adjust`. Save the result as `qvals`.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 14 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to perform multiple testing correction of p-values using Benjamini-Hochberg method ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # Multiple testing correction of p-values using Benjamini-Hochberg method\n&gt;  &gt; &gt; qvals = p.adjust(pvals,method =\&quot;hochberg\&quot;)\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nWhat do you see in this test? What would you report on this dataset, based on these values?\n\nTry sorting the q-values to see the most significant differences first:\n```\n# Sorting q-values\nsort(qvals)\n```\n\nNow that you have finished the tutorials, you should be able to analyze any new dataset of amplicon data, using the LotuS pipeline and performing a basic analysis with R, including\n* Data normalization\n* Clustering analysis\n* Ordination\n* Univariate statistics\nYou can always expand upon these concepts, using this tutorial as starting point. Just remember that R is a very flexible language, and all these commands can be expanded for new purposes and visualizations.\n\n### Data sources\nAll the material provided in this tutorial are from metagenomic study on mice knockouts. Further analysis of the data can be found in the reference below.\n\n### Reference \n\nHildebrand, F., Nguyen, A. T. L., Brinkman, B., Yunta, R. G., Cauwe, B., Vandenabeele, P.,  Raes, J. (2013). Inflammation-associated enterotypes, host genotype, cage and inter-individual effects drive gut microbiota variation in common laboratory mice. Genome Biology, 14(1), R4. doi:10.1186/gb-2013-14-1-r4\n\n&quot;,&quot;# Manipulation of variables \n{:.no_toc}\n\n### General functions\nThe big difference between R and other programming languages is that functions in R are designed to be applied to variables rather than to individual values to avoid loops e.g. if we want to log transform a whole dataset we can do this using a single operation:\n```\n&gt; v &lt;- c(1,10,100,1000,10000)\n&gt; log10(v)\n[1] 0 1 2 3 4\n```\nThe log10() function is written in such a way that it can be applied on a vector. This is true for all functions and operators in R:\n```\n&gt; v - 1\n[1] 0     9    99   999  9999\n```\nR has built-in functions for virtually any standard mathematical task.\n \n&lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../../images/Rgeneral_functions.png\&quot; alt=\&quot;general_functions\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; Overview of built-in functions&lt;/figcaption&gt;&lt;/figure&gt;\n\nArithmetic operators can be used on variables. Provided that the variables have the same dimensions, you can do element-wise addition, subtraction, multiplication and division of two vectors or tables. Element-wise means that the calculation is performed on the equivalent positions between the two variables: first element + first element, second element + second element etc.\n\n```\n&gt; v1&lt;-c(1,2,3)\n&gt; v2&lt;-c(4,5,6)\n&gt; z&lt;-v1+v2\n&gt; z\n[1] 5 7 9\n```\n\nIf you perform operations on vectors with different lengths (not recommended) then the vector with the shorter length is recycled to the length of the longer vector so that the first element of the shorter vector is appended to the end of that vector (a way of faking that it is of equal length to the longer vector) and so forth. You will get a warning, but R does let you perform the operation:  \n\n```\n&gt; x1 &lt;- c(1,2,3)\n&gt; x2 &lt;- c(3,4)\n&gt; x3 &lt;- x1 + x2\nWarning message: \nIn x1 + x2:\n  longer object length is not aa multiple of shorter object length\n&gt; x3\n[1] 4 6 6\n```\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Operations on variables** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 13a\n&gt;\n&gt; 1. Calculate log base2 of the activity in Drug_study\n&gt; 2. Round the result to the nearest integer\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  log.act &lt;- (log2(Drug_study$activity))\n&gt;    &gt;  round(log.act)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 13b\n&gt;\n&gt; 1. Create vector v as the sum of newVector and threes using an arithmetic operator \n&gt; 2. Print the content of v\n&gt; 3. Do the same for newVector and vector x2 with elements 3,1\n&gt; 4. Join the elements of newVector and threes into 1 vector q\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  v &lt;- newVector + threes\n&gt;    &gt;  v\n&gt;    &gt;  x2 &lt;- c(3,1)\n&gt;    &gt;  newVector + x2 \n&gt;    &gt;   q &lt;- c(newVector,threes)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 13c\n&gt;\n&gt; 1. Add a column called geneDensity to genomeSize containing the number of bp per gene for every organism \n&gt; 2. Round the numbers to the nearest integer\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  dens.fl &lt;- genomeSize$size / genomeSize$geneCount\n&gt;    &gt;  genomeSize$geneDensity &lt;- round(dens.fl)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\nSome functions only work on vectors. For instance sort() will sort data from smallest to largest (arguments allow other ordering) and order() returns the indices of the sorted elements:\n```\nx\n[1] 1 3 11 1 7\nsort(x)\n[1] 1 1 3 7 11\norder(x)\n[1] 1 4 2 5 3\n```\nIn the sorted vector the first element is also the first element of the original vector, the second element of the sorted vector has index 4 in the original vector etc.\nTo sort a data frame use order() inside square brackets:\n```\nmtcars[order(mtcars$mpg),]\n```\nTo sort on two columns (first on mpg, then on cyl): \n```\nmtcars[order(mtcars$mpg,mtcars$wt),]\n```\nTo sort in descending order place a minus sign in front of the variable:\n```\nmtcars[order(mtcars$mpg,-mtcars$wt),]\n```\n\nSelect the **labels** of a vector or table using names(). For tables rownames() and colnames() can access or set the either row or the column labels. Both functions will not work on vectors. \n\nThe length() function retrieves the number of elements of a vector. Used on data frames it doesn&#39;t throw an error but returns the number of columns instead. \n\nThe same is true for match(x,y). It compares x and y and returns a vector with the same length as x containing: \n-  NA for elements of x that are not in y  \n- the index in y for elements in x that are in y\n\nOn data frames it will not do an element-wise comparison but a column-wise comparison: \n```\nmatch(D1,D2) \n```\nwill return a vector with length equal to the number of columns in D1 containing:\n- NA for columns of D1 that are not in D2\n- the index in D2 for columns in D1 that are in D2 (so the complete column has to match, not the individual elements)\n\nImportant is to see the difference between the + operator and sum(). The former works element-wise on two variables, the latter calculates the sum of all elements of one vector.\n\nThere are also functions to be used only on tables, e.g. \n- dim() returns how many rows and columns a table has, nrow() and ncol() will get these values individually\n- t() transposes matrices (exchanges rows and columns), the output is a transposed matrix: the columns are the rows of the original matrix and vice versa\n\nUse merge() to join two data frames. Let?s say D1 has a column A with values. Data frame D2 has the same values stored in column A. Merge the two data frames on the basis of this common column:\n```\nnewD &lt;- merge(D1,D2)\n```\nIf (some of) the values of the common column differ, merge() will ignore these values. Use argument *all.x* to add an extra row for every different value to the resulting data frame. All rows where the values of the two data frames don?t correspond, will be filled up with NA values.\n\nMost functions operate on numbers but there are also functions for manipulating text, e.g. \n```\npaste(x,y,sep=\&quot; \&quot;) \n```\t\nconcatenates two strings x and y (glues them together into one string) separating them by the character defined by *sep*. Arguments *x* and *y* can be strings but they can also be vectors. If they are vectors, they are concatenated element-wise to give a character vector result.\n\nFurthermore there are also functions specific for factors. For instance to select the names of the categories (levels) of a factor use levels() and table() to create a contingency table. \n```\n table(cell_phone_data$own, cell_phone_data$grade)\n```\n\n&lt;figure id=\&quot;figure-2\&quot;&gt;&lt;img src=\&quot;../../images/Rtable_function.png\&quot; alt=\&quot;table_function\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 2:&lt;/span&gt; Example of a contingency table&lt;/figcaption&gt;&lt;/figure&gt;\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 13d\n&gt;\n&gt; You repeat the plant study experiment this time having the following numbers of plants developing lesions: 1, 6, 6, 5, 4\n&gt; 1. Add these data as a third column to the data frame \n&gt; 2. Relabel columns to Day, Infected and Repeat\n&gt; 3. Use paste() to add the word ?day? to the elements of the Day column. Look at the documentation first !\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  Plant_study$repeated &lt;- c(1,6,6,5,4)\n&gt;    &gt;  names(Plant_study) &lt;- c(\&quot;Day\&quot;,\&quot;Infected\&quot;,\&quot;Repeat\&quot;)\n&gt;    &gt;  ?paste\n&gt;    &gt;  Plant_study$Day &lt;- paste(Plant_study$Day,\&quot;day\&quot;,sep=\&quot;\&quot;)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt;  ```\n&gt;    &gt;  paste(Plant_study[,\&quot;Day\&quot;],\&quot;day\&quot;,sep=\&quot;\&quot;)\n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 13e\n&gt;\n&gt; 1. Change the label of the second column of Drug_study to drug\n&gt; 2. How many rows does Drug_study contain?\n&gt; 3. Order the rows according to decreasing activity\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  colnames(Drug_study)[2] &lt;- \&quot;drug\&quot;\n&gt;    &gt;  nrow(Drug_study)\n&gt;    &gt;  Drug_study[order(Drug_study$activity,decreasing=TRUE),]\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What happens when you run this code ?\n&gt;    &gt;  ```\n&gt;    &gt;  colnames(Drug_study$ID) &lt;- \&quot;id\&quot;\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What happens when you run this code ?\n&gt;    &gt;  ```\n&gt;    &gt;  colnames(Drug_study[2]) &lt;- \&quot;blabla\&quot;\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt;  ```\n&gt;    &gt;  Drug_study[order(Drug_study$activity),\&quot;ID\&quot;]\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt;  ```\n&gt;    &gt;  n &lt;- order(Drug_study$activity,decreasing=TRUE)\n&gt;    &gt;  Drug_study[n,]\n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 13f\n&gt;\n&gt; 1. Sort the elements of z from smallest to largest\n&gt; 2. Now use order(z). What&#39;s the difference with the previous exercise?\n&gt; 3. How many elements does z contain?\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  sort(z)\n&gt;    &gt;  order(z)\n&gt;    &gt;  length(z) \n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 13g\n&gt;\n&gt; Add a new row to data frame ab containing values: 3,4,7\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  d &lt;- c(3,4,7)\n&gt;    &gt;  ab &lt;- rbind(ab,d)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 13h\n&gt;\n&gt; 1. How many rows and columns are in the built-in data frame CO2 (data on CO2 uptake by plants)\n&gt; 2. Use levels() to retrieve the names of the Treatment categories\n&gt; 3. Create a contingency table with counts (number of plants) in every category of CO2 that is defined by Type and Treatment\n&gt; 4. Use unique() to count how many plants were studied\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  dim(CO2)\n&gt;    &gt;  levels(CO2$Treatment)\n&gt;    &gt;  table(CO2$Type,CO2$Treatment)\n&gt;    &gt;  length(unique(CO2$Plant))\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n### Functions helpful for working with large data sets\nResearch in biology/medicine often generates very large data sets. When you work with very large data sets, it is often useful to show only a small part of the data set;\n- head() shows the first 6 elements (vector) or rows (table) of a variable \n- tail() prints the last 6 elements or rows\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 14a\n&gt;\n&gt; 1. View the first 6 rows of the mtcars data frame\n&gt; 2. Return TRUE if mtcars contains cars with 6 gears and FALSE if not\n&gt; 3. How many cars with 3 gears are in mtcars?\n&gt; &gt;   &gt; ### {% icon solution %} Solution\n&gt; &gt;   &gt;  ```\n&gt; &gt;   &gt;  head(mtcars)\n&gt; &gt;   &gt;  nrow(subset(mtcars,gear==6))!=0\n&gt; &gt;   &gt;  nrow(subset(mtcars,gear==3))\n&gt; &gt;   &gt;  ```\n&gt; &gt;   {: .solution}\n{: .hands_on}\n\n### Functions for finding indices of specific elements\nThere are functions that help you locate specific values, the which functions:\n```\nwhich.min(x)\nwhich.max(x)\n```\nreturn the location (index) of the minimum, maximum or a specific value of a vector x. So max() will return the highest value in the data, which.max() will return the index of the highest value in the data.\n\nThe argument of which() is a logical expression and which() will return the indices of the elements for which the logical expression is TRUE. \n```\nx &lt;- c(1,5,8,4,6)\nx\n# [1] 1 5 8 4 6\nwhich(x == 5)\n# [1] 2\nwhich(x != 5)\n# [1] 1 3 4 5\n```\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 15a\n&gt;\n&gt; Get the data of the patient with the highest activity in Drug_study\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  Drug_study[which.max(Drug_study$activity),]\n&gt;    &gt;  \n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  n &lt;- which.max(Drug_study$activity)\n&gt;    &gt;  Drug_study[n,]\n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 15b\n&gt;\n&gt; 1. Get the index of the column called cyl in mtcars\n&gt; 2. Create a data frame that contains the car with the lowest mpg for each category of cyl\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  which(names(mtcars)==\&quot;cyl\&quot;)\n&gt;    &gt;  C4m &lt;- mtcars[order(mtcars$cyl,mtcars$mpg),][1,]\n&gt;    &gt;  C6 &lt;- subset(mtcars,cyl==6)\n&gt;    &gt;  C6m &lt;- C6[which.min(C6$mpg),]\n&gt;    &gt;  C8m &lt;- mtcars[order(-mtcars$cyl,mtcars$mpg),][1,]\n&gt;    &gt;  rbind(C4m,C6m,C8m)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n### Checking and converting types of variables\nTo check the data structure of an object you can use str() and the generic class() function:\n```\nclass(c(10,12,30))\n# [1] \&quot;numeric\&quot;\nclass(c(\&quot;alana\&quot;,\&quot;britt\&quot;,\&quot;chris\&quot;))\n# [1] \&quot;character\&quot;\nclass(c(TRUE,TRUE,FALSE))\n# [1] \&quot;logical\&quot;\n```\n\nYou can also use the specific is. functions e.g. is.numeric(), is.character(), is.Date(), is.vector(), is.matrix(), is.data.frame() etc.\n\nThe is.na(x) function returns TRUE when an element of x is missing:\n```\nx &lt;- c(1,2,3,NA)\nis.na(x)\n# [1] FALSE FALSE FALSE TRUE\n```\nTo recode values to missing values you don?t need is.na(). Select the rows that contain the value you want to recode, e.g. 99, and change the value using an assignment:\n```\ndata$v1[data$v1==99] &lt;- NA\n```\nTo exclude missing values you can use is.na() but there are alternatives. The problem with missing values is that when you apply arithmetic functions on variables that contain missing values they will return missing values and you will have no result. To circumvent this problem many functions have the *na.rm* argument. If you set *na.rm=TRUE* missing values are deleted before calculations are done.\n```\nmean(x) \t\t\t\n# NA\nmean(x,na.rm=TRUE) \t\n# 2\n```\nThe function na.omit() allows to create a new vector without missing values. If you apply this function on a data frame it will remove complete rows that contain one or more NA-values.\n```\nnewdata &lt;- na.omit(x)\n```\nYou can convert the data type of an object by using the as. functions e.g. as.numeric(), as.character(), as.Date(), as.vector(), as.matrix(),\nas.data.frame() etc.\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Checking and converting data types** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 16a\n&gt;\n&gt; We created a vector containing the days of the week and loaded this into a data frame called Plant_study. If we want to replace the days of the week by real dates, how should we proceed?\n&gt; \n&gt; To create a Date object in R:\n&gt; - define the date as a string in the following format: 1970-01-01\n&gt; - transform the string into a date by using as.Date()\n&gt; 1. Replace the days of the week by the dates of this week\n&gt; 2. What type of data is Plant_study ?\n&gt; 3. Convert Plant_study into a matrix called PS\n&gt; 4. Did the conversion work? Look at the matrix to see if there is a problem. \n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  Plant_study$Days &lt;- as.Date(c(\&quot;2019-01-09\&quot;,\&quot;2019-01-10\&quot;,\&quot;2019-01-11\&quot;,\&quot;2019-01-12\&quot;,\&quot;2019-01-13\&quot;))\n&gt;    &gt;  class(Plant_study)\n&gt;    &gt;  PS &lt;- as.matrix(Plant_study)\n&gt;    &gt;  PS\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 16b\n&gt;\n&gt; 1. Check the data type of the second column of Drug_study. Retrieve the column using a comma.\n&gt; 2. Convert the second column into a vector. \n&gt; 3. What is different now? Look at the vector.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  class(Drug_study[,2])\n&gt;    &gt;  v &lt;- as.vector(Drug_study[,2])\n&gt;    &gt;  v\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 16c\n&gt;\n&gt; Instead of deleting missing values with na.omit() you can select the non-missing values.\n&gt; 1. Create a vector with a missing value \n&gt; 2. Multiply all elements with 2. What happens?\n&gt; 3. Check if the 2nd element is missing\n&gt; 4. Delete the missing value using is.na() and the strategy above\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  x &lt;- c(1,2,3,NA)\n&gt;    &gt;  x*2\n&gt;    &gt;  is.na(x[2])\n&gt;    &gt;  x[!is.na(x)]\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 16d\n&gt;\n&gt; 1. Check if z is a vector or a data frame \n&gt; 2. Check if z contains numbers or characters\n&gt; 3. Convert z into a matrix\n&gt; 4. Convert the elements of z into characters\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  is.vector(z)\n&gt;    &gt;  is.data.frame(z) \n&gt;    &gt;  is.character(z)\n&gt;    &gt;  is.numeric(z)\n&gt;    &gt;  as.matrix(z) \n&gt;    &gt;  as.character(z)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 16e\n&gt;\n&gt; 1. Create a vector called words containing Hello, Hi \n&gt; 2. Convert the words into numbers. What happens?\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  words &lt;- c(\&quot;Hello\&quot;,\&quot;Hi\&quot;)\n&gt;    &gt;  as.numeric(words) \n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\nR is smart enough to catch you if you try to do an illogical conversion, such as convert characters to numbers. It does the conversion but the data is converted to NA values.\n&quot;,&quot;# Data structures in R\n{:.no_toc}\n\nThe power of R lies not in its ability to work with simple numbers but in its ability to work with large datasets.  R has a wide variety of data structures including scalars, vectors, matrices, data frames, and lists.\n\n### Matrices\nA matrix is a table, the columns are vectors of equal length. \nAll columns in a matrix must contain the same type of data. The top row, called the header, contains column labels. Rows can also have labels. Data values are called elements. Indices are often used as column and row labels.\n\n### Creating a matrix\nTo create a matrix M use the matrix() function\n```\nM &lt;- matrix(data,nrow=r,ncol=c,byrow=FALSE))\n```\n\nIt takes a long list of arguments:\n- *data* usually is a vector of elements to will fill the matrix\n- *nrow* and *ncol*: dimensions (number of rows and columns). Only one dimension argument is needed. If there are 20 elements in the *data* vector and *ncol=4* then R will automatically calculate that there should be 5 rows. \n- *byrow*: how the matrix is filled, *byrow=TRUE* fills the matrix row by row whereas *byrow=FALSE* fills the matrix column by column\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Data creation: matrices** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 8a\n&gt;\n&gt; 1. Create a 2x2 matrix named mat containing numbers 2,3,1,5\n&gt; 2. Print the matrix\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  mat&lt;-matrix(c(2,3,1,5),nrow=2,ncol=2)\n&gt;    &gt;  mat\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 8b\n&gt;\n&gt; 1. Create a 2x3 matrix named onemat consisting of all ones\n&gt; 2. Print the matrix\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  onemat&lt;-matrix(1,nrow=2,ncol=3)\n&gt;    &gt;  onemat\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 8c\n&gt;\n&gt; 1. Create a 3x3 matrix containing numbers 1,2,3,4,5,6,7 \n&gt; 2. Retrieve all elements that are larger than 3\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  m &lt;- matrix(c(1,2,3,4,5,6,7),ncol=3) \n&gt;    &gt;  m[m &gt; 3]\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n### Data frames\nJust like a matrix, a data frame is a table where each column is a vector. But a data frame is more general than a matrix: they are used when columns contain different data types, while matrices are used when all data is of the same type. \n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; R has a number of built-in data frames like mtcars. \n{: .comment}\n\n### Creating a data frame\nTo create a data frame D use the function data.frame() with the vectors we want to use as columns:\n```\nD &lt;- data.frame(column1,column2,column3)\n```\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; The columns of a data frame are all of equal length\n{: .comment}\n\nYou can provide names (labels) for the columns:\n```\nD &lt;- data.frame(label1=column1,label2=column2,label3=column3)\n```\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; As an argument of data.frame() you use label=vector_to_add: the equals (and not the assignment) operator is used because you are naming columns not creating new variables. \nIf you don&#39;t define labels (as in the first example), the names of the vector names are used as column names. \n{: .comment}\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Data creation: data frames** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 9a\n&gt;\n&gt; Create a data frame called Plant_study containing days and Plants_with_lesions. Name the columns Days and Plants.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  Plant_study &lt;- data.frame(Days=days,Plants=Plants_with_lesions)\n&gt;    &gt;  Plant_study\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 9b\n&gt;\n&gt; Create a data frame called Drug_study consisting of three columns: ID, treatment and smoking\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  Drug_study &lt;- data.frame(ID,treatment,smoking)\n&gt;    &gt;  Drug_study\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 9c\n&gt;\n&gt; Create a data frame genomeSize containing genome sizes and print it. \n&gt; - The first column is called organism and contains Human,Mouse,Fruit Fly, Roundworm,Yeast \n&gt; - The second column size contains 3000000000,3000000000,135600000,97000000,12100000\n&gt; - The third column geneCount contains 30000,30000,13061,19099,6034\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  organism &lt;- c(\&quot;Human\&quot;,\&quot;Mouse\&quot;,\&quot;Fruit Fly\&quot;, \&quot;Roundworm\&quot;,\&quot;Yeast\&quot;)\n&gt;    &gt;  size &lt;- c(3000000000,3000000000,135600000,97000000,12100000)\n&gt;    &gt;  geneCount &lt;- c(30000,30000,13061,19099,6034) \n&gt;    &gt;  genomeSize &lt;- data.frame(organism,size,geneCount)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 9d\n&gt;\n&gt; Create a data frame ab and print it. \n&gt; - The first column is called a and contains 1,3,2,1\n&gt; - The second column is called b and contains 2,3,4,1\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  a &lt;- c(1,3,2,1)\n&gt;    &gt;  b &lt;- c(2,3,4,1)\n&gt;    &gt;  ab &lt;- data.frame(a,b)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n##### Referring to the elements of a data frame\nReferring to elements of a data frame can be done in the same way as for matrices, using row and column **indices** in between square brackets. The only difference is that in data frames you can also use the **labels** of the columns to retrieve them.\n\nTo retrieve the element on the second row, first column:\n```\nD[2,1]\n```\n\nTo select all values from one dimension leave the index blank, e.g. all elements of the first column:\n```\nD[,1]\n```\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; If you want to retrieve **all** the rows you don?t write any index before the comma inside the square brackets.\n{: .comment}\n\nYou can also use column labels for retrieving elements. Column names have to be written between quotes:\n```\nD[,\&quot;label1\&quot;]\n```\n\nYou can also use the range function to select elements:\n```\nD[2:4,1]\n```\n\nThe **$** symbol can be used to retrieve a column based on its label e.g. to retrieve column label1 from D:\n```\nD$label1\n```\n\n&gt; ### {% icon comment %} Comment\n&gt; With $ you do not have to put quotes around the column name\n{: .comment}\n\nSince the result of $ is a vector, you can address a specific element of a column using its index:\n```\nD$label1[2]\n```\nretrieves the second element of the column called label1\n\nSpecific for data frames is the **subset()** function that can be used to select columns that satisfy a logical operation:\n```\nsubset(D,select=columns to extract)\nsubset(D,logical expression,columns to extract)\n```\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Data extraction: data frames** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 10a\n&gt;\n&gt; 1. Retrieve the data for the Volvo 142E from mtcars \n&gt; 2. Retrieve the gas usage (mpg column) for the Volvo 142E \n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  mtcars[\&quot;Volvo 142E\&quot;,]\n&gt;    &gt;  mtcars[\&quot;Volvo 142E\&quot;,\&quot;mpg\&quot;]\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  mtcars[\&quot;Volvo 142E\&quot;]\n&gt;    &gt;  \n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ##### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  mtcars[Volvo 142E,]\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 10b\n&gt;\n&gt; 1. Retrieve the IDs of the smoking patients in Drug_study\n&gt; 2. Retrieve ID and treatment of the smoking patients \n&gt; 3. Retrieve the smoking behavior of all the patients\n&gt; 4. Change the treatment of the fourth patient to A\n&gt; 5. Add a column called activity with values: 4, NA, 12.1, 2.5\n&gt; 6. Use subset() to retrieve the full ID and treatment columns\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  subset(Drug_study,smoking==TRUE,ID)\n&gt;    &gt;  subset(Drug_study,smoking==TRUE,c(ID,treament))\n&gt;    &gt;  Drug_study$smoking\n&gt;    &gt;  Drug_study$treatment[4] &lt;- \&quot;A\&quot;\n&gt;    &gt;  Drug_study$activity &lt;- c(4,NA,12.1,2.5)\n&gt;    &gt;  subset(Drug_study,select=c(ID,treatment))\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  Drug_study[Drug_study$smoking==TRUE,\&quot;ID\&quot;]\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  Drug_study[Drug_study$smoking==TRUE,ID]\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  Drug_study[,\&quot;smoking\&quot;]\n&gt;    &gt;  \n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ##### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt;  ```\n&gt;    &gt;  Drug_study[4,\&quot;treatment\&quot;] &lt;- \&quot;B\&quot;\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  Drug_study[\&quot;activity\&quot;] &lt;- c(4,NA,12.1,2.5)\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  subset(Drug_study,c(ID,treatment))\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  subset(Drug_study,,c(ID,treatment))\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; The order of the arguments is important except when you specify their names. \n{: .comment}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 10c\n&gt;\n&gt; On which days did we observe more than 2 infected plants in the plant experiment? Answer this question with and without using the subset() function.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  &gt; Plant_study[Plant_study$Plants &gt; 2,\&quot;Days\&quot;]\n&gt;    &gt;  &gt; subset(Plant_study,Plants &gt; 2,Days)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  Plant_study[Plant_study[\&quot;Plants\&quot;] &gt; 2,\&quot;Days\&quot;]\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 10d\n&gt;\n&gt; 1. Create vector q by extracting the a column of data frame ab (exercise 9) with and without subset().\n&gt; 2. Retrieve the second element of column a of data frame ab\n&gt; 3. Add column c with elements 2,1,4,7 to data frame ab\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  q &lt;- ab$a\n&gt;    &gt;  subset(q,select=a)\n&gt;    &gt;  ab$a[2]\n&gt;    &gt;  ab$c &lt;- c(2,1,4,7)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n##### Removing elements from a data frame\nTo remove elements from a data frame use negative indices just as in a vector e.g. to remove the second row from data frame D use:\n```\nD &lt;- D[-2,]\n```\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; The minus sign only works with numbers not with column labels. \n{: .comment}\n\nTo remove columns based on labels assign them to NULL:\n```\nD$genome &lt;- NULL\n```\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; Setting a column to NULL is done via an assignment so the removal is permanent. \n{: .comment}\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; Insteading of removing elements you can also define the elements you want to keep.\n{: .comment}\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Data removal: data frames** section\n{: .hands_on}\n\n##### Reordering columns in a data frame\nReordering columns is a special case of retrieving columns, e.g. for a data frame that has 4 columns you can switch the position of the second and third column as follows:\n```\nD2 &lt;- D[ ,c(1,3,2,4)]\n```\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; The first comma means keep all the rows, and the 1,3,2,4 refer to column indices. \n&gt; You can use indices or labels to refer to the columns. \n{: .comment}\n\nYou can also use subset():\n```\nD2 &lt;- subset(D,select=c(1,3,2,4))\n```\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Column reordering: data frames** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 11a\n&gt;\n&gt; Switch the position of the second and the third column of Drug_study\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  Drug_study[,c(1,3,2)]\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  subset(Drug_study,select=c(1,3,2))\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n### Lists\nA list is an ordered collection of objects (of any data type: string, numbers, vectors, matrices, data frames). Lists can even contain other lists as objects! A list allows you to gather a variety of objects under one name. It is not mandatory but very useful to give each object in a list a label.\n\n##### Creating a list\nTo create a list L use the list() function:\n```\nL &lt;- list(label1=object1,label2=object2,label3=object3)\n```\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 12a\n&gt;\n&gt; 1. Create a list called myList with the following objects: 5, 6, the word seven, the matrix mat.\n&gt; 2. Print the list.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  myList&lt;-list(5,6,\&quot;seven\&quot;,mat)\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  subset(Drug_study,select=c(1,3,2))\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n##### Referring to the elements of a list\nReferring to the elements of a list can be done in exactly the same way as for data frames, using row and column **indices or labels** in between square brackets. However, since a list can contain other lists or data frames you have to use **double square brackets** [[ ]] to retrieve elements. \n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; The $ operator also works to access the objects of a list.\n{: .comment}\n&quot;,&quot;### Exercise 1: simple gene expression study\n\nIn my qPCR experiment I want to study the expression of 12 genes of interest in 8 samples of interest. I want to use 2 PCR replicates for each reaction.\n\n&gt; How many 96 well plates do I need for this experiment ?\n&gt; &gt; I have 12 genes in 8 samples which gives a total of 96 reactions (one plate). I want to perform each reaction twice (2 PCR replicates) so I need two plates. However, I need to include reference genes in my experiment, preferably more than one. I can put these reference genes on a separate plate, I do not have to include them on each plate.\nIdeally, you need to include 3 reference genes so having 8 samples and 2 replicates this gives an additional 48 reactions. Thus, I need three 96 well plates to perform this experiment.\n\n| Do I need to include IRCs (inter-run calibrators) ?                      |\n| :--------------------------------------------------- |\n| No, I can easily fit all samples of the same gene on the same plate so I don&#39;t need to include IRCs. |\n\n### Exercise 2: a large study\n\nIn my qPCR experiment I want to study the pattern of expression of 96 genes (genes of interest and reference genes) in 96 samples of interest, divided into a few groups. I want to use 2 PCR replicates for each reaction.\n\n| Do I need to include IRCs (inter-run calibrators) ?                    |\n| :------------------------------------------------------- |\n| No, I can fit all samples of the same gene on the same plate so I don&#39;t need to include IRCs. |\n\nI want to include PCR replicates.\n\n| Do I need to include IRCs when I work on a 96 well plate ?                                                                                    |\n| :-------------------------------------------------------------------------------------------------------------------------------------------- |\n| Yes, I have 192 reactions per gene so I cannot place them on the same plate. Remember that replicates have to be located on the same plate \\! |\n\n| Do I need to include IRCs when I work on a 384 well plate ?                        |\n| :--------------------------------------------------------------------------------- |\n| No, I have 192 reactions per gene so I can even place two genes on the same plate. |\n\nI want to include no template controls but I don&#39;t want to increase the\nnumber of plates.\n\n| What is the most elegant strategy to make room for including negative controls ?      |                                                      \n| :------------------------------------------------------------------------------------ |\n| This kind of study screen for expression patterns and requires statistical analysis. Since you have many samples divided over a few groups it means you have many biological replicates so you could easily do without the PCR replicates. By doing so you preserve the biological variability which is often far greater than the technical variation. |\n\n### Exercise 3: how to fill plates ?\n\nIn my qPCR experiment I want to study the pattern of expression of 5 genes (genes of interest and reference genes) in 38 samples (samples of interest and control samples). I want to use 2 PCR replicates for each reaction.\n\n| What is the minimum number of 96 well plates I need for this experiment ? |\n| :------------------------------ |\n| 5 genes * 38 samples * 2 replicates = 380 reactions.\nI need a minimum of 4 plates for this experiment.\n\n| If I use the minimum number of 96 well plates do I need to include IRCs ?                                                      |\n| :----------------------------------------------------------------------------------------------------------------------------- |\n| Yes, 5 genes spread over 4 plates with 72 reactions per gene means that at least one gene will be spread over multiple plates. |\n\n| What can I do to avoid inter-run variability ?                                                                                                                                                                                         |\n| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| I can use 5 plates and fill them with one gene each. They will not be completely filled (72 reactions) but at least I do not have to use IRCs (which are additional reactions that also cost money) and I have no inter-run variation. |\n\nSuppose there&#39;s only one 96-well plate left in your lab. You have 10 samples (samples of interest + control samples) and you want to make the most of what you have.\n\n| How many genes of interest would you measure ? |\n| :------------------------------ |\n| Since you want to make most of what you have, let&#39;s assume you are omitting PCR replicates.\nTheoretically, you could fit 9 genes on your 96-well plate. However, to avoid pipetting mistakes I would measure only 8 genes so I can work with one row / gene. This is very handy for multichannel pipets.\n\n### Exercise 4: a growing study\n\nIn my qPCR experiment I want to study the pattern of expression of 24 genes (genes of interest and reference genes) in 48 samples (samples of interest and control samples). I want to use 2 PCR replicates for each reaction.\n\n| How many genes can I analyze on one 384 well plate ? |\n| :------------------------------ |\n| 48 samples * 2 replicates = 96 reactions per gene.\nI can analyze 4 genes on each 384 well plate.\n\nEach week I receive 2 additional samples to analyze.\n\n| Do I analyze them immediately after I get them ? |\n| :------------------------------ |\n| No. Since the samples are placed on different plates as in the previous experiment, you have to use IRCs. You typically need 3 IRCs and a no template control sample. It means that if you want to analyze these 2 samples you have to include 4 additional samples for each gene. This is a lot of overhead for just 2 samples !\nTry to avoid this: it&#39;s better to wait a few weeks until you have 6 or 8 or even more samples.\n\n### Exercise 5: a diagnostic copy number screen\n\nIn diagnostic screens all samples are important: you cannot leave out samples and all measurements need to be of the highest quality possible. In my qPCR experiment I want to study copy number variation of 16 genes\n(genes of interest and reference genes) and 2 calibrator samples (samples with known copy number). Since we need high quality data we will use 4 technical replicates.\n\n| Are we going to use sample maximization ?                                   |                   \n| :------------------------------------------------------------------------- |\n| No. In contrast to gene expression studies, where we want to compare expression levels of a gene between different groups of samples, copy number analyses do compare genes. It means that in this case the sample maximization approach (placing all samples of the same gene on the same plate) is not valid. Instead we use a gene maximization approach here (placing same sample for different genes on the same plate). |\n\n| How many samples can I fit on a 384 well plate ? |\n| :------------------------------ |\n| We have 16 (genes) * 4 (replicates) = 64 reactions per sample.\nThis means that we can fit 6 samples on a 384 well plate: 4 unknowns and 2 calibrators.\n\n### Exercise 6: fix experiments with bad or missing data\n\nIn my qPCR experiment I want to study gene expression of 6 genes (3 genes of interest and 3 reference genes) in 20 samples (samples of interest and control samples). I want to use 2 technical replicates. One of my genes of interest failed completely and I want to repeat the measurements for this gene in a new run.\n\n| Do I need to include IRCs ?                                                                                |\n| :--------------------------------------------------------------------------------------------------------- |\n| No. We can put the 20 samples of the gene that failed on a single plate so we do not have to include IRCs. |\n\n| Do I need to include reference genes ?                                                                 |\n| :----------------------------------------------------------------------------------------------------- |\n| No. We just repeat all samples for the gene that failed and replace the old data with the new results. |\n\nOne of the reference genes failed completely.\n\n| What should I do ?                                                                                                                                                                                                                                                                                     |\n| :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Depending on the quality of the two remaining reference genes, you should either do nothing or do the same as in the previous example where one of your genes of interest failed. If the two remaining reference genes are stable you can do the normalization with the two remaining reference genes. |\n\nThree samples failed completely.\n\n| What&#39;s the first thing I need to do ?                                                                                                                             |\n| :---------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Since they failed completely, they are probably of low quality. Therefore, you have to prepare the samples again, check their quality and then use them for qPCR. |\n\n| Do I need to include IRCs ?                                                                                             |\n| :---------------------------------------------------------------------------------------------------------------------- |\n| Yes. If you want to compare these samples with the samples that didn&#39;t fail, you have to perform inter-run calibration. |\n\nThree samples failed for one of the genes of interest\n\n| What is the first question I need to ask ? |\n| :----------------------------------------- |\n| Is the gene expressed in these samples ?   |\n\n| Is it possible the RNA of these three samples was of low quality ?        |\n| :------------------------------------------------------------------------ |\n| Not likely, the measurements for the other genes in these samples are ok. |\n\nThree samples failed for one of the reference genes\n\n| Can I use the measurements of that reference gene in the non-failing samples for normalization ?                                         |\n| :--------------------------------------------------------------------------------------------------------------------------------------- |\n| No, qbasePLUS requires that you use the same reference genes for all samples so you have to discard all samples for that reference gene. |\n\n### Exercise 7: dilution series for calculating amplification efficiencies\n\nIn my qPCR experiment I want to study 8 new genes for which I had to design new primer pairs in 12 samples (samples of interest and control samples). I want to use 2 technical replicates and 96 well plates.\n\n| What is the first thing I need to do ?                                                        |\n| :-------------------------------------------------------------------------------------------- |\n| Perform a pilot experiment to determine the amplification efficiencies of these primer pairs. |\n\nFor this I need a dilution series of representative cDNA template.\n\n| How many dilutions would you include ?                                           |\n| :------------------------------------------------------------------------------- |\n| A dilution series with 6 dilutions for 8 genes nicely fits into a 96 well plate. |\n\nA few weeks after my initial qPCR experiment I want to test these 8 genes in a new set of samples.\n\n| Do I have to repeat the pilot experiment ?      |\n| :---------------------------------------------- |\n| No, dilution series do not need to be repeated. |&quot;,&quot;# Installation\n## Windows\n&gt; Requirements to install E-Notebook 2014: \n&gt; 1. Microsoft Windows\n&gt; 2. MS Office, Adobe Reader (or similar)\n&gt; 3. ChemBioDraw (optional - see STEP 2)\n&gt; 4. Valid VIB login credentials. Check your login and password on [https://storefront.vib.be/](https://storefront.vib.be/).\n\n**STEP 1: E-Notebook 2014**\n\n1. Browse to [https://eln.vib.be/clickonce/](https://eln.vib.be/clickonce/)\n2. Click Install and open the file\n3. After the installation, the software is automatically launched and the login window appears\n4. Log in with your VIB credentials (see requirements)\n5. Close E-Notebook after successful launch: File - Exit or &#39;X&#39; in the right upper corner\n6. Generate a shortcut on the desktop (right click - Send to - Desktop): All Programs - PerkinElmer - E-Notebook 2014 Client\n7. Install ChemBioDraw (STEP 2)\n\n**STEP 2: ChemBioDraw**\nNote: In case you only reinstall the ELN client, you don&#39;t have to reinstall the ChemBioDraw component\n1. Download the ChemBioDraw installation file from the same website as E-Notebook 2014: [https://eln.vib.be/clickonce](https://eln.vib.be/clickonce)\n2. Start the installation\n3. Install ChemBioDraw ActiveX component in suggested destination\n4. Follow the installation wizard instructions\n5. Click on Install and subsequently on \&quot;Finish\&quot;\n\n&gt; Why use ELN throught Citrix on Windows? \nSome older Windows versions cause problems with the E-Notebook 2014 Client installation.\n\n**STEP 1: Citrix Workspace app**\n1. Browse to [http://www.citrix.com www.citrix.com] \n2. Click on Download\n3. Select Citrix Workspace app from the list of possible downloads\n4. Download and install Citrix Workspace app\n\n**STEP 2: Launch ELN online**\n1. Browse to [https://storefront.vib.be](https://storefront.vib.be)\n2. Login with your VIB credentials\n3. Launch the ELN application by clicking on the icon\n4. If your browser asks to download and open an .ica file, please agree\n5. Citrix Workspace will open en launch the application\n\n## MacOS, Linux, mobile devices\n**STEP 1: Citrix Workspace app**\n1. Browse to [https://www.citrix.com www.citrix.com] \n2. Click on Download\n3. Select Citrix Workspace app from the list of possible downloads\n4. Download and install Citrix Workspace app\n5. After the installation on Linux execute the following command:\n```\nsudo cp -a /usr/share/ca-certificates/mozilla/DigiCert_Assured_ID_ Root_ CA.crt /opt/Citrix/ICAClient/keystore/cacerts/\n```\n\n**STEP 2: Launch ELN online**\n1. Browse to [https://storefront.vib.be](https://storefront.vib.be)\n2. Login with your VIB credentials\n3. Launch the ELN application by clicking on the icon\n4. If your browser asks to download and open an .ica file, please agree\n5. Citrix Workspace will open en launch the application\n\n# Support\n- Call us at +32 (0)9 248 16 15\n- Mail us at eln@vib.be&quot;,&quot;# Login\nWhen launching the application (Windows: double-click the **E-notebook 2014 client** icon  Citrix: click on the ELN 2014 icon and open the .ica file, Citrix Workspace will launch the application), you will see the following login window:\n\nIn order to login on ELN, you need a **valid VIB account**. The VIB username usually has a format like: *firstname lastname*. More information on [https://help.vib.be](https://help.vib.be) or mail eln@vib.be.  \n\nWhen clicking on **Connect** the application will retrieve your data. The **Work Offline** option is only available with the client installation and will allow you to make adjustments to the data in your Offline folder.\n\n&gt; Note: when launching the application for the first time, a download of all collections will start, this usually takes 1 or 2 minutes.\n\n# Layout\nThe layout is resembling to Microsoft Office. It has 3 main parts; the ribbon with options on top, the navigation and history area on the left and the working area on the right.\n\nThe default starting point is the Home location, this gives an overview of all data in the navigation area on the left and any modified experiments since one month on the right.\nIn the Audit Trail (bottom left) you can find the history of the object selected above. This history allow you to access previous versions of an experiment and retrieve a file in order to bring it back to the present. Every version has a timestamp and operator (= user that pressed the save button). Previous versions of an experiment can**t be modified, only the last version is adjustable.\nNavigating to your colleagues or Home can be done with the orange icons in the upper left corner. Next to the navigation buttons you find the Save button. When saving you can add annotations as well.\n# Ribbon\nThe Ribbon is where you can find the options corresponding with your selection (navigation area or section). By default, there are three tabs: Home, View and Data. Sections have specific tabs in the ribbon, e.g. Document, Image, Text, Table, Property List, etc. An example can be found below (Text):\n\n# Project, Notebook, Experiment\nThere are 3 basic levels to organize your data: Project, Notebook and Experiment (see icons below). You can see them as folders with a certain hierarchy. Only an experiment contains files. To add one of the levels click on the icon in the **Home** tab in the ribbon. \n\n# Sections\nAn experiment consists of sections, every section is a file or page. To add a section, select the icon in the **Home** tab in the ribbon. Some sections are hidden behind the **Other** button.\nYou can add sections automatically by drag and dropping them into your experiment. E-Notebook will recognize Word, Excel and PowerPoint files, PDF documents and images. GraphPad Prism files are not native to E-Notebook and will result in an Ancillary data section, this will happen with any other file type that is not native to the program.\n## General Page\nCreating a new experiment will give you a blank experiment with only one section, by default this is the General page. This is an example of a General Page:\n\nEvery lab group has a slightly different version of this General page. The universal parts of this section are the **General Information** and the **Reference to experiment** field. In the first field you have the option to enter general properties of your experiment such as start date, project, etc. Adding extra properties is available in the **Property List** tab in the ribbon.\n\nAdding a reference to your experiment can be very useful to link similar experiment to each other or make a series of experiments. This refence can be any experiment within your group. To add a reference, click on the option in the **Home** tab in the ribbon.\n\nAs last there are 3 or 4 text boxes to add keywords, aim of experiment, results, specifications or a conclusion.\n## Microsoft Office sections\nThree MS Office applications are supported in the E-Notebook software: Word, Excel and PowerPoint. All other MS Office files can be uploaded using the Ancillary Data section.\n\nFor the supported application you can add files using the corresponding section. This will initially display a (print) preview of the file, double-clicking the preview will launch the MS Office application to make adjustments. All other options are displayed in the ribbon:\n\n## Images\nUsing the Image section in E-Notebook will allow you to import one (1) image file. All common image extensions are supported, camera brand specific files (e.g. RAW or DNG) can be uploaded using a non-file-specific section. Next to the image file itself you can add a title and notes.\n\n## PDF files and Captured Image\nUsing the PDF section in E-Notebook will allow you to import 1 PDF file. Next to the PDF file itself you can add a description, date and a document name.\n\n## Ancillary Data (a.k.a. Binder)\nThis non-file-specific section will save 1 file. In order to open the file , you must double-clicking on it, this will launch the according application outside ELN. Closing the external application again (e.g. after making adjustments) will result in this window:\n\nClick **Continue** to save your changes and re-upload the new file in ELN or click **Cancel** to ignore the changes.\n## Supplementary Data Management (SDM)\nFiles imported in this section will be saved on an internal network drive linked to ELN. This means that files in SDM won**t be accessible outside of your research center or university network. Files in the SDM section are not limited to the file size limit of 30 MB. \nNext to the default list of sections, there are some lab-specific sections for PCR or Western Blot. To add one of these lab-specific sections, click on the **Other** icon and select your section.\n\n# Sharing data and linking experiments\n## Access rights for others\nTo grant a colleague access to your data, you simple select the object and click on the View tab in the ribbon. In the Properties field you click on Security. A new window will appear (left picture). The inherited privileges are default settings, youre not able to modify this. The assigned privileges on the other hand can be modified by clicking Grant.\n\nBy filtering on user group or user you can select the group/person (right picture). The type of privilege can be: read, read and write, full control. You can define this in the next window.\n\nRemoving the privilege can de done by selecting the person or group and click on Remove. For both granting or removing access privileges there is no notification system, you have to tell them yourself.\n## Experiment shortcuts\nWhen a colleague granted you access to a project/notebook/experiment you can place a link to this object in your own ELN. This makes navigating to this object easier and allows you to group all your collaborations within your own ELN hierarchy. To create such a shortcut, follow these steps:\n1. Select the object of interest\n2. Right click  Copy\n3. Navigate to your own ELN\n4. Right-click on the location you want the link to appear\n5. Select Paste Reference\n\n&gt; Note: shortcuts can be removed, the original data however is not deleted. \n## Templates\nTemplates can be created by every user and can be shared with your colleagues. To create a template, follow this procedure:\n\n1.\tnavigate to User Configuration  Templates\n2.\tcreate new experiment\n3.\tbuild your new default experiment/template by adding information/sections\n4.\tsave your template\n\nNext time you want to create a new experiment, you will have the option to create a blank or template experiment. \n## Search\nThe collection search can be used for users, projects, notebooks and experiments. No content can be found with the search box in the upper right corner.\nThe Advanced Search option can find experiment content. You can find it in Quick Links above the navigation pane.\n\n\n&quot;,&quot;You need to do inter-run calibration if you want to compare samples from different runs e.g.:\n\n  - when it is not possible to get all samples for the same gene on the same plate\n  - when you do additional runs weeks or months after your initial experiment\n\nOf course there is a lot of variability between runs on a qPCR instrument:\n\n  - thermal block is not always heating uniformously\n  - quality of the lamp, the filters and the detector decreases over time\n  - data analysis settings on the qPCR instrument (baseline correction and threshold) can be slightly different\n  - efficiency of reagents (polymerase, fluorophores) is variable\n  - optical properties of the plastic plates vary\n\nFortunately, inter-run calibration allows you to eliminate most of this variability.\n\nIn this experiment we will analyze the data from the gene expression experiment (see Analyzing gene expression data in qbase+) together with data from 2 runs (Run4 and Run5) that were done weeks after the initial gene expression experiment.\n\nBecause the data comes from two different experiments spread over time, we have included three inter-run calibrators on the plates: Sample01, Sample02 and Sample03.\n\nThe principle of the IRCs is very similar to that of the reference genes:\nIn theory, the IRCs should have the same NRQ in each run. In practice, the difference in NRQ between two runs is a measure of the inter-run variation and can be used to adjust the NRQs to remove the inter-run variation.\n\n#### Creating a new Experiment\n| Import [Run1](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run1.xls), [Run2](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run2.xls), [Run3(all three in CFX format)](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run3.xls), [Run4](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run4.xls) and [Run5 (the latter two are in qBase format)](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run5.xls).\n| :----------------------------- |\n| Since the data is in files of two different format, you have to do a separate import for each format. So first import Run1, Run2 and Run3, then import Run4 and Run5. You can find the details on how to import CFX files in [](Loading_data_into_qbase+\&quot; title=\&quot;wikilink)Loading data into qbase+.\nThe details of importing qBase files are in [](Analyzing_data_from_a_geNorm_pilot_experiment_in_qbase+\&quot; title=\&quot;wikilink)Analyzing data from a geNorm pilot experiment in qbase+\n\n#### Analyzing the data\n\n| Use assay specific amplification efficiencies.\n| :----------------------------- |\n| You can find the details on how to convert the targets in the **Taking into account amplification efficiencies** section of Analyzing gene expression data in qbase+\n\nIn Analyzing gene expression data in qbase+ we have already checked the stability of the reference genes (see **Normalization** section). We determined that Flexible did not show stable expression.\n\n| Convert Stable and Nonregulated to Reference targets.\n| :----------------------------- |\n| You can find the details on how to convert the targets in the **Normalization** section of Analyzing gene expression data in qbase+\n| Appoint Sample01, Sample02 and Sample03 as IRCs.\n| :----------------------------- |\n| Leave the Analysis wizard by clicking the **Close wizard** button in the top menu.\n\n - Expand **Intermediate results** (red) in the **Project Explorer**\n - Double click **Interrun calibration** (green)\n\nThis opens the **Interrun calibration window**:\n\n - Click the **New** button (blue) to create a IRC\n - Once the IRC is created you have to appoint samples to it: select **Sample01** in the list of **Other samples**\n - Click the **Add Sample** button (purple)\n - Remember that you cannot give IRCs the same name in different runs: the software would think that they are technical replicates spread over different plates (which is not allowed). Therefore, in Run4 and Run5 we have given Sample01 another name: Sample01_2. Select **Sample01_2** in the list of **Other samples**\n - Click the **Add Sample** button (purple)\n\nYou have appointed the first IRC (grey), now do the same for the other two IRCs.\n\nRemember that for each target the variability of the normalized\nexpression levels of the IRCs between different runs will be used to\nadjust the other normalized expression levels of that target gene. The\nadjustment is done by amplifying the normalized expression levels with a\ncalibration factor that is calculated based on the normalized expression\nlevels of the IRCs.\nSince variability between runs is the same for each IRC, you expect that\nall IRCs measure the variability between the runs to the same extent,\nhence leading to similar calibration factors.\n\n| Do these IRCs generate similar calibration factors ?\n| :----------------------------- |\n| Open the **Calibration Factors** tab (red) of the **Interrun calibration window** and look at the result for Duvel:\n\nYou see that IRC2 returns a substantially different calibration factor in Run5 (green) so the validity of this IRC should be interpreted with care.\nFor Leffe the IRCs also gives inconsistent results in Run5. Switch to the results for Leffe by selecting **Leffe** in the **Targets** list (blue)\n| Do you still see the same expression pattern for Palm as you did in the first three runs ?\n| :----------------------------- |\n| Open the target bar chart for Palm.\n\nYou see that the pattern Palm showed in the first three runs (sample01 to sample16): high expression in the odd and low expression in the even samples is reversed in the samples from Run4 and Run5 (sample17 to sample25). In the latter runs you see high expression in the even and low expression in the odd samples. However, without annotation for Run4 and Run5 (which samples are treated and which not) it&#39;s impossible to interpret the bar chart.\n\n1. [Link](http://youtu.be/OJFsuZqNUHs)&quot;,&quot;# What is Inkscape?\nInkscape is professional quality vector graphics software which runs on Windows, Mac OS X and GNU/Linux. It is used by design professionals and hobbyists worldwide, for creating a wide variety of graphics such as illustrations, icons, logos, diagrams, maps and web graphics. Inkscape uses the W3C open standard SVG (Scalable Vector Graphics) as its native format, and is free and open-source software.\nDuring this training we will use **Inkscape 0.92** on Windows. To download the most recent version, browse to the [Inkscape Download page](https://inkscape.org/en/download/). For Windows 10 S: the Inkscape app is also available in the Microsoft Store.\n## External training material\n- [Online Inkscape tutorials](https://inkscape.org/en/learn/tutorials/).\n- [Nick Saporito Inkscape tutorials for beginners](https://www.youtube.com/playlist?listPLynG8gQD-n8BMplEVZVsoYlaRgqzG1qc4 )\n- [Nick Saporito Inkscape intermediate/advanced tutorials](https://www.youtube.com/playlist?listPLynG8gQD-n8AFcLFAkvqJYnQUiBweRh1y )\n\n## User Interface\nInkscape is a single-window program. Drawing tools are on the left hand side, option docks are on the right. \nIn the central window, you have the drawing area with default an A4 page as document layout. To select another format for e.g. posters, go to **File - Document Properties**. Next to the document size, you can adjust the background colour (default: transparant).\n\n## Import Images\nYou can import scalable vector graphic files (.svg) and also GraphPad Prism graphs (.emf or .pdf format).\nInkscape is not used for editing images like GIMP. If you import bitmap images, note that they are not scalable like vector objects!\n\n## Drawing lines and objects\nYou can draw a line with the Draw Bezier tool. You can make your own shape or just draw a line or path. On top of your drawing area you can select the Mode: Regular Bezier curves, Spiro paths, straight line segments and paraxial line segments. When selecting the straight line mode, you can hold the Ctrl button to make your line snap every 15 degrees around your first/previous point.\nYou can draw shapes by using the Rectangle tool, Ellipse tool and the Create Stars and Polygons tool. On top of the drawing area you can specify your polygon and star properties, size and lock aspect ration. Here is the Crtl key useful as well for creating squares, circles or specify the position of your object.\nWhen you have an object (polygon or others) you can select a color for the stroke and inside of the object. Selecting an object using the Selection tool will give you more options on top of the view area. You have the option to rotate, flip, change dimensions and XY position (in different units). You can change the position of the selected object compared to others (move up/down). \n\n## Paths\nA path consist of lines and nodes. These lines can be straight or curved and you can make an object using paths ( closed path). When in Path mode you have several options; add or remove a node, joining or breaking nodes apart and changing the node properties. You can also change the segment (line between nodes) properties with the options on top of the screen. \nYou can convert an object into a path to gain more flexibility by selecting the object and go to **Path  Object to path**. Afterwards you can use the object tool or the path tool to manipulate the object. \n\n## Fill and stroke\nPaths, lines and objects can be given a plain color, patterns, gradient color or left blank/transparent. You can also configure the stroke style and color. Click **Object  Fill and Stroke** to see all the options. Paths/lines can be transformed into arrows using the Stroke style option **Markers**.\n\n## Text\nAt the left there is also a Text tool available. With this tool you can create and change text, it&#39;s colour, font, style and size. After entering text, youre able to manipulate it like an object. You can also attach text into a frame by selecting both objects and click on **Text  Flow into Frame**.\nYou can also align text to a path. Select both text and path and click **Text  Put on Path**. Once the text in aligned to the path it stays adaptable and can be removed from the path; **Text - Remove from Path**.\nText is an object at first. When you select **Path - Object to path** you can modify your text like any other object that is converted into a path.\n\n## Grouping, aligning and arranging object/paths\nTo group several object you must select them all (hold Shift) and select **Object  Group**. To unite several paths you must select **Path  Combine**. Both options are the same and allow you to manipulate objects/paths as one. Both actions can be reversed (Ungroup / Break Apart).\nSeveral object must be aligned before you group them, think of text inside a box. To display the options, go to **Object - Align and Distribute**. When multiple objects are selected, you can align the top, bottom, left and right edges of the objects. Aligning on the central axes is also possible, this in both horizontal as vertical direction. The aligned objects always need an anchor, this can be changed in the box on top of the toolbox (Relative to:). This anchor can be an object (first, last, smallest or biggest) or the page, a selection or the complete drawing. Distributing objects works in a similar way, but manages the space between objects. For paths you can only align the nodes.\nAligning or distributing objects allows you to manipulate the X and Y position of your objects. There is also a virtual Z axis. When you have multiple objects with different colours, you can move the one above the other. Every new object you draw will be on top of all the rest. To raise an object one step or to the top, you can use the buttons on top of your screen. The same can be done to lower an object one step or to the bottom.\n\n## Path Effects and operations\nWhen you want to distribute/multiply an object along a guideline, there is a tool called Path Effects. First draw and select the object or group of objects and past it in the clipboard (Ctrl + C). Draw or select your path (guideline) and select **Path  Path Effects**. Click on the &#39;+&#39; sign and select the effect **Pattern Along Path**. In the new box on the right: select &#39;Repeated&#39; on the option Pattern copies. Now click on &#39;Paste path&#39; to paste the object you want to multiply. Note that only the shape is pasted, not the color. When adjusting the color, it will affect the entire path. To copy the colour, use Crtl+C again on your original, select your path of objects and go to **Edit - Paste Style - Paste Style**. There are also standard patterns to distribute along a path. When clicking on the &#39;+&#39; sign to add an effect, select Gears or Hatches (rough). Each of these effects have their own options to create an effect and to adjust the pattern.\nWhen it comes to paths, you can do much more than combining them. When you want to cut one shape out of another shape, you can use the options in the Path menu; Union, Difference, Intersection, Exclusion, Division and Cut Path.\n\n## Diagrams\nTo make a diagram with objects (circles, rectangles, stars, etc.) connected by lines, there is the Diagram connector tool. First you must draw and align the objects to create your diagram. Then select the Diagram connector tool. Every object can be selected by clicking in the white box in the middle of the object. Once connected the lines will follow the object if you move it to another place. The lines can be used as a path, therefore you can also modify them to e.g. dashed lines, arrows, etc.\n\n# Exercises\n&gt; ### {% icon hands_on %} Hands-on: Exercise 1\n&gt; Image 1 PNG: [Image 1](http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/Drawing.png)\n&gt; Image 1 SVG: [Image 1 SVG](http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/Drawing.svg)\n&gt; Task: Reproduce the top strand. Afterwards, reproduce the bottom strand using the first one.\n{: .hands_on}\n&gt; ### {% icon hands_on %} Hands-on: Exercise 2\n&gt; Image 2 PNG: [Image 2](http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/Drawing2.png)\n&gt; Image 2 SVG: [Image 2 SVG ](http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/Drawing2.svg)\n&gt; Task: Reproduce one of the sets of this image. Afterwards, reproduce the others using the first set.\n{: .hands_on}\n&gt; ### {% icon hands_on %} Hands-on: Exercise 3\n&gt; Image infographic 1: [Image 1](http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/procent_bars.png)\n&gt; Image infographic 2: [Image 2](http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/circle_infographic.png)\n&gt; Image infographic 3: [Image 3](http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/flower_diagram.png)\n&gt; Task: Try to reproduce one of these images using the video tutorial series from Nick (see top of this page).\n{: .hands_on}&quot;,&quot;# Bitmap vs Vector images\n## Bitmap \n- Pixels in a grid/map\n- Resolution dependent\n- Restricted to rectangle\n- Resizing reduces visual quality\n- Easily converted\n- Minimal support for transparency\n- Popular file formats: BMP, GIF, JPEG, JPG, PNG, TIFF\n\nBit depth or color depth is the amount of data assigned to every pixel (e.g. 1-bit = black/white, 4-bit = 16 colors/shades of grey, etc.) The more data, the more realistic your image will be. More data per pixel also means larger files.\n\n## Vector\n- Scalable\n- Resolution independent\n- No background\n- Inappropriate for photo-realistic images\n- XML based text format\n- Popular file formats: SVG, AI, CGM, DXF, WMF, EMF\n\n# Pixels\nResolution = number of pixels =  how much detail an image holds\nPPI: pixel per inch\n- Screen pixel density (monitor/smartphone)\n- Tells you how large an image is\n\nDPI: dots per inch\n- Print-out dots density (inkjet/laser printer)\n- Printer settings\n\nAn image at 300 PPI will look fine on a monitor, but printing is another matter! Print it on paper and you will notice the difference between 72 DPI and 300 DPI\n\n# File formats and compression\n## JPG/JPEG\n- Supports 26 million colours (24 bit)\n- Lossy compression (information is lost from original file)\n- Small file size (compressed)\n- Photographs\n## BMP\n- Supports 8/16/24-bit\n- Uncompressed file format\n- Large file size\n## TIFF\n- Tagged Image File Format\n- All colour and data information is stored\n- Uncompressed (lossy and lossless compression is possible)\n- Very large file size\n## GIF\n- Graphics Interchange Format\n- Only 256 colours possible (8-bit)\n- Replace multiple occuring patterns into one\n- Small file size\n- Animation\n## PNG\n- Portable Network Graphics\n- 256 / 16M colours\n- 8-bit transparancy\n- Lossless compression\n## SVG\n- Scalable Vector Graphics\n- XML-based format\n- Lossless data compression\n- Creatable and editable with a text editor\n- Can contain both bitmap and vector data\n## PDF\n- Portable Document Format\n- Can contain both bitmap and vector data\n## RAW/DNG\n- Digital Negative (DNG) is a universal RAW file format\n- Raw image file (without white balance, color saturation, contrast settings, )\n- RAW files can be camera brand specific\n- Large file size\n- Multiple options without taking the picture again\n## Publication vs Presentation\nKey features for publications:\n- Raw/uncompressed image file (e.g. TIFF)\n- High quality image (300 PPI) and resolution\n- Lossless compression (e.g. PNG)\n- Compression is sometimes allowed (check journal website!)\n\nKey features for presentation:\n- Normal quality image (72 PPI) and smaller resolution (max width: 1920 pixels)\n- Compression is allowed (e.g. JPEG)\n- Smaller file size\n\n# Guidelines on image editing\nScientific accepted image manipulations are described in guidelines. VIB also has a document to guide you in what is and what isn&#39;t acceptible when adjusting your images. Some examples are:\n- No specific feature within an image may be enhanced, obscured, moved, removed or introduced\n- Adjustments of brightness, contrast or color balance are acceptable if they are applies to the whole image as long as they do not misrepresent information in the original\n- Grouping of images from different parts of the same or different gel, fields or exposures must be made explicit by the arrangement of the figure (dividing lines)\n- The original data must be available by the author when asked to provide it, otherwise acceptance of the publications may be revoked\n\nyou can find all the VIB guidelines [here](http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/VIB_guidelines.pdf).&quot;,&quot;# What is GIMP?\nGIMP is short for **GNU Image Manipulation Program**. It is a free and Open-source, cross-platform image editor available for GNU/Linux, MacOS and Windows operating systems. During this training we will use **GIMP 2.10** on Windows. To download the most recent version for your OS, browse to the [GIMP Download page](https://www.gimp.org/downloads/).\n## External training material\n- [GIMP Manual page](https://www.gimp.org/docs/).\n- [GIMP 2.10 Basics on YouTube](https://www.youtube.com/watch?v=2EPIUyFJ4ag)\n- [Nick Saporito GIMP Tutorials](https://www.youtube.com/playlist?list=PLynG8gQD-n8Dl23X0o1HFu_5PmBl79niz)\n\n## User Interface\nGIMP has a &#39;Single-window&#39; mode, this allows you to switch from multiple windows (for e.g. multiple monitors) to a single window. When the &#39;Single-window&#39; mode is disabled, you have separate windows for toolboxes, view area and dockable dialogs. When enabled you have one window with all tools, options and dockable dialogs attached to the central view area. For beginners, we would advise the &#39;Single-window&#39; enabled.\nOn the left panel you have the &#39;Toolbox&#39; (if not present: **Windows - Toolbox** or press **Ctrl + B**) and underneath the &#39;Tool Options&#39; dialog. Selecting a tool will result in a different Tool Option bar. Every tool has his own set of parameters and functions, best to keep them close to each other. \nOn the right-hand panel you can find other &#39;dockable dialogs&#39;. These are easy to move, remove and re-introduce if necessary. To get a list of all &#39;dockable dialog&#39; go to **Windows  Dockable Dialogs - ...** . If you want a full screen view of your image select **Windows  Hide Docks**. \n\n## Import data and image properties\nTo import an image: **File  Open**\nWhen you select an image (any file type) in the import window, you get a preview and information on the right side. Click **Open** and the image(s) will be displayed in the middle box at zoom level 100% (1 pixel image = 1 pixel screen) or fitted to your windows. To zoom use Ctrl + mouse scroll up or down. Multiple images in GIMP are displayed in different tabs on top of the View Area.\nBefore you export your image, make sure it has the right resolution and pixel density. **Image - Image Properties** will give you all the information your image holds. This information can be very useful when you open an image from an unknown source.\n\n## Selection\nRectangular selection has several options and shortcut keys. The first icons in the tool options are the selection modes: add to selection (Shift), subtract from selection (Ctrl) and intersect with selection (Shift+Ctrl). More options are: feathering edges, rounding of the corners, expand from center, lock aspect ratio, size and position and if necessary to highlight the selection). The Ellipse selection tool has more or less the same options.\nThere are other selection tools available: Free Selection, Select by Color, Fuzzy Selection, Scissor Selection, Foreground Selection. Those tools have different tool options and are only used in specific cases.\n\n## Transforming\nThere are several ways to transform your image or selection; rotating, scaling, shearing and flipping. You can transform a selection, a layer or the image. When using the rotation tool, you have several options in the dockable dialog below. An important option is Clipping this will change the aspect ratio of your image after rotating. \nAnother way of rotating an entire image is: **Image  Transform  ...** then you have the option to flip (horizontal/vertical) or rotate (90/180). The entire image will be rotated including the selection and image orientation. \n\n## Layers\nMake sure you have the dockable dialog Layers in your window. All options for layers can be found in the menu bar Layer. You can make a new blank layer or duplicate the current layer (e.g. copy of original image to compare or as back-up). In the dockable dialog you can hide or show a layer (eye button), rename them or move them up and down in the layer stack. If you want to link/connect two or more layers, you can use the chain button (next to the eye button).\nTo copy a selection to a new layer, perform a regular copy/past action of that selection (Ctrl+C and then Ctrl+V) and select **Layer - To New Layer**\nIf you want to merge all layers into one layer you can select **Image  Merge Visible Layers**.\n\n## Brightness and contrast\nIn the menu bar you can find **Colors** . This menu has multiple option to manipulate your image; \n- Color Balance will change the cyan, magenta and yellow color levels of your image\n- Brightness and Contrast will change brightness and contrast and you can save these settings as a favorite \n- Threshold will reduce your image to two colors by using a threshold value\n- Adjust color curve will change the gamma setting of your image\n- Posterize will change the number of colors (2-256)\n\n## Guides and cropping\nYou can split your image in different sub-images. This can be done by using &#39;Guides&#39;. To create such a break-line, go to **Image - Guides - New Guide... or (by Percent)...**. You can create a horizontal or vertical guide at the value/percentage you enter. A guide will be displayed as a blue dashed line. To chop your image in multiple parts, go to **Filters- Web- Slice** (Older versions: Image - Transform - Guillotine). The sub-images will be generates in the folder you selected.\nIf you only want a selection of your image without all the rest you can crop by clicking **Image  Crop to Selection** or use the Crop tool from the Toolbox.\n\n## Scaling and print size\nWhen you want to scale your image to a smaller resolution you can select **Image  Scale Image**. There you can scale in pixels (or another unit) and you can lock the aspect ratio (chain symbols).\nIf you want to change the print size to make your image suitable for publication you can select **Image - Print Size...**. There you can change the dimension/resolution and pixel density of your image.\n\n## Remove background color\nIf you download an image of a company or university logo, it might have a white (or any other color) background. This can be very annoying when the destination background is different. In order to remove the background color, we first have to add an alpha channel to this image: **Layer - Transparency - Add Alpha Channel** - If the Alpha channel is already present, skip this step. Now you&#39;re able to get a transparent background using the option: **Image - Color to Alpha**. In the new window you can select the color which you would like to convert to transparent pixels. You can either select by clicking the color bar or use the color picker icon.\n\n## Exporting\nSelect **File  Export as**\nIf you click on the &#39;+&#39; next to Select File Type, you have a list of all possible extensions in which you can export your image. Each of those file formats has different compression options.\n\n# Exercises on image manipulations in GIMP\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 1\n&gt; Source file: [http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/original_file.tif Image 1]\n&gt; Task: Split this image in 2 parts, one for each gel. Make sure the band are horizontal and export the 2 new images in the same file format as the original. You can adjust brightness and contrast to make all the band more visible.\n{: .hands_on}\n&gt; ### {% icon hands_on %} Hands-on: Exercise 2\n&gt; Source file: [http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/Exercise1.1.jpg Image 2]\n&gt; Task: Rotate this image 45 degrees and crop an image of 500x500 pixels out of the original. Make sure the printing resolution is set to 300 ppi and export this image as a PNG file. Adjust brightness and contrast to make this image look better.\n{: .hands_on}\n&gt; ### {% icon hands_on %} Hands-on: Exercise 3\n&gt; Source file: [http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/Exercise1.2.jpg Image 3]\n&gt; Task: Cut this image in 4 equal parts. Know that the printing width is 150 mm and the journal demands a minimum op 300 ppi for all 4 images. Also export each of them in a different file formats without losing image quality. Adjust brightness and contrast to your own opinion.\n{: .hands_on}\n&gt; ### {% icon hands_on %} Hands-on: Exercise 4\n&gt; Source file: [http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/Exercise1.3.jpg Image 4]\n&gt; Task: Adjust brightness and contract of this images and export it in a way to make the file as small as possible. Use preferably lossless compression (try lossy compression to compare file size), there is no restriction on file formats. Be sure your image is exported with at least 300 ppi.\n{: .hands_on}\n&gt; ### {% icon hands_on %} Hands-on: Exercise 5\n&gt; Source file: select from the internet\n&gt; Task: Download an image from your most favorite brand and remove the white (or other color) background. Export this new image in a format that support transparent pixels.\n{: .hands_on}&quot;,&quot;qbase+ is software to visualize and analyze qPCR data. It allows you to perform various types of analyses:\n  - statistical analysis of gene expression\n  - advanced copy number analysis\n  - miRNA profiling\n  - ChIP-qPCR analysis\n# Installation and licensing\nYou can find the installation instructions on [VIB qbase+ support page](https://www.bits.vib.be/index.php/software-overview/qbaseplus)\nVIB only offers qbase+ to VIB scientists, you need a valid VIB email address to run the software. Biogazelle (the company who has developed the software) have written a manual with instructions on how to use the software. Download [Biogazelle&#39;s user manual](https://www.biogazelle.com/system/files/manuals/qbaseplus_manual_0.pdf). Before you can download the manual you have to log on to [the qbase+ website](https://www.qbaseplus.com/) using your qbase+ account. Use your VIB email address for setting up this account.\n# Training material\n  - [slides](http://data.bits.vib.be/pub/trainingen/qbasePLUS/qbase_2018.pdf)\n  \n  **Extra**\n  - [clean log10 transformed CNRQs](http://data.bits.vib.be/pub/trainingen/qbasePLUS/Log10CNRQsClean.xlsx) for checking normality in Prism\n  - [clean untransformed CNRQs](http://data.bits.vib.be/pub/trainingen/qbasePLUS/CNRQsClean.xlsx) for visualization in Prism\n  - [R script](http://data.bits.vib.be/pub/trainingen/qbasePLUS/qPCR.R) for analysis and visualization\n  - [log10 transformed CNRQs of control samples](http://data.bits.vib.be/pub/trainingen/qbasePLUS/resultslog.csv) for analysis and visualization in R\n  - [log10 transformed CNRQs of treated samples](http://data.bits.vib.be/pub/trainingen/qbasePLUS/resultslogTreated.csv) for analysis and visualization in R\n&quot;,&quot;# OTU creation using LotuS \n{:.no_toc}\n\nIn this tutorial we will create a genus abundance table from two 454 sequencer runs using a pipeline called LotuS. A genus abundance table contains counts of different genera in a several of samples  Rows are the different genera and columns the samples. As a simple example, take a look at this table:\n\n|                     |        |       |        |       |      |\n|:--------------------|:-------|:------|:-------|:------|:-----|\n|Genus\t              | bl10   |bl11   |bl12\t|bl128\t|bl13  |\n|Bacteria             |24      |52     |39\t|63\t|181   |\n|Bacteroides\t      |169     |27     |7\t|42\t|6     |\n|Porphyromonadacea    |370     |346    |621\t|565\t|224   |\n\nThis table tells us how often we observe unclassified Bacteria, Bacteroides and unclassified Porphyromonadaceae in the 5 samples bl10, bl11, bl12, bl128 and bl13. A matrix like this will be used for the next tutorial on numerical ecology and created from raw sequence data within this tutorial.\n\n## The data\n\nIn a recent experiment, we sequenced 73 samples in two 454 runs, the raw fasta and quality files are in `/home/VIBTrainingX/metagenomics/` on the bits server. For each run we have a fasta (.fna) and quality (.qual) file. Go to this directory using the command `cd` and become aware of the files required from the experimenter (command `ls`). You can always take a look at files and their contents using viewing commands like `less`.\n\nThe sequence files were multiplexed before the experiment, that is a small nucleotide sequence  the barcode - was attached to each read, specific for each experiment. A mapping file is typically used, containing the link between a sequence barcode and the name of the experiment and is essential to demultiplex the fasta files. \n\n## The tools\n\nLotuS is actually a set of tools that were installed in the `/opt/` folder. First go to [the lotus website](http://psbweb05.psb.ugent.be/lotus/) and familiarize yourself with the basic documentation.\n\nTo start the exercises, go to the directory where Lotus is installed. \n```\ncd /opt/lotus-1.62/lotus_pipeline/\n```\n\nFrom this directory you can run all the tools. To reach all data files (e.g. input files) you have to provide the path to the files: `~/metagenomics/`\n\n## The analysis\n\n### Creation of Mapping file. \n\n[An Excel](http://data.bits.vib.be/pub/trainingen/metagenomics/Mice_experiment.xlsx) is provided, with some basic experiment annotation. The fwd primer is given as `ACTYAAAKGAATTGACGG`, but if you search for the primer sequence in the reads (in one of the .fna files) you will not find it because you need to reverse translate the primer sequence first using [http://www.bioinformatics.org/sms/rev_comp.html this tool]. So you see annotation provided by the provider is not always correct.\n \nLotus needs experiment annotation to map input files to barcodes. Based on the documentation on [http://psbweb05.psb.ugent.be/lotus/documentation.html#MapFile the Lotus website], create a mapping file for this experiment. This means that you need to replace the column headers of the Excel file to terms that are accepted by Lotus and that you have to indicate that there is a .fna and a .qual file for each run. The header line should be preceeded by a `#`. The mapping file should at least contain four columns with the following headers:\n\n* SampleID\n* BarcodeSequence\n* fnaFile\n* qualFile\n\nSave the file as a tab-delimited text file.\n\nYou can always test the validity of your mapping file with the command \n```\n./lotus.pl -check_map [your mapping file]\n```\n\nIf you have fastq files as input the fnaFile and qualFile columns would be replaced by one fastqFile column.\n\n### Changing  the data format of the input files.\n\nSometimes you need to transcribe data from one format to another. For instance we could transform the fasta files (.fna) to fastq files (.fq). This can be done with the program `sdm`, that is part of the LotuS pipeline. Take a look at the sdm help by typing `./sdm` and exploring the options, e.g.\n \n```\n./sdm -help_commands\n```\n\nThen, using command line arguments, transcribe the fasta + qual files of the Anh experiment into fastq files. Take a look at output and log files created by sdm.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 1 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt; \n&gt;  &gt; How to transform fasta + qual files into fastq files ?\n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; sudo ./sdm -i_fna ~/metagenomics/Anh.1.fna -i_qual ~/metagenomics/Anh.1.qual -o_fastq t1.fq\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nIn the lotus_pipeline folder the fastq file t1.fq was generated, to take a look at the file use\n```\nhead t1.fq\n```\n\nDo the same for the t1.log file: you see that sdm is not only used to transform fasta into fastq files but it is also capable of doing quality filtering on the raw reads files.\n\n### Setting up a quality filter of the input sequence files.\n\nSince we want to make sure the quality filtering of the input file is strict, LotuS offers several quality filtering options. Quality settings are different for different data formats, thats why Lotus offers a file with specific settings for each platform. Since we have 454 data we will take a look at the file sdm_454.txt.\n```\nless sdm_454.txt\n``` \n\nRead the comments (line starting with #) to each option and think which quality filtering options might be important in order to create OTUs from the raw sequences. (Hint: an OTU is a clustering of similar sequences with the aim to have one cluster of sequences for each species that was originally present in the samples. Take into account that sequencing machines make errors and that PCR amplification of the 16S rDNA is similarly with errors). Think about a set of parameters, including the statistical information from step 2, and save these in your copy of sdm_options.txt for later use.\n\nCheck the sdm [quality filter settings](http://psbweb05.psb.ugent.be/lotus/documentation.html#SDMconfig). Some of the default filter settings are:\n\n* MinSeqLength=250 : Only use reads of at least 250 nt long after processing (remember we are working with long reads from 454 sequencing)\n* TruncateSequenceLength = 250 : Cut all reads after 250 nt\n* QualWindowWidth = 50 and QualWindowThreshold = 25 : Remove all reads where average quality is &lt;= 25 over a 50bp window\n* maxAccumulatedError = 0,5 : Remove all remaining bases when accumulated error score &gt;= 0,5&lt;/li&gt;\n* maxHomonucleotide = 8 : Remove all reads with a homonucleotide run (repeat of same nt) &gt;= 8\n* RejectSeqWithoutFwdPrim = TRUE : Remove all reads that do not contain the forward primer\n\n### Demultiplexing  and quality filter the input files.\n\nFor this step you will need the mapping file from Step 1 and the file with the quality filtering settings for 454 data. Use the sdm command to demultiplex and filter all input files at the same time into a local folder &#39;&#39;demultDir&#39;&#39;. First create the folder where the demultiplexed files will be written in ~/metagenomics/:\n```\nmkdir ~/metagenomics/demultDir\n```\n\nSince the mapping file contains information on all files, you have to provide an input path to the folder that contains the input files (.fna + .qual) to sdm.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 2 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt; How to demultiplex and quality filter files ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; ./sdm -i_path ~/metagenomics/ -o_fastq t1.fq -o_demultiplex ~/metagenomics/demultDir/ -map ~/metagenomics/map.txt -options sdm_454.txt \n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; Input is the folder containing the .fna and .qual files. The demultiplexing will fill the demultDir folder with fastq files.\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nDiscuss the output files and what each of these represents. In this experiment multiple samples were sequenced in the same lane. Two lanes were used, each containing 37 samples. After sequencing, this results in two files with reads. To know which sample a read comes from, unique bar codes are incorporated into the adapter sequences. One specific bar code for each sample. In this step reads from different samples (but from the same lane thus in the same fasta file) are split over separate fastq files, one for each sample. \n\n### Mapping file creation when sequence provider provides demultiplexed files.\n\nNow that you have demultiplexed the files into a single folder, you might be aware that sequence providers often deliver files in this format: already demultiplexed into single files. In this case slight modifications to the mapping file are enough to change the input from non-demultiplexed large file(s) to demultiplexed-many-small-files.\n\nNote that lotus has a special script that creates the mapping file for you in this case. The script is autoMap.pl. It is used to link SampleIDs to demultiplexed files. Run autoMap.\n\n```\n./autoMap.pl ~/metagenomics/demultDir/ ~/metagenomics/automap.txt 1,1\n```\n\n### Running Lotus.\n\nWe will run Lotus on the demultiplexed files. Use the mapping file you generated in Step 5 and the settings file sdm_454.txt. Use the utax taxonomy to assign a phylogeny to the derived OTUs. Run lotus from out the /opt/lotus_pipeline/ and save the output in the folder &#39;&#39;testR&#39;&#39;\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 3 \n&gt;\n&gt; &gt; ### {% icon question %} Question\n&gt; &gt; How to run lotus\n&gt; &gt;\n&gt; &gt; &gt; ### {% icon solution %} Solution\n&gt; &gt; &gt; ```\n&gt; &gt; &gt; sudo ./lotus.pl -i ~/metagenomics/demultDir/ -o ~/metagenomics/testR/ -m ~/metagenomics/automap.txt \n&gt; &gt; &gt; ```\n&gt; &gt; &gt; Input is the folder containing the .fna and .qual files. The demultiplexing will fill the demultDir folder with fastq files.\n&gt; &gt; {: .solution }\n&gt; {: .question }\n{: .hands_on }\n\nIn case you haven&#39;t done any quality filtering yet, you can still do it now. The command would then be:\n```\nsudo ./lotus.pl -i ~/metagenomics/demultDir/ -o ~/metagenomics/testR/ -m ~/metagenomics/automap.txt -s sdm_454.txt\n```\n\n* Peek at the file hiera_RDP (using `head`). The file maps eachg OTU to a genus.\n* Peek at the file OTU.txt (using `head`). The first line contains the number of reads that represent OTU_1 in each sample.\n* Peek at the file otus.fa (using `head`). It contains the reads representing each OTU. You can use this file to blast the sequences to check if they are really from the OTU they were assigned to.\n* Go to the folder higherLvl. This contains the data that we are going to use in the Ecology analysis.\n* Go to the folder LotuSLogs. This contains the settings of the analysis. For instance, peek a the file demulti.log: it shows how many reads were rejected... The file citations.txt contains the references for reporting your LotuS results. \n\n### Using a different taxonomy assignment on a finished run.\n\nIn this step we want to reassign the taxonomy to a LotuS run, but keep exactly the same OTUs. In this exercise, assign the OTUs to the Silva taxonomy. \n\nThis option is useful, if e.g. you want to keep your work on a given OTU set (as well as the phylogenetic tree), but want to try out what would have happened if you had used e.g. Silva as reference database instead of utax.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 4 \n&gt;\n&gt; &gt; ### {% icon question %} Question\n&gt; &gt; How to reassign the taxonomy with Silva as reference database? \n&gt; &gt;\n&gt; &gt; &gt; ### {% icon solution %} Solution\n&gt; &gt; &gt; ```\n&gt; &gt; &gt; sudo ./lotus.pl -i ~/metagenomics/demultDir/ -o ~/metagenomics/testR2/ -m ~/metagenomics/automap.txt -s sdm_454.txt -refDB SLV -redoTaxOnly 1\n&gt; &gt; &gt; ```\n&gt; &gt; &gt; Input is the folder containing the .fna and .qual files. The demultiplexing will fill the demultDir folder with fastq files.\n&gt; &gt; {: .solution }\n&gt; {: .question }\n{: .hands_on }\n\n### Using  a custom database.\n\nThe research of honey bee gut communities have very specific taxonomic names for already known bacteria. In order to accomodate for their naming sheme, we will use a very specific database that contains 16S sequences of bacteria mostly found in the honey bee gut. Download the [bee taxonomy in tax format](http://psbweb05.psb.ugent.be/lotus/packs/DB/beeTax/beeTax.tax) and [http://psbweb05.psb.ugent.be/lotus/packs/DB/beeTax/beeTax.fna bee taxonomy in fna format].\n\nUse the two provided files (fna, tax) to again redo the taxonomy, but this time assigning first using the honey bee DB and secondly everything with low hit should be assigned with the SILVA database. \n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 5 \n&gt;\n&gt; &gt; ### {% icon question %} Question\n&gt; &gt; Use honey bee taxonomy database ? \n&gt; &gt;\n&gt; &gt; &gt; ### {% icon solution %} Solution\n&gt; &gt; &gt; ```\n&gt; &gt; &gt; sudo ./lotus.pl -i XX -o ~/metagenomics/testR3/ -redoTaxOnly 1 \\\n&gt; &gt; &gt; -m ~/metagenomics/LASI_Spring_2_bees_barn_3_map_lts_5.txt \\\n&gt; &gt; &gt; -refDB ~/metagenomics/beeTax.fna,SLV -tax4refDB ~/metagenomics/beeTax.tax \n&gt; &gt; &gt; ```\n&gt; &gt; &gt; Input is the folder containing the .fna and .qual files. The demultiplexing will fill the demultDir folder with fastq files.\n&gt; &gt; {: .solution }\n&gt; {: .question }\n{: .hands_on }\n\n### Get  everything assigned!\n\nIn this step we want to assign every OTU sequence to a database target  and we dont care about false positive assignments! Of course this is per se wrong, but in some cases you just want to know what the best hit would be, even if it is only 90% similar to your OTU sequence. LotuS provides several options that allow tweaking towards more lenient assignments. Find all options related to this and try to create the most extreme case with these options, by reassigning the taxonomy again as in the previous step.\n\n### Try a different sequence clustering algorithm.\n\nNow rerun lotus, but try to optimize for a lot of small, hard defined OTUs (that might correspond to something like strain level). Which clustering algorithm might be suitable? Which clustering cutoffs make sense? For this specific run, use the first mapping file you created (step 1) and the non-demultiplexed input files. Save this output in the folder &#39;&#39;testR4&#39;&#39;\n\n### Your own best run.\n\nNow that you have run LotuS with various databases and options, go back and look at the output folder of the different runs, look at the statistics provided in the &#39;&#39;LotuSLogS&#39;&#39; subfolder. Based on this, tune the sdm filtering parameter file from step 3 (again), choose the database you think best suited/most interesting, and choose a clustering algorithm. With this create run the sample set again, saving the output in folder &#39;&#39;testrun1.3&#39;&#39;. This output folder you can use in the following session on numerical ecology.\n\nIf LotuS run has finished, go to the specified output folder and copy the genus.txt from the output folder to your home folder: \n```\ncp testrun1.3/ higherLvl/genus.txt ~\n```\n\n### Using Illumina data as input.\n\nIn all the analysis before we were using 2 x 454 runs from an outdated next generation sequencing technology. For the next exercise we will look at the output of an Illumina miSeq sequencing platform, that is still being used a lot nowadays.\n\nSet up the mapping file, using [http://data.bits.vib.be/pub/trainingen/metagenomics/Miseq.xlsx the provided Miseq.xlsx file]. Run LotuS, after you set up a custom sdm configuration file and using a combination of parameters you learned about in previous steps.\n\nThis run might take some time longer to finish. Be sure you set it to use all the cores of your computer and let it run over the lunch break.\n\nCongratulations, now you know how to process raw sequence files to meaningful summary tables, that can be directly analyzed in R or even Excel! In the next tutorial this matrix will be analyzed with the help of R, after the lunch break.\n\n&quot;,&quot;# Reading and writing files\n{:.no_toc}\n\n### Reading files\nEntering data in R can be done by typing the values when you create a variable. In most cases, however, you will have a file with data that was created by an instrument in your lab. How to import such a file into R? \n\nThere is a manual available in the R documentation called **R Data Import/Export**. It&#39;s accessible using help.start() and covers in detail the functionality R has to import and export data. Reading this is highly recommended. This manual covers importing data from spreadsheets, text files, and networks.\n\n### Reading text files\nMost instruments put out data in text format: tab-delimited text (.txt) or comma-separated value files (.csv). Both  can be easily opened in R. \n\nThe most convenient method to import data into R is to use the read functions, like read.table(). These functions can read data in a text file. In Notepad you can save such a file as a regular text file (extension .txt). Many spreadsheet programs can save data in this format. Reading means opening the file and storing its content into a data frame.\n```\nread.table(file,header=FALSE,sep=\&quot;\&quot;,dec=?.?,skip=0,comment.char=\&quot;#\&quot;)\n```\n\nThis function has a long list of arguments, the most important ones are:\n- *file*: path on your computer to the file e.g. D:/trainingen/Hormone.csv \n\tIf it is stored in the working directory, you can simply use its name. You can also use *file=file.choose()* to browse to the file and select it. File can be replaced by a url to load a file with data from the internet.\n- *header*: does the first line of the file contain column names?\n- *dec*: symbol used as decimal separator\n- *sep* symbol used as column separator, default is a whitespace or tab\n- *skip*: number of lines to skip in the file before starting to read data\n- *comment.char*: symbol to define lines that must be ignored during reading\n\nSee the documentation for an overview of all the arguments. The output of every read function is a data frame.\n\nThere are functions to read specific file formats like .csv or tab-delimited .txt files. In the documentation of read.table() you see that these functions are called read.csv() and read.delim().  Both functions call read.table(), but with a bunch of arguments already set.  Specifically they set up *sep* to be a tab or a comma, and they set *header=TRUE*.  \n\n```\nread.delim(file,header=TRUE,sep=\&quot;\\t\&quot;)\n```\nOn the documentation page, you see that these functions each have two variants that have different default settings for the arguments they take:\n```\nread.csv(   file,header=TRUE,sep= \&quot;,\&quot;,dec=\&quot;.\&quot;, ...)\nread.csv2(  file,header=TRUE,sep= \&quot;;\&quot;,dec=\&quot;,\&quot;, ...)\nread.delim( file,header=TRUE,sep=\&quot;\\t\&quot;,dec=\&quot;.\&quot;, ...)\nread.delim2(file,header=TRUE,sep=\&quot;\\t\&quot;,dec=\&quot;,\&quot;, ...)\n```\nOriginally the CSV format was designed to hold data values separated by commas. In .csv files that are made on American computers this is the case. However, in Europe the comma was already used as a decimal separator. This is why .csv files that are made on a European computer use the semicolon as a separator. \n\nFor instance, the file below contains a header row and three columns, separated by semicolons. It uses the comma as decimal separator.\n```\nPatient;Drug;Hormone\n1;A;58,6\n2;A;57,1\n3;B;40,6\n```\nObviously, the file is a European CSV file, to open it use read.csv2()\n\n### Reading Excel files\nTo import Excel files via a command the easiest way is to let Excel save the file in .csv or tab delimited text format and use the read functions. \n\nAn easy way to import Excel files is to use the RStudio interface although I prefer to use commands. To use the interface go to the **Environment** tab and click the **Import Dataset** button. \n\nRStudio can import 3 categories of files: text files, Excel files and files generated by other statistical software. To read .xls or .xlsx files select **From Excel**. \n\nA dialog opens with options on the import. You can import data from your computer (**Browse**) or from the internet (provide a url and click **Update**). Click **Browse**, locate the Excel file and click **Open**.\n\nThe **Data Preview** section shows what the data will look like in R.\n\nThe **Import Options** section allows you to specify the import parameters. \n- *Name*: name of the data frame that will hold the imported data. The default is the name of the file that you are opening.\n- *Skip*: number of rows at the top of the file to skip during import. Some data formats contain a number of header rows with general info like parameter settings, sample names etc. These rows are followed by the actual data. Skip allows you to skip over the header rows and import the actual data. \n- If the first row of the file contains column names, select *First Row as Names*\n- *Open data viewer* shows the data in the script editor upon import\n\nClick **Import**.\n\nBehind the scenes RStudio uses the **readxl** package that comes with the tidyverse package. You can also use the functions of this package directly in commands. \n\nCompared to other packages for reading Excel files (gdata, xlsx, xlsReadWrite) readxl has no external dependencies, so it?s easy to install and use on all operating systems. It supports the  .xls format and the .xlsx format. The easiest way to install it from CRAN is to install the whole tidyverse package but you have to load readxl explicitly, since it is not a core tidyverse package.\n\nOnce imported into RStudio the data is stored in a data frame and you can use it as input of commands. The data frame appears in the list of **Data in the Environment tab**.\n\n&lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../../images/Rfile_imported.png\&quot; alt=\&quot;file_imported\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; Inspect Variables and Data Frames in the Environment tab&lt;/figcaption&gt;&lt;/figure&gt;\n\nIf you want to view the data frame you can **click its name in the Environment** tab and it will appear in a separate tab in the script editor.\n\n&lt;figure id=\&quot;figure-2\&quot;&gt;&lt;img src=\&quot;../../images/Rview_file.png\&quot; alt=\&quot;view_file\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 2:&lt;/span&gt; View file content&lt;/figcaption&gt;&lt;/figure&gt;\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Reading files** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 17a\n&gt;\n&gt; 1. Import the file [GeneEx.csv](http://data.bits.vib.be/pub/trainingen/RIntro/GeneEx.csv) into a data frame called GeneEx\n&gt; 2. Rename the two last columns Ct1 and Ct2\n&gt; 3. Create a new column containing the average Ct: (Ct1+Ct2)/2\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  GeneEx &lt;- read.csv2(\&quot;Rdata/GeneEx.csv\&quot;)\n&gt;    &gt;  colnames(GeneEx)[c(3,4)] &lt;- c(\&quot;Ct1\&quot;,\&quot;Ct2\&quot;)\n&gt;    &gt;  GeneEx$Average_Ct &lt;- (GeneEx$Ct1 + GeneEx$Ct2)/2\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  Which of these 2 commands will work ?\n&gt;    &gt; ```\n&gt;    &gt;  GeneEx &lt;- read.csv2(\&quot;Rdata/GeneEx\&quot;)\n&gt;    &gt;  GeneEx &lt;- read.csv2(\&quot;http://data.bits.vib.be/pub/trainingen/RIntro/GeneEx.csv\&quot;)\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt; Which of these 2 commands will work ?\n&gt;    &gt;  ```\n&gt;    &gt;  names(GeneEx[c(3,4)]) &lt;- c(\&quot;Ct11\&quot;,\&quot;Ct21\&quot;)\n&gt;    &gt;  names(GeneEx)[3:4] &lt;- c(\&quot;Ct11\&quot;,\&quot;Ct21\&quot;)\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt; What&#39;s the difference in result between these 2 commands ?\n&gt;    &gt; ```\n&gt;    &gt; GeneEx$Average_Ct2 &lt;- (GeneEx$Ct1+GeneEx[4])/2\n&gt;    &gt; GeneEx[5] &lt;- (GeneEx[3]+GeneEx[4])/2\n&gt;    &gt; ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt; Can you use sum() instead of + ?\n&gt;    &gt; ```\n&gt;    &gt; sum(GeneEx$Ct1,GeneEx$Ct2)\n&gt;    &gt; (GeneEx$Ct1+GeneEx$Ct2)\n&gt;    &gt; ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt; Can you use mean() instead of +/2 ?\n&gt;    &gt; ```\n&gt;    &gt; mean(GeneEx$Ct1,GeneEx$Ct2)\n&gt;    &gt; mean(GeneEx$Ct1)\n&gt;    &gt; ```\n&gt;    {: .question}\n{: .hands_on}\n\n### Reading other files\nAlso of note is an R package called **foreign**. This package contains functionality for importing data into R that is formatted by most other statistical software packages, including SAS, SPSS, STRATA and others. \n\n### Writing files\nReversely, to write a data frame to a file you can use the generic function:\n```\nwrite.table(x,file=?name.txt?,quote=TRUE,row.names=TRUE,col.names=TRUE)\n```\nThis function has a long list of arguments, the most important ones are:\n- *x*: data frame to be written to a file\n- *file*: name or full path of the file e.g. D:/trainingen/Hormone.csv\n- *quote*: if TRUE, strings, row and column names will be surrounded by double quotes. If FALSE, nothing is quoted.\n- *sep*: column separator\n- *row.names*: boolean indicating whether the row names of x are to be written or a character vector of row names to be written\n- *col.names*: boolean indicating whether the column names of x are to be written or a character vector of column names to be written\n- *append=FALSE*: if TRUE x is **added** to the file defined by *file*\n- *eol = ?\\n?*: end-of-line character, default ?\\n? represents an enter\n- *na=?NA?*: string to use for missing values in the data\n- *dec=?.?*: decimal separator\n\nSee the help file for a full overview of all arguments. \n\nTo specifically write .csv files use write.csv() or write.csv2(). See the help file for a description of the difference between them. \n\nExcel can read .csv files but if you really want to write .xls or .xlsx files use the openxlsx package.  \n\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 17b\n&gt;\n&gt; 1. Read the file [RNASeqDE.txt](http://data.bits.vib.be/pub/trainingen/RIntro/RNASeqDE.txt) into a data frame called DE. It contains the differentially expressed genes from an RNA-Seq experiment.  \n&gt; 2. Split the table into a table of upregulated genes (log2foldchange &gt; 0) and a table of downregulated genes and store them in data frames called up and down.\n&gt; 3. How many up- and downregulated genes are there?\n&gt; 4. What is the gene with the highest log2 fold change?\n&gt; 5. What is the data of the gene with the lowest adjusted p-value (= padj)?\n&gt; 6. Write the Ensembl IDs (= row names) of the upregulated genes to a file called up.txt. You will use this file for functional enrichment analysis using online tools like ToppGene,EnrichR? These tools want a file with only Ensembl IDs as input (one per line, no double quotes, no column headers, no row names).\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  DE &lt;- read.table(\&quot;Rdata/RNASeqDE.txt\&quot;,header=TRUE)\n&gt;    &gt;  up &lt;- DE[DE$log2FoldChange &gt; 0,]\n&gt;    &gt;  down &lt;- DE[DE$log2FoldChange &lt; 0,]\n&gt;    &gt;  nrow(up) \n&gt;    &gt;  nrow(down)\n&gt;    &gt;  rownames(up[which.max(up$log2FoldChange),])\n&gt;    &gt;  DE[which.min(DE$padj),]\n&gt;    &gt;  write.table(rownames(up),file=\&quot;up.txt\&quot;,quote=FALSE,col.names=FALSE,row.names=FALSE)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt; Which of the following 2 commands will not work properly ?\n&gt;    &gt; ```\n&gt;    &gt;  DE &lt;- read.table(\&quot;Rdata/RNASeqDE.txt\&quot;)\n&gt;    &gt;  file &lt;- file.choose()\n&gt;    &gt;  DE &lt;- read.table(file,header=TRUE)\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt; Will the following command work ?\n&gt;    &gt; ```\n&gt;    &gt;  up &lt;- subset(DE,log2FoldChange &gt; 0)\n&gt;    &gt;  \n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt; What&#39;s the difference between these 2 commands ?\n&gt;    &gt;  ```\n&gt;    &gt;  which.max(up$log2FoldChange)\n&gt;    &gt;  max(up$log2FoldChange)\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt; Will this command write Ensembl IDs and log fold changes ?\n&gt;    &gt; ```\n&gt;    &gt;  toprint &lt;- as.data.frame(up$log2FoldChange)\n&gt;    &gt;  write.table(toprint,file=\&quot;up.txt\&quot;,quote=FALSE,col.names=FALSE)\n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 17c\n&gt;\n&gt; Which type of files are imported by read.delim ? \n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt; Check the documentation and look at the default for *sep* \n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 17d\n&gt;\n&gt; 1. Read the file [ALLphenoData.tsv](http://data.bits.vib.be/pub/trainingen/RIntro/ALLphenoData.tsv) into a variable called pdata using one of the read functions\n&gt; 2. What type of data structure is pdata ?\n&gt; 3. What are the names of the columns of pdata ?\n&gt; 4. How many rows and columns are in pdata ? \n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;  ```\n&gt;    &gt;  pdata &lt;- read.delim(\&quot;Rdata/ALLphenoData.tsv\&quot;)\n&gt;    &gt;  class(pdata)\n&gt;    &gt;  colnames(pdata)\n&gt;    &gt;  dim(pdata)\n&gt;    &gt;  ``` \n&gt;    {: .solution}\n{: .hands_on}\n&quot;,&quot;# Tools  \n{:.no_toc}\n\n## Lotus pipeline \nLotuS offers a lightweight complete 16S/18S/ITS pipeline to\n- Demultiplex and filter fasta or fastq sequences\n- Denoise, remove chimeric sequences and cluster sequences into very high quality OTUs that perform at a similar level to mothur / dada2\n- Determine taxonomic origin of each OTU using &gt;5 spezialized and general purpose database or statistical algorithms\n- Construct OTU, genus, family, class, order and phylum abundance tables in .txt or .biom format\n- Reconstruct OTU phylogenetic tree\n\nMore information at [LotuS home page](http://psbweb05.psb.ugent.be/lotus/downloads.html)\n\n## usearch \n\nDownload [usearch version 8](http://www.drive5.com/usearch/download.html) and copy the executable in a folder e.g. /usr.bin/tools/ which you can reach (you might to be superuser for this)\n\nMake executable:\n```\nsudo chmod +x /usr/bin/tools/usearch8.1.1861_i86linux32\n```\n\nCreate a symbolic link into the folder where Lotus will search for it:\n\n``\nsudo ln -s /usr/bin/tools/usearch8.1.1861_i86linux32 /usr/bin/tools/lotus_pipeline/bin/usearch_bin\n```\n\n## R package \n\nYou also need R with the vegan package installed.\n&quot;,&quot;#### Create a project\n\nWhen you use qbase+ for the first time, you can&#39;t do anything unless you\ncreate a project to store your experiments in.\n\n| Create a new Project |\n| :----------------------------------- |\n| When you double click the qbase+ icon, the software starts up automatically opens the Start page where you can create a new project by clicking the Create new project button : This will create a new project with a default name like Project 1 . |\n\n#### Create an experiment\n\nTo open actual data (one/more runs) in qbase+, creating a project is not sufficient. You need to create an experiment in this project to hold the run data.\n\n| Create a new Experiment called GeneExpression in the new project. |\n| :----------------------------------- |\n| Select the Create a new qbase+ experiment option  in the Start page. Type a name for th new experiment . Click the Next button at the bottom of the page . This will create the experiment.\n\nWhen you leave the **Start page**, the **Import run** page is automatically opened allowing you to import the actual qPCR data into qbase+.\n\n#### Loading the data\n\nFirst a few quick words about the data set. Well be working with data coming from 3 runs (plates in the qPCR instrument): [Run1](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run1.xls), [Run2](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run2.xls) and [Run3](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run3.xls)\n\nThe data consist of Cq values for:\n\n  - 3 reference target genes: Stable, Nonregulated, and Flexible\n  - 3 target genes of interest: Duvel, Leffe, and Palm\n\neach measured twice (= technical replicates) in 16 different samples. Half of the samples have undergone a treatment, half of them are untreated control samples.\n\nThe data set also contains a series of standard samples consisting of a four-fold dilution series of cDNA for each target gene. These measurements allow to generate a standard curve from which target-specific amplification efficiencies can be calculated. Finally, negative controls (No Template Controls) have been measured. The goal of the analysis is to identify target genes of interest that have different expression levels in the treated samples compared to the untreated control samples.\n\n| In GeneExpression load CFX run files [Run1](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run1.xls), [Run2](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run2.xls) and [Run3](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run3.xls).\n| :---------------------------- |\n|  \n* Click the **Import runs** button  to open the **Import Run** window\n* Click the **Browse** button  to go to the directory that stores the files containing the qPCR data\n\nSelect the 3 run files simultaneously by holding the **Ctrl** key on your keyboard during the selection in Windows or the command button in MacOSX.\n\nClick the **Open** button \n\nNow you go back to the **Import Run** window, click the **Next** button (purple)\n\n* \nqbase+ tries to recognize the format of the selected import files. If only one format matches the files (as in our case CFX), it is selected and the quick import option is enabled. Click the **Finish** button.\n\nIn the Imported run names area on the **Import run** page you should now see the names of the 3 run files. If these are the correct files, click the **Next** button at the bottom of the page.\n\n#### Adding annotation to the data\n\nWhen you leave the **Import run** page, you are redirected to the **Sample target list** page, which gives you an overview of the targets (= genes) and samples qbase+ detected when reading in the datafiles.\nTake a look at the data. You see that the list of samples and targets matches the description of the qPCR experiment at the top of this page. The samples in this experiment are divided into two groups: samples that received some kind of treatment and untreated control samples. This information was not included in the run files so qbase+ does not know which sample belongs to which group. However, this is relevant information: in our analysis we are going to compare the expression of our genes of interest between treated and untreated samples. This means that qbase+ needs the grouping annotation to be able to perform the analysis we want to do. So we have to give qbase+ this annotation: we can do this by adding a custom sample property. To do this we need to create a sample properties file with a specific format that is described in [the tutorial](http://data.bits.vib.be/pub/trainingen/qbasePLUS/TutorialIII.pdf). You can find the file in the qbase+ folder on the BITS laptops or you can [download the file here](http://data.bits.vib.be/pub/trainingen/qbasePLUS/Sample_Properties_file.xlsx).\n\n| How to add the grouping annotation ?\n| :---------------------------- |\n|  To import the file containing to grouping annotation:\n\n* select **Add samples and targets** \n* click **Import sample list** \n* browse to the folder that contains the samples file\n* select the file and click **Open**\n* click **Next**\n\nIn the **Importing samples** window, you have to tell qbase+ which sample annotation you want to import from the sample properties file\n\nIn our case we could import Quantities (this annnotation is available in the sample properties file) but the quantities of the standard samples were included in the run files so qbase+ has already imported this annotation from the run files during data import.\nWe definitely need to import the Custom properties since they were not a part of the run files. The Treatment property will tell qbase+ which samples belong to the group of control samples and which samples belong to the group of treated samples.\nClick the **Next** button at the bottom of the page to finish the import.\n\nAt this point you don&#39;t see the custom annotation that you have imported, you will see it later in the analysis during scaling\nLeaving the **Sample target list** page takes you to the **Run annotation** page, where you have to confirm again that the sample and gene names are ok. If this is not the case you can adjust the annotation here.\n\nClick the **Next** button at the bottom of the page\n\nOur data file contains all required annotation:\n\n  - Cq values\n  - sample and target names\n  - sample types\n  - quantities for the standard samples\n  - grouping of the samples\n\n\n\nOnce runs are imported, you can start analyzing the data. Data consist\nof Cq values for all the wells.\n\n#### Specifying the aim of the experiment\n\nOn the **Aim** page you tell the software what type of analysis you want to do. Different types of analyses require different parameters, parameter settings and different calculations. By selecting the proper analysis type, qbase+ will only show the relevant parameters and parameter settings.\n\nSince we are doing a **gene expression analysis** in this exercise, this the option we should select. Click the **Next** button on the bottom of the page to go to the **Technical quality control** page.\n\n#### Checking the quality of technical replicates and controls\n\nThe **Technical quality control** page handles the settings of the requirements that the data have to meet to be considered high quality. For instance the maximum difference between technical replicates is defined on this page. If there are technical replicates in the data set, qbase+ will detect them automatically (they have the same sample and target name) and calculate the average Cq value. In theory, technical replicates should generate more or less identical signals.\n\n| How to set the maximum difference in Cq values for technical replicates ?\n| :---------------------------- |\n|  The quality criterium that the replicates must meet to be included for further analysis is one of the parameters in qbase+. You can set it on the **Technical quality control** page:\n\nThe default maximum allowed difference in Cq values between technical replicates is 0.5\n\nAdditionally, you can do quality checks based on the data of the positive and negative controls.\n| How to set quality requirements for the control samples ?\n| :---------------------------- |\n|  On the same **Technical quality control** page you can define the minimum requirements for a well to be included in the calculations:\n\n* **Negative control threshold** : minimum allowed difference in Cq value between the sample with the highest Cq value and the negative control with the lowest Cq value: the default is 5 which means that negative controls should be more than 5 cycles away from the sample of interest.\n* **Lower and upper boundary** : allowed range of Cq values for positive controls.\n\nExcluded means that the data are ignored in the calculations.\n\n| How to check if there are wells that do not meet these criteria ?\n| :---------------------------- |\n|  You can see flagged and excluded data by ticking the **Show details** options  on the **Technical quality control** page and clicking the **Next** button (purple) at the bottom of the page.\n\nQbase+ will open the results of the quality checks for the replicates  and the controls  on two different tabs. These tabs show lists of samples that failed the quality control criteria. When you open the replicates tab  you can get an overview of the flagged  or the excluded (purple) wells. Select the **failing**  wells.\n\nWhen the difference in Cq between technical replicates exceeds 0.5, the wells end up in the flagged or failing list. They are included in calculations unless you exclude them by unticking them. You see that the two replicates of Palm in Sample05 have very different Cq values. All other bad replicates are coming from standard samples.\nIf you are finished checking the data quality, click **Next** to go to the **Amplification efficiencies** page.\n\n#### Taking into account amplification efficiencies\n\nQbase+ calculates an amplification efficiency (E) for each primer pair (= gene). Genes have different amplification efficiencies because:\n\n  - some primer pairs anneal better than others\n  - the presence of inhibitors in the reaction mix (salts, detergents) decreases the amplification efficiency\n  - inaccurate pipetting\n\nQbase+ has a parameter that allows you to specify how you want to handle amplification efficiencies on the **Amplification efficiencies** page.\n\n| How to specify the amplification efficiencies strategy you want to use ?\n| :---------------------------- |\n|  Since we have included a dilution series for creating a standard curve in our qPCR experiment, we will select\n\n* **Use assay specific amplification efficiencies**\n* **Calculate efficiencies from included standard curves**\n\nAmplification efficiencies are calculated based on the Cq values of a serial dilution of representative template, preferably a mixture of cDNAs from all your samples. Since you know the quantity of the template in each dilution, you can plot Cq values against template quantities for each primer pair. Linear regression will fit a standard curve to the data of each gene, and the slope of this curve is used to calculate the amplification efficiency.\n\n| How to check the amplification efficiencies of the genes ?\n| :---------------------------- |\n|  Once you have made this selection, qbase+ starts calculating the efficiencies and the results are immediately shown in the **calculation efficiencies** table.\n\nIn this way, one amplification efficiency (E) for each gene is calculated and used to calculate **Relative Quantities (RQ)**:\nCq is calculated for each well by subtracting the Cq of that well from the average Cq across all samples for the gene that is measured in the well. So Cq is the difference between the Cq value of a gene in a given sample and the average Cq value of that gene across all samples. Cq is subtracted from the average because in this way high expression will result in a positive Cq and low expression in a negative Cq. \n**So at this point the data set contains one RQ value for each gene in each sample.**\n\nClick **Next** to go to the **Normalization** page.\n\n#### Normalization\n\nDifferences in amplification efficiency are not the only source of variability in a qPCR experiment. Several factors are responsible for noise in qPCR experiments e.g. differences in:\n\n  - amount of template cDNA between wells\n  - RNA integrity of samples\n  - efficiency of enzymes used in the PCR or in the reverse\n    transcription\n\nNormalization will eliminate this noise as much as possible. In this way it is possible to make a distinction between genes that are really upregulated and genes with high expression levels in one group of samples simply because higher cDNA concentrations were used in these samples.\nIn qPCR analysis, normalization is done based on housekeeping genes.\n\nHousekeeping genes are measured in all samples along with the genes of interest. In theory, a housekeeping gene should have identical RQ values in all samples. In reality, noise generates variation in the expression levels of the housekeeping genes. This variation is a direct measure of the noise and is used to calculate a normalization factor for each sample.\nThese normalization factors are used to adjust the RQ values of the genes of interest accordingly so that the variability is eliminated.\n\nThese adjusted RQ values are called **Normalized Relative Quantities (NRQs)**. In qbase+ housekeeping genes are called reference genes. In our data set there are three reference genes: Stable, Non-regulated and Flexible. On the **Normalization page** we can define the normalization strategy we are going to use, appoint the reference genes and check their stability of expression.\n\n| How to specify the normalization strategy you want to use ?\n| :---------------------------- |\n|  You can specify the normalization strategy you want to use on the Normalization method page:\n\n* **Reference genes** normalization is based on the RQ values of the housekeeping genes\n* **Global mean** normalization calculates normalization factors based on the RQ values of all genes instead of only using the reference genes. This strategy is recommended for experiments with more than 50 random genes. Random means that the genes are randomly distributed over all biological pathways.\n* **Custom value** normalization is used for specific study types. This strategy allows users to provide custom normalization factors such as for example the cell count.\n* **None** means that you choose to do no normalization at all. This option should only be used for single cell qPCR.\n\nWe have incorporated 3 housekeeping genes in our experiment so we select the **Reference genes** strategy.\n\n| How to appoint reference targets ?\n| :---------------------------- |\n|  You have to indicate which targets should be used as reference genes since qbase+ treats all genes as targets of interest unless you explicitly mark them as reference genes on the Normalization method page:\n\nWe have measured 3 housekeeping genes: Stable, Flexible and Non-regulated so we tick the boxes in front of their names.\n\nIt&#39;s not because you have appointed genes as reference genes that they necessarily are **good** reference genes. They should have stable expression values over all samples in your study. Fortunately, qbase+ checks the quality of the reference genes. For each appointed reference gene, qbase+ calculates two indicators of expression stability\n\n  - **M** (geNorm expression stability value): calculated based on the pairwise variations of the reference genes.\n  - **CV** (coefficient of variation): the ratio of the standard deviation of the NRQs of a reference gene over all samples to the mean NRQ of that reference gene.\n\nIt is considered that the higher these indicators the less stable the reference gene.\n\n| Are Flexible, Stable and Nonregulated good reference targets ?\n| :---------------------------- |\n|  M and CV values of the appointed reference genes are automatically calculated by qbase+ and shown on the Normalization method page:\n\nThe default limits for M and CV were determined by checking M-values and CVs for established reference genes in a pilot experiment that was done by Biogazelle. Based on the results of this pilot experiment, the threshold for CV and M was set to 0.2 and 0.5 respectively.\nIf a reference gene does not meet these criteria it is displayed in red. As you can see the M and CV values of all our reference exceed the limits and are displayed in red.\n\nIf the quality of the reference genes is not good enough, it is advised to remove the reference gene with the worst M and CV values and re-evaluate the remaining reference genes.\n\n| Which reference target are you going to remove ?                                                                                                                                    |\n| :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Both the M-value and the CV are measures of variability. The higher these values the more variable the expression values are. So we will remove the gene with the highest M and CV. |\n\nYou can remove a reference gene simply by unticking the box in front of its name.\n\n| Are the two remaining reference genes good references ?\n| :---------------------------- |\n|  After removing Flexible as a reference gene the M and CV values of the two remaining reference genes decrease drastically to values that do meet the quality criteria. M and CV values that meet the criteria are displayed in green.\n\nThis exercise shows the importance of using a minimum of three reference genes. If one of the reference genes does not produce stable expression values as is the case for Flexible, you always have two remaining reference genes to do the normalization.\n\n[See how to select reference genes for your qPCR experiment](http://wiki.bits.vib.be/index.php/Using_GeneVestigator_to_select_candidate_reference_genes).\n\n**So after normalization you have one NRQ value for each gene in each sample.**\n\nClick **Next** to go to the **Scaling** page.\n\n#### Scaling\n\nRescaling means that you calculate NRQ values relative to a specified reference level.\n\nQbase+ allows you to rescale the NRQ values using one of the following as a reference:\n\n  - the sample with the minimal expression\n  - the average expression level of a gene across all samples\n  - the sample with the maximal expression\n  - a specific sample (e.g. untreated control)\n  - the average of a certain group (e.g. all control samples): this is\n    often how people want to visualize their results\n  - positive control: only to be used for copy number analysis\n\nAfter scaling, the expression values of the choice you make here will be set to 1 e.g. when you choose **average** the average expression level across all samples will be set to 1 and the expression levels of the individual samples will be scaled accordingly.\n\n| How to scale to the average of the untreated samples ?\n| :---------------------------- |\n|  You can specify the scaling strategy on the **Scaling** page. Select **Scale to group** and set the **Scaling group** to the **untreated** samples . This is one of the reasons why you need the grouping annotation.\n\nRescaling to the average of a group is typically used to compare results between 2 groups, e.g. treated samples against untreated controls. After rescaling, the average of the NRQs across all untreated samples is 1 and the NRQs of the treated samples are scaled accordingly.\n\nClick **Next** to go to the **Analysis** page.\n\n#### Visualization of the results\n\nOne of the things you can select to do on the **Analysis** page is viewing the relative expression levels (= scaled NRQs) of each of the genes in a bar chart per gene. It is recommended to visualize your results like this.\n\nIt is possible to view the relative expression levels of all genes of interest on the same bar chart. You can use this view to see if these genes show the same expression pattern but you cannot directly compare the heights of the different genes because each gene is independently rescaled\\!\n\n| How to visualize single gene expression bar charts ?\n| :---------------------------- |\n|  Select **Visually inspect results For individual targets** on the **Analysis** page and click **Finish**\n\n| How to visualize the expression levels of Palm in each sample ?\n| :---------------------------- |\n|  Select **Visually inspect results For individual targets** on the **Analysis** page and click **Finish**\n\nThe **Target** select box allows you to select the gene you want to view the expression levels of. Relative expression levels are shown for each sample. Error bars are shown and represent the technical variation in your experiment (variation generated by differences in amounts pipetted, efficiency of enzymes, purity of the samples...).\n\nYou see that Palm has a low expression level and a very large error bar in Sample05 because the two replicates of this sample had very different Cq values. You can group and colour the bars according to a property.\n\n| How to group the bars of Palm according to treatment (so treated at one side and untreated at the other side)\n| :---------------------------- |\n|  In the **Grouping** section you can specify the property you want to group by.\n\n| How to view average expression levels in each group ?\n| :---------------------------- |\n|  In the **Grouping** section you can choose to plot individual samples as shown above but you can also choose to **plot group average** expression levels.\n\nThe error bars that you see here represent biological variation and will be used later on in the statistical analysis. The error bars are 95% confidence intervals which means that they represent the range that will contain with 95% certainty the real average expression level in that group of samples.\nThe nice characteristic of 95% confidence intervals is the following:\n\n  - if they do not overlap you are sure that the expression levels in the two groups are significantly different, in other words the gene is differentially expressed\n  - if they do overlap you cannot say that you are sure that the expression levels are the same. You simply dont know if the gene is differentially expressed or not.\n\n| Assess the effect of switching the Y-axis to a logarithmic scale for Palm.\n| :---------------------------- |\n|  In the **Y axis** section you can specify if you want a linear or logarithmic axis.\nAs you can see you do not change the expression values, you just change the scale of the Y axis. Switching the Y-axis to a logarithmic scale can be helpful if you have large differences in NRQs between different samples\n\n| Assess the effect of switching the Y-axis to a logarithmic scale for Flexible.\n| :---------------------------- |\n|  Switch to the bar charts of Flexible. By switching the Y-axis to logarithmic you can now see more clearly the differences between samples with small NRQs.\n\n#### Statistical analysis\n\nOnce you generate target bar charts you leave the **Analysis wizard** and you go to the regular qbase+ interface. Suppose that you want to perform a statistical test to prove that the difference in expression that you see in the target chart is significant.\nAt some point, qbase+ will ask you if your data is coming from a normal distribution. If you don&#39;t know, you can select **I don&#39;t know** and qbase+ will assume the data are not coming from a normal distribution and perform a stringent non-parametric test.\nHowever, when you have **7 or more replicates per group**, you can check if the data is normally distributed using a statistical test. If it is, qbase+ will perform a regular t-test. The upside is that the t-test is less stringent than the non-parametric tests and will find more DE genes. However, you may only perform it on normally distributed data. If you perform the t-test on data that is not normally distributed you will generate false positives i.e. qbase+ will say that genes are DE while in fact they are not. Performing a non-parametric test on normally distributed data will generate false negatives i.e. you will miss DE genes.\n\nChecking if the data is normally distributed can be easily done in GraphPad Prism. To this end you have to export the data.\n| How to export the data ?\n| :---------------------------- |\n|  To export the results click **the upward pointing arrow** in the qbase+ toolbar:\nYou want to export the normalized data so select **Export Result Table (CNRQ)**:\nYou will be given the choice to export results only (CNRQs) or to include the errors (standard error of the mean) as well . We don&#39;t need the errors in Prism so we do not select this option.\nThe scale of the Result table can be linear or logarithmic (base 10) . Without user intervention, qbase+ will automatically log10 transform the CNRQs prior to doing statistics. So we need to check in Prism if the log transformed data are normally distributed.\nAdditionally, you need to tell qbase+ where to store the file containing the exported data. Click the **Browse** button for this .\n\nExporting will generate an Excel file in the location that you specified. However, the file contains the results for all samples and we need to check the two groups (treated and untreated) separately. The sample properties show that the even samples belong to the treated group and the odd samples to the untreated group.\nThis means we have to generate two files:\n\n  - [a file containing the data of the untreated samples](http://data.bits.vib.be/pub/trainingen/qbasePLUS/resultslog.csv)\n  - [a file containing the data of the treated samples](http://data.bits.vib.be/pub/trainingen/qbasePLUS/resultslogTreated.csv)\n\nNow we can open these files in Prism to check if the data is normally distributed.\n\n| How to import the data of the untreated samples in Prism ?\n| :---------------------------- |\n|  \n* Open Prism\n* Expand **File** in the top menu\n* Select **New**\n* Click **New Project File**\n* In the left menu select to create a **Column** table. Data representing different groups (in our case measurements for different genes) should always be loaded into a column table.\n* Select **Enter replicate values, stacked into columns** (this is normally the default selection) since the replicates (measurements for the same gene) are stacked in the columns.\n* Click **Create**\n\nPrism has now created a table to hold the data of the untreated samples but at this point the table is still empty. To load the data:\n\n* Expand **File** in the top menu\n* Select **Import**\n* Browse to the resultslog.csv file, select it and click **Open**\n* In the **Source** tab select **Insert data only**\n* Since this is a European csv file commas are used as decimal separators so in contrast to what its name might imply, semicolons and not commas are used to separate the columns in the csv file (you can open the file in a text editor to take a look). In American csv files dots are used as decimal separator and the comma is used to separate the columns. Prism doesn&#39;t know the format of your csv file so you have to tell him the role of the comma in your file. Select **Separate decimals**\n* Go to the **Filter** tab and specify the rows you want to import (the last rows are these of the standard and the water samples, you don&#39;t want to include them)\n* Click **Import**\n\nAs the file is opened in Prism you see that the first column containing the sample names is treated as a data column. Right click the header of the first column and select **Delete**\n\n| How to check if the data of the untreated samples comes from a normal distribution ?\n| :---------------------------- |\n|  \n* Click the **Analyze** button in the top menu\n* Select to do the **Column statistics** analysis in the **Column analyses** section of the left menu\n* In the right menu, deselect **Flexible**. It&#39;s a bad reference gene so you will not include it in the qbase+ analysis so there&#39;s no point checking its normality (it is probably not normally distributed). In that respect you could also deselect the other two reference genes since you will do the DE test on the target genes and not on the reference genes.\n* Click **OK**\n* In the **Descriptive statistics** and the **Confidence intervals** section deselect everything except **Mean, SD, SEM**. These statistics is not what we are interested in: we want to know if the data comes from a normal distribution. The only reason we select Mean, SD, SEM is because if we make no selection here Prism throws an error.\n* In the **Test if the values come from a Gaussian distribution** section select the **D&#39;agostino-Pearson omnibus test** to test if the data are drawn from a normal distribution. Although Prism offers three tests for this, the D&#39;Agostino-Pearson test is the safest option.\n* Click **OK**\n\nPrism now generates a table to hold the results of the statistical analysis: As you can see, the data for Palm are not normally distributed.\n\nSince we found that there&#39;s one group of data that does not follow a normal distribution, it&#39;s no longer necessary to check if the treated data are normally distributed but you can do it if you want to. We will now proceed with the statistical analysis in qbase+. Statistical analyses can be performed via the **Statistics wizard**.\n\n| How to open the Statistics wizard ?\n| :---------------------------- |\n|  You can open it in the **Project Explorer** (window at the left):\n\n* expand **Project1** if it&#39;s not yet expanded\n* expand the **Experiments** folder in the project if it&#39;s not yet expanded\n* expand the **GeneExpression** experiment if it&#39;s not yet expanded\n* expand the **Analysis** section if it&#39;s not yet expanded\n* expand the **Statistics** section\n* double click **Stat wizard**\n\nThis opens the **Statistics wizard** that allows you to perform various kinds of statistical analyses.\n\n| Which kind of analysis are you going to do ?                                                                                                                                                                                                                                                      |\n| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| On the **Goal** page: Select **Mean comparison** since you want to compare expression between two groups of samples so what you want to do is comparing the mean expression of each gene in the treated samples with its mean expression level in the untreated samples. Click **Next**. |\n\n| How to define the groups that you are going to compare ?\n| :---------------------------- |\n|  On the **Groups** page: specify how to define the two groups of samples that you want to compare. Select **Treatment** as the grouping variable to compare treated and untreated samples. Click **Next**.\n\n| How to define the genes that you want to analyze ?\n| :---------------------------- |\n|  On the **Targets** page: specify for which targets of interest you want to do the test. Deselect **Flexible** since you do not want to include it in the analysis. It&#39;s just a bad reference gene. Click **Next**.\n\nOn the **Settings** page you have to describe the characteristics of your data set, allowing qbase+ to choose the appropriate test for your data. \n\nThe first thing you need to tell qbase+ is whether the data was drawn from a normal or a non-normal distribution. Since we have 8 biological replicates per group we can do a test in Prism to check if the data are normally distributed.\n\n| Which gene(s) is/are differentially expressed ?\n| :---------------------------- |\n|  On the **Settings** page you describe the characteristics of your data set so that qbase+ can choose the ideal test for your data. For our data set we can use the default settings. Click **Next**. In the results **Table** you can see that the p-value for Palm is below 0.05 so Palm is differentially expressed.\n\n\n\nIn this example we will analyze data from another expression study with the following characteristics:\n\nAll samples fit in a single run: [Run7](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run7.xls)\nWe have the following samples:\n\n  - 5 control samples: control1, control2\n  - 5 treated samples: treated1, treated2\n  - 1 no template control: NTC\n\nThe expression of the following genes was measured:\n\n  - 2 reference genes: refgene1 and refgene2\n  - 2 genes of interest: gene1 and gene2\n\nThere are two technical replicates per reaction\n\n#### Creating a new experiment\n\n| Create a new Experiment called GeneExpression2 in Project1\n| :---------------------------- |\n| You can find the details on how to create a new experiment in Creating a project and an experiment\n\n#### Loading the data\n\n| Import [Run7](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run7.xls). This file is in qBase format.                    |\n| :-------------------------------------------------------------------------------------------------------------------------------------- |\n| You can find the details on how to import the data file in the **Loading the data into qbase+** section of Analyzing data from a geNorm pilot experiment in qbase+ |\n\n#### Adding sample annotation\n\nDownload the [the sample properties file](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Sample_Properties_GE2.xlsx).\n| Add a custom sample property called Treatment.\n| :---------------------------- |\n| You can find the details on how to add a custom sample property in the **Adding annotation to the data** section of Loading data into qbase+\n\n#### Analyzing the data\n\n| Choose the type of analysis you want to perform.\n| :---------------------------- |\n| \n\n| Check controls and replicates.\n| :---------------------------- |\n| First set the minimum requirements for controls and replicates  You see that 6 replicates do not meet these requirements . Select to **Show details and manually exclude bad replicates**\nAll negative controls pass the test . Positive controls were not included in this analysis. Qbase+ will now open the results for the failing replicates: as you can see the difference in Cq values between these replicates is not that big. They fail to meet the requirement just slightly.\n\n| Which amplification efficiencies strategy are you going to use ?\n| :---------------------------- |\n| You don&#39;t have data of serial dilutions of representative template to build standard curves so the only choice you have is to use the default amplification efficiency (E = 2) for all the genes.\n\n| Appoint the reference genes as reference targets.\n| :---------------------------- |\n| You can find the details on how to appoint reference targets in the **Normalization** section of Analyzing gene expression data in qbase+\n\n| Is the stability of the reference genes ok ?\n| :---------------------------- |\n| In the **Reference target stability window** the M and CV values of the reference genes are shown in green so the stability of the reference genes is ok. You can find the details on how to check reference target stability in the **Normalization** section of [](Analyzing_gene_expression_data_in_qbase+\&quot; title=\&quot;wikilink)Analyzing gene expression data in qbase+\n\n| Which scaling strategy are you going to use ?\n| :---------------------------- |\n| Since you have a treated and a **control** group, it seems logical to use the average of the control group for scaling. You can find the details on how to specify the scaling strategy in the **Scaling** section of Analyzing gene expression data in qbase+\n\nLook at the target bar charts.\n\n| In the target bar charts group the samples according to treatment.\n| :---------------------------- |\n| You can find the details on how to group the samples in the **Visualization of the results** section of Analyzing gene expression data in qbase+\n\nThe samples of each group are biological replicates so you might want to generate a plot that compares the average expression of the treated samples with the average expression of the untreated samples.\n\n| In the target bar charts plot the group averages instead of the individual samples.\n| :---------------------------- |\n| In the **Grouping** section at the bottom of the chart you can select **Plot group average**:\n\n| Are there any genes for which you see a clear difference in expression between the two groups ?\n| :---------------------------- |\n| For gene 1, the mean expression levels in the two groups are almost the same and the error bars completely overlap.\n\nWhen you look at the title of the Y-axis, you see that 95% confidence levels are used as error bars. In case of 95% confidence intervakls you can use the following rules:\n\n* if they do not overlap: you are certain that the difference between the means of the two groups is significant\n* if they do not overlap: you know nothing with certainty: the means can be different or they can be the same\n\nSo for gene 1 the means are very close but just based on the plot we may not make any conclusions with certainty. For gene 2, the mean expression levels in the two groups are very different and the error bars do not overlap. So the 95% confidence intervals do not overlap meaning that we can be certain that the difference between the means of the two groups is significant.\n\n| Use a statistical test to compare the expression levels between the two groups of samples ?\n| :---------------------------- |\n| You only have 5 replicates per group so you cannot test if the data comes from a normal distribution. Qbase+ will assume they&#39;re not normally distributed and perform a non-parametric Mann-Whitney test.\n\nThe p-value of gene2 is smaller than 0.05 so it has a statistically significant difference in expression levels in treated samples compared to untreated samples. For gene1 the p-value is 1 so we have no evidence to conclude that the expression of gene1 is different in treated compared to untreated samples. You can find the details on how to compare the means of the two groups in the **Statistical analysis** section of Analyzing gene expression data in qbase+\n&quot;,&quot;The following exercise will make you familiar with the Primer3Plus software for designing primers for PCR. Primer3Plus is the user-friendly version of Primer3, the standard software for primer design.\n\n### Criteria for qPCR primers\n\nPrimers for qPCR have to follow all the gudelines for regular primers is and an additional set of rules specific for qPCR primers:\n\n  - qPCR products are small: 80-160 bp\n  - use intron or exon-exon junction spanning primers to detect genomic DNA contamination in the RNA samples. Primers of intron spanning primer pairs are located at both sides of an intron and will therefore generate a larger product on genomic DNA (containing the intron). Primer pairs containing an exon-exon junction spanning primer will not generate a PCR product on genomic DNA since the exon-exon junction only exist in the cDNA.\n  - primer length between 9 and 30 bp with an optimum at 20 bp\n  - melting temperature (Tm) of the primers between 58 and 60C with an optimum at 59C\n  - maximum Tm difference between the primers of a pair: 2C\n  - GC content of the primers between 30 and 80% with an optimum at 50%\n  - the 5 nucleotides at the 3&#39; end of the primers should have no more than 2 G or C bases\n  - avoid runs of 4 or more identical nucleotides (especially Gs)\n  - primers must specifically target the region you want to amplify\n\nThere are many programs for designing primers, the most important ones:\n\n  - [Primer3](http://frodo.wi.mit.edu/) \\[1\\] or use it&#39;s user-friendly version: [Primer3Plus](http://primer3plus.com/cgi-bin/dev/primer3plus.cgi)\\[2\\]\n  - [PrimerBLAST](http://www.ncbi.nlm.nih.gov/tools/primer-blast/index.cgi?LINK_LOC=BlastHome)\\[3\\]\n\nThe major downside of Primer3 and Primer3Plus is the fact that you have to check the specificity of the primers yourself. Primer3 will suggest a number of primer pairs that fulfill all of the above requirements, but Primer3 will not check the specificity of the primers. So you have use BLAST to check the specificity of the suggested primer pairs. Very often, the selected primers are not specific and you have to repeat the entire Primer3 analysis.\nIf you use Primer3 and do the BLAST yourself, BLAST against Refseq sequences unless they are not available for the organism you work with or you have reasons to believe that they are not complete (i.e. they do not represent the full genome). For model organisms, you can BLASTagainst the Refseq database. Limit the database to sequences from the organism you work with.\nAdditionally, it is especially important to check that the primers are specific at the 3&#39; end because that&#39;s the site where the polymerase will attach nucleotides. So it is recommended to not use primers that contain long identical stretches (\\&gt; 15nt for primers of 20nt long) to other regions in the genome, and certainly not if these stretches comprise the last nucleotide at the 3&#39; end of the primer.\nFor these exercises we will use PrimerBLAST since [it uses the same algorithm to pick primers as Primer3](http://www.ncbi.nlm.nih.gov/tools/primer-blast/primerinfo.html) \\[4\\] and does the specificity check for you\\!\n\n## Designing qPCR primers for the fruit fly tap gene\n\n### Designing qPCR primers using PrimerBLAST\n\nThe RefSeq entry NM_079400 contains the sequence of the D. melanogaster mRNA coding for tap, the target of Poxn. Tap encodes a bHLH protein expressed in larval chemosensory organs and involved in the response to sugar and salt. We wish to amplify the region encoding the Helix-loop-helix domain. In the sequence of the RefSeq record, the domain is located between position +577 and +745.\nWe want to design qPCR primers for measuring the expression level of the hlh domain using SYBR green. Remember that it is advised to design intron/exon-exon junction spanning primers for qPCR experiments that are based on fluorescent labels to detect/avoid amplification of contaminating genomic DNA.\n\n| Check in NCBIs Gene database if the hlh domain contains any introns ? |\n| :------------------------------ |\n|To know the location of the introns, you need the genomic sequence instead of the mRNA sequence.\n\n - Go to [the NCBI RefSeq record](https://www.ncbi.nlm.nih.gov/nuccore/NM_079400).\n - In the right menu click the link to the **Gene** record\n - In the **Genomic regions, transcripts and products** secton you can see that the gene contains no introns: the transcript is not chopped up into pieces when aligned to the genome. Click [here](https://www.ncbi.nlm.nih.gov/gene/39934) for an example of a gene with introns.\n\nNext, we will design primers to measure the expression of the hlh domain.\n\n| Go to Primer BLAST by using the link in the Refseq record |\n| :------------------------------ |\n|Go back to the RefSeq mRNA record. There, you can go directly to PrimerBLAST by clicking the **Pick Primers** link in the **Analyze this sequence** section of the right menu.\n\nSince you want to measure the expression of the hlh domain you want\nprimers that are located inside the domain.\n\n| Define the range of the sequence in which you want to design primers. |\n| :------------------------------ |\n|You have to specify the range as follows:\n\n| Define the primer parameters to comply with the rules of qPCR primer design: product size and Tm. |\n| :------------------------------ |\n|To comply with the rules for qPCR primer design, you have to change the settings for PCR product size and melting temperature:\n\n| The PrimerBLAST automatically decides to check primer specificity in the Drosophila (organism ID: 7227) RefSeq mRNA database which is exactly what you want. For the qPCR you are going to use RNA samples from fruitfly. This means that the primers will only come into contact with Drosophila mRNAs so you only have to check their specifity in this database. Make sure the last 2 nucleotides are completely specific. |\n| :------------------------------ |\n|You want to ensure that the 3&#39; end of the primers really is specific:\n\nThe PrimerBLAST gives you a set of 9 primer pairs that are specific (according to the criteria that you have specified) and that fulfill all other requirements that you have defined. Look at the detailed report of the first primer pair:\nAll parameters are quite self-explanatory except for the Self complementary and Self 3&#39;complementarity scores.\n\n  - The first score represents the local alignment score when aligning a primer to itself. The scoring system gives 1.00 for a match, -1.00 for a mismatch. This means that the lower the score (the more mismatches), the less likely that the primer binds to itself.\n  - The second score represents the global alignment score when aligning a primer to itself. Here again, the lower the score, the better.\n\nThe scores are followed by information on the specificity of the primer: alignments of the two primers to all target sequences from the database that match the criteria that you specified. In these alignments dots represent matching nucleotides while letters represent mismatches. A specific primer pair will have two alignments (one for each primer): both perfect alignments (all dots) to the sequence you want to amplify.\n\n### Analyzing primer characteristics using OligoAnalyzer\n\n[OligoAnalyzer](https://eu.idtdna.com/calc/analyzer) is a tool implemented by ID\\&amp;T (who sell primers) to check the characteristics of your primers. Take the first primer that is suggested by Primer-BLAST, the pair resulting in a product of 100bp.\n\n| What&#39;s the Tm of the first primer ? |\n| :------------------------------ |\n|Copy the sequence of the first primer in the **Sequence** box, adjust the concentrations to these that are typically used in PCR (see slides) and click **Analyze**:\nAs you can see the predicted melting temperature is 63.9 C, which is slightly different from the prediction made by BLAST. There are many different methods to predict Tm and each method will give a different result. Assumed concentrations of primers and ions have an enormous impact on the Tm prediction. So don&#39;t worry about these differences: these are theoretical calculations anyway, the only way to determine Tm values is by doing actual PCR. As long as the difference in Tm between the two primers is not too large, everything is fine.\n\n| What&#39;s the Tm of the second primer ?                                                                                                                                             |\n| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Copy the sequence of the second primer in the **Sequence** box and click **Analyze**. The predicted melting temperature is also 63.9 C , the same Tm as the first primer. |\n\nRemember that the second primer had a large Self complementarity score according to PrimerBLAST.\n\n| Check the self-complementarity of the second primer in OligoAnalyzer ? |\n| :------------------------------ |\n|Click **Self-Dimer**:\n\nYou see that the highest scoring alignment indeed has 6 matches, giving a score of 6 as predicted by PrimerBLAST.\n\n| Do you expect this self-complementarity will give problems in the PCR ? |\n| :------------------------------ |\n|No, the complementarity is concentrated at the center of the primer, not at the 3&#39; end. Since polymerases add bases at the 3 end of the primer, the primer duplex cannot be extended so it will not give rise to aspecific products. [ID&amp;amp;T](https://eu.idtdna.com/pages/docs/default-source/default-document-library/idt_self-dimer_and_hetero-dimer_results_guide.pdf) recommends to avoid complementary stretches of more than 2 bp at the 3 end.\nHowever, even if the primer dimer cannot be extended, it could interfere when its formation competes with the annealing of primer and target. This is only the case when the stability of the dimer is similar to the stability of a perfectly matched primer-target duplex. The stability of the perfectly matched duplex is shown as a Maximum Delta G at the top of results. So non-extendable dimer structures that are much shorter than the intended duplex, as we have here, are not going to disrupt the PCR reaction.\nIt is advised to review all possible interactions between primers so both Self-Dimer (primers binding to themselves) and Hetero-Dimer (primers binding to each other) interactions between primers are examined.\n\n| Is it likely that the primers bind to each other ? |\n| :------------------------------ |\n|Click **Hetero-Dimer**:\n\nThis opens a text box to enter the second primer. Click **Analyze**. There is one structure (the fourth one) that looks problematic because there is a stretch of 3 matching nucleotides at the 3&#39;end of one of the primers.\n\nSo you might consider taking a look at the second pair of primers that PrimerBLAST suggests. On the other hand, this structure is has relatively high free energy (delta G). The structure with the lowest total free energy, the target-primer duplex, is most important because it will dominate in solution. Structures with higher free energy are less stable and will be present in smaller amounts in the reaction mixture.\n\nTake a look at the second primer pair that was suggested by PrimerBLAST.\n\n| Is it likely that these primers bind to each other ?                                 |\n| :----------------------------------------------------------------------------------- |\n| No these primers do not form duplex structures that could pose a problem during PCR. |\n\n## Designing qPCR primers for the human F9 gene\n\n### Designing qPCR primers using PrimerBLAST\n\nThe RefSeq entry NM_000133.3 contains the sequence of the human mRNA coding for coagulation factor F9. The gene contains 8 coding exons and gives rise to a transcript of 2780 bp encoding a protein of 461 amino acids.\nNext, we want to design primers to measure the expression of the F9 gene.\n\nGo to [the RefSeq record of this transcript](http://www.ncbi.nlm.nih.gov/nuccore/NM_000133.3) to study its structure. When you scroll down to the **features** section you see that the CDS is located from position 40 to position 1415. Since RNA degradation starts at the 5&#39;end of transcripts, we don&#39;t want to pick primers at the 5&#39;end. On the other hand, we don&#39;t want to pick primers in the long 3&#39;UTR either because it doesn&#39;t contain any introns (the exons are all coding) and we want to design exon-exon junction or intron spanning primers.\nLet&#39;s try to find exon-exon junction spanning primers between position 400 and 1600, with optimal anneal temperature = 60.\n\n| Find primers that fulfill the above defined criteria |\n| :------------------------------ |\n|Go to [PrimerBLAST](http://www.ncbi.nlm.nih.gov/tools/primer-blast/index.cgi?LINK_LOC=BlastHome) and fill in the form as follows:\n\nExclude predicted sequences in the database to search in .\n\n| Find primers that fulfill the above defined criteria |\n| :------------------------------ |\n|Go to [PrimerBLAST](http://www.ncbi.nlm.nih.gov/tools/primer-blast/index.cgi?LINK_LOC=BlastHome) and fill in the remainder of the form as follows:\n\nThe PrimerBLAST gives you a set of 10 primer pairs. Look at the detailed\nreport of the first primer pair:\n\nAs you can see the primers are not specific: they can bind to various other targets albeit with lower affinity because of the mismatches . The best option seems to be primer pair 7, which binds to both F9 transcript variants and potentially to one unintended target, but as you can see the last nucleotide at the 3&#39; end of both primers are specific.\n\n### In silico PCR in the UCSC Browser\n\nWe will proceed using the third primer pair Primer-BLAST suggests. You can visualize the PCR product (and additional annotation) in the UCSC Genome Browser using [UCSC&#39;s In Silico PCR tool](http://genome.ucsc.edu/cgi-bin/hgPcr).\nSelect the most recent version of the human genome and paste the sequences of forward and reverse primers in their respective boxes. Click **submit**\nNormally, this returns the location and the sequence of the PCR product but our primer pair doesn&#39;t return a match. When you think about this was to be expected since we are working with exon-exon junction spanning primers that are not able to match the genome sequence. So checking SNPs is not so straight-forward in the case of exon-exon junction spanning primers.\nWe will repeat the primer search now searching for intron-spanning primers to show you how to use the in silico PCR tool. Taking into account the fact that the results for the exon-exon junction spanning primers were so messy we will make the search more stringent this time:\n\n  - We will the minimum number of mismatches to 4\n  - and at least 3 mismatches in the last 3 bps at the 3&#39;end\n\n| Find intron spanning primers that fulfill the above defined criteria |\n| :------------------------------ |\n|Go back to the Primer-BLAST and fill in the form like in the previous exercise except that they should span an intron:\n\nPrimer-BLAST returns 10 primer pairs. Again the seventh primer pair is\nthe specific one.\n\n| Take the seventh suggested primer pair and check for SNPs in the UCSC Browser |\n| :------------------------------ |\n|Go to [PrimerBLAST](http://www.ncbi.nlm.nih.gov/tools/primer-blast/index.cgi?LINK_LOC=BlastHome) and paste the sequences of forward and reverse primers in their respective boxes.\nThis time the search finds a PCR product:\n\nClicking the location visualizes the PCR product in the UCSC genome browser. Remove unnecessary trancks by right clicking the box in front of them and selecting **hide**\n\nAdd tracks showing relevant annotation like position of SNPs...\n\nSetting the SNPs track from **hide** to **full** shows the SNPs in the browser. Center the forward primer by grabbing and dragging it to the center.\n\nZoom in to **base** display to see if the forward primer is matching any SNPs.\n\nAs you can see the forward primer does match two SNPs but none of them are located near the 3&#39;end of the primer.\n\n1.  &lt;http://frodo.wi.mit.edu/&gt;\n2.  &lt;http://primer3plus.com/cgi-bin/dev/primer3plus.cgi&gt;\n3.  &lt;http://www.ncbi.nlm.nih.gov/tools/primer-blast/index.cgi?LINK_LOC=BlastHome&gt;\n4.  &lt;http://www.ncbi.nlm.nih.gov/tools/primer-blast/primerinfo.html&gt;&quot;,&quot;# Data structures in R\n{:.no_toc}\n\nThe power of R lies not in its ability to work with simple numbers but in its ability to work with large datasets. R has a wide variety of data structures including scalars, vectors, matrices, data frames, and lists.\n\n### Vectors\nThe simplest data structure is the *vector*, a single row consisting of data values of the same type, e.g. all numbers, characters, Booleans... \n\n#### Creating a vector\nThe function **c()** (short for \&quot;combine values\&quot; in a vector) is used to create vectors. The only arguments that need to be passed to c() are the  values that you want to combine into a vector. \nYou can create a **numeric** (a), **character** (b) or **logical** (c) vector:\n```\na &lt;- c(1,2,5.3,6,-2,4)\nb &lt;- c(\&quot;janick\&quot;,\&quot;jasper\&quot;,\&quot;niels\&quot;)\nc &lt;- c(TRUE,TRUE,TRUE,FALSE,TRUE,FALSE)\n```\nYou can also create a vector by **joining existing vectors with the c () function:**\n```\nx1 &lt;- c(1,2,3)\nx2 &lt;- c(3,4)\nc(x1,x2)\n# [1] 1 2 3 3 4\n```\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Data Creation: vectors** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 4a\n&gt;\n&gt; You count every day how many plants of the initial set of 40 plants developed lesions as a result of a mold infection. \n&gt; \n&gt; 1. Create a vector called Plants_with_lesions containing the results of your counts: 1,3,4,2,6\n&gt; 2. Create a vector days containing the days of the week in the following format: Mon, Tues, Wednes, Thurs, Fri.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  &gt; Plants_with_lesions &lt;- c(1,3,4,2,6)\n&gt;    &gt;  &gt; days &lt;-  c(\&quot;Mon\&quot;,\&quot;Tues\&quot;,\&quot;Wednes\&quot;,\&quot;Thurs\&quot;,\&quot;Fri\&quot;)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 4b\n&gt;\n&gt; Create a vector newVector with the following elements: 2,5,5,3,3,6,2 and print its content.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  newVector &lt;- c(2,5,5,3,3,6,2)\n&gt;    &gt;  newVector\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\nIf you need a sequence of consecutive integers you can create it with the **start:end** notation, e.g. a vector with values from 5 through 9\n```\n5:9\t\n# [1] 5 6 7 8 9\n```\nYou can also define a decreasing sequence of integers:\n```\n9:5\t\n# [1] 9 8 7 6 5\n```\nYou can create the same vector with the seq() function:\n```\nseq(5,9)  \n# [1] 5 6 7 8 9\n```\n\nBut seq (short for sequence) can do a lot more: it allows to take increments other than 1. It takes four arguments:\n- *from*: the first number in the sequence\n- *to*: the last possible number in the sequence. \n- *by=increment*: increment, can be added or subtracted depending on the start and the end of the sequence. If from &gt; to then subtract increment, if from &lt; to then add increment.\n- *length.out*: alternative to end, number of elements in the vector.\n\nAs you can see, some arguments of a function have a name, e.g. the increment argument is called *by*. \n\nThe **rep()** function **repeats** a value a specified number of times.\n```\nrep(\&quot;bla\&quot;, 3)\n# [1] \&quot;bla\&quot; \&quot;bla\&quot; \&quot;bla\&quot;\n```\nYou can combine these functions with the c() function to make more complicated vectors:\n```\nc(rep(1,3), rep(2,3), rep(3,3))\n# [1] 1 1 1 2 2 2 3 3 3\n```\n\nTo generate a **random** set of **numbers** drawn from a normal distribution with a given mean and spread use the **rnorm(n, mean = 0, sd = 1)** function where:\n- *n*: how many random numbers do you want ?\n- *mean*: mean of the normal distribution\n- *sd*: standard deviation of the normal distribution\n```\nrnorm(1000, 3, 0.25)\n```\ngenerates 1000 numbers from a normal distribution with mean 3 and sd=0.25\n\nThe normal distribution implies that numbers close to the mean have a higher probability of occurring than numbers far from the mean.\n\nIf you want a set of random numbers from a uniform distribution (every number in the specified range has the same probability of being drawn) you can use the **runif(n, min=0, max=1)** function where:\n- *n*: how many random numbers do you want ?\n- *min*: lowest number of the range of numbers to choose from\n- *max*: highest number of the range of numbers to choose from\n\nThe most freedom is given by the **sample(x, size, replace = FALSE)** function: it takes a random sample of a specified size from the elements of x either with or without replacement:\n- *x*: a vector of elements from which to choose\n- *size*: how many random numbers do you want ?\n- *replace*: place sampled numbers back in set or not ?\n```\nsample(c(0,1), 100, replace=TRUE)\n```\t\ngenerates a set of 100 random zeros or ones.\n\nSuppose you want to simulate 10 rolls of a dice. Because the outcome of a single roll is a number between 1 and 6, your code looks like this:\n```\nsample(1:6, 10, replace=TRUE)\n# [1] 2 2 5 3 5 3 5 6 3 5\n```\nYou tell sample() to return 10 values, each in the range 1:6. Because every roll of dice is independent, you sample with replacement. This means that you put the element you?ve drawn back into the list of values to choose from.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 4c\n&gt;\n&gt; For a study checking the effect of a drug on a disease, we want to store patient info. \n&gt; \n&gt; 1. Create a vector named ID containing numerical values 1,2,3,4\n&gt; 2. Create a vector named treatment containing values A, placebo, B, and a missing value.\n&gt; 3.  Use the rep() function to create a vector called smoking containing booleans true, true, true, and false. Check the documentation and the examples of usage of rep(). \n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  ID &lt;- 1:4\n&gt;    &gt;  treatment &lt;- c(\&quot;A\&quot;,\&quot;placebo\&quot;,\&quot;B\&quot;,NA)\n&gt;    &gt;  smoking &lt;- c(rep(TRUE,3),FALSE)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt;  ```\n&gt;    &gt;  smoking &lt;- c(rep(true,3),false)\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt;  ```\n&gt;    &gt;  smoking &lt;- c(rep(\&quot;true\&quot;,3),\&quot;false\&quot;)\n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 4d\n&gt;\n&gt; Create vector threes consisting of 3,3,3,3,3,3,3 and print the content of threes\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  threes&lt;-rep(3,7)\n&gt;    &gt;  threes\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 4e\n&gt;\n&gt; Print ha ha ha ha\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  rep(\&quot;ha\&quot;,4) \n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; Vectors cannot hold values of different types! R automatically converts all values to the same type so that the vector can hold them. If one of the values is a string all values will be converted to strings or in case of a mix of integers and booleans all values will be converted to integers. \n{: .comment}\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; Words used as values have to be written between quotes, words used as variable names do not! If R encounters a word without quotes it will try to find a variable with that name.\n{: .comment}\n\n#### Referring to elements of a vector\nEvery element in a vector is assigned an index (= its position in the vector) in the order in which elements were entered. This index starts with one, not zero. \n\nYou can extract elements from vectors in two ways:\n1. You directly identify specific elements using their indices\n2. You create a logical operation to select certain elements.\n\nTo refer to elements of a vector use indices or a logical operation inside square brackets []\ne.g. to retrieve the 2nd element of vector a use:\n```\na[2]\n```\nto retrieve the 2nd, 3rd and 4th element of vector a use:\n```\na[2:4]\n```\nto retrieve the 2nd and 4th element of vector a use:\n```\na[c(2,4)]\n```\nYou also see [] when you look at output in the console. The number in between the square brackets is the index of the first value on the line. \n```\nv &lt;- c(rep(5,10),rep(10,5))\n#[1] 5 5 5 5 5 5 5 5 5 5 10 10\n#[13] 10 10 10 \n```\nThere are 12 values on the first line, so on the second line of data, the first value (10) is actually on the 13th position in the vector v. So [13] refers to the index of the first element on the line.\n\nRetrieving elements using a logical operation is done as follows:\n```\nx\n#[1] 1 3 11 1 7\nx[x &lt; 4]\n#[1] 1 3 1\n```\nRetrieving data with logical operators is based on the following fact: every logical statement produces the outcome TRUE or FALSE.\n```\nx &lt; 4\n#[1]  TRUE  TRUE  FALSE  TRUE  FALSE\n```\n\nLogical operators applied to vectors will result in a vector of the same length consisting of TRUE or FALSE values depending on whether the statement is true for the particular element. If you use the outcomes of a logical operation to retrieve elements of a vector, only the elements where the outcome is TRUE will be selected. \n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Data extraction: vectors** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 5a\n&gt;\n&gt; Create a vector named x containing the numbers 20 to 2. Retrieve elements that are larger than 5 and smaller than 15.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  x &lt;- 20:2\n&gt;    &gt;  x[x &gt; 5 &amp; x &lt; 15]\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  x[15 &gt; x &gt; 5]\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  x(x &gt; 5 &amp; x &lt; 15)\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  x[x &gt; 5] &amp; x[x &lt; 15]\n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 5b\n&gt;\n&gt; 1. Retrieve the 4th and 5th elements from the days vector.\n&gt; 2. Retrieve elements from Plants_with_lesions that are larger than 2.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  days[c(4,5)]\n&gt;    &gt;  Plants_with_lesions[Plants_with_lesions &gt; 2]\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  days[4,5]\n&gt;    &gt;  \n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  days[4:5]\n&gt;    &gt;  \n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  days(4:5)\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 5c\n&gt;\n&gt; Create vector y with elements 9,2,4 and retrieve the second element of y.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  y &lt;-c (9,2,4)\n&gt;    &gt;  y[2] \n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 5d\n&gt;\n&gt; 1. Create vector z with elements 1, 2, 3, 4, 12, 31, 2, 51, 23, 1, 23, 2341, 23, 512, 32, 312, 123, 21, 3\n&gt; 2. Retrieve the 3rd, 4th, 5th, 6th and 7th element\n&gt; 3. Retrieve the 2nd and 4th element\n&gt; 4. Retrieve elements from z that are larger than 100\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  z &lt;- c(1,2,3,4,12,31,2,51,23,1,23,2341,23,512,32,312,123,21,3)\n&gt;    &gt;  z[3:7] \n&gt;    &gt;  z[c(2,4)]\n&gt;    &gt;  z[z &gt; 100] \n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Logical and arithmetic operations on variables** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 5h\n&gt;\n&gt; Retrieve elements from newVector (exercise 4b) that are larger than the corresponding elements of vector threes (exercise 4d).\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  newVector[newVector &gt; threes]\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n#### Removing, changing or adding elements in a vector\nTo remove an element from a vector use a negative index: ?-? indicates ?NOT? followed by the index of the element you want to remove, e.g. to remove the second element of vector z use:\n```\nz &lt;- z[-2]\n```\n\nChange or add elements by assigning a new value to that element . \n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Data removal vectors** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 6a\n&gt;\n&gt; From vector x (exercise 5a) remove the first 8 elements and store the result in x2.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  x2 &lt;- x[-(1:8)]\n&gt;    &gt;  x2\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  x2 &lt;- x[-1:8]\n&gt;    &gt;  \n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 6b\n&gt;\n&gt; Retrieve the same elements from z as in exercise 5d2 but first replace the 3rd element by 7.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  z[3] &lt;- 7\n&gt;    &gt;  z[3:7] \n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n### Factors\nYou can tell R that a variable is categorical (= text labels representing categories although sometimes numbers are also used) by making it a factor. \n\nThe difference between a categorical variable and a continuous variable is that a categorical variable represents a limited number of categories. A continuous variable is the result of a measurement and can correspond to an infinite number of values. \n\nIn most cases categorical data is used to **describe** other data, it is not used in calculations e.g. which group does a measurement belong to. Storing data as factors ensures that the graphing and statistical functions in R will treat such data correctly.\n\nThere are two types of categorical data:\n1. unranked categorical data do not have an implied order\n2. ranked categorical data do have a natural ordering\n\nR will treat factors by default as unranked but you can create ordered (ranked) factors. \n\nTo create a factor, first create a vector and then convert it to a factor using the factor() function:\n```\nv &lt;- c(1,4,4,4,3,5,4,4,5,3,2,5,4,3,1,3,1,5,3,4)\nv\n#[1] 1 4 4 4 3 5 4 4 5 3 2 5 4 3 1 3 1 5 3 4\nf &lt;- factor(v,ordered=TRUE)\nf\n#[1] 1 4 4 4 3 5 4 4 5 3 2 5 4 3 1 3 1 5 3 4\n#Levels: 1 &lt; 2 &lt; 3 &lt; 4 &lt; 5 \n```\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; The factor() function creates \&quot;Levels\&quot;: these are the labels of the categories.\n{: .comment}\n\nThe only **required argument** of the factor() function is a **vector** of values which will be factorized. Both numeric and character vectors can be made into factors but you will use factor() typically for numerical data that represents categories. \n\nWhen you create a vector containing text values in R you have to factorize it but if you store the vector as a column in a data frame, text data is automatically converted to a factor. \n\nWhen you import data into R using read.() functions, the data is automatically stored in a data frame so text will be automatically converted into a factor. \n\nSo in reality (since you mostly import data into R) you use factor() mainly to factorize **numbers** that represent categories.\n\nBy default, factor() transforms a vector into an unordered factor, as does the automated factorization of the read.() functions. Unordered means that the categories are processed in alphabetical order: High will be plotted before Low since H comes first in the alphabet. \n\nIf the categories are ranked, you have to create an ordered factor, you have to add two additional arguments: \n- Set *ordered* to TRUE to indicate that the factor is ordered\n- *levels*: a vector of category labels (as strings) in the correct order\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Data creation: factors** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 7a\n&gt;\n&gt; 1. Create a vector gender with the following elements: Male, Female, male. \n&gt; 2. Convert gender into a factor with levels: Male and Female\n&gt; 3. Print the content of the factor. What happens?\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  gender &lt;- c(\&quot;Male\&quot;,\&quot;Female\&quot;,\&quot;male\&quot;)\n&gt;    &gt;  gender &lt;- factor(gender,levels=c(\&quot;Male\&quot;,\&quot;Female\&quot;))\n&gt;    &gt;  gender\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n&quot;,&quot;# Genome assembly with Velvet: Background\n{:.no_toc}\n\nVelvet is one of a number of *de novo* assemblers that use short read sets as input (*e.g.* Illumina Reads). The assembly method is based on the manipulation of de Bruijn graphs, via the removal of errors and the simplication of repeated regions.\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; For information about Velvet, you can check its (nice) [Wikipedia page](https://en.wikipedia.org/wiki/Velvet_assembler).\n{: .comment}\n\nFor this tutorial, we have a set of reads from an imaginary *Staphylococcus aureus* bacterium with a miniature genome (197,394 bp). Our mutant strain read set was sequenced with the whole genome shotgun method, using an Illumina DNA sequencing instrument. From these reads, we would like to rebuild our imaginary *Staphylococcus aureus* bacterium via a *de novo* assembly of a short read set using the Velvet assembler.\n\n&gt; ### Agenda\n&gt;\n&gt; In this tutorial, we will deal with:\n&gt;\n&gt; 1. TOC\n&gt; {:toc}\n&gt;\n{: .agenda}\n\n# Get the data\n\nWe will now import the data that we will use for the tutorial.\n\n&gt; ### {% icon hands_on %} Hands-on: Getting the data\n&gt;\n&gt; 1. Create and name a new history for this tutorial.\n&gt; 2. Import from [Zenodo](https://doi.org/10.5281/zenodo.582600) or from the data library the files:\n&gt;    - [`mutant_R1.fastq`](https://zenodo.org/record/582600/files/mutant_R1.fastq)\n&gt;    - [`mutant_R2.fastq`](https://zenodo.org/record/582600/files/mutant_R2.fastq)\n&gt;\n&gt;    &gt; ### {% icon tip %} Tip: Importing data via links\n&gt;    &gt;\n&gt;    &gt; * Copy the link location (Right-click on the filename then \&quot;Copy Link Address\&quot;)\n&gt;    &gt; * Open the Galaxy Upload Manager\n&gt;    &gt; * Select **Paste/Fetch Data**\n&gt;    &gt; * Paste the link into the text field\n&gt;    &gt; * Change the data-type to **fastqsanger**\n&gt;    &gt; * Press **Start**\n&gt;    {: .tip}\n&gt;\n&gt; 3. Change the name of the files to `mutant_R1` and `mutant_R2`.\n&gt;\n&gt;    As a default, Galaxy uses the link as the name of the new dataset. It also does not link the dataset to a database or a reference genome.\n&gt;\n&gt;    {% include snippets/rename_dataset.md %}\n&gt;\n&gt; 4. Inspect the content of a file.\n&gt;\n&gt;    &gt; ### {% icon tip %} Tip: Inspecting the content of a dataset\n&gt;    &gt;\n&gt;    &gt; * Click on the {% icon galaxy-eye %} (eye) icon next to the relevant history entry\n&gt;    &gt; * View the content of the file in the central panel\n&gt;    {: .tip}\n&gt;\n&gt;    &gt; ### {% icon question %} Questions\n&gt;    &gt;\n&gt;    &gt; 1. What are four key features of a FASTQ file?\n&gt;    &gt; 2. What is the main difference between a FASTQ and a FASTA file?\n&gt;    &gt;\n&gt;    &gt; &gt; ### {% icon solution %} Solution\n&gt;    &gt; &gt; 1. Each sequence in a FASTQ file is represented by 4 lines: 1st line is the id, 2nd line is the sequence, 3rd line is not used, and 4th line is the quality of sequencing per nucleotide\n&gt;    &gt; &gt; 2. In a FASTQ file, not only are the sequences present, but information about the quality of sequencing is also included.\n&gt;    &gt; {: .solution }\n&gt;    {: .question}\n&gt;\n{: .hands_on}\n\nThe reads have been sequenced from an imaginary *Staphylococcus aureus* bacterium using an Illumina DNA sequencing instrument. We obtained the 2 files we imported (`mutant_R1` and `mutant_R2`)\n\n&gt; ### {% icon question %} Question\n&gt;\n&gt; Why do we have 2 files here if we only sequenced the bacteria once?\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt; 1. The bacteria has been sequenced using paired-end sequencing. The first file corresponds to forward reads and the second file to reverse reads.\n&gt; {: .solution }\n{: .question}\n\n# Evaluate the input reads\n\nBefore doing any assembly, the first questions you should ask about your input reads include:\n\n- What is the coverage of my genome?\n- How good is my read set?\n- Do I need to ask for a new sequencing run?\n- Is it suitable for the analysis I need to do?\n\nWe will evaluate the input reads using the FastQC tool. This tool runs a standard series of tests on your read set and returns a relatively easy-to-interpret report. We will use it to evaluate the quality of our FASTQ files and combine the results with MultiQC.\n\n&gt; ### {% icon hands_on %} Hands-on: FastQC on a fastq file\n&gt;\n&gt; 1. **FastQC** {% icon tool %} with the following parameters\n&gt;    - \&quot;Short read data from your current history\&quot; to (**Multiple datasets**) `mutant_R1.fastq` and `mutant_R2.fastq`\n&gt;\n&gt; 2. **MultiQC** {% icon tool %} with the following parameters\n&gt;    - \&quot;Software name\&quot; to `FastQC`\n&gt;    - \&quot;Result file\&quot; to the raw data files generated by FastQC\n&gt;\n{: .hands_on}\n\nMultiQC generates a webpage combining reports for FastQC on both datasets. It includes these graphs and tables:\n\n- General statistics\n\n    This is important in setting maximum k-mer size for an assembly.\n\n    &gt; ### {% icon comment %} Getting the length of sequences\n    &gt;\n    &gt; * Click on **Configure Columns**\n    &gt; * Check **Length**\n    &gt; * Close the window\n    {: .comment}\n\n    &gt; ### {% icon question %} Questions\n    &gt;\n    &gt; 1. How long are the sequences?\n    &gt; 2. What is the average coverage of the genome, given our imaginary *Staphylococcus aureus* bacterium has a genome of 197,394 bp?\n    &gt;\n    &gt; &gt; ### {% icon solution %} Solution\n    &gt; &gt; 1. The sequences are 150 bp long\n    &gt; &gt; 2. We have 2 x 12,480 sequences of 150 bp, so the average genome coverage is: 2 * 12480 * 150 / 197394, or approximately 19 X coverage.\n    &gt; {: .solution }\n    {: .question}\n\n- Sequence Quality Histograms\n\n    Dips in quality near the beginning, middle or end of the reads may determine the trimming/cleanup methods and parameters to be used, or may indicate technical problems with the sequencing process/machine run.\n\n    &lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../../images/fastqc_per_base_sequence_quality_plot.png\&quot; alt=\&quot;Sequence Quality Histograms with the mean quality value across each base position in the read\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; The mean quality value across each base position in the read&lt;/figcaption&gt;&lt;/figure&gt;\n\n    &gt; ### {% icon question %} Questions\n    &gt;\n    &gt; 1. What does the y-axis represent?\n    &gt; 2. Why is the quality score decreasing across the length of the reads?\n    &gt;\n    &gt; &gt; ### {% icon solution %} Solution\n    &gt; &gt; 1. The y-axis represents the quality score for each base (an estimate of the error during sequencing).\n    &gt; &gt; 2. The quality score is decreasing accross the length of the reads because the sequencing become less and less reliable at the end of the reads.\n    &gt; {: .solution }\n    {: .question}\n\n- Per Sequence GC Content\n\n    High GC organisms tend not to assemble well and may have an uneven read coverage distribution.\n\n- Per Base N Content\n\n    The presence of large numbers of Ns in reads may point to a poor quality sequencing run. You will need to trim these reads to remove Ns.\n\n- k-mer content\n\n    The presence of highly recurring k-mers may point to contamination of reads with barcodes or adapter sequences.\n\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; For a fuller discussion of FastQC outputs and warnings, see the [FastQC website link](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/), including the section on each of the output [reports](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/3%20Analysis%20Modules/), and examples of [\&quot;good\&quot;](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/good_sequence_short_fastqc.html) and [\&quot;bad\&quot;](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/bad_sequence_fastqc.html) Illumina data.\n{: .comment}\n\nWe won&#39;t be doing anything to these data to clean it up as there isn&#39;t much need. Therefore we will get on with the assembly!\n\n\n# Assemble reads with Velvet\n\nNow, we want to assemble our reads to find the sequence of our imaginary *Staphylococcus aureus* bacterium. We will perform a *de novo* assembly of the reads into long contiguous sequences using the Velvet short read assembler.\n\nThe first step of the assembler is to build a de Bruijn graph. For that, it will break our reads into k-mers, *i.e.* fragments of length *k*. Velvet requires the user to input a value of *k* (k-mer size) for the assembly process. Small k-mers will give greater connectivity, but large k-mers will give better specificity.\n\n&gt; ### {% icon hands_on %} Hands-on: Assemble the reads\n&gt;\n&gt; 1. **FASTQ interlacer** {% icon tool %} with the following parameters\n&gt;    - \&quot;Type of paired-end datasets\&quot; to `2 separate datasets`\n&gt;    - \&quot;Left-hand mates\&quot; to `mutant_R1.fastq`\n&gt;    - \&quot;Right-hand mates\&quot; to `mutant_R2.fastq`\n&gt;\n&gt;    Currently our paired-end reads are in 2 files (one with the forward reads and one with the reverse reads), but Velvet requires only one file, where each read is next to its mate read. In other words, if the reads are indexed from 0, then reads 0 and 1 are paired, 2 and 3, 4 and 5, etc. Before doing the assembly *per se*, we need to prepare the files by combining them.\n&gt;\n&gt; 2. **velveth** {% icon tool %} with the following parameters\n&gt;    - \&quot;Hash Length\&quot; to `29`\n&gt;    - \&quot;Input Files\&quot;: click on `Insert Input Files`\n&gt;    - \&quot;file format\&quot; to `fastq`\n&gt;    - \&quot;read type\&quot; to `shortPaired reads`\n&gt;    - \&quot;Dataset\&quot; to the pairs output of **FASTQ interlacer**\n&gt;\n&gt;    The tool takes our reads and break them into k-mers.\n&gt;\n&gt; 3. **velvetg** {% icon tool %} with the following parameters\n&gt;    - \&quot;Velvet Dataset\&quot; to the output of **velveth**\n&gt;    - \&quot;Using Paired Reads\&quot; to `Yes`\n&gt;\n&gt;    This last tool actually does the assembly.\n{: .hands_on}\n\nTwo files are generated:\n\n- A \&quot;Contigs\&quot; file\n\n    This file contains the sequences of the contigs longer than 2k. In the header of each contig, a bit of information is added:\n    - the k-mer length (called \&quot;length\&quot;): For the value of k chosen in the assembly, a measure of how many k-mers overlap (by 1 bp each overlap) to give this length\n    - the k-mer coverage (called \&quot;coverage\&quot;): For the value of k chosen in the assembly, a measure of how many k-mers overlap each base position (in the assembly).\n\n    ![Contigs output](../../images/image10.png)\n\n- A \&quot;Stats\&quot; file\n\n    This is a tabular file giving for each contig the k-mer lengths, k-mer coverages and other measures.\n\n    ![Contigs stats output](../../images/image11.png)\n\n# Collect some statistics on the contigs\n\n&gt; ### {% icon question %} Question\n&gt;\n&gt; 1. How many contigs have been built?\n&gt; 2. What is the mean, min and max length of the contigs?\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt; 1. 190\n&gt; &gt; 2. To compute this information, we can use the Datamash tool on the 2nd columns (length). Be careful with the first line, the header. As a result, we obtain: 597.82 as mean, 1 as min and 12904 as max. It would mean that the smallest contig has a length of 1 bp, even smaller than k. The length on the 2nd column corresponds to length of the contig in k-mers. This means that the smallest contig has a length of 1k = 29. So to obtain the real length, we need to add k-1 to the length. We then obtain a mean contig length of 625.82 bp, a min contig of 29 bp and a max contig of 12,932 bp.\n&gt; {: .solution }\n{: .question}\n\nThis table is limitted, but we will now collect more basic statistics on our assembly.\n\n&gt; ### {% icon hands_on %} Hands-on: Collect fasta statistics on our contigs\n&gt;\n&gt; 1. **Quast** {% icon tool %} with\n&gt;    - \&quot;Contigs/scaffolds output file\&quot; to the output of **velvetg**\n&gt;    - \&quot;Type of data\&quot; to `contig`\n&gt;    - \&quot;Reference File\&quot; to `wildtype.fna`\n&gt;    - \&quot;Type of organism\&quot; to `Prokaryotes`\n&gt;    - \&quot;Lower Threshold\&quot; to `500`\n&gt;    - \&quot;Thresholds\&quot; to `0,1000`\n{: .hands_on}\n\nThis tool generates 5 output files, but we will focus on the HTML report and the Icarus viewer.\n\n&gt; ### {% icon question %} Question\n&gt;\n&gt; 1. What is represented in the Icarus viewer?\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt; 1. Icarus is a novel genome visualizer for accurate assessment and analysis of genomic draft assemblies. It draws contigs ordered from longest to shortest, highlights N50, N75 (NG50, NG75) and long contigs larger than a user-specified threshold\n&gt; {: .solution }\n{: .question}\n\nThe HTML report reports many statistics computed by QUAST to assess the quality of the assembly:\n\n- Statistics about the quality of the assembly when compared to the reference (fraction of the genome, duplication ratio, etc)\n- Misassembly statistics, including the number of misassemblies\n\n    A misassembly is a position in the contigs (breakpoints) that satisfy one of the following criteria:\n    - the left flanking sequence aligns over 1 kbp away from the right flanking sequence on the reference;\n    - flanking sequences overlap on more than 1 kbp\n    - flanking sequences align to different strands or different chromosomes\n\n- Unaligned regions in the assembly\n- Mismatches compared to the reference genomes\n- Statistics about the assembly *per se*, such as the number of contigs and the length of the largest contig\n\n&gt; ### {% icon question %} Question\n&gt;\n&gt; 1. How many contigs have been constructed?\n&gt; 2. Which proportion of the reference genome do they represent?\n&gt; 3. How many misassemblies have been found?\n&gt; 4. Has the assembly introduced mismatches and indels?\n&gt; 5. What are N50 and L50?\n&gt; 6. Is there a bias in GC percentage induced by the assembly?\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt; 1. 190 contigs have been constructed, but only 47 have a length &gt; 500 bp.\n&gt; &gt; 2. The contigs represents 87.965% of the reference genome.\n&gt; &gt; 3. 1 misassembly has been found: it corresponds to a relocation, *i.e.* a misassembly event (breakpoint) where the left flanking sequence aligns over 1 kbp away from the right flanking sequence on the reference genome.\n&gt; &gt; 4. 8.06 mismatches per 100 kbp and 4.03 indels per 100 kbp are found.\n&gt; &gt; 5. N50 is the length for which the collection of all contigs of that length or longer covers at least half an assembly. In other words, if contigs were ordered from small to large, half of all the nucleotides will be in contigs this size or larger. And L50 is the number of contigs equal to or longer than N50: L50 is the minimal number of contigs that cover half the assembly.\n&gt; &gt; 6. The GC % in the assembly is 33.64%, really similar to the one of the reference genome (33.43%).\n&gt; {: .solution }\n{: .question}\n\n# Discussion\n\n&gt; ### {% icon hands_on %} (Optional) Hands-on: Rerun for values *k* ranging from 31 to 101\n&gt;\n&gt; 1. **velveth** {% icon tool %} with the same parameters as before except\n&gt;    - \&quot;Hash Length\&quot; to a value between 31 and 101\n&gt; 2. **velvetg** {% icon tool %} with the same parameters as before\n&gt; 3. **Quast** {% icon tool %} with the same parameters as before\n{: .hands_on}\n\nWe have completed an assembly on this data set for a number of k values ranging from 29 to 101. A few of the assembly metrics appear below.\n\n&lt;figure id=\&quot;figure-2\&quot;&gt;&lt;img src=\&quot;../../images/number_of_contigs.png\&quot; alt=\&quot;contigs\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 2:&lt;/span&gt; Number of contigs in the assembly for various k-mer sizes&lt;/figcaption&gt;&lt;/figure&gt;\n\n&lt;figure id=\&quot;figure-3\&quot;&gt;&lt;img src=\&quot;../../images/largest_contig.png\&quot; alt=\&quot;largest_contig\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 3:&lt;/span&gt; Largest contig in each of the assemblies by k-mer size&lt;/figcaption&gt;&lt;/figure&gt;\n\n&lt;figure id=\&quot;figure-4\&quot;&gt;&lt;img src=\&quot;../../images/total_bp.png\&quot; alt=\&quot;total_bp\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 4:&lt;/span&gt; Total number of base pairs in all the contigs for each assembly by k-mer size&lt;/figcaption&gt;&lt;/figure&gt;\n\n&lt;figure id=\&quot;figure-5\&quot;&gt;&lt;img src=\&quot;../../images/n50.png\&quot; alt=\&quot;n50\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 5:&lt;/span&gt; N50 metric for each of the assemblies by k-mer size&lt;/figcaption&gt;&lt;/figure&gt;\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; 1. Are there any distinct features in the charts?\n&gt; 2. Does it look like one assembly might be better than some of the others?\n&gt;\n{: .question}\n\nThe reasons for these patterns will be discussed in detail in the De Bruijn graph assembly slides and tutorial.\n&quot;,&quot;Since normalization of qPCR data is based on the assumption that the reference targets have the same expression level in all samples it is crucial that the expression of the chosen reference genes is stable.\nHowever, none of the so-called **housekeeping** genes is universally stably expressed.\n\n[Genevestigator](https://www.genevestigator.com/gv/), both the commercial and the free version, contains a tool, called RefGenes, that allows to identify candidate reference genes that display very stable expression in the context that you are working in, typically a certain tissue of a certain organism.\n\nGenevestigator is a platform that contains curated public microarray data from thousands of experiments/conditions.\n\nRefGenes allows you to select the conditions that are relevant for you, e.g. mouse liver, human fibroblasts, or Arabidopsis thaliana leaves. In a next step, RefGenes identifies the genes with the most stable expression in the selected conditions.\n\n## Starting the RefGenes tool\n\n| How to start the RefGenes tool ? |\n| :-------------------------------- |\n| - Open the [RefGenes page](http://www.refgenes.org/rg/).\n - Click **start GENEVESTIGATOR**\n - Click the **Install/Start** button\n - This will automatically open a Genevestigator startup page. Keep this page open during the analysis. Closing this page will close Genevestigator.\n - Login. Also for the free version you need to create an account (use your academic email for this since you will need your vib email to get access to the commercial version).\n - Genevestigator is opened automatically\n\n## The Genevestigator user interface\n\nThe Genevestigator consists of the following components:\n  - **Sample Selection** panel: to choose the experimental conditions you&#39;re interested in (green)\n  - **Gene Selection** panel: to choose the genes you&#39;re interested in (blue)\n  - Center panel shows an overview of all available tools (purple). Once you have selected a tool, the panel will show the results of the analysis that is done by the tool.\n  - **Home** button (red) allows to return to the overview of the tools at any time. The text next to the home button indicates the toolset that you have selected.\n\nClick the **RefGenes** tool at the bottom.\n\n## Using the RefGenes tool to find reference genes\n\n### STEP 1: Choose samples from a biological context similar to those in your qPCR expriment\n\n| How to choose the samples you want to analyze ? |\n| :-------------------------------- |\n|\n - Click the **New** button in the **Sample Selection** panel. The selection of samples defines which data are used for the analysis.\n - Select the organism you&#39;re interested in (in this example: human)\n - Select the array type you want to analyze (in this example: human 133_2).\nFor most organisms Genevestigator contains expression data from multiple types of microarrays, e.g. different generations of Affymetrix GeneChips. On these arrays, genes are sometimes represented by different sets of probes. To keep the analysis results easily interpretable, data from different array types are not mixed.\n - Click the **Select particular conditions** button to select all samples with a certain annotation, e.g. all data from a certain tissue type.\n - Select the type of conditions (red) you want to base your selection on (in this example: Anatomy). For each type (anatomy, neoplasms, perturbations, development...) you can browse the corresponding ontologies and select the desired condition(s) (green) (in this example: cardiac muscle).\n - Click **OK**\n\nNote that you can select multiple tissues.\nWhen you select samples for use in the RefGenes tool, you have to focus on microarrays from samples that were collected in conditions similar to those in your qPCR experiment. Don&#39;t make a too general selection, e.g. all human samples: you might end up with genes that are stable in most conditions but not in yours. Don&#39;t make a very specific selection either, e.g. human heart samples from patients taking the same medication as yours. If you want to broaden your study later on with samples from other patients, your reference genes might not be valid anymore. It is recommended to select reference genes in the same organism and the same / a similar tissue type as the one that you used in your experiments.\n\n### STEP 2: Select the gene(s) you want to measure in your qPCR experiment\n\nThis step is not essential, but it helps you to see whether your target gene(s) is (are) strongly or weakly expressed in the conditions of interest selected in STEP1. This allows you to search for candidate reference genes in a similar range of expression.\n\n| How to choose the genes you want to analyze ? |\n| :-------------------------------- |\n|\n - Click the **New** button in the **Gene Selection** panel.\n - Enter the name of your target gene in the text area (in this example: GOT1) and click **OK**\n - Open the RefGenes tool (if you haven&#39;t done that already). A red box plot representing the distribution of the expression levels of GOT1 in the 68 selected human heart samples appears in the center panel. As you can see, this gene is highly expressed in heart.\n\n\n\n\n### STEP 3: Find candidate reference genes\n\nThe reference genes that are suggested by GeneVestigator have the\nfollowing characteristics:\n\n  - They have the most stable expression levels across all selected samples (a small boxplot)\n  - Their overall expression level is similar to that of the target gene(s) of your qPCR experiment\n| How to find the candidate reference genes ? |\n| :-------------------------------- |\n|Click the **Run** button in the RefGenes tool. RefGenes will show the top 20 most stable genes with similar expression levels:\n\n\n\n## Exercises\n\n### Finding candidate reference genes in the free version of Genevestigator\n\nNow we will make a more elaborate exercise on finding candidate reference genes. We will do the analysis in the free version of RefGenes but the analysis in the commercial version is very similar.\nSuppose we want to compare the expression stability of the 4 commonly used reference genes for qPCR on mouse liver samples (ACTB, GAPDH, HPRT and TUBB4B) to that of 4 reference genes that are suggested by Genevestigator.\nTo this end we open the RefGenes tool and select the liver samples of the mouse 430_2 arrays.\n\n| Check the expression stability of the 4 commonly used reference genes ? |\n| :-------------------------------- |\n|\n - Click the **New** button in the **Gene Selection** panel to create a new selection. The selection of samples defines which data are used for the analysis.\n - Enter the name of your target gene in the text area (for example: ACTB) and click **OK**\n\nWhen you are using the commercial version, you may enter multiple genes at the same time, in the free version you have to enter them one by one. This means that you have to add the first gene as described above and then add the next gene by clicking the **Add** button and so on...\n\nFinally you end up with an expandable list of the genes you asked for and you can tick or untick them to control the display of their expression data in the main window. When you tick the 4 commonly used reference genes you can see how stable they are expressed in the 651 mouse liver samples that are stored in Genevestigator:\n\nAs you can see, the expression levels of the commonly used reference genes in the selected mouse liver samples is pretty variable which is also confirmed by their relatively high SD values.\nOften there are multiple probe sets for the same gene. When you use the free version you may only choose one probe set per gene so you have to make a choice. How to make that choice ?\nAffymetrix probe set IDs have a certain meaning: what comes after the underscore tells you something about the quality of the probes:\n\n  - **_at** means that all the probes of the probe set hit one known transcript. This is what you want: probes specifically targeting one transcript of one gene\n  - **_a_at** means that all the probes in the probe set hit alternate transcripts from the same gene. This is still ok the probes bind to multiple transcripts but at least the transcripts come from the same gene (splice variants)\n  - **_x_at** means that some of the probes hit transcripts from different genes. This is still not what you want: the expression level is based on a combination of signals of all the probes in a probe set so also probes that cross-hybridize\n  - **_s_at** means that all the probes in the probe set hit transcripts from different genes. This is definitely not what you want: if the probes bind to multiple genes you have no idea whose expression you have measured on the array\n\nSo I always ignore probe sets with s or x. If you have two specific probe sets for a gene, they should more or less give similar signals. If this is not the case, I base my choice upon the expression level that I expect for that gene based on previous qPCR results.\n\nAs you can see, each of these 4 commonly used reference genes has a high expression level. Most genes do not have such high expression levels. In most qPCR experiments your genes of interest will have low or medium expression levels, so these reference genes will not be representative for the genes of interest.\n\nReference genes should ideally have similar expression levels as the genes of interest. Therefore, we will select the four most stably expressed genes with a medium expression level (between 8 and 12) according to the RefGenes tool.\n\n| Select the 4 most stably expressed candidate reference gene with medium expression levels. |\n| :-------------------------------- |\n|\n - Untick all target genes.\n - Click the **Run** button at the top of the main window and check if the range is set correctly\n\nSelect the 4 candidates with the lowest SD: Then, we performed qPCR on a representative set of 16 of our liver samples to measure the expression of these 8 candidate reference genes and analyzed the data ([See how to select the best reference genes using geNorm in qbase+](http://wiki.bits.vib.be/index.php/Analyzing_data_from_a_geNorm_pilot_experiment_in_qbase%2B)).\n\n\n### Finding candidate reference genes in the commercial version of Genevestigator\n\nWe will do the same exercise as above in the commercial version of Genevestigator. The difference between the free and commercial version of RefGenes is the number of target genes you can select. In the free version you have to select one gene and then gradually add all other genes one at a time. The commercial version allows you to load as many target genes as you want simultaneously. As a consequence, you can select multiple probe sets for the same gene.\nAll VIB scientists have free access to the commercial version of Genevestigator via their VIB email address. If you don&#39;t know your VIB email address, check [the Who&#39;s Who of VIB](http://www.vib.be/en/whoiswho/Pages/default.aspx).\n\n  - Open a browser and go to the [Genevestigator website](https://www.genevestigator.com/)\n  - If it&#39;s your **first time to access Genevestigator**, create an account by clicking **join now** button. You will be redirected to a new window in which you will give some personal information including a valid VIB email address. Click **Register** and check your email to activate your new account. Go back to the [GeneVestigator website](https://www.genevestigator.com/)\n  - Choose the research field you want to investigate: **pharma/biomediacal** or **plant biology** by clicking the corresponding button\n  - Click **Start**\n  - Use your VIB email address and password to login to Genevestigator.\n  - This will automatically open a Genevestigator startup page in your browser. Keep this page open during the analysis. Closing this page will close Genevestigator.\n  - Genevestigator is opened automatically\n\nOpen the RefGenes tool by clicking its icon in the **Further tools** secion and select the liver samples of the mouse 430_2 arrays [as explained in the previous exercise](http://wiki.bits.vib.be/index.php/Using_GeneVestigator_to_select_candidate_reference_genes#STEP_1:_Choose_samples_from_a_biological_context_similar_to_those_in_your_qPCR_expriment).\n| Check the expression stability of the 4 commonly used reference genes ? |\n| :-------------------------------- |\n| - Click the **New** button in the **Gene Selection** panel to create a new selection. The selection of samples defines which data are used for the analysis.\n - Enter the names of the 4 commercial reference genes in the text area and click **OK**\n\nI still remove probe sets with an _s or _x since they do not specifically bind to one single gene:\nFinally you end up with an expandable list of the genes you asked for and you can tick or untick them to control the display of their expression data in the main window. By default all probe sets are ticked so you can see how stable the commonly used reference genes are expressed in the 651 mouse liver samples that are stored in Genevestigator:\nAs you can see, the expression levels of the commonly used reference genes in the selected mouse liver samples is pretty variable which is also confirmed by their relatively high SD values.\n\nThe next step of selecting the 4 most stable candidate reference genes with medium expression levels is exactly the same as described above for the free version of RefGenes.\n\n| Create a new gene selection with 20 found candidate reference genes and call it mouse_references. |\n| :-------------------------------- |\n|Click the **New** button at the top of the main window to create a new selection.\n\nTo change the name of the selection right click the name in the **Gene selection** panel and select **Rename**\n\n| Identify perturbations where the mouse_references genes show more than 1,5 fold differential expression using the Condition perturbations tool. |\n| :-------------------------------- |\n|Click the **Home** button at the top to go back to the tools overview page.\n\nClick the **Perturbations** tool in the **Condition Search tools** section\n\n\nMake a **New Sample selection** including all mouse 430_2 arrays.\nUntick all genes except for the first one and filter the long heatmap for at least 1.5 fold change differential expression:\n\n\nYou now get a list of mouse samples in which the gene is not stably expressed so you can check if any of these samples is related to the samples in your study. Hover your mouse over the name of a sample to see more details about the sample.\nYou can do this for each of the candidate reference genes and select the ones that best fit your needs\n\n[Exercise on selecting reference genes for metacaspases in Arabidopsis thaliana](http://wiki.bits.vib.be/index.php/GV_Exercise.1).\n\n\nIn a geNorm pilot experiment you analyze a set of candidate reference genes in a representative set of samples that you want to test in your final experiment. Based on the M-values and CVs that are calculated by qbase+, you can choose the genes that most satisfy the criteria for a good reference gene.\n\n### Exercise 1: reference genes for mouse liver\n\nWe come back on the 8 candidate reference genes that we selected for mouse liver:\n\n  - 4 commonly used reference genes: ACTB, TUBB4B, GAPDH and HPRT\n  - 4 candidate reference genes with very stable medium expression levels selected based on expression data coming from more than 600 microarrays of mouse liver samples using Genevestigator: Gm16845, MUSK, OTOP3, EDN3\n\nWe have measured their expression in a represetative set of 16 of our mouse liver samples, each in triplicate. We will now analyze the stability of these candidate reference genes in our samples.\n\n#### Creating a new Experiment\n\n| Create a new Experiment called GeNormMouse in Project1 |\n| :------------------------------------------- |\n| Open qbase+ or, if the software is already open, click the Launch Wizard button.\n\nYou can find the details on how to create a new experiment in Creating a project and an experiment\n\n#### Loading the data into qbase+\n\nThe data is stored in [the RefGenes folder](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/RefGenes.zip). It consists of 8 Excel files, one file for each candidate reference gene. If you are not working on a BITS laptop, download and unzip the folder.\n\n| Import the data. This files are in qBase format. |\n| :------------------------------------------- |\n| You can find the details on how to start the data import in Loading data into qbase+\n\nUnlike the previous exercise, qbase+ does not allow you to do a quick import this time. In the Import Run window Manual import is selected:\nMake sure that Upload file to Biogazelle support for further analysis is NOT selected and click Next\nMake sure the correct File type is selected (qBase) and click Finish.\nThis file contains the data of the geNorm pilot experiment. In the pilot experiment, 8 candidate reference genes were measured in 16 representative mouse liver samples.\n#### Analyzing the geNorm pilot data\n\n| Specify the aim of the experiment. |\n| :------------------------------------------- |\n| In this experiment we want to select the ideal reference genes for our next experiments so we choose selection of reference genes (geNorm)\n\n| Check the quality of the replicates (use default parameter settings). |\n| :------------------------------------------- |\n| You can find the details on how to check the quality of the replicates in the Checking the quality of technical replicates and controls section of Analyzing gene expression data in qbase+\n\nWe haven&#39;t included any positive or negative controls so you don&#39;t need to show their details.\n\n| Select the Amplification efficiencies strategy you want to use. |\n| :------------------------------------------- |\n| You can find the details on how to select the Amplification effciencies strategy in the Taking into account amplification efficiencies section of Analyzing gene expression data in qbase+\n\nWe haven&#39;t included dilution series nor do we have data from previous qPCR experiments regarding the amplification efficiencies so we choose to use the same efficiency for all genes.\nIt is of course better to include a dilution series for each gene to have an idea of the amplification efficiencies of each primer pair.\n\n| Convert all genes to Reference genes. |\n| :------------------------------------------- |\n| You can convert all the genes simultaneously by selecting Use all targets as candidate reference genes\n\nClick Finish.\n\n| Which genes are you going to use as reference targets in further experiments ? |\n| :------------------------------------------- |\n| Upon clicking Finish, the geNorm window containing the analysis results is automatically opened. The geNorm window consists of three tabs. The tabs are located at the bottom of the window: geNorm M, geNorm V and Interpretation.\nThe first tab, geNorm M, shows a ranking of candidate genes according to their stability, expressed in M values, from the most unstable genes at the left (highest M value) to the best reference genes at the right (lowest M value):\nThe second tab, geNorm V, shows a bar chart that helps determining the optimal number of reference genes to be used in subsequent analyses:\n\nThe number of reference genes is a trade-off between practical considerations and accuracy. It is a waste of resources to quantify more genes than necessary if all candidate reference genes are relatively stably expressed and if normalization factors do not significantly change when more genes are included. However, Biogazelle recommends the minimal use of 3 reference genes and stepwise inclusion of more reference genes until the next gene has no significant contribution to the normalization factors.\nTo determine the need of including more than 3 genes for normalization, pairwise variations Vn/n+1 are calculated between two sequential normalization factors. Simply stated: V is measure of the added value of adding a next reference gene to the analysis. A large variation means that the added gene has a significant effect and should be included.\nIn normal experiments like the Gene expression experiment (see Analyzing gene expression data in qbase+), we only have 3 reference genes so we will see only 1 bar here. But in this geNorm pilot experiment, we analyzed 8 candidate reference genes, so we see 6 bars.\nAll pairwise variations are very low, so even the inclusion of a third gene has no significant effect. Based on a preliminary experiment that was done by Biogazelle, 0.15 is taken as a cut-off value for V, below which the inclusion of an additional reference gene is not required. Normally this threshold is indicated by a green line on the geNorm V bar chart. However since all V-values fall below the threshold in this geNorm pilot experiment, you dont see this line on the bar chart.\nSo, these results mean that for all subsequent experiments on these samples, two reference genes, EDN3 and MUSK, would be sufficient. However, as stated before, Biogazelle recommends to always include at least three reference genes in case something goes wrong with one of the reference genes (so also include Gm16845). |\nThese are artificial data. But when you read [the paper by Hruz et al., 2011](http://www.biomedcentral.com/1471-2164/12/156/abstract) you see that the genes that are selected by Genevestigator are often outperforming the commonly used reference genes.\n\n### Exercise 2: reference genes for human heart\n\n#### Creating a new Experiment\n\n| Create a new Experiment called GeNormHuman in Project1        |\n| :------------------------------------------------------------ |\n| You can find the details on how to create a new experiment in Creating a project and an experiment |\n\n#### Loading the data into qbase+\n| Import [Run6](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run6.xls) . This file is in qBase format. |\n| :------------------------------------------- |\n| You can find the details on how to start the data import in Loading data into qbase+. Unlike the previous exercise, qbase+ does not allow you to do a quick import this time. In the Import Run window Manual import is selected:\n\nMake sure that Upload file to Biogazelle support for further analysis is NOT selected and click Next. Select the correct File type (qBase) and click Finish. This file contains the data of the geNorm pilot experiment. In the pilot experiment, 10 candidate reference genes were measured in 20 representative samples.\n\n#### Analyzing the geNorm pilot data\n\n| Specify the aim of the experiment.        |\n| :---------------------------------------- |\n| In this experiment we want to select the ideal reference genes for our next experiments so we choose selection of reference genes (geNorm) |\n\n| Check the quality of the replicates and the controls (use default parameter settings). |\n| :------------------------------------------- |\n| You can find the details on how to check the quality of the replicates in the Checking the quality of technical replicates and controls section of Analyzing gene expression data in qbase+\n\nAll replicates and controls have met the quality criteria so there&#39;s no need to inspect them further. |\n| Select the Amplification efficiencies strategy you want to use. |\n| :------------------------------------------- |\n| You can find the details on how to select the Amplification effciencies strategy in the Taking into account amplification efficiencies section of Analyzing gene expression data in qbase+. We haven&#39;t included dilution series nor do we have data from previous qPCR experiments regarding the amplification efficiencies so we choose to use the same efficiency (E=2) for all genes. |\n\nIt is of course better to include a dilution series for each gene to have an idea of the amplification efficiencies of each primer pair.\n| Convert all genes to Reference genes.                                                                         |\n| :------------------------------------------------------------------------------------------------------------ |\n| You can convert all the genes simultaneously by selecting Use all targets as candidate reference genes |\n\nClick Finish.\n\n| Which genes are you going to use as reference targets in further experiments ? |\n| :------------------------------------------- |\n| Upon clicking Finish, the geNorm window containing the analysis results is automatically opened. The geNorm window consists of three tabs. The tabs are located at the bottom of the window: geNorm M, geNorm V and Interpretation.\nThe first tab, geNorm M, shows a ranking of candidate genes according to their stability, expressed in M values, from the most unstable genes at the left (highest M value) to the best reference genes at the right (lowest M value):\nThe second tab, geNorm V, shows a bar chart that helps determining the optimal number of reference genes to be used in subsequent analyses:\n\nThe number of reference genes is a trade-off between practical considerations and accuracy. It is a waste of resources to quantify more genes than necessary if all candidate reference genes are relatively stably expressed and if normalization factors do not significantly change when more genes are included. However, Biogazelle recommends the minimal use of the 3 most stable candidate reference genes and stepwise inclusion of more reference genes until the next gene has no significant contribution to the normalization factors.\nTo determine the need of including more than 3 genes for normalization, pairwise variations Vn/n+1 are calculated between two sequential normalization factors. Simply stated: V is measure of the added value of adding a next reference gene to the analysis. A large variation means that the added gene has a significant effect and should be included.\nIn normal experiments like the Gene expression experiment, see Analyzing_gene_expression_data_in_qbase+, we only have 3 reference genes so we will see only 1 bar here. But in this geNorm pilot experiment, we analyzed 10 candidate reference genes, so we see 8 bars.\nAll pairwise variations are very low, so even the inclusion of a third gene has no significant effect. Based on a preliminary experiment that was done by Biogazelle, 0.15 is taken as a cut-off value for V, below which the inclusion of an additional reference gene is not required. Normally this threshold is indicated by a green line on the geNorm V bar chart. However since all V-values fall below the threshold in this geNorm pilot experiment, you dont see this line on the bar chart.\nSo, these results mean that for all subsequent experiments on these samples, two reference genes, HPRT1 and GADP, would be sufficient. However, as stated before, Biogazelle recommends to always include at least three reference genes in case something goes wrong with one of the reference genes (so also include YHWAZ). \n\n\n\nIn this example we will analyze data from an artificial expression study containing the following samples:\n  - 6 treated samples: treated1, treated2, ... treated6\n  - 6 control samples: control1, control2, ... control6\n\nIn this study, the expression of the following genes was measured:\n  - 4 commonly used reference genes: ACTB, HPRT, GAPDH, and TUBB4. We have seen in [the previous exercise](http://wiki.bits.vib.be/index.php/Analyzing_data_from_a_geNorm_pilot_experiment_in_qbase%2B#Exercise_1:_reference_genes_for_mouse_liver) that the expression of these reference genes in mouse liver samples is not as stable as generally thought.\n  - 3 genes of interest:\n      - Low: a gene with low expression levels\n      - Medium: a gene with moderate expression levels\n      - HighVar: a gene with low and very noisy expression\n\nIn general, the lower the expression level, the more noisy the qPCR results will become. For each of the genes of interest we have included a run in which a 2-fold difference in expression between control and treated samples was created (Low1, Medium1 and HighVar1) and a run with a 4-fold difference in expression (Low2, Medium2 and HighVar2).\nThere are three technical replicates per reaction. In a second experiment we used [the reference genes that were obtained via Genevestigator](http://wiki.bits.vib.be/index.php/Using_GeneVestigator_to_select_candidate_reference_genes#Finding_candidate_reference_genes_in_the_free_version_of_Genevestigator) and that proved to be [more stably expressed in mouse liver samples than the commonly used references](http://wiki.bits.vib.be/index.php/Analyzing_data_from_a_geNorm_pilot_experiment_in_qbase%2B#Exercise_1:_reference_genes_for_mouse_liver).\nThe data can be found in the NormGenes folder on the BITS laptops or can be downloaded: [from our website](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/NormGenes.zip).\n\n#### Creating a new experiment\n\n| Create a new Experiment called NormGenes1 in Project1 |\n| :---------------------------------------------------- |\n| You can find the details on how to create a new experiment in Creating a project and an experiment |\n\n#### Loading the data\n\n| Import Run1 to Run5. These files are in qBase format. |\n| :---------------------------------------------------- |\n| You can find the details on how to import the data file in the Loading the data into qbase+ section of Analyzing data from a geNorm pilot experiment in qbase+ |\n\nWe are going to compare expression in treated versus untreated samples so we need to tell qbase+ which samples are treated and which not. To this end, we have constructed [a sample properties file](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Sample_Properties_Norm.xlsx) in Excel containing the grouping annotation as a custom property called Treatment.\n\n| Import the Sample Properties file. |\n| :---------------------------------------------------- |\n| You can find the details on how to import the data file in the Adding annotation to the data section of Loading data into qbase+.\n\n| Select to import the custom property. |\n| :---------------------------------------------------- |\n| So as you can see we have 6 treated and 6 untreated samples and we have measured the expression of the 4 commonly used reference genes and 6 genes of interest:\n\n#### Analyzing the data\n\n| Which amplification efficiencies strategy are you going to use ?     |\n| :------------------------------------------------------------------- |\n| You don&#39;t have data of serial dilutions of representative template to build standard curves so the only choice you have is to use the default amplification efficiency (E = 2) for all the genes. |\n\n| Appoint the reference genes. |ACTB, GAPDH, HPRT and TUBB4B are the reference genes:\nYou can find the details on how to appoint reference targets in the Normalization section of Analyzing gene expression data in qbase+ |\n\n| Is the stability of the reference genes ok ?                                                                 |\n| :----------------------------------------------------------------------------------------------------------- |\n| The M and CV values of the reference genes are shown in green so the stability of the reference genes is ok. |\n\n| Which scaling strategy are you going to use ? |Since you have a treated and a control group, it seems logical to use the average of the control group for scaling.\n\nYou can find the details on how to specify the scaling strategy in the Scaling section of Analyzing gene expression data in qbase+\nLook at the target bar charts.\n\n| In the target bar charts plot the average expression level of each group. |In the Grouping section at the bottom of the chart you can select Plot group average: Now do exactly the same for the second experiment with the same genes of interest but with other reference genes. This means that you have to return to the Analysis wizard. To this end, click the Launch wizard button a the top of the page:\n\n| Create a new Experiment called NormGenes2 in Project1 |\n| :---------------------------------------------------- |\n| You can find the details on how to create a new experiment in Creating a project and an experiment |\n\n| Import Run5 to Run9. These files are in qBase format. |\n| :---------------------------------------------------- |\n| You can find the details on how to import the data file in the Loading the data into qbase+ section of Analyzing data from a geNorm pilot experiment in qbase+ |\n\n| Import the Sample Properties file.                    |\n| :---------------------------------------------------- |\n| You can find the details on how to import the data file in the Adding annotation to the data section of Loading data into qbase+. Select to import the custom property. |\n\nSo as you can see we have 6 treated and 6 untreated samples and we have measured the expression of the 4 new reference genes and 6 genes of interest:\n| Appoint the reference genes. |EDN3, Gm16835, MUSK and OTOP3 are the reference genes:\n| :---------------------------------------------------- |\n| You can find the details on how to appoint reference targets in the Normalization section of Analyzing gene expression data in qbase+ |\n\n| Is the stability of the reference genes ok ?                                                                 |\n| :----------------------------------------------------------------------------------------------------------- |\n| The M and CV values of the reference genes are shown in green so the stability of the reference genes is ok. |\n\nAs you can see the M and CV values of these reference genes is much lower than these of the 4 commonly used reference genes pointing to the fact that genes are more stably expressed. It&#39;s not that the commonly used reference genes are bad references. Then qbase+ would not display them in green. It&#39;s just that the other reference genes are more stable. But this can have a big impact on the results of your analysis...\n\n| Use the average of the control group for scaling |You can find the details on how to specify the scaling strategy in the Scaling section of Analyzing gene expression data in qbase+\n\nPlot the average expression level of each group. Now we will compare the target bar charts of the second and the first experiment to assess the influence of the stability of the reference targets on the analysis results.\n\n| How to display the target bar charts of the second and the first experiment next to each other ? |You can display the bar charts next to each other by clicking the tab of the bar chart of the second experiment. Drag the tab to the right while you hold down the mouse button until you see and arrow at the right side of the qbase+ window and a dark grey box in the right half of qbase+ window. Release the mouse button when you see the arrow and the box. Now the two bar charts should be next to each other. Some laptop screens are too small to nicely display the two bar charts next to other. If this is the case switch to full screen mode by double clicking the tab of the first experiment. |\n\nNow you can compare the expression of each gene in the first and in the second experiment.\n\nWhen we do this for HighVar1 for instance, you see that the average expression levels of both groups are the same in the first and the second experiment (check the scales of the Yaxis\\!). Both experiments detect the two-fold difference in expression level between the groups. However, the error bars are much larger in the first experiment than in the second. The variability of the reference genes does have a strong influence on the errors and the size of the error bars will influence the outcome of the statistical test to determine if a gene is differentially expressed or not. The larger the error bars the smaller the less likely it is that the test will say that the groups differ.\n\nRemember that the error bars represent 95% confidence intervals:\n  - if the error bars of the two groups do not overlap: you are certain that the difference between the means of the two groups is significant\n  - if they do not overlap: you know nothing with certainty: the means can be different or they can be the same. Of course the more they overlap the smaller the chance that there is a significant difference between the groups.\n\nCheck out the results of HighVar2. Here, you clearly see the influence of the reference genes. Again, the fourfold difference in expression is detected by both experiments but:\n\n  - the least stable reference genes (experiment 1) give large overlapping error bars\n  - the most stable reference (experiment 2) give smaller, barely overlapping error bars\n\nThis means that in experiment 2, a statistical test will probably declare that HighVar2 is differentially expressed while in experiment 1 this will not be the case. We will test this assumption by performing a statistical test.\n\n#### Statistical analysis of differential expression\n\n| Use a non-parametric test to identify DE genes in experiment 1 ? |\n| :---------------------------------------------------- |\n| You can find full details on statistical analyses in qbase+ in the statistical analysis section of analyzing gene expression data in qbase+. In brief, you need to perform the following steps:\n\nOpen the Statistical wizard\n\nThe goal of this analysis is to compare the mean expression levels of our genes of interest in treated and untreated samples\n\nUse the Treatment property to identify treated and untreated samples\n\nAnalyze all genes of interest\n\nUse the default settings to perform the non-parametric Mann-Whitney test\n\nAs you can see, none of the genes is considered DE by the very conservative non-parametric test. Additionally most genes have the same p-value. That&#39;s normal when you don&#39;t have many replicates. In our case, we have 6 replicates. Non-parametric tests are based on a ranking of the data values and there are not so many ways to rank 6 data points. This is why you see the same p-values for many genes.\nAs said before, the non-parametric test is very stringent. If the data do come from a normal distribution, the test will generate false positives. Some of the genes might have have been labeled not DE while in fact they are DE so you might have missed some differential expression. The choice of statistical test with 6 biological replicates depends on what you prefer: false negatives or false positives. Most people will choose false negatives since they don&#39;t want to invest time and money in research on a genes that was labeled DE while in fact it is not DE.\n\nSuppose I don&#39;t mind false positives but I don&#39;t want to miss any potential DE genes. In that case, it&#39;s better to go for a t-test. Let&#39;s repeat the test n ow choosing a parametric t-test.\n| Use a t-test to identify DE genes in experiment 1 ? |\n| :---------------------------------------------------- |\n| You can find full details on statistical analyses in qbase+ in the statistical analysis section of analyzing gene expression data in qbase+.\nIn brief, you need to perform the following steps:\nOpen the Statistical wizard\nThe goal of this analysis is to compare the mean expression levels of our genes of interest in treated and untreated samples\nUse the Treatment property to identify treated and untreated samples\nAnalyze all genes of interest\nDescribe the data set as log-normally distributed\n\nStill none of the genes is considered DE but you do see that the p-values of the t-test are lower than these of the Mann-Whitney test.\n\n| Use a non parametric test to identify DE genes in experiment 2 ? |\n| :---------------------------------------------------- |\n| You can find full details on statistical analyses in qbase+ in the statistical analysis section of analyzing gene expression data in qbase+.\nIn brief, you need to perform the following steps:\n\nOpen the Statistical wizard\nThe goal of this analysis is to compare the mean expression levels of our genes of interest in treated and untreated samples\nUse the Treatment property to identify treated and untreated samples\nAnalyze all genes of interest\nUse default settings\n\nNow you see that 4 out of the 6 genes are considered DE. This is also what we expected since 3 of our genes of interst have a 4-fold difference in expression level between the two groups. It&#39;s understandable that it&#39;s hard to detect 2-fold differences in expression especially when the expression of the gene is somewhat variable as is the case for Low1 and HighVar1 but a 4-fold difference is a difference that you would like to detect.\n| Use a t-test to identify DE genes in experiment 2 ? |\n| :---------------------------------------------------- |\n| You can find full details on statistical analyses in qbase+ in the statistical analysis section of analyzing gene expression data in qbase+.\nIn brief, you need to perform the following steps:\n\nOpen the Statistical wizard\nThe goal of this analysis is to compare the mean expression levels of our genes of interest in treated and untreated samples\nUse the Treatment property to identify treated and untreated samples\nAnalyze all genes of interest\nDescribe the data as log normally distributed\n\nAgain the t-test generates lower p-values than the Mann-Whitney test but realize that choosing the t-test when the data is not normally distributed will generate false positives \\!&quot;,&quot;## What&#39;s the biology behind a list of genes ?\n\nOmics experiments typically generate lists of hundreds of interesting genes: \n- up- or downregulated genes identified in an RNA-Seq experiment\n- somatically mutated genes in a tumor identified by exome sequencing\n- proteins that interact with a bait identified in a proteomics experiment\n- ...\n\n### Over-representation analysis\n\nSince it&#39;s impossible to evaluate each gene individually, the most meaningful approach is to see what functional annotations the genes in the list have in common e.g. are many of them involved in the same pathway ?\n\nFunctional characterization of a gene list involves the following steps:\n1. Add functional annotations to the genes in the list\n2. Define a background: typically the full set of all genes in the genome\n3. Perform a  statistical test to identify **enriched** functions, diseases, pathways\n\nEnriched means over-represented, occurring more frequently in the list than expected by chance based on the background data. \n\nIt is recommended to **characterize up- and downregulated genes separately**.\n\n!! Thousands of pathways are tested for enrichment, this could lead to false positives. **Multiple testing correction** is used to correct the p-values from the individual enrichment tests to reduce the chance of false positives !!\n\n#### ToppGene: most up-to-date but only human, mouse and rat\n[ToppGene](https://toppgene.cchmc.org/) is the most up-to-date portal for gene list functional enrichment. See [this overview](https://toppgene.cchmc.org/navigation/database.jsp) of their resources of functional annotations and their last update date. \n\nThe **ToppFun** tool returns enriched terms from GO, phenotypes, pathways, protein interactions, domains, transcription factor binding sites, miRNA-target genes, disease associations, drug-gene interactions compiled from various data sources...\n\nIt supports gene symbols, Ensembl, Entrez, RefSeq and UniProt IDs from human. However, since gene symbols for human, mouse and rat are identical the tool can also be used for mouse and rat. \n\n&gt; ### {% icon hands_on %} Exercise ToppGene\n&gt;  How to do functional enrichment analysis with ToppFun ?\n&gt;    &gt; ### {% icon solution %} answer\n&gt;    &gt; - On the [ToppGene](https://toppgene.cchmc.org/) page click the first link **[ToppFun](https://toppgene.cchmc.org/enrichment.jsp): Transcriptome, ontology, phenotype, proteome...**\n&gt;    &gt; - Enter gene symbols or Ensembl IDs in the box **Training Gene Set**\n&gt;    &gt; - Click **Submit Query**\n&gt;    &gt; - If the gene list contains non-approved symbols or duplicates, they are listed under **Genes Not found**. \n&gt;    &gt; \n&gt;    &gt; ![ToppGene_Not_Found](../../images/FunTopp_NF.png)\n&gt;    &gt; - In the section **Calculations** select the functional annotation types you want to test (all in our case) and select the multiple correction method (default FDR is ok) and the significance cut-off level (default 0.05 is ok)\n&gt;    &gt; - Click **Start**\n&gt;    &gt; - **Input Parameters** summarizes the input parameters of the search. Click the **Show Detail** (red) link to see them. \n&gt;    &gt; - **Training results** contains the enrichment analysis results. **Download all** (blue) will download the analysis results as a text file.\n&gt;    &gt; - Click the **Display chart** (green) link to visualize the results\n&gt;    &gt; \n&gt;    &gt; ![ToppGene_Results](../../images/FunTopp_Results.png)\n&gt;    &gt; - If you want to see which genes from your list belong to a certain annotation click the number in the **Genes from innput** column\n&gt;    &gt; \n&gt;    {: .solution}\n{: .hands_on}\n\n#### Enrichr: longest list of resources but not so up-to-date\n\n[Enrichr](http://amp.pharm.mssm.edu/Enrichr/) use a respectable number of [resources](http://amp.pharm.mssm.edu/Enrichr/index.html#stats) to compute enrichment but they are not as regularly updated as those of ToppGene. To learn more about Enrich, see their [FAQ page](http://amp.pharm.mssm.edu/Enrichr/#help).\n\nEnrichr uses a list of gene symbols as input (one per line). It only supports human, mouse and rat. You can upload the list by selecting a text file or by simply pasting the list of gene symbols into the text box. \n\n&gt; ### {% icon hands_on %} Exercise 1 Enrichr\n&gt;  How to perform functional enrichment analysis in Enrichr ?\n&gt;  \n&gt;  Browse to [Enrichr submission page](http://amp.pharm.mssm.edu/Enrichr/index.html) and click the **Submit** button\n{: .hands_on}\n\nThe results page consists of multiple tabs, each tab giving an overview of a specific type of annotation (Transcription, Pathways, Ontologies...), e.g. \n\n&gt; ### {% icon hands_on %} Exercise 2 Enrichr\n&gt;  How to visualize the results for KEGG pathways as a bar chart ?\n&gt;    &gt; ### {% icon solution %} answer\n&gt;    &gt; Go to the **Pathways** tab and expand the results for **KEGG** as a bar chart.\n&gt;    {: .solution}\n{: .hands_on}\n\nThe bar charts are interactive: hover your mouse over the bars to see the enrichment scores. Clicking the bars will order the terms according to different scores.\n\nThe length of the bar represents the significance of that specific term. In addition, the brighter the color, the more significant that term is.\n\nEnrichr implements three approaches to compute enrichment scores:\n- The **p-value** comes from a test implemented in most enrichment analysis tools: the hypergeometric test\n- The **q-score** is the adjusted p-value using the Benjamini-Hochberg method for correction for multiple hypotheses testing.\n- EnrichR computes enrichment using the hypergeometric test for many random gene sets to compute mean and standard deviation of the expected rank for each annotation. Then it computes an **odds ratio** reflecting the deviation of the actual rank from this expected rank.\n- They combine the p-value of the hypergeometric test with the odds ratio into a **combined score**\n \n&gt; ### {% icon hands_on %} Exercise 3 Enrichr\n&gt; How to obtain the table containing the actual scores ?\n&gt; Sort the terms according to adjusted p-value\n&gt;    &gt; ### {% icon solution %} answer\n&gt;    &gt; - If you want to see the actual scores click the **Table** tab\n&gt;    &gt; - Click the name of the column you want to use for sorting\n&gt;    &gt; \n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Exercise 4 Enrichr\n&gt; Look at the results for GO Biological processes, OMIM disease, and TargetScan miRNAs\n&gt; \n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Exercise 5 Enrichr\n&gt;  How to visualize enriched Transfac and Jaspar TFBS as a network ?\n&gt;    &gt; ### {% icon solution %} answer\n&gt;    &gt; - Go to the **Transcription** tab and click **TRANSFAC and JASPAR PWMs**\n&gt;    &gt; - Visualize the results as a network by clicking then **Network** tab \n&gt;    &gt; \n&gt;    {: .solution}\n{: .hands_on}\n\nEach node in the network represents a term (in this case a Transcription Factor) and a link between two nodes means that the 2 transcription factors have some genes from the list in common. the genes are linked to both transcription factors. Since these transcription factors share target genes from the list they might interact to regulate the process you&#39;re studying.\n\n#### Webgestalt: all organisms but one resource at a time\n\nThis tool largely overlaps in data-sources with Enrichr but updates them more regularly.\n\n[WebGestalt](http://www.webgestalt.org/) accepts many ID types and supports 12 different model organisms. For other organisms it allows to upload your own functional annotation database (see section 3.1 of the [manual](http://www.webgestalt.org/WebGestalt_2019_Manual.pdf) of this tool).\n\n&gt; ### {% icon hands_on %} Exercise 1 WebGestalt\n&gt;  How to calculate enrichment of KEGG pathways in a list of genes ?\n&gt;    &gt; ### {% icon solution %} answer\n&gt;    &gt; - In the **Organism** box select the correct organism\n&gt;    &gt; - In the **Method** box select **Over-Representation Analysis**\n&gt;    &gt; - In the **Functional Database** boxes select **pathway** and **KEGG**\n&gt;    &gt; - In the **Gene ID type** box select the correct ID type\n&gt;    &gt; - Upload the list of IDs\n&gt;    &gt; - In the **Select Reference Set** box select the correct background, for lists generated by RNA-Seq experiments **genome, protein-coding** is a good choice because that is what you have measured\n&gt;    &gt; - Click the **Submit** button\n&gt;    &gt; \n&gt;    {: .solution}\n{: .hands_on}\n\nThe **Enrichment results** can be visualized as a table, a bar chart or a Volcano plot. Dark blue bars are considered significantly enriched. \n\n![WebGestalt_Results](../../images/FunWebG_Results1.png)\n\nClicking a bar shows the details on the bottom half of the page: \n- **FDR** is the corrected p-value (blue)\n-**Mapped input** represents your gene list\n- **gene set** is the total group of genes in the genome with this annotation\n- **overlap** is the number of genes from your list with this annotation. They are listed in the table.\n\n![WebGestalt_Results](../../images/FunWebG_Results2.png)\n\n&gt; ### {% icon hands_on %} Exercise 2 WebGestalt\n&gt; Repeat the enrichment analysis on Wiki pathways\n{: .hands_on}\n\nAgain, many more tables can be generated in WebGestalt and you should choose the type of enrichment that fits your experimental needs. Data can be saved back to disk for further use.\n\n### g:Profiler: many organisms but limited resources\n[g:Profiler](https://biit.cs.ut.ee/gprofiler/) supports a [long list of organisms but has less resources](https://biit.cs.ut.ee/gprofiler/page/organism-list) than the other tools since it retrieves functional annotations from Ensembl representing GO terms, pathways, networks, regulatory motifs, and disease phenotypes. \n\nIt is very [regularly updated](https://biit.cs.ut.ee/gprofiler/page/news).\n\n&gt; ### {% icon hands_on %} Exercise 1 g:Profiler\n&gt;  How to calculate enrichment in a list of genes ?\n&gt;    &gt; ### {% icon solution %} answer\n&gt;    &gt; - For Enrichment analysis you need to use the **g:GOSt** tool.\n&gt;    &gt; - **Upload query**: a file with gene IDs (in this example Ensembl IDs - one per line). \n&gt;    &gt; - In the **Functional Database** boxes select **pathway** and **KEGG**\n&gt;    &gt; - In the **Gene ID type** box select the correct ID type\n&gt;    &gt; - Select the **Organism** you need\n&gt;    &gt; - Click the **Run query** button\n&gt;    &gt; \n&gt;    &gt; ![g:Profiler_Interface](../../images/FungP_Interface.png)\n&gt;    &gt; \n&gt;    {: .solution}\n{: .hands_on}\n\nThis tool produces visually attractive results. Every dot in the graph represents a functional annotation. Hover your mouse over a dot to show details like the name of the annotation and the corrected p-value. \n\n![g:Profiler_Results](../../images/FungP_Results.png)\n\nAlso the detailed results are very visual. \n\n### Gene set enrichment analysis\nSome omics experiments generate a ranked list of genes:\n- genes ranked by differential expression score from a RNA-Seq experiment\n- genes ranked by sensitivity in a genome-wide CRISPR screen\n- mutated genes ranked by a score from a cancer driver prediction method\n- ...\n\nTo analyze these lists, the following steps are taken\n1. The genes are divided into groups based on functional annotation (gene sets)\n2. For every group enrichment of high or low scores is calculated\n\nGroups of related genes are called gene sets: a *pathway gene set* includes all genes in a pathway. \n\nThis is why this type of analysis is called GSEA, Gene Set Enrichment Analysis. It assumes a whole-genome ranked list as input. \n\n\n#### GSEA\nGSEA is most often done in R or via software that you install on your computer like  [GSEA](http://software.broadinstitute.org/gsea/) from the Broad Institute. \n\nGSEA is recommended when ranks are available for all or most of the genes in the genome (e.g. RNA-Seq data). It is not suitable when only a small portion of genes have ranks available (e.g. an experiment that identifies mutated cancer genes).\n\n#### g:Profiler\nIf you only have scores for a subset of the genome you should analyze the data using [g:Profiler](https://biit.cs.ut.ee/gprofiler/)with the **Ordered query** option.\n\n![gProfiler_Ranked](../../images/FungP_Ranked.png)\n\nYour list should now consist of gene IDS ordered according to decreasing importance (in this case increasing corrected p-value for differential expression). \n\ng:Profiler performs enrichment analysis with increasingly larger numbers of genes starting from the top of the list. This procedure identifies functional annotations that associate to the most dramatic changes, as well as broader terms that characterise the gene set as a whole.\n\n&gt; ### {% icon hands_on %} Exercise 2 g:Profiler\n&gt; Repeat the enrichment analysis with the ranked gene list\n{: .hands_on}\n\n### Resources of functional annotation\nFunctional annotations can be very diverse: molecular functions, pathways (genes that work together to carry out a biological process), interactions, gene regulation, involvement in disease... \n\nOnline enrichment analysis tools often have functional annotation built-in for a limited set of organisms but some tools like WebGestallt also allow to upload your own annotation. \n\n[Pathguide](http://www.pathguide.org/) contains info about hundreds of pathway and molecular interaction related resources. It allows organism-based searches to find resources that contain functional info on the organism you work on. \n\nGene sets based on GO, pathways,omics studies, sequence motifs, chromosomal position, oncogenic and immunological expression\nsignatures, and various computational analyses maintained by the GSEA team of [MSigDB](http://www.msigdb.org).\n\n### Choosing the right background\nFunctional enrichment methods require the definition of background genes for comparison. **All annotated protein-coding genes** are often used as default. This leads to false-positive results if the experiment measured only a subset of all genes. For example, setting a custom background is important in analyzing data from targeted sequencing or phosphoproteomics experiments. The appropriate **custom background** in this example would include all genes in the sequencing panel or all known or all phosphoproteins.\n&quot;,&quot;# Introduction\n{:.no_toc}\n\n&lt;!-- This is a comment. --&gt;\n\nThe goal of homology modeling is to predict the 3D structure of a protein that comes close to what would be achieved experimentally with X-Ray experiments.\n\nMain principles of homology modeling\n\n- We predict the structure of a protein sequence on the basis of the structure of another protein with a similar sequence (the template)\n- If the sequences are similar, the structures will have a similar fold\n- Structure is more conserved than sequence\n\n&gt; ### Agenda\n&gt;\n&gt; In this tutorial, we will cover:\n&gt;\n&gt; 1. TOC\n&gt; {:toc}\n&gt;\n{: .agenda}\n\n# Main ingredients for homology modelling \n\n## The sequence\n\nLast week my colleague sequenced a plant protein. He is not a bioinformatician. Yet, he would like to know what the structure might look like to do some rounds of rational mutagenesis. Let&#39;s try to address the problem for him.\n \nHe came up with this sequence:\n\n```\nSVCCPSLVARTNYNVCRLPGTEAALCATFTGCIIIPGATCGGDYAN\n```\n\n## Searching for the template structure\n\nActually, the first step is to check whether the PDB already contains the structure of this sequence. That would be easy so we don&#39;t have to model anything. We will use Blast again to search with the sequence.\n\n**TODO: add hands-on area with Blast search on PDB page**\n\n&gt; ### {% icon hands_on %} Hands-on: Data upload\n&gt;\n&gt; 1. Create a new history for this tutorial\n&gt; 2. Import the files from [Zenodo]() or from the shared data library\n&gt;\n&gt;    ```\n&gt; \n&gt;    ```\n&gt;    ***TODO***: *Add the files by the ones on Zenodo here (if not added)*\n&gt;\n&gt;    ***TODO***: *Remove the useless files (if added)*\n&gt;\n&gt;    {% include snippets/import_via_link.md %}\n&gt;    {% include snippets/import_from_data_library.md %}\n&gt;\n&gt; 3. Rename the datasets\n&gt; 4. Check that the datatype\n&gt;\n&gt;    {% include snippets/change_datatype.md datatype=\&quot;datatypes\&quot; %}\n&gt;\n&gt; 5. Add to each database a tag corresponding to ...\n&gt;\n&gt;    {% include snippets/add_tag.md %}\n&gt;\n{: .hands_on}\n\nA suitable template structure to make a high quality model should have following properties:\n\n- The highest possible sequence identity from all structures in the PDB when aligned to the target sequence\n- A good resolution (and R-factor): if many identical template structures exist with the same sequence, filter by resolution\n- Is solved by X-RAY, not NMR\n\n&gt; ### {% icon hands_on %} Hands-on: Data upload\n&gt;\n&gt; 1. Create a new history for this tutorial\n&gt; 2. Import the files from [Zenodo]() or from the shared data library\n&gt;\n&gt;    ```\n&gt; \n&gt;    ```\n&gt;    ***TODO***: *Add the files by the ones on Zenodo here (if not added)*\n&gt;\n&gt;    ***TODO***: *Remove the useless files (if added)*\n&gt;\n&gt;    {% include snippets/import_via_link.md %}\n&gt;    {% include snippets/import_from_data_library.md %}\n&gt;\n&gt; 3. Rename the datasets\n&gt; 4. Check that the datatype\n&gt;\n&gt;    {% include snippets/change_datatype.md datatype=\&quot;datatypes\&quot; %}\n&gt;\n&gt; 5. Add to each database a tag corresponding to ...\n&gt;\n&gt;    {% include snippets/add_tag.md %}\n&gt;\n{: .hands_on}\n\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; 1. Is there a difference in the number of identities, positives and gaps between the two remaining x-ray structures? \n&gt; 2. What is the PDB ID with the highest resolution, does not have insertions or deletions and should thus be the better template structure? \n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; 1. **TODO** \n&gt; &gt; 2. **TODO** \n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\n\n## Aligning target and template sequence and template selection\n\nThe alignment is the most crucial part of homology modeling. We will not explain what an alignment is and how you make it, this should be known. In an alignment, we put homologous sequences on top of each other in a text file. The point is that amino acids that are on top of each other in the same column are assumed to have the equivalent position in the 3D structure. So if the template sequence has an Ala at position 3, where the target sequence has a Phe, homology modelling tools will use the backbone of the template structure and replace the sidechain at position 3 from Ala to Phe.\n\n&gt; ### {% icon hands_on %} Hands-on: Data upload\n&gt;\n&gt; 1. Create a new history for this tutorial\n&gt; 2. Import the files from [Zenodo]() or from the shared data library\n&gt;\n&gt;    ```\n&gt; \n&gt;    ```\n&gt;    ***TODO***: *Add the files by the ones on Zenodo here (if not added)*\n&gt;\n&gt;    ***TODO***: *Remove the useless files (if added)*\n&gt;\n&gt;    {% include snippets/import_via_link.md %}\n&gt;    {% include snippets/import_from_data_library.md %}\n&gt;\n&gt; 3. Rename the datasets\n&gt; 4. Check that the datatype\n&gt;\n&gt;    {% include snippets/change_datatype.md datatype=\&quot;datatypes\&quot; %}\n&gt;\n&gt; 5. Add to each database a tag corresponding to ...\n&gt;\n&gt;    {% include snippets/add_tag.md %}\n&gt;\n{: .hands_on}\n\n\nTo extract the sequence from the template structure, display the FASTA sequence of the template structure and paste it into the text editor on the first line.\n\n&lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../../images/image_name\&quot; alt=\&quot;Alternative text\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; Legend of the image&lt;/figcaption&gt;&lt;/figure&gt;\n\nThe idea is to keep the theory description before quite simple to focus more on the practical part.\n\n&lt;figure id=\&quot;figure-2\&quot;&gt;&lt;img src=\&quot;../../images/image_name\&quot; alt=\&quot;Alternative text\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 2:&lt;/span&gt; Legend of the image&lt;/figcaption&gt;&lt;/figure&gt;\n\n\n# Building the homology model with Swiss Model \n\nOur current request for homology modelling is a rather safe one, so we can use an automatic server for homology modelling. There are many automatic tools available and many of them compete in regular competitions like lastly, the 12th Community Wide Experiment on the Critical Assessment of Techniques for Protein Structure Prediction (CASP12) - [1].\n\nIn our example, we take the [Swiss Model server](https://swissmodel.expasy.org/interactive). SWISS-MODEL is a fully automated protein structure homology-modelling server, accessible via the ExPASy web server, or from the program DeepView (Swiss Pdb-Viewer). The purpose of this server is to make Protein Modelling accessible to all biochemists and molecular biologists worldwide.\n\n&gt; ### {% icon hands_on %} Hands-on: Template selection step with Swiss Model \n&gt;\n&gt; 1. Browse to the [Swiss Model server](https://swissmodel.expasy.org/interactive) \n&gt; 2. On the first page, paste the sequence of our unknown protein in the field &#39;Target Sequence&#39; and give the project a name. \n&gt; &lt;figure id=\&quot;figure-3\&quot;&gt;&lt;img src=\&quot;../../images/Modelling_sequence_template_step1.png\&quot; alt=\&quot;Swiss Model Start page\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 3:&lt;/span&gt; Start page of Swiss Model&lt;/figcaption&gt;&lt;/figure&gt;\n&gt; 3. Click &#39;Search templates&#39; to initiate the first step. \n&gt;    Thereafter, the server identifies structural template(s) and gives an overview list of hits \n&gt;    which you can select the templates from.\n&gt;\n{: .hands_on}\n\n&gt; ### {% icon question %} Question\n&gt;\n&gt; Which of the 10 (at the time of writing) possible template structures would you select as template for the model building process? \n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; **TODO: add link with 10 template** \n&gt; &gt; We suggest as template **1jxx.1.A** given that it is an X-ray structure with high resolution and a very high \n&gt; &gt; sequence identity (X-ray, 0.9 , 78.26 %).\n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\n\n&gt; ### {% icon hands_on %} Hands-on: Model Building Step and Visualisation \n&gt;\n&gt; 1. Once you have selected the template, hit &#39;Build Model&#39; to start the homology modelling procedure. \n&gt;    The server will alignment of target sequence and template structure(s), build a model and evaluate it. \n&gt;    These steps require specialized software and integrate up-to-date protein sequence and structure databases. \n&gt;    Each of the above steps can be repeated interactively until a satisfying modelling result is achieved. \n&gt;\n&gt; 2. Once the model has been built, you can download it.\n&gt; 3. If the Swiss Model server is too busy at the moment you execute the request, you can download the model from\n&gt;    [here](https://zenodo.org/record/3551850#.Xdqs4ehKiUk).\n&gt; 4. Load the created model into YASARA. \n&gt;    Perform a structural superposition with your reference e.g. 1CRN \n&gt;    try to detect the differences through manipulating the visualisations.\n&gt;    &lt;figure id=\&quot;figure-4\&quot;&gt;&lt;img src=\&quot; \&quot; alt=\&quot;superposition\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 4:&lt;/span&gt; Superposition of 1CRN with the obtained model&lt;/figcaption&gt;&lt;/figure&gt;\n&gt;\n{: .hands_on}\n\n\n# Conclusion\n{:.no_toc}\n\nHomology modelling evolved over the years and many online tools for homology modelling are available. You have used the Swiss Model service with a reasonable simple modelling request. Often, in research projects, homology modelling can be rather difficult and needs expert knowledge depending on the actual situation (sequence conservation, available templates, etc.).\n&quot;,&quot;# Introduction\n{:.no_toc}\n\n&lt;!-- This is a comment. --&gt;\n\nMutations in proteins can have various origins. Natural occurring mutations are random and can have any kind of effect on the protein structure and/or function. Mutations can have no effect at all, be stabilizing of destabilizing. In the last two cases, these can lead to diseases.\n\nBut we can also make mutations in the wet lab to study the effect of a single residue position on protein stability, interaction with a peptide ligand etc ... Such site-directed mutagenesis in the wet lab is hard labour and costs money, I don&#39;t have to explain that to you. So wouldn&#39;t it be easier, cheaper and more rational if you could predict the effect of some mutations first with bioinformatics and then test the really interesting ones in the lab?\n\nFoldX is a molecular modeling tool that can quantitatively predict the change in free energy (kcal/mol) upon mutation. These values approach experimental determined values. FoldX is a non-interactive command line program. In other words, not user friendly. But the bright news is that I recently developed a YASARA plugin for FoldX, so that all predictions are just a few clicks away. And the nice thing is, it&#39;s all free!\n\n&gt;\n&gt; In this tutorial, we will cover:\n&gt;\n&gt; 1. TOC\n&gt; {:toc}\n&gt;\n{: .agenda}\n\n# P53 as example protein \n\nIn this section we will let the FoldX plugin loose on some real world examples and give you step-by-step instructions on how to proceed and analyze the results. We will use the P53 tumor suppressor protein as our example molecule. In a first exercise you will make a point mutation with FoldX and determine if the mutation is stabilizing or destabilizing for the P53 structure. In a second exercise you will design a mutation in the P53 structure at the DNA binding interface and determine how the mutation affects the interaction energy of P53 with the DNA strand.\n\n## Get data\n\n&gt; ### {% icon hands_on %} Hands-on: Data upload\n&gt;\n&gt; Download the file [2AC0.sce](https://zenodo.org/record/3551686/files/2AC0.sce?download=1).\n&gt;\n{: .hands_on}\n\n# What do FoldX energies mean?\n\n\nBefore we start, some basic information about FoldX energies is necessary.\n\nFirst of all, FoldX energies are expressed in kcal/mol.\n\nThe main focus of FoldX is the prediction of free energy changes, e.g. what happens to the free energy of the protein when we mutate an Asp to a Tyr? FoldX will then calculate the free energy of the wild type (WT) and the mutant (MT) and make the difference:\n\n```\nddG(change) = dG(MT) - dG(WT)\n```\n\nFoldX is trained to make ddG(change) approach experimental values. It is important to realize that dG(WT) and dG(MT) are meaningless numbers as such. These do not correlate with experimental values. Only ddG(change) does.\n\nAs a rule of thumb we use:\n\n```\nddG(change) &gt; 0 : the mutation is destabilizing\n\nddG(change) &lt; 0 : the mutation is stabilizing\n```\n\nThe error margin of FoldX is approximately 0.5 kcal/mol, so changes in that range are insignificant. \n\n# How to minimize the structure with FoldX\n\nFoldX assumes that the starting structure has been energy minimized. Although crystal structures with high resolution represent the form with a low energy, FoldX performs best when we minimize it just before we do the predictions. This FoldX procedure is called RepairPDB and should be done on each structure you want to perform calculations on.\n\nOpen the YASARA scene 2AC0.sce in YASARA. This is a part of a tetrameric complex of the transcription factor P53 bound to DNA. I removed 3 of the 4 P53 structures for simplicity and visualized some nice features.\n\nLoad the scene with:\n\n```\nFile &gt; Load &gt; YASARA Scene\n```\n&lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../../images/Training_1.png\&quot; alt=\&quot;monomer bound to DNA -80width\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; P53 monomer bound to DNA&lt;/figcaption&gt;&lt;/figure&gt;\n\nTo Repair (or minimize) the structure with FoldX go to:\n```\nAnalyse &gt; FoldX &gt; Repair object \n```\n\n&lt;figure id=\&quot;figure-2\&quot;&gt;&lt;img src=\&quot;../../images/Training_2.png\&quot; alt=\&quot;Select the object for repairing\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 2:&lt;/span&gt; Select the object for repairing&lt;/figcaption&gt;&lt;/figure&gt;\n\nAnd select the only object in the list.\n\nWhen the Repair is finished, the Repaired Object is placed in Object 2 (see top right corner) and superposed with the original Object 1. Take a look at the sidechains and see what FoldX has done while Repairing.\n\nIf you feel the repair takes too long (more than 10 minutes) due to a slow computer, download and open this YASARA Scene with the [Repaired Object](https://zenodo.org/record/3551686/files/2AC0_Repaired.sce?download=1).\n\nBecause we will continue working with this Repaired Object, we can now hide the entire Object 1 by toggling the Visibility column in the top right corner head-up display (HUD).\n\n# How to analyze a mutation \n\nFoldX has mutated the Ala to Trp and the structure with the Trp mutation has been loaded in the next Object (3) and is superposed with the wild type (WT, Object 2). We selected an option to show the VdW clashes in WT and mutant. The atoms that give rise to steric clashes are colored in red. Toggle the Visibility of Object 2 (WT) and Object 3 (mutant) and see how many clashes we introduced by mutating the Ala to Trp.\n\n\n&lt;figure id=\&quot;figure-3\&quot;&gt;&lt;img src=\&quot;../../images/Training_7.png\&quot; alt=\&quot;Zoomed-in-view on the original Ala159, no Vander Waals clashes here\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 3:&lt;/span&gt; Zoomed-in-view on the original Ala159, no Vander Waals clashes here&lt;/figcaption&gt;&lt;/figure&gt;\n\n&lt;figure id=\&quot;figure-4\&quot;&gt;&lt;img src=\&quot;../../images/Training_8.png\&quot; alt=\&quot;Zoomed-in-view on the mutated Ala159Trp, lots of red Vander Waals clashes here\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 4:&lt;/span&gt; Zoomed-in-view on the mutated Ala159Trp, lots of red Vander Waals clashes here&lt;/figcaption&gt;&lt;/figure&gt;\n\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; Van der Waals clashes are red colored atoms. \n&gt; Do you see a difference around the mutation site between WT and mutant? \n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; Toggle the Visibility of WT and mutant to see the differences. \n&gt; &gt; Open the Console by pressing the spacebar twice and see the free energy change of the mutation. \n&gt; &gt; Anything above a change of +0.5kcal/mol is already assumed to be destabilizing.\n&gt; &gt; In the console - to open press spacebar twice - we see an energy change of +29 kcal/mol.\n&gt; &gt; This is clearly a destabilizing mutation.\n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\n&lt;figure id=\&quot;figure-5\&quot;&gt;&lt;img src=\&quot;../../images/Training_9.png\&quot; alt=\&quot;In the console - to open press spacebar twice - we see an energy change of +29 kcal/mol.\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 5:&lt;/span&gt; Open the console to explore the situation.&lt;/figcaption&gt;&lt;/figure&gt;\n\n# Study the effect of a second mutation \n\nHide Object 3 by toggling its Visibility so that only Object 2 (the repaired WT) is visible.\nFirst turn on all atoms in the molecules G and H (DNA) again as you did previously, because the FoldX run has hidden it (it rearranged the view to show the VdW clashes).\n\nShow the sidechain of Arg273 of Object 2 by searching for it in the sequence selector, then right-click on it and go to:\n\n\n```\nShow atoms &gt; Sidechain and CA and zoom in on Arg273\n```\n\nNotice how the positively charged Arginine is making an electrostatic interaction with the negative phosphate from the DNA backbone.\n\n&lt;figure id=\&quot;figure-6\&quot;&gt;&lt;img src=\&quot;../../images/Training_10.png\&quot; alt=\&quot;R273 makes an electrostatic interaction with the DNA phosphate groups.\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 6:&lt;/span&gt; R273 makes an electrostatic interaction with the DNA phosphate groups.&lt;/figcaption&gt;&lt;/figure&gt;\n\nLet&#39;s see what would happen to the interaction energy between the DNA and P53 when we mutate this Arginine to Alanine.\n\nRight-click on this Arg273 in the sequence selector and go to:\n\n```\nFoldX &gt; Mutate residue\n```\n\nA number of menus is now presented and here is what you need to do in each menu:\n\n1. Select Calculate interaction energy change\n2. Select Ala\n3. &#39;Move neighbours&#39; and &#39;Show disrupted and new hydrogen bonds&#39;\n4. Don&#39;t change any numerical options in the last menu\n\n&lt;figure id=\&quot;figure-7\&quot;&gt;&lt;img src=\&quot;../../images/Training_11.png\&quot; alt=\&quot;View of the first options menu with &#39;Show new and disrupted hydrogen bondsxi&#39; selected.\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 7:&lt;/span&gt; View of the first options menu with &#39;Show new and disrupted hydrogen bonds&#39; selected.&lt;/figcaption&gt;&lt;/figure&gt;\n\n&gt; ### {% icon question %} Questions\n&gt; \n&gt; 1. What is the change in interaction energy is between P53 and DNA chain G upon mutation?\n&gt;    And what is the reason?\n&gt; 2. Why doesn&#39;t the mutation affect the interaction with DNA chain H?\n&gt;\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; 1. Toggle the Visibility between this mutant and the WT structure and see how the hydrogen bonding changes and check the output in the Console. \n&gt; &gt;    &lt;figure id=\&quot;figure-8\&quot;&gt;&lt;img src=\&quot;../../images/Training_12.png\&quot; alt=\&quot;Mutation\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 8:&lt;/span&gt; Change in interaction energy&lt;/figcaption&gt;&lt;/figure&gt;\n&gt; &gt;    We see that the mutation decreases the interaction with DNA strand G by approximately 1 kcal/mol\n&gt; &gt;    since we lost 1 hydrogen bond.\n&gt; &gt;\n&gt; &gt; 2. ***TODO***  \n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\n# Conclusion\n{:.no_toc}\n\nInstead of DNA-protein, FoldX can of course also calculate interaction energy changes in protein-protein or peptide-protein complexes.\n\n&quot;,&quot;&gt; ### Agenda\n&gt;\n&gt; In this tutorial, we will deal with:\n&gt;\n&gt; 1. TOC\n&gt; {:toc}\n&gt;\n{: .agenda}\n\n# Search for a structure\n#### Via [UniProt](http://www.uniprot.org/)\nThe way of searching for a specific protein structure depends on the data you already have. You might already have the PDB ID (a unique identifier), that&#39;s an easy one. But mostly you have the protein name or you just have a sequence. In the last cases I recommend to start from the UniProt website at &lt;http://www.uniprot.org&gt;, which is the best annotated protein database in the world. Our first model protein will be the molecular chaperone DnaK from *E. coli*. Below is an image of the UniProt search box where you can start your search for proteins.\n\n&lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../../images/uniprotsearchbox.png\&quot; alt=\&quot;uniprotsearchbox.png\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; Search box&lt;/figcaption&gt;&lt;/figure&gt;\n\n&gt; ### {% icon hands_on %} Explore a PDB structure on the Uniprot web site\n&gt;\n&gt; 1. Go to the UniProt website and search for the DnaK protein\n&gt; - The UniProt search engine returns a list of DnaK protein sequences from a variety of organisms. An entry with accession code **P0A6Y8** and entry name **DNAK_ECOLI** should be near the top of this list.\n&gt; 2. Click on the *accession code* (column Entry) to view the protein page of this DnaK from the model organism *Escherichia coli*.\n&gt; 3. Click on *Structure* in the left-side menu and then look at the *3D structure databases* table.\n{: .hands_on }\n\n&gt; ### {% icon question %} Guidelines which PDB structures to select\n&gt;\n&gt; Which structures (give the 4-character PDB ID) of the C-terminal domain of DnaK should preferentially be use for analysis and why?\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt; Usually, the recommended selection criteria are using an X-ray structure with low resolution and low Rfree factor. Furthermore, the PDB database has pre-calculated a validation report for all of the structures.\n&gt; &gt; As an example, have a look at https://www.ebi.ac.uk/pdbe/entry/pdb/4EZX under the section &#39;Experiments and Validation&#39;. For many PDB structures, there is also a re-done structure available with a vast amount of informaton on the quality of the X-ray structure and suggested &#39;better&#39; models e.g. (https://pdb-redo.eu/db/4ezx). In our case, we could opt for the structures 1DKX and 4EZX.\n&gt; &gt;\n&gt; &gt; This is a difficult example since there are so many high resolution structures available. So, it is recommended to study the articles and compare the available structures to find your favorite structure for further analysis.\n&gt; &gt;\n&gt; {: .solution}\n{: .question }\n\n\n#### Via the Protein Data Bank by PDB ID\n\n&lt;iframe src=\&quot;https://h5p.org/h5p/embed/577970\&quot; width=\&quot;699\&quot; height=\&quot;418\&quot; frameborder=\&quot;0\&quot; allowfullscreen=\&quot;allowfullscreen\&quot;&gt;&lt;/iframe&gt;\n&lt;script src=\&quot;https://h5p.org/sites/all/modules/h5p/library/js/h5p-resizer.js\&quot; charset=\&quot;UTF-8\&quot;&gt;&lt;/script&gt;\n\n&lt;iframe src=\&quot; https://docs.google.com/presentation/d/1lgEeigU8M45xF2BjQgPumgxalzfiHZeD/preview\&quot; width=\&quot;640\&quot; height=\&quot;480\&quot;&gt;&lt;/iframe&gt; \n\n\nYou can find structural information directly at the PDB database. The web site of the PDB consortium is located at &lt;http://www.wwpdb.org&gt;. This web site provides links to all members of the PDB (left side). It is a question of taste which resource you start off with. For X-ray structures, it is currently PDBe, RCSB PDB, PDBj. For NMR structres, you find the BMRB. In today&#39;s course, we focus on the PDB resources only.\n\nBelow is an image of the RCSB search box &lt;http://www.rcsb.org/pdb/home/home.do&gt; where you can start your search for structures.\n\n![Pdbsearchbox_RCSB.png](../../images/Pdbsearchbox_RCSB.png)\n\nThe PDB file with ID **1DKX** contains the atomic coordinates of the molecular chaperone (DnaK) from *E. coli*.\n\n&gt; ### {% icon hands_on %} Search a structure on the RCSB web site\n&gt;\n&gt; 1. Go to the PDB website and type 1DKX in the search box\n{: .hands_on }\n\n\nThis will lead you to the same page we got earlier through UniProt.\n\n#### Via the Protein Data Bank by sequence\n\nIn lots of cases we only have a sequence of which we would like to find out if there is structural information. The PDB can be searched using a sequence as input. Here is the sequence of the C-terminal substrate binding domain of DnaK:\n```\n    DVKDVLLLDVTPLSLGIETMGGVMTTLIAKNTTIPTKHSQVFSTAEDNQSAVTIHVLQGE\n    RKRAADNKSLGQFNLDGINPAPRGMPQIEVTFDIDADGILHVSAKDKNSGKEQKITIKAS\n    SGLNEDEIQKMVRDAEANAEADRKFEELVQTRNQGDHLLHSTRKQVEEAGDKLPADDKTA\n    IESALTALETALKGEDKAAIEAKMQELAQVSQKLMEIAQQQHAQQQTAGADASANNAKDD\n    DVVDAEFEEVKDKK\n```\nThe PDB allows sequence searches through the same search box we used before.\n\n![Pdbsearchbox_RCSB.png](../../images/Pdbsearchbox_RCSB.png)\n\nThere is also an Advanced Search section, with a Blast/Fasta option in the Sequence Features section.\n\n![Blastpdb.png](../../images/Blastpdb.png)\n\n&gt; ### {% icon hands_on %} Hands-on: BLAST search for PDB structure\n&gt;\n&gt; 1. Go to the Advanced Search section\n&gt; 2. Please select &#39;Sequence BLAST/PSI-BLAST&#39; in the Query type drop down.\n&gt;    This method allows you to change some parameters for the search.\n&gt; 3. Copy and paste the sequence in the &#39;&#39;Sequence&#39;&#39; field\n&gt; 4. Press &#39;&#39;Submit query&#39;&#39;.\n&gt; 5. You should see the same structures popping up as you saw in the UniProt page of DnaK.\n{: .hands_on}\n\n# The PDB file\n\n## Introduction\n\nA PDB (Protein Data Bank) file is a plain text file that contains the\natom coordinates of a solved 3D structure of a protein or even DNA. Such\ncoordinate files can be obtained at the Protein Data Bank at\n&lt;http://www.rcsb.org/pdb&gt;. Each PDB file has a unique identifier (ID)\nconsisting of 4 characters, the first one is always a number. Note: It\nhas been announced that the 4 character code will change in the future\n&lt;https://www.wwpdb.org/news/news?year=2017\\#5910c8d8d3b1d333029d4ea8&gt;.\n\nThe PDB file with ID **1DKX** contains the atomic coordinates of the\nmolecular chaperone (DnaK) from *E coli*.\n\n&gt; ### {% icon hands_on %} Hands-on: BLAST search for PDB structure\n&gt;\n&gt; 1. Go to the PDB website at &lt;http://www.rcsb.org/pdb&gt;\n&gt; 2. Type 1DKX in the search and try to answer the following questions.\n{: .hands_on}\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; 1. How many molecules were solved in this PDB file? What kind of molecules are these (proteins, peptides, DNA, ...)?\n&gt; 2. Does the structure represent the full protein? If not, how many residues are missing? Hint: Click on the UniProt KB link in the Sequence tab to see the full sequence.\n&gt; 3. Was this structure solved by X-Ray or NMR?\n&gt; 4. What is the atomic resolution and R-factor?\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt; 1. Two, called polymers or chains: they are polypeptides ![Type](../../images/Mol_desc_1DKX.png)\n&gt; &gt; 2. To answer this question you can go to the sequence tab at the top:\n&gt; &gt;    - ![Uniprot view](../../images/Pdb_firstresiduesmissing_1dkx.png)\n&gt; &gt;    - Summary: a large chunk of the N-terminus is missing from the structure, the C-terminus is virtually complete.\n&gt; &gt; 3. X-RAY diffraction, as shown by Experimental Details\n&gt; &gt; 4. Atomic resolution: 2.00 ngstrom and R-factor of 0.206\n&gt; {: .solution }\n{: .question}\n\n\n## Downloading the structure\n\nThe file that holds the 3D coordinates can be downloaded by clicking on\n*Download files* in the top right corner and then choosing *PDB file (text)*.\nFor convenience, save this file on your desktop. The filename is the\n4-character unique PDB ID.\n\n![Pdbdownloadfile1.png](../../images/Pdbdownloadfile1.png)\n\n&gt; ### {% icon hands_on %} Hands-on: Open downloaded PDB file in an editor\n&gt; 1.   Open this file with a text editor, e.g. WordPad is an excellent tool for that.\n&gt; 2. Do you see the different sections in the PDB file? Analyse some ATOM lines and try to explain what kind of data is in each column.\n{: .hands_on}\n\nAdditional exercises on searching PDB can be found on [the basic bioinformatics exercises page](http://wiki.bits.vib.be/index.php/Exercises_on_Protein_Structure).\n&quot;,&quot;# Introduction\n{:.no_toc}\n\n&lt;!-- This is a comment. --&gt;\n\nThe goal of this exercise is appreciate how protein interactions can be studied through visual inspection and other software tools. Protein interactions can be classified into different groups regarding the molecular properties and functions of the interacting partners. (These groups are intertwined in several cases.) Some examples include:\n\n- the interactions of proteins with other proteins, small molecules, carbohydrates, lipids or nucleic acids;\n- Receptor-ligand interactions;\n- Antigen-antibody interactions;\n- Enzymatic interactions, enzyme-inhibitor interactions.\n\n&gt; ### Agenda\n&gt;\n&gt; In this tutorial, we will cover:\n&gt;\n&gt; 1. TOC\n&gt; {:toc}\n&gt;\n{: .agenda}\n\n# Exploring the structure of a nanobody-stabilized active state of the 2 adrenoceptor - the ligand \n\nWe will start with exploring one crystal structure of the 2 adrenoceptor. Together with the Steyaert lab from VIB, Kobilka published several crystal structures of the 2 adrenoceptor in its various activation states (Rasmussen et al. Nature 2011, 477)\n\n\n&gt; ### {% icon hands_on %} Get the structure\n&gt;\n&gt; 1. Download the crystal structure 3P0G from the PDB into YASARA. \n&gt;\n&gt;    ```\n&gt;    File - Load - PDB file from internet    \n&gt;    ```\n&gt;    As you can immediately appreciate, it is a bigger crystal structure with more than one molecule. \n&gt;\n{: .hands_on}\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; 1. How many molecules are present in the crystallized structures? \n&gt; 2. And how many chain identifiers are used? \n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; 1. Answer for question1\n&gt; &gt; 2. Answer for question2\n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\nSome software routines need seperate chain identifiers for molecular entities to work correctly, so we suggest to rename the small molecule to chain L.\n\n\n&gt; ### {% icon hands_on %}  \n&gt;\n&gt; 1. Activate the Head-up display\n&gt; 2. Select Rename\n&gt; 3. Enter &#39;L&#39; to proceed with the renaming. \n&gt;\n{: .hands_on}\n\nWe first have a look whether we can find out if there are specific interactions of the small molecule ligand with the adrenoreceptor.\n\nIn order to do so, we first have to add Hydrogens to all present molecules.\n\n&gt; ### {% icon hands_on %}  \n&gt;\n&gt; 1. Edit - Add - hydrogens to : All \n&gt; 2. Change the display of the ligand to Sticks\n&gt; 3. Select the amino acids of the binding pocket i.e. a sphere of 10 Angstrom around the ligand\n&gt;    ```\n&gt;    Select  in sphere around  Residue and drag with the mouse until the display says 10 \n&gt;    ``` \n&gt; 4. ```\n&gt;    View  show interactions  hydrogen bonds of - Residues\n&gt;    ```\n&gt;    select &#39;Selected&#39; in the panel Belongs to or has\n&gt;    and press OK in the subsequent window\n&gt;\n{: .hands_on}\n\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; Between which amino acids and the ligand do you see hydrogen bonds?\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; 1. Answer for question1\n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\n\nGiven that hydrogen bonding is dependent on the definition of a hydrogen bond in the program, it is not a bad idea to use other tools to compare the analysis. There are many options to do this online if you look at published crystal structures. Next to the tools which are directly linked out from the web site of the crystal structure at the PDB database you can use the [ProteinPlus server](http://proteinsplus.zbh.uni-hamburg.de/)\n\nGo to the web site of ProteinPlus and enter the PDB code 3P0G into the search box. After clicking on Go, you should be presented with on overview of tools the ProteinPlus server provides.\n\nWe do not go into great detail on all the tools but only mention PoseView. With this tool, you can prepare an automatic sketch of the small molecule-protein interactions.\n\n&lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../../images/ProteinPlusPoseView.png\&quot; alt=\&quot;Protein Plus Server\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; Overview of 3P0G&lt;/figcaption&gt;&lt;/figure&gt;\n&lt;figure id=\&quot;figure-2\&quot;&gt;&lt;img src=\&quot;../../images/3P0G_A_PoseView_Input.png\&quot; alt=\&quot;Zoom on ligand of 3P0G\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 2:&lt;/span&gt; Zoom on ligand co-crystallized with 3P0G&lt;/figcaption&gt;&lt;/figure&gt;\n\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; Between which amino acids and the ligand do you see hydrogen bonds? \n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; 1. According to PoseView, between which amino acids and the ligand do you see hydrogen bonds?\n&gt; &gt; 2. What other interactions are presented in the sketch? \n&gt; &gt; 3. Inspect the visualisation in Yasara: Do you see the interactions in Yasara as well? \n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\n\n# Exploring the structure of a nanobody-stabilized active state of the 2 adrenoceptor - the nanobody \n\nIn order to estimate the binding energy between the nanobody and the 2 adrenoceptor, we can use the FoldX tool AnalyseComplex. It is recommended to calculate these binding energies on energy-minimized structures. To illustrate the effect of the energy minimization, we compare the interaction energy of the current crystal structure and its minimized structure.\n\n\n## Use the tool FoldX tool AnalyseComplex \n\n&gt; ### {% icon hands_on %} \n&gt;\n&gt; 1. Given that energy-minimization takes a while for this rather large complex,\n&gt;     please download the Yasara scene [here](http://data.bits.vib.be/pub/trainingen/PSA/3P0G_1.sce)  \n&gt;    \n&gt;    Calculate the interaction energies between the chain A and B of the object 3P0G \n&gt;    and the RepairObj1, respectively. \n&gt;\n&gt;    ```\n&gt;    Analyze - FoldX - Interaction energy of molecules\n&gt;    ```\n{: .hands_on}\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; 1. What is the dG in the two cases? \n&gt; 2. Any idea why the difference is rather hugh?\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; 1. Answer for question1\n&gt; &gt; 2. Answer for question2\n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\nThis command also creates a list of residues forming the interface of the two proteins. Hit space to see the list of residues in the interface.\n\nTip: This list can also be useful if you want to make visualisations of the interaction site.\n\n\n# Comparing the active and the inactive conformation of the 2 adrenoceptor \n\nIn case, there is still time, I would recommend to try to use some of your capabilities you learned today and create a superposition of the inactive and active conformation of the 2 adrenoceptor. We take one of crystal structures which are available: 3SN6\n\n**TODO: add remark that we use the first chain A from 3P0G as target**\n\n```\nFile - Load - PDB file from Internet\n```\n\nYou will be kind of overwhelmed once the structure is loaded into Yasara. In order to get a first quick overview, click on the &#39;Center&#39; buttom in the menu of Yasara (5th buttom from the left). Then, it is time to look at the PDB entry of 3SN6 in the PDB database to have a first idea on what molecules are in the PDB file.\n\nAs you see on the website [3SN6](http://www.rcsb.org/pdb/explore/explore.do?structureId=3SN6i), the chain R consists of 2 molecules, the 2 adrenoceptor and lysozyme. \nIn the corresponding article, it is stated that &#39;the unstructured amino terminus of the 2AR is replaced with T4 lysozyme (T4L)&#39;.\n\nSince this is an extra molecule in the crystal structure which disturbes our view, we will delete it.\n\nAfter the manipulation, the overall picture should look roughly like this.\n\n&lt;figure id=\&quot;figure-3\&quot;&gt;&lt;img src=\&quot;../../images/3SN6_withoutLysozyme.png\&quot; alt=\&quot;Superposition\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 3:&lt;/span&gt; Overview of 3SN6 without lysozyme&lt;/figcaption&gt;&lt;/figure&gt;\n\nIn the following step, we superimpose only the receptors. The rest of the structures will move along.\n\n```\nAnalyze - Align - Pairwise, based on structure - Molecules with MUSTANG\n\nFirst, select the first chain R from 3SN6 and second, the first chain A from 3P0G as target\n\n```\n\n&lt;figure id=\&quot;figure-4\&quot;&gt;&lt;img src=\&quot;../../images/image_name\&quot; alt=\&quot;Alternative text\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 4:&lt;/span&gt; Legend of the image&lt;/figcaption&gt;&lt;/figure&gt;\n\n# Conclusion\n{:.no_toc}\n\nSum up the tutorial and the key takeaways here. We encourage adding an overview image of the\npipeline used.\n&quot;,&quot;&lt;!--\n# Introduction\n{:.no_toc}\n\n&lt;!-- This is a comment. --&gt;\n\nGeneral introduction about the topic and then an introduction of the\ntutorial (the questions and the objectives). It is nice also to have a\nscheme to sum up the pipeline used during the tutorial. The idea is to\ngive to trainees insight into the content of the tutorial and the (theoretical\nand technical) key concepts they will learn.\n--&gt;\n\n&gt; ### Agenda\n&gt;\n&gt; In this tutorial, we will cover:\n&gt;\n&gt; 1. TOC\n&gt; {:toc}\n&gt;\n{: .agenda}\n\n## Install Python and PovRay\n\nPython and PovRay should be installed already, so you can skip this part.\n\nThe programming language Python must be installed to use some very useful YASARA features. Simply start YASARA as administrator. Right click the YASARA icon on the desktop and choose \&quot;Run as administrator\&quot;. Once the program is opened, click\n\n```\nHelp &gt; Install program &gt; Python\n```\n\nPovRay is used to make high quality publication-ready images and should be downloaded first with:\n\n```\nHelp &gt; Install program &gt; PovRay\n```\n\n## Tutorial movie\n\nPlay the movie \&quot;Working with YASARA\&quot;:\n\n```\nHelp &gt; Play help movie &gt; General: Working with YASARA\n\n```\n\n## Scene styles\n\nOpen the PDB with code 1TRZ in YASARA.\n```\nFile &gt; Load &gt; PDB file from Internet\n```\nIf this option is not there, it means you haven&#39;t installed Python yet. Please check above.\n\nThe molecule will be loaded and presented in the ball style. Different scene styles exist to rapidly change the view:\n\n* F1: Ball\n* F2: Ball &amp; Stick\n* F3: Stick\n* F4: C-alpha\n* F5: Tube\n* F6: Ribbon\n* F7: Cartoon\n* F8: Toggle sidechains on/off (press multiple times and see what happens)\n\n**Be careful!** If you have just made a nice close-up of e.g. an active site where you show some residues and hide others, and put some atoms in balls while others are in sticks, you will lose everything when you press one of the F-keys!!! The F-keys change the viewing style without asking.\n\nTry all the different scene styles!\n\n## Showing and hiding residues\n\nThe function keys F1-F3 show all atoms and residues by default. The keys F4-F7 do not explicitly show atoms and residues but are merely a impressionistic representation of the structure. The F8 keys does, to a certain extent, show atoms, but only of side chains, not main chain atoms.\nMostly to do structure analysis, we want to show only the most interesting residues, the ones we want to analyze, and hide all the others.\n\nThe structure of insulin was crystallized together with some water molecules. In many cases, it is no problem to permanently delete those waters. To visualize the waters, select an atom view such as F1, F2 or F3. See the red water (oxygen) atoms floating around the surface?\n```\nEdit &gt; Delete &gt; Waters\n```\n\nThen select the base scene style without any explicit atoms, e.g. tube style (F5). Press F5. This is our representation of the backbone.\n\nThere are several ways to show the residues of interest:\n\n1. From the menu\n```\n   View &gt; Show atoms in &gt; Residue\n```\n   Select Cys7 from Molecule **A** and press OK\n2. From the sequence selector &lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../images/Seqselector.png\&quot; alt=\&quot;seqselector.png\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; Seqselector.png&lt;/figcaption&gt;&lt;/figure&gt;\n   Hover the mouse on the bottom of the screen, you will see the sequence selector opening. Open it permanently by pressing the blue nailpin on the left side of it. Search for Cys7 from Molecule **B**, right-click and select:  \n```\n   Show &gt; Residue\n```\n\nNow show the atoms of His5 in Molecule B using a method of choice.\n\nAnd now that we&#39;re on it, what is special about the two cysteines we just visualized?\n\n**Hiding** individual atoms or residues works in the same way as showing them, only now you should go to **Hide atoms** in the menus.\n\n## Showing and hiding secondary structure\n\nMost published molecular images show a detailed active site and all the\nrest is hidden for clarity. From the previous exercise we show the atoms\nof 3 residues (let&#39;s assume this is our active site). Now secondary\nstructure of the rest of the molecule is also still visible. To hide all\nthat, we do not have to hide atoms, but hide the secondary structure\n(the F5 tube view) from the rest of the structure. Atoms and residues in\nYASARA are not the same as the term &#39;secondary structure&#39;. Atoms and\nresidues are balls and sticks, &#39;secondary structure&#39; is an artistic\nimpression of the structure (beta sheet arrows, helix ribbons, ...). If\nyou get this concept, you are a YASARA master.\n\nSo let&#39;s hide many of the secondary structure, but keep just a few\nstretches around our active site. Our active site is Cys7 (A), Cys7 (B)\nand His 5 (B). This can be done in several ways. Since we would have to\nhide almost everything, I propose to hide first everything and then show\nagain those stretches that we want. But if you have a better idea, I\nwould like to hear it.\n\nHide all secondary structure:\n```\n   View &gt; Hide secondary structure of &gt; All\n```\n\nThen show stretches of residues 2-10 in Mol B and residues 4-10 in Mol A\nin tube view as:\n```\n    View &gt; Show secondary structure &gt; Tube through &gt; Residue\n```\nThen select the correct stretches of residues by keeping the CTRL key\npressed to select multiple residues.\n\nThere are still some metal-bound histidines flying around that weren&#39;t\nhidden because they are metal bound (a YASARA specific thing). Hide\nthose histidines by clicking on one of the sidechain atoms, then\nright-click and select:\n\n```\n   Hide atoms &gt; Residue\n```\n\nThe nasty dative bonds and metals can be removed simply by deleting all\nof them:\n```\n   Edit &gt; Delete &gt; Residue &gt; Name\n```\n\nIn the name column select all the metals and ions you can find.\n\nEt voil, a publication ready image!\n\n&lt;figure id=\&quot;figure-2\&quot;&gt;&lt;img src=\&quot;/home/albot/all-images-wiki/Insulin_hires.jpg\&quot; alt=\&quot;center\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 2:&lt;/span&gt; Insuline&lt;/figcaption&gt;&lt;/figure&gt;\n\n## Labels\n\nYou can put labels on the residues you want to highlight by going to the\nmain menu or selecting an atom from a residue and right-click. In the\nlatter case you select:\n```\n   Label &gt; Residue\n```\nNote that *residue name* and *residue number* is automatically selected.\nChange the height to 0.5 or so and select a nice color for the label.\nPresto\\!\n\n## Colors\n\nYou can color on all levels: atoms, residues, molecules and objects. So\nbe careful, if you color a residue, all of its atoms will get that\ncolor. If you color a molecule, all atoms in that molecule will get that\ncolor.\n\nLet&#39;s color the secondary structure (the backbone in our case) of our\nactive site in orange. But the sidechains should keep their Element\ncolors. So we shouldn&#39;t color entire residues, but only a selected atom\nset. Therefore our selection will be at the atom level, not the residue\nlevel. Go to:\n\n    View &gt; Color &gt; Atom &gt; Belongs to or has &gt; Backbone\n\nThen select the orange color (color code 150) and select &#39;Apply unique\ncolor&#39;.\n\nBeautiful, isn&#39;t it?\n\n## Saving all the beautiful work\n\nIt would be a pitty that you spent hours creating fancy molecular\ngraphics for that next Nature paper while you can&#39;t continue on the work\nthe next day. That&#39;s why YASARA can save the entire Scene including\norientations, colors, views, everything. To save the current scene, go\nto:\n\n    File &gt; Save as &gt; YASARA Scene\n\n    Choose a filename such as MyInsulin.sce\n\nTo load the work again in YASARA go to:\n\n    File &gt; Load &gt; YASARA Scene\n\n    Careful: loading a Scene will erase everything else!\n\n## Creating high quality images\n\nTo save the current view to a high quality publication ready image file,\ngo to:\n\n    File &gt; Save as &gt; Ray-traced hires screenshot\n\nThis requires that the PovRay program has been installed. See the first\nitem on this page.\n\nUsually, you prefer to have a transparent background, so check the\nrespective box.\n\n## Distances\n\n**Distances** between atoms are calculated as follows:\n\n  - select the first atom\n  - keep CTRL pressed and select the second atom.\n  - left of the screen indicates the &#39;Marked Distance&#39; in Angstrom.\n\n&lt;!-- end list --&gt;\n\n    What is the distance between the C-alpha (CA) atoms of Tyr19 and Leu16?\n\nTo solve the question you need to select a view that shows you atoms\nincluding C-alphas. Possible views or scene styles that show these atoms\ncan be F1 (ball), F2 (stick), F3 (ball\\&amp;stick) and F4 (C-alpha). The\nviews F5-F8 won&#39;t show you any CA&#39;s explicitly. Try it.\n\n    So you&#39;ve probably noticed that pressing the CTRL button allows you to select multiple atoms. This is important for the next exercise.\n\n## Hydrogen bonds\n\nTo show hydrogen bonds, YASARA needs the actual hydrogens to be present.\nIn NMR structures these are normally there. But in X-Ray structures\nhydrogens are missing. Luckily YASARA can add the hydrogens for you.\n\n    Select tube view (F5) and toggle on the sidechains with F8.\n\nAdd hydrogens with:\n\n    Edit &gt; Add &gt; Hydrogens to all\n\nThen show the hydrogen-bonds:\n\n    View &gt; Show interactions &gt; Hydrogen bonds of&gt; All &gt; OK\n\nIf the view is to chaotic for you, toggle off the sidechains with F8\n(press untill the sidechains are hidden).\n\nDo you see the typical helix and beta sheet pattern?\n\n    Arg22 from Molecule/Chain B is making an hydrogen bonded electrostatic interaction (salt bridge) with another residue. Which residue?\n\nTo remove the hydrogen bonds, you have multiple choices:\n\n    View &gt; Hide hydrogen bonds of &gt; All\n\nor just delete all hydrogens (this will also delete all hydrogen bonds):\n\n    Edit &gt; Delete &gt; Hydrogens\n\n## Surfaces\n\nIt can be very useful and informative to show the molecular surface of a\nprotein. you can visualize cavities, ligand binding sites, etc ... To\nshow the molecular surface of one monomer of dimeric insulin, go to:\n\n    View &gt; Show surface of &gt; Molecule\n\nSelect in the *Name* column A and B (these are the two chains in 1\nsubunit). Press *Continue with surface color* and make sure Alpha is\n100. Any number lower than 100 will create transparency in the surface\n(could be nice as well).\n\n## Molecular graphics exercise\n\nTry to reproduce the following image of the 1TRZ insulin structure\n(hints below):\n\n[image:insulin.png](image:insulin.png \&quot;wikilink\&quot;)\n\nHints:\n\n  - choose the proper secondary structure scene style (F6 was used here)\n  - find the correct orientation first\n  - color all backbone atoms in gray\n  - find the residue numbers of the 2 colored helices\n  - color those residues magenta\n  - show the sidechain atoms and the CA of the two histidines and the\n    glutamate\n  - color the sidechain atoms of all residues in the Element color\n  - label the histidines and the glutamate\n  - if you need some help how to change the parameters for the label,\n    please have a look at Help -\\&gt; Show user manual and search in\n    Commands / Index\n\n## More coloring\n\nDownload GroEL via PDB code 1WE3 in YASARA.\n\nTry to reproduce (approximately) the following image (hints below):\n\n[image:groel.png](image:groel.png \&quot;wikilink\&quot;)\n\nHints:\n\n  - load the PDB as File \\&gt; Load \\&gt; PDB file from internet\n  - zoom out and find the correct orientation\n  - delete the ADP, DMS and Mg molecules (are treated as residues in\n    YASARA). So Edit \\&gt; Delete \\&gt; Residue \\&gt; Adp ...\n  - color by molecule (every molecule will get another color) and color\n    by gradient (now you need to specify 2 colors, the begin and end\n    color).\n  - choose a first color (eg. color with code 0)\n  - choose a second color (eg. color with code 300, so you go over the\n    entire color wheel spectrum)\n\nMore exercises can be found on the [basic bioinformatics exercises\npage](http://wiki.bits.vib.be/index.php/Exercises_on_Protein_Structure).\n\n\n## Get data\n\n&gt; ### {% icon hands_on %} Hands-on: Data upload\n&gt;\n&gt; 1. Create a new history for this tutorial\n&gt; 2. Import the files from [Zenodo]() or from the shared data library\n&gt;\n&gt;    ```\n&gt;    \n&gt;    ```\n&gt;    ***TODO***: *Add the files by the ones on Zenodo here (if not added)*\n&gt;\n&gt;    ***TODO***: *Remove the useless files (if added)*\n&gt;\n&gt;    {% include snippets/import_via_link.md %}\n&gt;    {% include snippets/import_from_data_library.md %}\n&gt;\n&gt; 3. Rename the datasets\n&gt; 4. Check that the datatype\n&gt;\n&gt;    {% include snippets/change_datatype.md datatype=\&quot;datatypes\&quot; %}\n&gt;\n&gt; 5. Add to each database a tag corresponding to ...\n&gt;\n&gt;    {% include snippets/add_tag.md %}\n&gt;\n{: .hands_on}\n\n# Title of the section usually corresponding to a big step in the analysis\n\nIt comes first a description of the step: some background and some theory.\nSome image can be added there to support the theory explanation:\n\n&lt;figure id=\&quot;figure-3\&quot;&gt;&lt;img src=\&quot;../../images/image_name\&quot; alt=\&quot;Alternative text\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 3:&lt;/span&gt; Legend of the image&lt;/figcaption&gt;&lt;/figure&gt;\n\nThe idea is to keep the theory description before quite simple to focus more on the practical part.\n\n***TODO***: *Consider adding a detail box to expand the theory*\n\n&gt; ### {% icon details %} More details about the theory\n&gt;\n&gt; But to describe more details, it is possible to use the detail boxes which are expandable\n&gt;\n{: .details}\n\nA big step can have several subsections or sub steps:\n\n\n## Sub-step with **My Tool**\n\n&gt; ### {% icon hands_on %} Hands-on: Task description\n&gt;\n&gt; 1. **My Tool** {% icon tool %} with the following parameters:\n&gt;    - {% icon param-file %} *\&quot;Input file\&quot;*: File\n&gt;    - *\&quot;Parameter\&quot;*: `a value`\n&gt;\n&gt;    ***TODO***: *Check parameter descriptions*\n&gt;\n&gt;    ***TODO***: *Consider adding a comment or tip box*\n&gt;\n&gt;    &gt; ### {% icon comment %} Comment\n&gt;    &gt;\n&gt;    &gt; A comment about the tool or something else. This box can also be in the main text\n&gt;    {: .comment}\n&gt;\n{: .hands_on}\n\n***TODO***: *Consider adding a question to test the learners understanding of the previous exercise*\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; 1. Question1?\n&gt; 2. Question2?\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; 1. Answer for question1\n&gt; &gt; 2. Answer for question2\n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\n\n## Re-arrange\n\nTo create the template, each step of the workflow had its own subsection.\n\n***TODO***: *Re-arrange the generated subsections into sections or other subsections.\nConsider merging some hands-on boxes to have a meaningful flow of the analyses*\n\n# Conclusion\n{:.no_toc}\n\nSum up the tutorial and the key takeaways here. We encourage adding an overview image of the\npipeline used.\n&quot;,&quot;&gt; ### Agenda\n&gt;\n&gt; In this tutorial, we will cover:\n&gt;\n&gt; 1. TOC\n&gt; {:toc}\n&gt;\n{: .agenda}\n\n# Structural comparison and RMDD \nWe compare structures by superposing (or structurally align) them on top of each other. That is, we\n superpose structurally equivalent atoms. For now, we will only superpose CA atoms, so backbones. B\nut Yasara also can superpose on any type of atom you want. You always need to specify:\n\n-  source object(s): the structure(s) that needs to be rotated and translated to superpose on anoth\ner structure\n-  target object: the structure to superpose on\n\nAn optimal superposition is found when the root-mean-square deviation (RMSD) is at a minimum. The R\nMSD is given as:\n&lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../../images/RMSD.gif\&quot; alt=\&quot;RMSD\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; calculation of RMSD&lt;/figcaption&gt;&lt;/figure&gt;\nwhere R is the distance between two structurally equivalent atom pairs (CA in our case) and n is th\ne total number of atom pairs.Get data\n\n&gt; ### {% icon hands_on %} Hands-on: Data download\n&gt;\n&gt; 1. Download the following adapted PDB files from [Zenodo](https://zenodo.org/record/3550492#.XdeNL1dKiUk) \n&gt;\n&gt;    ```\n&gt;     1DKX_1.pdb 1DKY_1.pdb 1DKZ_1.pdb 3DPO_1.pdb 3DPP_1.pdb \n&gt;    ```\n&gt;\n{: .hands_on}\n\n# Superimposing multiple structures using YASARA \n\nNow load all of them in YASARA:\n\n```\nFile &gt; Load &gt; PDB File\n```\n\nand select the CA (C-alpha) view (F4) and superpose with the MUSTANG algorithm:\n\n\n```\nAnalyze &gt; Align &gt; Objects with MUSTANG\n```\n\n\nIn the first window you have to select the source objects that will be repositioned. Select Objects 2 till 5. In the second window you select the target Object to superpose on. That would then be the first object.\n\nNotice that YASARA prints the RMSD of every superposition in the lower Console. Open the Console by pressing the spacebar once or twice to extend it.\n\nColor the atoms by their B-factor:\n\n```\nView &gt; Color &gt; Atom &gt; Belongs to or has &gt; All\nThen choose BFactor in the next window and press &#39;Apply unique color&#39;.\n```\n\nHigh BFactors are yellow, low BFactors are blue.\n\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; Question: Do you see a correlation between the BFactors and the variability in the structure?\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; 1. Yes, add explanation here\n&gt; &gt; **TODO**: add image\n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\n\n# Conclusion\n{:.no_toc}\n\nSuperimposition of related structures is a very efficient approach to spot similarities and differences of structutally related proteins.\n&quot;,&quot;# What is R ?\n{:.no_toc}\n\nR is many things: a project, a language... \nAs a **project**, R is part of the [GNU free software project](http://www.gnu.org). The development of R is done under the philosophy that software should be free of charge. This is good for the user, although there are some disadvantages: R comes with ABSOLUTELY NO WARRANTY. This statement comes up on the screen every time you start R. There is no company regulating R as a product. The R project is largely an academic endeavor, and most of the contributors are statisticians, hence the sometimes incomprehensible documentation. \nAs a **computer language** it was created to allow manipulation of data, statistical analysis and visualization. It is not easy to learn the language if you haven&#39;t done any programming before but it is worth taking the time as it can be a very useful tool.  An enormous variety of statistical analyses are available and R allows you to produce graphs exactly as you want them with publication quality. \n\n### Good things about R\n- It&#39;s free\n- It works on Windows, Mac and Linux\n- It can deal with very large datasets (compared to Excel)\n- A lot of freedom: graphs can be produced to your own taste\n- Supports all statistical analyses: from basic to very complex\n\n### Bad things about R\n- It can struggle with extremely large datasets\n- Difficult if you don&#39;t have any programming experience \n- Open source: many people contribute thus consistency can be low\n- Open source: documentation can be poor or written by/for experts\n- Can contain  bugs and errors: packages that are widely used are probably correct, niche packages can contain errors, there is no central team assessing the quality of the code\n\n# Installing R\nR is available on the [CRAN website](https://cran.r-project.org/) (Comprehensive R Archive Network]. \nIt can be installed on Linux, Mac and Windows. On the top of the CRAN page is a section with **Precompiled Binary Distribution**: R versions you can download as an .exe file (for Windows users) and are easy to install. What you download is the basic R installation: it contains the base package and other packages considered essential enough to include in the main installation. Exact content may vary with different versions of R.\nAs R is constantly being updated and new versions are constantly released, it is recommended to regularly install the newest version of R. \n\n# Installing RStudio\nAlthough you can work directly in the R editor, most people find it easier to use [RStudio](https://www.rstudio.com/)  on top of R. RStudio is free and available for Windows, Mac and Linux. You need to have R installed to run Rstudio. \n\n# RStudio user interface\nWatch this [video tutorial](https://www.youtube.com/watch?v=5YmcEYTSN7k) on the different components of the RStudio user interface and this [video tutorial](https://www.youtube.com/watch?v=o0Y478jOjGk) on how to use the RStudio user interface.\n\n### The script editor\nA script is a text file that contains all the commands you want to run. You can write and run scripts and you can also save them so next time you need to do a similar analysis you can change and re-run the script with minimal effort. An R project can contain multiple scripts. \nThe script editor highlights syntax in scripts making it easy to find and prevent errors. It has many features that will help you write scripts e.g. autocompletion, find/replace, commenting. \n\n### Autocompletion\nIt supports the automatic completion of code, e.g. if you have an object named relfreq in your workspace, type rel in the script editor and it will show a list of possibilities to complete the name.\n\n&lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../../images/Rautocompletion.png\&quot; alt=\&quot;autocompletion\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; Example for autocompletion&lt;/figcaption&gt;&lt;/figure&gt;\n\n### Find and replace\nFind and replace can be opened using Ctrl+F.\n\n### Adding comments to scripts\nIn scripts you must include comments to help you remember or tell collaborators what you did. Comments are lines that start with a # symbol. This symbol tells R to ignore  this line. Comments are displayed in green.\nYou can comment and uncomment large selections of code using: **Comment/Uncomment Lines**\n\n&lt;figure id=\&quot;figure-2\&quot;&gt;&lt;img src=\&quot;../../images/Rcomment_uncomment.png\&quot; alt=\&quot;comment_uncomment\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 2:&lt;/span&gt; Menu Comment/Uncomment Lines&lt;/figcaption&gt;&lt;/figure&gt;\n\n### Adding section headings to scripts\nAdd section headings to your scripts using the following format: #Heading Name####\n\n&lt;figure id=\&quot;figure-3\&quot;&gt;&lt;img src=\&quot;../../images/Rsection_headings.png\&quot; alt=\&quot;section_headings\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 3:&lt;/span&gt; Define section headings&lt;/figcaption&gt;&lt;/figure&gt;\n\nAt the bottom of the script editor you can quickly navigate to sections in your script. Especially in long scripts this is very useful.\n\n### Creating a new script\nClick **File** in the top menu and select **New File &gt; R Script**.\n\n&lt;figure id=\&quot;figure-4\&quot;&gt;&lt;img src=\&quot;../../images/Rnew_script.png\&quot; alt=\&quot;new_script\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 4:&lt;/span&gt; File Menu / New File&lt;/figcaption&gt;&lt;/figure&gt;\n\nBesides a simple R script, there are many other file types you can create: \n- [R markdown](http://rmarkdown.rstudio.com/) file: incorporate R-code and its results in a report \n- R Notebook: R Markdown file with chunks of code that can be executed interactively, with output visible beneath the code\n- R Sweave file: incorporate R-code and its results in a Latex report\n\n### Opening an existing script\nClick **File** in the top menu and select **Open File**.\n\nScripts are opened as a tab in the script editor. You can open several scripts at the same time in RStudio. \n\n### Running a script\nTo run a script you select the code that you want to execute in the script editor and click the **Run** button at the top right of the script editor. \n\n![run_script](../../images/Rrun_script.png)\n\nThe code will be executed in the console.\n\n### Saving a script\n\nIf there are unsaved changes in a script, the name of the script will be red and followed by an asterisk. To save the script click the **Save** button: ![save_script](../../images/Rsave_script.png)\n\nR scripts should have the extension .R \nOnce it is saved the asterisk disappears and the name becomes black.\n\n### The console\nThe  &gt; symbol in the console shows that R is ready to execute code \ne.g. type 10+3 and press return\n```\n&gt; 10 + 3\n[1] 13\n&gt;\n```\nThe result is printed in the console. \n\nIt is recommended to write commands in a script rather than typing them directly into the console. Creating a script makes it easier to reproduce, repeat and describe the analysis. If you select commands in the script editor and press the **Run** button, you will see the commands appearing in the console as they are executed. \n\nIf the &gt; symbol does not reappear upon execution of a command it means that R has crashed or is still calculating. To terminate a command press Esc.\n\nThe console also has many [features that make life easier](https://support.rstudio.com/hc/en-us/articles/200404846-Working-in-the-Console) like autocompletion, retrieving previous commands.\n\n### Environment\nA list of all variables (numbers, vectors, plots, models...) that have been imported or generated. The variables that R creates and manipulates are called *objects*. \nTo remove all variables that have been generated in the RStudio session:\n```\n&gt; rm(list=ls())\n```\nls() lists the objects in the current workspace and rm() removes them.\n\n### History\nAn overview of the last 500 commands that were run in the console: see [how to use the history](https://support.rstudio.com/hc/en-us/articles/200526217-Command-History).\n\n### Connections\nAn interface to easily [connect to databases](http://db.rstudio.com/) in R. \n\n### Files\nThe list of files and folders in the working directory. RStudio has a default working directory, typically your home folder.\n\n### Changing the working directory\n Often you want to work in the folder that contains the data. In that case you can change the working directory. \n Check which folder R is using as a working directory:\n```\n&gt; getwd()\n```\nChange the working directory:\n```\n&gt; setwd(\&quot;D:/trainingen/zelfgegeven/R/\&quot;)\n```\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; You need to use / or \\\\ in paths. Either will work but \\ will not since R sees it as the character that represents a division. \n{: .comment}\n\nChanging your working directory will make relative file references in your code invalid so you type this in the console **at the start of the analysis**.\n\nAlternatively you can change the working directory in the **Files** tab, expand **More** and select **Set As Working Directory**.\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; 1. Download the demo script for this lesson and open it in RStudio\n&gt; [`Demo_1.R`](http://data.bits.vib.be/pub/trainingen/RIntro/Demo_1.R)\n&gt; 2. From the demo script run the **Set working directory** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 1\n&gt;\n&gt; Set the working directory to the folder that contains the demo script that you have downloaded and check if it was changed. \n{: .hands_on}\n\nTo list the files in the working directory:\n```\n&gt; list.files() \n```\n\n### Plots\nPlots that are generated by the code you run will appear here.\nTo save a plot click the **Export** button: ![export_plot](../../images/Rexport_plot.png)\n\n### Packages\nR is popular because of the enormous diversity of packages. R is essentially a modular environment and you install and load the modules (packages) you need. Packages are available at the [CRAN](https://cran.r-project.org/web/packages/available_packages_by_name.html) and [Bioconductor](http://www.bioconductor.org/packages/release/BiocViews.html) websites. \nInstalling a package means that a copy of the package is downloaded and unzipped on your computer. If you want to know in what directory R stores the packages, type:\n\n```\n&gt;.libPaths()\n[1] \&quot;D:/R-3.6.0/library\&quot;\n&gt;\n```\nto see the default path where R stores packages. If you want to change this folder use the *destdir* argument of the install.packages() function:\n\n```\n&gt; install.packages(\&quot;car\&quot;,destdir=\&quot;C:/Users/Janick/R\&quot;)\n```\nYou only need to install a package once, as it is saved on your computer.\n\n### Installing R packages\nWatch this [video tutorial](https://www.youtube.com/watch?v=u1r5XTqrCTQ ) on how to install CRAN packages. \nWhen you have made changes to the right side of the Rstudio user interface (packages, files tab...), R is sometimes slow to show these changes. In that case hit the refresh button: ![refresh_button](../../images/Rrefresh_button.png)\n\nSome packages are not available on the CRAN site. Download in compressed format (as a .zip or .tar.gz file) from the source site. To install: select **Install from Package Archive File (.zip; .tar.gz)** in the **Install Packages** window and R will put it in the appropriate directory. \n\n&lt;figure id=\&quot;figure-5\&quot;&gt;&lt;img src=\&quot;../../images/Rinstall_zip.png\&quot; alt=\&quot;install_zip\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 5:&lt;/span&gt; Installing packages downloaded from their source site&lt;/figcaption&gt;&lt;/figure&gt;\n\n### Installing Bioconductor packages\nBioconductor is a set of R packages that provides tools for the analysis of high-throughput data, e.g. NGS data.\nMake sure you have the BiocManager package installed:\n```\n&gt; if (!requireNamespace(\&quot;BiocManager\&quot;)) \ninstall.packages(\&quot;BiocManager\&quot;) \n```\nThe if statement is checking if you already have the BiocManager package installed, if not then install.packages() will install it. BiocManager is a package to install and update Bioconductor packages. Once BiocManager is installed, you can install the Bioconductor core packages:\n```\n&gt; BiocManager::install()\n```\nTo install additional Bioconductor packages e.g. **GenomicFeatures** you type the following command:\n```\n&gt; BiocManager::install(\&quot;GenomicFeatures\&quot;)\n```\nOverview of all available Bioconductor [packages](https://www.bioconductor.org/packages/release/BiocViews.html#___Software) and [workflows](https://www.bioconductor.org/packages/release/BiocViews.html#___Workflow).\n\n### Installing packages from GitHub\nGit is a free and open source version control system. Version control helps software developers manage changes to code by keeping track of every change in a special database. If a mistake is made, the developer can turn back the clock and compare earlier versions of the code to fix the mistake. \nThere is an install_github() function in the devtools packageto install R packages hosted on GitHub:\n```\n&gt; install.packages(\&quot;devtools\&quot;) \n&gt; library(devtools)\n&gt; devtools::install_github(\&quot;statOmics/MSqRob&amp;copy;MSqRob0.7.6\&quot;)\n```\n\n### Loading packages\n Each time you want to use a package you have to load it (activate its functions). Loading a package is done by selecting it in the list of installed packages or by typing the following command:\n```\n&gt; library(\&quot;name_of_package\&quot;)\n```\nIf R responds:\n```\nError in library(car) : there is no package called &#39;car&#39;\n```\nor similar, it means that the car package needs to be installed first.\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; Run commands of the **Installation** section of the demo script\n{: .hands_on}\n\n### Help\nYou can find a lot of documentation online: e.g. the [getting help section](https://www.r-project.org/help.html) of the R website. R documentation is not easily accessible nor well-structured  so it can be a challenge to consult the help files of R packages online. By far the most user-friendly interface for searching the R documentation is the [Rdocumentation website](https://www.rdocumentation.org/).\nAdditional useful links:\n- [Documentation of RStudio](https://support.rstudio.com/hc/en-us/categories/200035113-Documentation) \n- [Quick R by DataCamp](https://www.statmethods.net/about/sitemap.html): loads of basic and advanced tutorials\n- [R-bloggers](https://www.r-bloggers.com/): R-news and tutorials contributed by bloggers\n- [Rseek](https://rseek.org/): Google specifically for R.\n- [Google&#39;s R style guide](https://google.github.io/styleguide/Rguide.xml): Programming rules for R designed in collaboration with the entire R user community at Google to make R code easier to read, share, and verify.\n\nAccess the R documentation in RStudio using commands: help() or ?\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Get help** section\n{: .hands_on}\n\n### Viewer\nViews HTML files that are located on your computer.\n\n[All RStudio keyboard shortcuts](https://support.rstudio.com/hc/en-us/articles/200711853-Keyboard-Shortcuts)\n\n# Expressions in R\nR can handle any kind of data: numerical, character, logical... \n\n### Character data\nCharacter data like \&quot;green\&quot;, \&quot;cytoplasm\&quot; must be typed in between **single or double quotes**:\n```\n&gt; x &lt;- \&quot;Hello\&quot;\n```\nTo use quotes in the text escape the quotes:\n```\n&gt; x &lt;- \&quot;say \\\&quot;Hello\\\&quot;\&quot;\n```\nNames of packages, files, paths on your computer, urls are all text data and need to be typed in between quotes. Names of variables do not. \n\n### Booleans\nBoolean values are **TRUE** and **FALSE** without quotes because they are Booleans not text. \n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; R is case sensitive: true and false are not recognized as Booleans. They have to be written in capitals.\n{: .comment}\n\n### Missing values\nMissing values are represented by **NA** (Not Available) without quotes. \nImpossible values (e.g., dividing by zero) are represented by the symbol NaN (Not A Number).\n\n### Arithmetic operators\n\n&lt;figure id=\&quot;figure-6\&quot;&gt;&lt;img src=\&quot;../../images/Rarithmetic_operators.png\&quot; alt=\&quot;arithmetic_operators\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 6:&lt;/span&gt; Overview of arithmetic operators&lt;/figcaption&gt;&lt;/figure&gt;\n\nArithmetic operators follow the standard **order of priority**, with exponentiation the highest and addition and subtraction the lowest priority, but you can control the order with **parentheses**. Do not use brackets as these are for other purposes in R. \n\n### Logical operators\nLogical operators can be used to selectively execute code based on certain conditions. They allow to create logical expressions (comparisons) that return TRUE or FALSE. \n\n&lt;figure id=\&quot;figure-7\&quot;&gt;&lt;img src=\&quot;../../images/Rlogic_operators.png\&quot; alt=\&quot;logic_operators\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 7:&lt;/span&gt; Overview of logical operators&lt;/figcaption&gt;&lt;/figure&gt;\n\nLogical expressions may be combined using logical operators. The NOT operator (!) can be used to assess whether something is NOT the case. \n\n```\n&gt; x = 1\n&gt; y = 2   \n&gt; z = x &gt; y      \t\tis x larger than y? \n&gt; z              \t\t\tFALSE \n&gt; u = TRUE\n&gt; v = FALSE \n&gt; u &amp; v          \t\t\tu AND v: FALSE \n&gt; u | v          \t\t\tu OR v: TRUE \n&gt; !u             \t\t\tNOT u: FALSE\n```\n&gt; ### {% icon hands_on %} Hands-on: Exercise 2a\n&gt;\n&gt;    &gt; ### {% icon question %} Question \n&gt;    &gt; What&#39;s the difference between x=2 and x==2 ? \n&gt;    &gt;\n&gt;    &gt; &gt; ### {% icon solution %} Solution\n&gt;    &gt; &gt;  The = operator attributes a value to a variable (see next section), x becomes 2. \n&gt;    &gt; &gt;  The == is a logical operator, testing whether the logical expression x equals 2 is TRUE or FALSE.\n&gt;    &gt; {: .solution }\n&gt;    {: .question }\n&gt;\n{: .hands_on }\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 2b\n&gt;\n&gt; Check if the words UseR and user are equal. \n{: .hands_on}\n\n&gt; ### {% icon comment %} R is case sensitive\n&gt;\n&gt; As exercise 2b showed R is indeed case sensitive.\n{: .comment}\n\n# Assigning variables\nA variable allows you to save a value or an object (a plot, a table, a list of values) in R. \nA value or object is assigned to a variable by the assignment operator **&lt;-**\nIt consists of the two characters &lt; (less than) and - (minus): \n```\n&gt; v &lt;- 4\tnow the value of variable v is 4\n````\nIn most contexts the = operator can be used as an alternative:\n```\n&gt; v &lt;- 4 \n&gt; v = 4 \ngive the same result: a variable called v with value 4\n```\nAfter R has performed the assignment you will not see any output, as the value 4 has been saved to variable v. You can access and use this variable at any time and print its value in the console by running its name:\n```\n&gt; v\n[1] 4\n```\nYou can now use v in expressions instead of 4\n```\n&gt; v * v\n[1] 16\n```\nYou can re-assign a new value to a variable at any time: \n```\n&gt; v &lt;- \&quot;a cool variable\&quot;\n&gt; v\n[1] \&quot;a cool variable\&quot;\n```\n\nR is not very fussy as far as syntax goes. Variable names can be anything, though they cannot begin with a number or symbol. Informative names often involve using more than one word. Providing there are **no spaces** between these words you can join them using dots, underscores and capital letters though the Google R style guide recommends that names are joined with a dot. \n\n### Using operators to create variables\nYou can combine variables into a new one using operators (like + or /).\n\n### Using functions to create variables\nA function is a piece of code that performs a specific task. \nFunctions are called by another line of code that sends a request to the function to do something or return a variable. The call may pass *arguments* (inputs) to the function. In other words a function allows you to combine variables (arguments) into a new variable (returned variable).\nThere are lots of built in functions in R and you can also write your own. Even the base package supplies a large number of pre-written functions to use. Other packages are filled with additional functions for related tasks.\nCalling a function in R has a certain syntax:\n**output &lt;- function(list of arguments)** \nFor example: \n```\n&gt; p &lt;-  ggplot(mtcars,(aes(wt,mpg))\n```\nIn this example **ggplot()** is the **function**. The brackets () are always needed. Before a function can start the actions and calculations  it encodes, it needs prior information: **input** data and parameter settings. These are called the **arguments** of the function. In this example the arguments are:\n- **mtcars**: a table containing the input data\n- **aes(wt,mpg)**: defines the two columns of the table you want to plot: weight (wt) along the X-axis and miles/gallon (mpg) along the Y-axis.\n\nTo see the arguments of a function you can use **?** or **help()**:\n```\n&gt; ? ggplot \n&gt; help(ggplot)\n```\nThis opens the documentation of the function in the **Help** tab including an overview of the arguments of the function. At the bottom of the documentation page you find examples on how to use the function.\nThe function generates a plot so the plot **p** is the **output** of the function.  \n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Assigning variables** section\n{: .hands_on}\n\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 3a\n&gt;\n&gt; 1. Create a variable called patients with value 42\n&gt; 2. Print the value of patients divided by 2\n&gt; 3. Create a variable called patients_gr2 with value 24\n&gt; 4. Print the total number of patients\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  &gt; ```\n&gt;    &gt;  &gt; patients &lt;- 42\n&gt;    &gt;  &gt; patients/2\n&gt;    &gt;  &gt; patients_gr2 &lt;- 24\n&gt;    &gt;  &gt; total_patients &lt;- patients + patients_gr2\n&gt;    &gt;  &gt; total_patients\n&gt;    &gt;  &gt;```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  \&quot;patients\&quot; &lt;- 42\n&gt;    &gt;  \&quot;patients\&quot;/2\n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 3b\n&gt;\n&gt; Check the arguments of the mean() function. \n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  ?mean\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\nThe mean() function has many arguments and each argument has a default value. To use the default values simply do not specify these arguments in the function call. You only have to specify the arguments for which you want to use a value other than the default.\nTo show the **examples** section instead of the full documentation page:\n```\n&gt; example(min) \n```\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 3c\n&gt;\n&gt; Calculate and print the sum of patients and patients_gr2 using the sum() function.\n&gt;    &gt; ### {% icon solution %} solution: answer\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  sum(patients,patients_gr2)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  Replace the sum() function with the mean() function. What happens ?\n&gt;    &gt;    &gt; ### {% icon solution %} solution: answer\n&gt;    &gt;    &gt;  Look at the help of the sum() function. What&#39;s the first argument ? \n&gt;    &gt;    &gt;  Compare with the first argument of the mean() function\n&gt;    &gt;   {: .solution}\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  Will the code below work ?\n&gt;    &gt;  ```\n&gt;    &gt;  sum (patients,patients_gr2)\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  Will the code below work ?\n&gt;    &gt;  ```\n&gt;    &gt;  sum ( patients , patients_gr2 )\n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\nSometimes functions from different packages have the same name. In that case use **package::function** to specify the package you want to use, e.g. ggplot2::ggplot() where ggplot2 is the name of the package and ggplot() is the name of the function.\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 3d\n&gt;\n&gt; Create a variable patients_gr3 with value \&quot;twenty\&quot; and print the total number of patients\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  patients_gr3 &lt;- \&quot;twenty\&quot;\n&gt;    &gt;  patients + patients_gr3\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 3e\n&gt;\n&gt; 1. Create variable x with value 5\n&gt; 2. Create variable y with value 2\n&gt; 3. Create variable z as the sum of x and y and print the value of z\n&gt; 4. Print x - y\n&gt; 5. Print the product of x and y and add 2 to it\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  x &lt;- 5\n&gt;    &gt;  y &lt;- 2\n&gt;    &gt;  z &lt;- x+y\n&gt;    &gt;  z\n&gt;    &gt;  x-y\n&gt;    &gt;  x*y+2\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 3f\n&gt;\n&gt; What is the difference between \n&gt; correctLogic &lt;- TRUE  \n&gt; incorrectLogic &lt;- \&quot;TRUE\&quot;\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 3g\n&gt;\n&gt; Is there a difference between \n&gt; name &lt;- \&quot;Janick\&quot; \n&gt; name &lt;- &#39;Janick&#39;\n&gt; name &lt;- Janick\n{: .hands_on}\n&quot;],&quot;collections&quot;:[{&quot;docs&quot;:[],&quot;files&quot;:[],&quot;output&quot;:true,&quot;relative_directory&quot;:&quot;_posts&quot;,&quot;label&quot;:&quot;posts&quot;,&quot;directory&quot;:&quot;/srv/jekyll/_posts&quot;,&quot;permalink&quot;:&quot;/:categories/:year/:month/:day/:title:output_ext&quot;}],&quot;config&quot;:null,&quot;data&quot;:{&quot;functional_analysis&quot;:{&quot;name&quot;:&quot;functional_analysis&quot;,&quot;type&quot;:&quot;basics&quot;,&quot;category&quot;:&quot;omics&quot;,&quot;title&quot;:&quot;Functional Analysis&quot;,&quot;summary&quot;:&quot;Functional characterization of a gene list&quot;,&quot;requirements&quot;:null,&quot;maintainers&quot;:[&quot;janick-bits&quot;]},&quot;basic-bioinformatics&quot;:{&quot;name&quot;:&quot;basic-bioinformatics&quot;,&quot;type&quot;:&quot;basics&quot;,&quot;category&quot;:&quot;basics&quot;,&quot;title&quot;:&quot;Basic Bioinformatics Concepts, Databases and Tools&quot;,&quot;summary&quot;:&quot;Bioinformatics Introduction&quot;,&quot;requirements&quot;:null,&quot;maintainers&quot;:[&quot;abotzki&quot;]},&quot;R&quot;:{&quot;name&quot;:&quot;R&quot;,&quot;type&quot;:&quot;basics&quot;,&quot;category&quot;:&quot;programming&quot;,&quot;title&quot;:&quot;Introduction to R&quot;,&quot;summary&quot;:&quot;Introduction to R&quot;,&quot;requirements&quot;:null,&quot;maintainers&quot;:[&quot;janick-bits&quot;]},&quot;gimp-inkscape&quot;:{&quot;name&quot;:&quot;gimp-inkscape&quot;,&quot;type&quot;:&quot;basics&quot;,&quot;category&quot;:&quot;software&quot;,&quot;title&quot;:&quot;Initiation GIMP and Inkscape&quot;,&quot;summary&quot;:&quot;This course aims at introducing GIMP and Inkscape (free alternatives for Adobe Photoshop and Illustrator) to prepare images for publication, annotate plots and images, and create figures (diagrams, infographics, ...). It is also a prerequisite for the &#39;Image Ethics and Poster Design&#39; course.&quot;,&quot;requirements&quot;:null,&quot;maintainers&quot;:[&quot;chdeb&quot;]},&quot;contributors&quot;:{&quot;chdeb&quot;:{&quot;name&quot;:&quot;Christof De Bo&quot;,&quot;email&quot;:&quot;christof.debo@vib.be&quot;},&quot;tmuylder&quot;:{&quot;name&quot;:&quot;Tuur Muyldermans&quot;,&quot;email&quot;:&quot;tuur.muyldermans@vib.be&quot;},&quot;janick-bits&quot;:{&quot;name&quot;:&quot;Janick Mathys&quot;,&quot;email&quot;:&quot;janick.mathys@vib.be&quot;},&quot;abotzki&quot;:{&quot;name&quot;:&quot;Alexander Botzki&quot;,&quot;email&quot;:&quot;alexander.botzki@vib.be&quot;},&quot;jvdurme&quot;:{&quot;name&quot;:&quot;Joost Van Durme&quot;,&quot;email&quot;:&quot;bits@vib.be&quot;},&quot;hildebra&quot;:{&quot;name&quot;:&quot;Falk Hildebrand&quot;,&quot;email&quot;:&quot;bits@vib.be&quot;}},&quot;eln&quot;:{&quot;name&quot;:&quot;eln&quot;,&quot;type&quot;:&quot;basics&quot;,&quot;category&quot;:&quot;software&quot;,&quot;title&quot;:&quot;Electronic Lab Notebook&quot;,&quot;summary&quot;:&quot;This course aims at introducing ELN or E-notebook 2014 by PerkinElmer.&quot;,&quot;requirements&quot;:null,&quot;maintainers&quot;:[&quot;chdeb&quot;]},&quot;qbase-plus&quot;:{&quot;name&quot;:&quot;qbase-plus&quot;,&quot;type&quot;:&quot;basics&quot;,&quot;category&quot;:&quot;software&quot;,&quot;title&quot;:&quot;QPCR analysis using qbase+&quot;,&quot;summary&quot;:&quot;QPCR analysis using qbase+&quot;,&quot;requirements&quot;:null,&quot;maintainers&quot;:[&quot;chdeb&quot;]},&quot;protein-structure-analysis&quot;:{&quot;name&quot;:&quot;protein-structure-analysis&quot;,&quot;type&quot;:&quot;basics&quot;,&quot;category&quot;:&quot;basics&quot;,&quot;title&quot;:&quot;Protein Structure Analysis&quot;,&quot;summary&quot;:&quot;Analyzing the protein structure of your protein-of-interest can be advantageous in multiple ways. It can help you discover regions which are good candidates to interact with other proteins. It can help you discover new domains. It can help with identifying differences with homologuous proteins and a lot more.&quot;,&quot;extra&quot;:&quot;protein_analysis&quot;,&quot;requirements&quot;:null,&quot;maintainers&quot;:[&quot;abotzki&quot;],&quot;references&quot;:[{&quot;authors&quot;:&quot;Switchlab&quot;,&quot;title&quot;:&quot;Home of FoldX plugin&quot;,&quot;link&quot;:&quot;http://foldxyasara.switchlab.org/&quot;,&quot;summary&quot;:&quot;More information about FoldX plugin and troubleshooting&quot;},{&quot;authors&quot;:&quot;Wikipedia&quot;,&quot;title&quot;:&quot;Wiki page about PDB&quot;,&quot;link&quot;:&quot;https://en.wikipedia.org/wiki/Protein_Data_Bank&quot;,&quot;summary&quot;:&quot;wiki page explaining information on PDB&quot;},{&quot;authors&quot;:&quot;YASARA developers&quot;,&quot;title&quot;:&quot;Working with YASARA&quot;,&quot;link&quot;:&quot;http://www.yasara.org/movies.htm&quot;,&quot;summary&quot;:&quot;Movie tutorials on YASARA&quot;}]},&quot;metagenomics&quot;:{&quot;name&quot;:&quot;metagenomics&quot;,&quot;type&quot;:&quot;basics&quot;,&quot;category&quot;:&quot;omics&quot;,&quot;title&quot;:&quot;Metagenomics&quot;,&quot;summary&quot;:&quot;Metagenomics&quot;,&quot;maintainers&quot;:[&quot;janick-bits&quot;,&quot;abotzki&quot;],&quot;references&quot;:[{&quot;authors&quot;:&quot;Falk Hildebrand&quot;,&quot;title&quot;:&quot;Lotus pipeline&quot;,&quot;link&quot;:&quot;http://psbweb05.psb.ugent.be/lotus/downloads.html&quot;,&quot;summary&quot;:&quot;More information about the Lotus pipeline&quot;},{&quot;authors&quot;:&quot;Robert Edgar&quot;,&quot;title&quot;:&quot;usearch version&quot;,&quot;link&quot;:&quot;http://www.drive5.com/usearch/download.html&quot;,&quot;summary&quot;:&quot;usearch version has to be downloaded seperately due to licensing.&quot;},{&quot;authors&quot;:&quot;vegan&quot;,&quot;title&quot;:&quot;R package vegan&quot;,&quot;link&quot;:&quot;https://cran.r-project.org/web/packages/vegan/index.html&quot;,&quot;summary&quot;:&quot;further analysis with R package vegan&quot;}]}},&quot;documents&quot;:[],&quot;related_posts&quot;:null,&quot;pages&quot;:[&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;---\nname: galaxy_training_material\nchannels:\n  - conda-forge\n  - bioconda\n  - defaults\ndependencies:\n  - gmp=6.1.2\n  - jemalloc=5.0.1\n  - libiconv=1.15\n  - nodejs=9.11.1\n  - openssl=1.0.2o\n  - pandas=0.22.0\n  - pip\n  - pip:\n    - pathspec==0.5.6\n    - oyaml\n  - planemo&gt;=0.55.0\n  - readline=7.0\n  - requests=2.18.4\n  - ruby=2.4.4\n  - yaml=0.1.7\n  - yamllint=1.11.0\n  - zlib=1.2.11\n  - libxml2\n  - ephemeris\n  - pkg-config\n&quot;,&quot;&lt;ol id=\&quot;markdown-toc\&quot;&gt;\n  &lt;li&gt;&lt;a href=\&quot;#overview-questions\&quot; id=\&quot;markdown-toc-overview-questions\&quot;&gt;Overview Questions&lt;/a&gt;    &lt;ol&gt;\n      &lt;li&gt;&lt;a href=\&quot;#what-is-this-website\&quot; id=\&quot;markdown-toc-what-is-this-website\&quot;&gt;What is this website?&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=\&quot;#what-are-the-tutorials-for\&quot; id=\&quot;markdown-toc-what-are-the-tutorials-for\&quot;&gt;What are the tutorials for?&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=\&quot;#what-audiences-are-the-tutorials-for\&quot; id=\&quot;markdown-toc-what-audiences-are-the-tutorials-for\&quot;&gt;What audiences are the tutorials for?&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=\&quot;#how-is-the-content-licensed\&quot; id=\&quot;markdown-toc-how-is-the-content-licensed\&quot;&gt;How is the content licensed?&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=\&quot;#how-can-i-advertise-the-training-materials-on-my-posters\&quot; id=\&quot;markdown-toc-how-can-i-advertise-the-training-materials-on-my-posters\&quot;&gt;How can I advertise the training materials on my posters?&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=\&quot;#how-do-i-use-this-material\&quot; id=\&quot;markdown-toc-how-do-i-use-this-material\&quot;&gt;How do I use this material?&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=\&quot;#how-can-i-get-help\&quot; id=\&quot;markdown-toc-how-can-i-get-help\&quot;&gt;How can I get help?&lt;/a&gt;&lt;/li&gt;\n    &lt;/ol&gt;\n  &lt;/li&gt;\n  &lt;li&gt;&lt;a href=\&quot;#for-instructors\&quot; id=\&quot;markdown-toc-for-instructors\&quot;&gt;For Instructors&lt;/a&gt;    &lt;ol&gt;\n      &lt;li&gt;&lt;a href=\&quot;#where-do-i-start\&quot; id=\&quot;markdown-toc-where-do-i-start\&quot;&gt;Where do I start?&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=\&quot;#how-can-i-fix-mistakes-or-expand-an-existing-tutorial-using-the-github-interface\&quot; id=\&quot;markdown-toc-how-can-i-fix-mistakes-or-expand-an-existing-tutorial-using-the-github-interface\&quot;&gt;How can I fix mistakes or expand an existing tutorial using the GitHub interface?&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=\&quot;#sustainability-of-the-training-material-and-metadata\&quot; id=\&quot;markdown-toc-sustainability-of-the-training-material-and-metadata\&quot;&gt;Sustainability of the training-material and metadata&lt;/a&gt;&lt;/li&gt;\n    &lt;/ol&gt;\n  &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1 id=\&quot;overview-questions\&quot;&gt;Overview Questions&lt;/h1&gt;\n\n&lt;h2 id=\&quot;what-is-this-website\&quot;&gt;What is this website?&lt;/h2&gt;\n\n&lt;p&gt;This website is a collection of hands-on tutorials that are designed to be interactive.&lt;/p&gt;\n\n&lt;p&gt;This material is developed and maintained by the &lt;a href=\&quot;https://www.bits.vib.be/\&quot;&gt;VIB Bioinformatics Core&lt;/a&gt;.&lt;/p&gt;\n\n&lt;h2 id=\&quot;what-are-the-tutorials-for\&quot;&gt;What are the tutorials for?&lt;/h2&gt;\n\n&lt;p&gt;These tutorials can be used for learning and teaching how for general data analysis, and for learning/teaching specific domains such as metagenomcis and differential gene expression analysis with RNA-Seq data.&lt;/p&gt;\n\n&lt;h2 id=\&quot;what-audiences-are-the-tutorials-for\&quot;&gt;What audiences are the tutorials for?&lt;/h2&gt;\n\n&lt;p&gt;There are two distinct audiences for these materials.&lt;/p&gt;\n\n&lt;ol&gt;\n  &lt;li&gt;&lt;strong&gt;Self-paced individual learners.&lt;/strong&gt; These tutorials provide everything you need to learn a topic, from explanations of concepts to detailed hands-on exercises.&lt;/li&gt;\n  &lt;li&gt;&lt;strong&gt;Instructors.&lt;/strong&gt; They are also designed to be used by instructors in teaching/training settings. Slides, and detailed tutorials are provided.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h2 id=\&quot;how-is-the-content-licensed\&quot;&gt;How is the content licensed?&lt;/h2&gt;\n\n&lt;p&gt;The content of this website is licensed under the &lt;a href=\&quot;https://creativecommons.org/licenses/by/4.0/\&quot;&gt;Creative Commons Attribution 4.0 License&lt;/a&gt;.&lt;/p&gt;\n\n&lt;h2 id=\&quot;how-can-i-advertise-the-training-materials-on-my-posters\&quot;&gt;How can I advertise the training materials on my posters?&lt;/h2&gt;\n\n&lt;p&gt;We provide some QR codes and logos in the &lt;a href=\&quot;https://github.com/vibbits/training-material/tree/master/assets/images\&quot;&gt;images folder&lt;/a&gt;.&lt;/p&gt;\n\n&lt;h2 id=\&quot;how-do-i-use-this-material\&quot;&gt;How do I use this material?&lt;/h2&gt;\n\n&lt;p&gt;Many topics include slide decks and if the topic you are interested in has slides then start there.  These will introduce the topic and important concepts.&lt;/p&gt;\n\n&lt;h2 id=\&quot;how-can-i-get-help\&quot;&gt;How can I get help?&lt;/h2&gt;\n\n&lt;p&gt;If you have questions about this training material, you can reach us sending an email to bits@vib.be.&lt;/p&gt;\n\n&lt;h1 id=\&quot;for-instructors\&quot;&gt;For Instructors&lt;/h1&gt;\n\n&lt;p&gt;This material can also be used to teach the content in a group setting to students and researchers.&lt;/p&gt;\n\n&lt;h2 id=\&quot;where-do-i-start\&quot;&gt;Where do I start?&lt;/h2&gt;\n\n&lt;p&gt;Spend some time exploring the different tutorials and the different resources that are available. Become familiar with the structure of the tutorials and think about how you might use them in your teaching.&lt;/p&gt;\n\n&lt;h2 id=\&quot;how-can-i-fix-mistakes-or-expand-an-existing-tutorial-using-the-github-interface\&quot;&gt;How can I fix mistakes or expand an existing tutorial using the GitHub interface?&lt;/h2&gt;\n\n&lt;p&gt;Please submit an issue via github.&lt;/p&gt;\n\n&lt;h2 id=\&quot;sustainability-of-the-training-material-and-metadata\&quot;&gt;Sustainability of the training-material and metadata&lt;/h2&gt;\n\n&lt;p&gt;This repository is hosted on &lt;a href=\&quot;https://github.com/\&quot;&gt;GitHub&lt;/a&gt; using git as a &lt;a href=\&quot;https://en.wikipedia.org/wiki/Distributed_version_control\&quot;&gt;DVCS&lt;/a&gt;. Therefore the community is hosting backups of this repository in a decentralised way. The repository is self-contained and contains all needed content and all metadata.&lt;/p&gt;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;\n&quot;,&quot;### How to fill the slide decks?\n\nPlease follow our\n[tutorial to learn how to fill the slides](/topics/contributing/tutorials/create-new-tutorial-slides/slides.html)\n&quot;,&quot;### Protein Structure Analysis ###\n\n- Sequences, structures and databases\n- Experimental methods (X-rays, electrons and NMR)\n- Finding and visualising structures from the  Protein Data Bank\n- Comparing structures\n- Modelling mutations\n- Creating homology models\n\n---\n### Sequences and Structures ###\n\nadd one slide over transcription / translation / \n\n---\n\n### Amino acids and peptide structure\n\n![](/topics/protein-structure-analysis/images/amino-acids.png)\n\n---\n\n### The Structure-Function Connection ###\n\n.pull-left[\n- Folded proteins provide a well-defined 3D arrangement of functional groups, creating microenvironments and active sites.\n- Structural changes  are often involved in functional  mechanisms  (motor proteins, ...)\n]\n.image-90[![](/topics/protein-structure-analysis/images/hemoglobin.png)]\n\n\n---\n\n### Databases\n\n.pull-left[\n**Uniprot** approx. 1100,000 sequences\n\n- mainly determined by large-scale DNA sequencing of individual genes or whole genomes\n- increasingly automated annotation\n\n**Protein Data Bank** approx. 141,000 \nexperimentally determined structures\n\n- Mainly determined by X-ray crystallography and high-resolution NMR spectroscopy\n- Automation is increasing, but there are still significant limitations in the rate of solving new structures\n]\n\n\n]\n.pull-right[ .image-50[![](/topics/protein-structure-analysis/images/uniprot-logo.png)]\n             .image-50[![](/topics/protein-structure-analysis/images/pdb-logo.png)]\n]\n\n---\n\n### X-Ray Crystallography ###\n\n![](/topics/protein-structure-analysis/images/xray-tech-setup.png)\n\n.pull-left[\n\n.left[In a crystal, a large number  of macromolecules are  packed together in a regular grid, with consistent  orientations and relative  distances. \nWhen exposed  to an X-ray beam, this  arrangement gives rise to\ndiffracted rays in specific directions,  resulting in discrete spots on the planar\ndetector. By rotating the crystal, a series  of images is obtained. From these, the\nintensities of all the diffracted rays of the  crystal can be derived.]\n\n]\n.pull-right[ .image-90[![](/topics/protein-structure-analysis/images/diffraction-pattern.png)]\n]\n\n\n---\n\n### X-Ray Crystallography ###\n\n.pull-left[\n.image-50[![](/topics/protein-structure-analysis/images/diffraction-pattern.png)]\n]\n.pull-right[.image-50[![](/topics/protein-structure-analysis/images/electron-density.png)]]\n\n|              |          |               |\n|:-------------|:--------:|--------------:|\n| Diffraction Spot Intensities and Phases $$F_{obs}(h,k,l)$$ and $$\\phi_{obs}(h,k,l)$$ | $$R_{cryst} = \\frac{\\sum_{h,k,l}F_{obs}-F_{calc}}{\\sum_{h,k,l}F_{obs}}$$ | Electron density $$\\rho(x,y,z)$$ |\n\n\n---\n\n### The Protein Databank ###\n\n.pull-left[ .image-80[![](/topics/protein-structure-analysis/images/wwpdb-welcome-page.png)] \n\n\n.pull-right[ \n.left[ [http://www.wwpdb.org](http://www.wwpdb.org) ]\n- contains structures of  proteins, nucleic acids  and complexes,  determined by X-ray  crystallography, NMR  spectroscopy\n- No purely theoretical  or ab initio models  (since 2006)\n- Also stores supporting  experimental data\n- Full deposition now  required by all peer-reviewed journals\n]\n]\n\n---\n\n### Exercise 1: Search the PDB ###\n\n- Use the UniProt site to search for dnak.  \n- Use the PDB site to search for dnak.\n - Compare the UniProt and PDB result lists.\n- Use the sequence search function to see if there are structures with sequences similar to that of the  DnaK C-terminal domain.\n- Look at the summary pages of a number of  structures and note some interesting properties.\n- Select a number of structures and create a report  page.\n\n---\n\n### PDB File Format ###\n\n![](/topics/protein-structure-analysis/images/pdb-file-format.png)\n\n---\n\n### Occupancy ###\n\n![](/topics/protein-structure-analysis/images/occupancy.png)\n\n\n---\n\n### Related Web sites ###\n\n- Nucleic Acid Database: DNA and RNA structures\n\n.left[[http://ndbserver.rutgers.edu/](http://ndbserver.rutgers.edu/)]\n\n- PDB-REDO: automatically re-refined deposited  structures, using the latest methods\n\n.left[[http://www.cmbi.ru.nl/pdb_redo/](http://www.cmbi.ru.nl/pdb_redo)]\n\n- EBI: many online tools for structure analysis\n\n[http://www.ebi.ac.uk/Tools/structure/](http://www.ebi.ac.uk/Tools/structure/).left[]]\n\n- Replaced Electron Density Server: convenient overview of  quality parameters for crystal structures\n\n.left[[http://www.ebi.ac.uk/pdbe/litemol](http://www.ebi.ac.uk/pdbe/litemol)]\n\n---\n\n### High-Resolution NMR Spectrometry ###\n\n.left[Many atomic nuclei, including the ubiquitous hydrogen nuclei,  resonate at specific radio frequencies when placed in a  strong, uniform magnetic field. The chemical environment of each individual atom slightly modulates its exact resonance  frequency.]\n\n.image-80[![](/topics/protein-structure-analysis/images/nmr-peaks-to-structure.png)]\n\n.left[In macromolecules with thousands of atoms, many different  effects combine to generate an extremely complicated pattern of chemical shifts, \nwhich therefore more or less uniquely  identify each atom. Multidimensional spectra allow these  frequencies to be assigned to specific atoms.]\n---\n\n### High-Resolution NMR Spectroscopy ###\n\n.left[When two atoms are near each other in 3D space, they can exchange magnetization, giving rise to crosspeaks at the  intersection of their respective frequencies.]\n\n.image-50[![](/topics/protein-structure-analysis/images/nmr-noe.jpg)]\n\n.left[This nuclear Overhauser effect (NOE) is used to effectively measure the distances between pairs of atoms, at least  qualitatively.]\n\n---\n\n### High-Resolution NMR Spectroscopy ###\n\n.left[After identification of the atoms by means of their unique chemical shifts, distance restraints are derived from the  Overhauser crosspeaks. An extended model of the protein  is  generated,  \nand  then  condensed  into  a  shape  that  is consistent with as many of distance restraints as possible.]\n\n.image-50[![](/topics/protein-structure-analysis/images/nmr-model-example.png)]\n\n---\n\n### Other methods ###\n\n\n- Electron microscopy (and especially Cryo-electron microscopy): Electron crystallography and single particle reconstruction\r\n-Small-angle X-ray and neutron scattering (SAXS and SANS)\n\n\n.image-80[![](/topics/protein-structure-analysis/images/saxs.png)]\n\n---\n\n### Related Web sites ###\n\n- BioMagResBank: experimental data for NMR-  derived structures (lists of distance restraints  and other experimentally derived properties)\n\n.left[[http://www.bmrb.wisc.edu/](http://www.bmrb.wisc.edu/)]\n\n- BioIsis: database of SAXS-derived structures\n\n.left[[http://www.bioisis.net](http://www.bioisis.net)]\n\n- EMBL database of SAXS-derived structures\n\n.left[[http://www.sasbdb.org](http://www.sasbdb.org)]\n\n- EM Databank for cryo-EM structures\n\n[http://www.emdatabank.org](http://www.emdatabank.org.left[)]\n\n---\n\n### Assessing Structure Quality ###\n\nGeneral geometric properties (bond lengths and angles, Ramachandran distribution, ): MolProbity  [Link](http://molprobity.biochem.duke.edu/)\n\n.left[ **Crystal Structures** ]\n- Diffraction data resolution and completeness (PDB)\n- Final $$ R_{cryst} $$ and $$ R_{free} $$ factors (PDB)\n- Local correspondence to electron density (EDS)\n\n.left[**NMR Structures**]\n- Number of distance restraints and additional experimental data sources (BMRB)\n- Local restraint density (on-line NMR constraint analyser)\n[link](http://molsim.sci.univr.it/bioinfo/tools/constraint/index.html)\n\n.left[**Other techniques**]\n- Difficult to generalise: carefully read and consider the  published protocol\n\n---\n\n### Molecular Graphics Software ###\n\n- [PyMOL](http://www.pymol.org/): high-quality output,  good examples on [Wiki](http://www.pymolwiki.org/)\n- [Chimera](http://www.cgl.ucsf.edu/chimera/): good  documentation on website\n- [VMD](http://www.ks.uiuc.edu/Research/vmd/):  excellent for the analysis of MD trajectories\n- [Yasara](http://www.yasara.org)  \n- [SwissPDBViewer](http://spdbv.vital-it.ch/)\n\n---\n\n### YASARA ###\n\n.left[\nYasara View is freely available and provides  basic visualisation functions.\n\nYasara Model, Dynamics and Structure provide  additional functionality.\n\nAn add-on module for NMR structures is  available.\n\nThe program can be combined with the WHAT-  IF program for structure validation, and with  FoldX for energy calculations.]\n\n---\n\n### Exercise 2: show a structure ###\n\n.left[\nLoad PDB entry 1TRZ using the File menu.\n\nCompare the default representations (F1-F8)  and use the various controls to change the view  of the protein.\n\nExplore the Edit and View menus to change  various aspects of the graphical representation  of the structure.\n\nExamine the hydrogen bonding patterns.  Display a molecular surface.\n\nCreate an interesting view of the molecule and  save it as a high-resolution image.\n]\n---\n\n### Protein folds are the structures of domains ###\n\n.left[\nSimilarities in assembly of secondary structure elements\n\nSo not based on sequence like motifs but on 3D structure\n\nFolds represent the shapes of protein domains!\n]\n\nExamples: TODO (add images e.g. alpha solenoid, DNA clamp, thioredoxin fold)\n\n---\n\n### Databases of protein folds ###\n\n- SCOP (http://scop.mrc-lmb.cam.ac.uk/scop/)\n- CATH (http://www.cathdb.info/)\n\n\n---\n\n### check on slides from course Wim Vranken ###\n\nsee also (http://www.ii.uib.no/~slars/bioinfocourse/PDFs/structpred_tutorial.pdf)\n\n---\n\n### Structure Superposition ###\n\n.left[\nStructures can be superimposed to achieve the best  possible match between corresponding atoms. It is  possible to consider all atoms, or only a subset  (such as the C atoms).\n\nWhen the structures are very similar, determining  which atoms should be matched to each other is  trivial. When there are larger differences, it takes  more preparation.\n\nDifferent algorithms use different combinations of  sequence- and secondary of tertiary structure-based information.\n]\n\n---\n\n### Exercise 3: Compare Structures ###\n\n.left[\nDownload the five provided PDB files and open  them in Yasara.\n\nUse the `Analyze|Align|Objects` with MUSTANG  function to align the four last objects with the first one.\n\nUse the space bar to open the text console and  see the reported root mean square deviations as well as the number of residues matched.\n]\n\n$$ rmsd = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}R_{i}^{2}} $$ \n\n.left[\nColor all structures by B factor and compare the  distribution to the local variability of the structures.\n]\n---\n\n### PDB File Surprises ###\n\n- Missing atoms, residues and loops  \n- Multiple molecules in the asymmetric unit\n- Incomplete oligomers due to coincident crystal and  oligomer symmetry\n- C-only models  lternate conformations\n- Multiple models, especially for NMR ensembles\n- Use of B factors to represent other properties  ther non-standard extensions (PDBQT, ...)\n\n---\n\n### Force Fields ###\n\n- Energy terms representing physical interactions\n\n - Covalent bond lengths and angles\n - Dihedral angles and van der Waals forces (steric effects)\n - Electrostatic interactions and hydrogen bonds\n\n\n- Energy can be minimized, and forces can literally be derived from the potential function.\n\n- Consistency and careful consideration of the  properties to be simulated are essential.\n\n---\n\n### Force Field Terms ###\n\n.left[Each energy term has a functional form, which includes one or more parameters:]\n\n- Covalent bond energy term\n To do: add formula\n- Van der Waals contact energy term\n\n.left[The parameters are collectively optimized to  reproduce a chosen set of experimentally observed parameters.\n\nA given force field should be used as a  consistent system, and can only be used to predict properties that are covered by the  training set.\n]\n\n---\n\n### FoldX ###\n\n\n.left[\nIs designed for quantitative modelling of the contribution of structural interactions to the stability of proteins and protein complexes. It also supports  protein/DNA complexes.\n\nThe force field describes the different interactions in a  protein structure or complex in analytical terms. It has  been calibrated using a set of experimentally determined  stabilities.\n\nApplications include the optimisation of structures, the calculation of the stability of complexes, and predicting  the effect of amino-acid or base-pair mutations on these  properties.\n]\n\n---\n\n### The FoldX Plugin for Yasara\t###\n\n.left[\nIn order to make FoldX more accessible and  integrate its functions into Yasara, dr. Joost van  Durme (SWITCH laboratory) made a Yasara plugin  module that can apply FoldX functions to structures  that are loaded as Yasara objects.\n\nThis greatly simplifies the use of FoldX, and allows  for a quick visual analysis of the resulting changes  in the structures.\n\nMore information can be found at [wiki](http://foldxyasara.switchlab.org/index.php/) [FoldX](http://foldxsuite.crg.eu/)\n]\n\n---\n\n### Exercise 4a: Repair a PDB File ###\n\n- Load the 1CRN PDB file.\n- Use the Repair object option in the Analysis |  FoldX menu to activate the corresponding FoldX  function.\n- Select the object to repair.\n\n.left[This exports the object as a temporary PDB file,  starts FoldX with the appropriate options, and loads  the repaired PDB file as a new object in Yasara.]\n\n- Compare the original and repaired objects.  \n- Describe the changes that were introduced.\n\n---\n\n### Exercise 4b: Model a Mutation ###\n\n- Load the 2AC0.sce Yasara scene file.\n- Set an appropriate structure representation.\n- Locate residue Ala159 using the sequence view,  and right-click to access the `FoldX|Mutate` residue function. Change it to a Trp residue.\n- Look at the effect of the substitution on the  structure, and use the space bar to open the text  console and read the output of the FoldX  calculation.\n- Mutate Arg273 to an alanine side chain. Discuss  the effects of this substitution.\n\n---\n\n### Homology Modelling ###\n\n- When a structure is available for a protein with a  similar sequences, it is possible to predict the  structure of a new sequence with varying degrees of  confidence.\n- Use PSI-BLAST/DELTA-BLAST to detect sequences with similar structures.\n- All homology modelling procedures start from an  alignment of the template and target sequences.  The quality of this alignment will have a major  impact on the resulting model.\n- Available applications include stand-alone programs  (Modeller, FoldX, ) and web-based services (such as SwissModel).\n\n \n\n---\n\n### Exercise 5: Make a Homology  Model using Swiss Model ###\n\nsee []()\n\n---\n\n### Predict protein structures by fold recognition ###\n\n1. Search SCOP/CATH for protein with same fold and known 3D structure\n2. Align each amino acid of query sequence to a position in the template structure\n3. Evaluate how well the sequence fits the fold and select best-fit fold\n4. Build structural model of query based on alignment with selected fold\n\n- Phyre (http://www.sbg.bio.ic.ac.uk/phyre2/html/page.cgi?id=index)\n- HHpred (http://toolkit.lmb.uni-muenchen.de/hhpred)\n- DescFold (http://202.112.170.199/DescFold/)\n\n.left[Works because:\n- Number of different folds in nature is fairly small (approximately 1300)\n- 90% of new submissions in PDB have similar folds to those already in PDB\n- Not always accurate\n]\n\n---\n\n### Guidelines to improve fold recognition results ###\n\n- Run as many methods as you can\n- Run each method on many sequences from your homologous protein family\n- After all of these runs, build up a consensus picture of the likely fold\n- Compare function of your protein to function of the proteins with the likely fold\n- Compare secondary structure of your protein to that of the likely fold\n\n\n---\n\n### Similarity searches based on 3D structure ###\n\n.left[\nSimilarity on structural level: aligning 3D structures\n\nStructure of query protein is known and aligned to PDB structures\n- VAST+ (https://www.ncbi.nlm.nih.gov/Structure/vastplus/vastplus.cgi)\n- DALI (http://ekhidna.biocenter.helsinki.fi/dali_server/)\n\nCompare proteins with low sequence similarity:\nsimilar structure implies homology -&gt; same function\n\nCan help to find active sites\n]\n\n---\n\n### Exercise 6: Study Protein-Ligand Interactions ###\n\nsee []()\n\n---\n\n### On-Line References ###\n\n- Crystallography 101 (Bernhard Rupp):  (http://www.ruppweb.org/Xray/101index.html)\n- Protein NMR, A Practical Guide (Vicky Higman) (http://www.protein-nmr.org.uk/)\n- Model validation course  (http://xray.bmc.uu.se/gerard/embo2001/modval/index.html)\n- Assessing model quality (http://spdbv.vital-it.ch/TheMolecularLevel/ModQual/)\n\n- Lectures by Burkhard Rost on protein structure  prediction (https://www.youtube.com/channel/UCU6j8BG4RbEtTgyIZJ6Vpow)\n\n---\n&quot;,&quot;$font-size: 15px;\n$tutorial-box-spacing: 1rem;\n\n// palette\n$white: #fff;\n$gray: #777;\n$light-gray: #ddd;\n$text-color: #292b2c;\n\n$red: #f00000;\n$orange: #f06d00;\n$yellow: #be9900;\n$green: #339e3a;\n$blue: #009090;\n$dark-blue: #1b2944;\n$light-blue: #5daadd;\n$purple: #882d60;\n$mid-gray: #9d9d9d;\n\n// colors general\n$bg-color: $dark-blue;\n$menu-color: $dark-blue;\n\n// colors tutorial boxes\n$overview-color: #8A9AD0;\n$agenda-color: #86D486;\n$keypoints-color: #FFA1A1;\n$tip-color: #FFE19E;\n$warning-color: #de8875;\n$comment-color: #ffecc1;\n$handson-color: #dfe5f9;\n$question-color: #8A9AD0;\n$solution-color: #B8C3EA;\n$details-color: $light-gray;\n$feedback-color: #86D486;\n\n\n@mixin matrix-table (){\n  table {\n      width:unset;\n      margin-left:auto;\n      margin-right:auto;\n  }\n\n  table thead th {\n      border-bottom: 2px solid #777;\n      text-align: left;\n  }\n\n  table td:first-child, table th:first-child  {\n      border-right: 2px solid #777;\n      font-weight: bold;\n      text-align: left;\n  }\n\n  table td:not(first-child), table th:not(first-child) {\n      text-align: center;\n      border-right: 1px solid #ddd;\n      border-left: 1px solid #ddd;\n  }\n}\n\n@mixin tutorial-box ($bg-color, $color: rgba(255,255,255,.75)) {\n    margin-top: 3 * $tutorial-box-spacing;\n    padding: $tutorial-box-spacing $tutorial-box-spacing - 0.11rem $tutorial-box-spacing;\n    border: 1px solid $bg-color;\n    box-shadow: 3px 3px $bg-color;\n    &amp; &gt; h3 {\n        font-size: $font-size + 3;\n        margin-left: -$tutorial-box-spacing;\n        margin-right: -$tutorial-box-spacing;\n        margin-top: -3.90rem;\n        padding-top: $tutorial-box-spacing / 2;\n        padding-bottom: $tutorial-box-spacing / 2;\n        padding-left: $tutorial-box-spacing;\n        padding-right: $tutorial-box-spacing;\n        background-color: $bg-color;\n        color: $color;\n        vertical-align: 1em;\n        float: left;\n        border-top-left-radius: 8px;\n        border-top-right-radius: 8px;\n\n        .fa {\n            padding-right: $tutorial-box-spacing / 5;\n        }\n    }\n}\n\n@mixin matrix-table (){\n  table {\n      width:unset;\n      margin-left:auto;\n      margin-right:auto;\n      margin-top: 20pt;\n  }\n\n  table thead th {\n      border-bottom: 2px solid #777;\n      text-align: left;\n  }\n\n  table td:first-child, table th:first-child  {\n      border-right: 2px solid #777;\n      font-weight: bold;\n      text-align: left;\n  }\n\n  table td:not(first-child), table th:not(first-child) {\n      text-align: center;\n      border-right: 1px solid #ddd;\n      border-left: 1px solid #ddd;\n  }\n}\n\n\nbody {\n    font-size: $font-size;\n    word-wrap: break-word;\n    position: relative;\n}\n\nh1,\nh2,\nh3,\nh4 {\n    margin-top: 2rem;\n}\n\nimg {\n    max-width: 95%;\n    margin: 2.5%;\n}\n\npre {\n    padding: 1rem;\n    background-color: lighten($gray, 40%);\n}\n\nfigure {\n  text-align: center;\n  margin: 1rem 2rem;\n\n  &amp; &gt; img {\n      margin-bottom: 1rem;\n  }\n\n  .figcaption-prefix {\n      font-weight: 600;\n  }\n\n  figcaption {\n    text-align: justify;\n  }\n}\n\nfooter {\n    margin-top: 3em;\n    text-align: center;\n    color: $gray;\n    font-size: $font-size - 2;\n}\n\n.follow-up {\n    p {\n        font-size: 18px;\n    }\n}\n\n.navbar {\n    background-color: $bg-color!important;\n\n    .navbar-collapse {\n        justify-content: flex-end;\n        align-items: flex-end;\n        min-width: 0;\n    }\n}\n\n.main-content {\n    padding-top: 1rem;\n}\n\n.table {\n    td {\n        vertical-align: middle;\n    }\n\n    .fa {\n        font-size: $font-size + 5;\n    }\n\n}\n\n.topic-icon {\n    padding: .5rem .75rem;\n}\n\n.training-network-map {\n    width: 90%;\n    margin: 0 auto;\n}\n\n.tutorial {\n    &amp; &gt; h1:first-child {\n        margin-bottom: 1rem;\n    }\n\n    table {\n        display: block;\n        width: 100%;\n        overflow-x: auto;\n        max-width: 100%;\n        margin-bottom: 1rem;\n\n        th,\n        td {\n            padding: .75rem;\n            vertical-align: top;\n            border-top: 1px solid #eceeef;\n        }\n\n        thead th {\n            vertical-align: bottom;\n            border-bottom: 2px solid #eceeef;\n        }\n    }\n\n    // tutorial boxes\n    blockquote {\n        ul,\n        ol,\n        &amp; &gt; blockquote,\n        p {\n            margin-bottom: 0px;\n        }\n\n        &amp;.agenda {\n            @include tutorial-box($agenda-color, $text-color);\n        }\n\n        &amp;.tip {\n            @include tutorial-box($tip-color, $text-color);\n        }\n\n        &amp;.question {\n            @include tutorial-box($question-color, $text-color);\n        }\n\n        &amp;.solution {\n            @include tutorial-box($solution-color, $text-color);\n        }\n\n        &amp;.comment {\n            @include tutorial-box($comment-color, $text-color);\n        }\n\n        &amp;.hands_on {\n            @include tutorial-box($handson-color, $text-color);\n        }\n\n        &amp;.key_points {\n            @include tutorial-box($keypoints-color, $text-color);\n        }\n\n        &amp;.overview {\n            @include tutorial-box($overview-color, $text-color);\n        }\n\n        &amp;.warning {\n            @include tutorial-box($warning-color, $text-color);\n        }\n\n        &amp;.details {\n            @include tutorial-box($details-color, $text-color);\n        }\n\n        &amp;.quote {\n            border-left: 5px solid #eee;\n            padding-left: 1em;\n        }\n\n        &amp;.matrix {\n            @include matrix-table();\n        }\n\n        &amp;.feedback{\n            @include tutorial-box($feedback-color, $text-color);\n        }\n    }\n\n    .fold-unfold {\n        margin-left: $tutorial-box-spacing;\n    }\n\n    .google-form {\n        width: 100%;\n        height: 1100px;\n        border: 0;\n    }\n}\n\n.contributors {\n    padding: 0;\n\n    .carousel-item {\n        align-items: flex-start;\n        flex-wrap: wrap;\n        flex-direction: row;\n        justify-content: space-around;\n    }\n\n    .carousel-item.active,\n    .carousel-item-next,\n    .carousel-item-prev {\n        display: flex;\n    }\n\n    .hall-of-fame-hero {\n        margin: 0;\n        width: 20%;\n\n        .name {\n            font-size: 0.7em;\n        }\n    }\n}\n\n.contributors-line {\n    color: $gray;\n    font-size: 1.2em;\n    margin-bottom: 5rem;\n}\n\n.hall-of-fame {\n    display: flex;\n    flex-wrap: wrap;\n    flex-direction: row;\n    justify-content: space-around;\n}\n\n.hall-of-fame-hero {\n    width: 140px;\n    margin: 1rem;\n    text-align: center;\n\n    .name {\n        margin-top: 0.5rem;\n    }\n\n    .contact-items {\n        margin-top: 0.2rem;\n    }\n\n    .thumbnail img {\n        background-color: white;\n        border-radius: 20px;\n        border: 1px solid $light-gray;\n        padding: 5px;\n        width: 100%;\n        -webkit-transition: border 0.2s ease-in-out;\n        -o-transition: border 0.2s ease-in-out;\n        transition: border 0.2s ease-in-out;\n    }\n\n    a.thumbnail {\n        &amp;:hover,\n        &amp;:focus,\n        &amp;:active {\n            img {\n                border-color: $menu-color;\n            }\n        }\n    }\n}\n\n// This is a fix to get the hamburger button (menu/navbar) correctly placed on\n// small screens.\n@media (max-width: 575px) {\n    .navbar &gt; .container {\n        position: initial;\n        margin-left: initial;\n        margin-right: initial;\n    }\n}\n\n// This applies a \&quot;dark\&quot; style to the dropdown menus on small devices since\n// Bootstrap v4 does not do that by default.\n@media (max-width: 768px) {\n    .navbar {\n        .dropdown-menu {\n            background-color: transparent;\n            border-color: transparent;\n        }\n\n        .dropdown-item {\n            color: rgba($white, .5);\n\n            &amp;:hover,\n            &amp;:focus,\n            &amp;:active {\n                background-color: transparent;\n                color: rgba($white, .75);\n            }\n        }\n\n        .nav-item,\n        .dropdown-item {\n            overflow: hidden;\n            white-space: nowrap;\n            text-overflow: ellipsis;\n        }\n    }\n}\n\n@media (min-width: 768px) {\n    .tutorial table,\n    .table-responsive {\n        display: table;\n    }\n\n    .citation {\n        text-align: justify;\n    }\n}\n\n@media (max-width: 1200px) {\n    .navbar-nav i {\n        display: none;\n    }\n}\n\n.label {\n    display: inline;\n    padding: .2em .6em .3em;\n    font-size: 75%;\n    font-weight: bold;\n    line-height: 1;\n    color: #fff;\n    text-align: center;\n    white-space: nowrap;\n    vertical-align: baseline;\n    border-radius: .25em;\n}\n\n.label-default {\n    background-color: #999999;\n}\n\n.level {\n    color: lightgray;\n    margin-right: 0.5em;\n\n    .fa {\n        font-size: 0.9em;\n    }\n    &amp;.introductory i:first-of-type {\n        color: green;\n    }\n    &amp;.intermediate i:not(:last-of-type) {\n        color: orange;\n    }\n    &amp;.advanced {\n        color: red;\n    }\n}\n\n\n\n.visually-hidden {\n    border: 0;\n    clip: rect(0 0 0 0);\n    height: 1px;\n    margin: -1px;\n    overflow: hidden;\n    padding: 0;\n    position: absolute;\n    width: 1px;\n}\n\n\n/* WCAG Contrast. These aim to pass AA level for normal sized text. */\na {\n    color: #0070e8;\n\n    &amp;:hover,\n    &amp;:focus,\n    &amp;:active {\n        color: #004590;\n    }\n}\n\ncode {\n    color: #8b3035;\n}\n\n\nnav[data-toggle=&#39;toc&#39;] {\n    margin-top: 30px;\n    margin-bottom: 30px;\n    .nav {\n        li {\n            a {\n                padding-left: 0px;\n                &amp;:hover,\n                &amp;:focus,\n                &amp;:active{\n                    padding-left: 0px;\n                    color: #004590;\n                    border-left: none;\n                }\n            }\n\n            .active {\n                padding-left: 0px;\n                color: #004590;\n                border-left: none;\n            }\n        }\n\n        .nav li {\n            a,\n            .active {\n                padding-left: 10px;\n                &amp;:hover,\n                &amp;:focus,\n                &amp;:active{\n                    padding-left: 10px;\n                }\n            }\n\n            &amp;:hover,\n            &amp;:focus,\n            &amp;:active{\n                padding-left: 10px;\n            }\n        }\n    }\n\n    .nav-link.active:hover {\n        padding-left: 0px;\n        color: #004590;\n        border-left: none;\n    }\n}\n\n.col-sm-2 {\n    padding-left: 0px;\n}\n\n/* small screens */\n@media screen and (max-width: 768px) {\n    nav[data-toggle=&#39;toc&#39;] {\n        display: none !important;\n    }\n\n    .col-sm-10 {\n        max-width: 100%;\n    }\n}\n\n.contributor-badge {\n    /* prevent breaking across lines */\n    white-space: nowrap;\n\n    img {\n        height: 1.25em;\n        border-radius: 50%;\n        margin: 0.25em;\n    }\n}\n\n\ndiv.highlight {\n\tposition: relative;\n}\ndiv.highlight .btn{\n\t-webkit-transition:opacity .3s ease-in-out;\n\t-o-transition:opacity .3s ease-in-out;\n\ttransition:opacity .3s ease-in-out;\n\topacity:0;\n\tpadding:2px 6px;\n\tposition:absolute;\n\tright:4px;\n\ttop:4px;\n\tfont-family: -apple-system,BlinkMacSystemFont,\&quot;Segoe UI\&quot;,Roboto,\&quot;Helvetica Neue\&quot;,Arial,sans-serif;\n}\n\ndiv.highlight:hover .btn,div.highlight .btn:focus{\n\topacity:1\n}\n\n#supporting_materials ul li {\n    div {\n        display: flex;\n        flex-direction: row;\n        align-items: center;\n\n        div {\n            a.topic-icon {\n                padding: 0 .5rem 0 .5rem;\n            }\n\n            a.topic-icon.btn {\n                padding-top: 0;\n                padding-bottom: 0;\n            }\n        }\n\n        div:first-child {\n            a.topic-icon {\n                padding-left: 0;\n            }\n        }\n\n        div:not(:first-child):before {\n            content: \&quot; - \&quot;;\n        }\n    }\n}\n&quot;,&quot;&quot;,&quot;.enlarge120[\n\n# ***De novo* Genome Assembly**\n\n]\n\n#### With thanks to T Seemann, D Bulach, I Cooke and Simon Gladman\n---\n.enlarge120[\n\n# ***De novo* assembly**\n\n]\n\n.pull-left[\n\n**The process of reconstructing the original DNA sequence from the fragment reads alone.**\n\n* Instinctively like a jigsaw puzzle\n\n  * Find reads which \&quot;fit together\&quot; (overlap)\n  * Could be missing pieces (sequencing bias)\n  * Some pieces will be dirty (sequencing errors)\n\n]\n\n.pull-right[ ![](../../images/Humpty.jpg) ]\n\n---\n\n# **Another View**\n\n![](../../images/newspaper.png)\n\n---\n\n# **Assembly: An Example**\n\n---\n\n# **A small \&quot;genome\&quot;**\n\n![](../../images/shakespear1.png)\n\n---\n\n# **Shakespearomics**\n\n![](../../images/shakespear2.png)\n\n---\n\n# **Shakespearomics**\n\n![](../../images/shakespear3.png)\n\n---\n\n# **Shakespearomics**\n\n![](../../images/shakespear4.png)\n\n---\n\n# **So far, so good!**\n\n---\n\n# **The Awful Truth**\n\n![](../../images/notsimply.png)\n\n## \&quot;Genome assembly is impossible.\&quot; - A/Prof. Mihai Pop\n\n---\n.enlarge120[\n\n# **Why is it so hard?**\n\n]\n\n.pull-left[\n* Millions of pieces\n  * Much, much shorter than the genome\n  * Lots of them look similar\n* Missing pieces\n  * Some parts can&#39;t be sequenced easily\n* Dirty Pieces\n  * Lots of errors in reads\n]\n\n.pull-right[ ![](../../images/worlds_hardest.png) ]\n\n---\n\n# **Assembly recipe**\n\n* Find all overlaps between reads\n  * Hmm, sounds like a lot of work..\n* Build a graph\n  * A picture of the read connections\n* Simplify the graph\n  * Sequencing errors will mess it up a lot\n* Traverse the graph\n  * Trace a sensible path to produce a consensus\n\n---\n\n![](../../images/olc_pic.png)\n\n---\n\n# **A more realistic graph**\n\n![](../../images/real_graph.png)\n\n---\n\n# .image-15[![](../../images/nofun.png)] **What ruins the graph?**\n\n* Read errors\n  * Introduces false edges and nodes\n\n* Non haploid organisms\n  * Heterozygosity causes lots of detours\n\n* Repeats\n  * If they are longer than the read length\n  * Causes nodes to be shared, locality confusion.\n\n---\n\n# **Repeats**\n\n---\n.enlarge120[\n# **What is a repeat?**\n]\n\n.pull-left[\n\n#### ***A segment of DNA which occurs more than once in the genome sequence***\n\n* Very common\n  * Transposons (self replicating genes)\n  * Satellites (repetitive adjacent patterns)\n  * Gene duplications (paralogs)\n\n]\n\n.pull-right[\n\n![](../../images/triplets.png)\n\n]\n\n---\n\n# **Effect on Assembly**\n\n![](../../images/repeat_effect.png)\n\n---\n.enlarge120[\n# **The law of repeats** .image-15[![](../../images/repeatafterme.png)]\n]\n\n## **It is impossible to resolve repeats of length S unless you have reads longer than S**\n\n## **It is impossible to resolve repeats of length S unless you have reads longer than S**\n\n---\n\n# **Scaffolding**\n\n---\n.enlarge120[\n# **Beyond contigs**\n]\n\n.pull-left[\n\nContig sizes are limited by:\n\n* the length of the repeats in your genome\n  * Can&#39;t change this\n\n\n* the length (or \&quot;span\&quot;) of the reads\n  * Use long read technology\n  * Use tricks with other technology\n\n]\n\n---\n.enlarge120[\n# **Types of reads**\n]\n\n.pull-left[.enlarge120[**Example fragment**]]\n\n\n.remark-code[.enlarge120[atcgtatgatcttgagattctctcttcccttatagctgctata]]\n\n.pull-left[.enlarge120[**\&quot;Single-end\&quot; read**]]\n\n\n.remark-code[.enlarge120[**atcgtatg**atcttgagattctctcttcccttatagctgctata]]\n\nsequence *one* end of the fragment\n\n.pull-left[.enlarge120[**\&quot;Paired-end\&quot; read**]]\n\n\n.remark-code[.enlarge120[**atcgtatg**atcttgagattctctcttcccttatag**ctgctata**]]\n\nsequence both ends of the same fragment\n\n**We can exploit this information!**\n---\n\n.enlarge120[# **Scaffolding**]\n\n* **Paired end reads**\n  * Known sequences at each end of fragment\n  * Roughly known fragment length\n\n* **Most ends will occur in same contig**\n\n* **Some will occur in different contigs**\n  * ***evidence that these contigs are linked***\n---\n\n.enlarge120[# **Contigs to Scaffolds**]\n\n![](../../images/scaffolding.png)\n\n---\n\n.enlarge120[# **Assessing assemblies**]\n\n* We desire\n  * Total length similar to genome size\n  * Fewer, larger contigs\n  * Correct contigs\n\n* Metrics\n  * No generally useful measure. (No real prior information)\n  * Longest contigs, total base pairs in contigs, **N50**, ...\n\n---\n\n.enlarge120[# **The \&quot;N50\&quot;**]\n\n.enlarge120[***The length of that contig from which 50% of the bases are in it and shorter contigs***]\n\n* Imagine we have 7 contigs with lengths:\n  * 1, 1, 3, 5, 8, 12, 20\n\n* Total\n  * 1+1+3+5+8+12+20 = 50\n\n* N50 is the \&quot;halfway sum\&quot; = 25\n  * 1+1+3+5+8+**12** = 30 (&gt;25) so **N50 is 12**\n\n---\n\n.enlarge120[# **2 levels of assembly**]\n\n* Draft assembly\n  * Will contain a number of non-linked scaffolds with gaps of unknown sequence\n  * Fairly easy to get to\n\n* Closed (finished) assembly\n  * One sequence for each chromosome\n  * Takes a **lot** more work\n  * Small genomes are becoming easier with long read tech\n  * Large genomes are the province of big consortia (e.g. Human Genome Consortium)\n\n---\n.enlarge120[# **How do I do it?**]\n---\n.enlarge120[\n# **Example**\n\n* Culture your bacterium\n\n\n* Extract your genomic DNA\n\n\n* Send it to your sequencing centre for Illumina sequencing\n  * 250bp paired end\n\n\n* Get back 2 files\n  * .remark-code[MRSA_R1.fastq.gz]\n  * .remark-code[MRSA_R2.fastq.gz]\n\n\n* ***Now what?***\n]\n\n---\n.enlarge120[# **Assembly tools**\n\n* **Genome**\n  * **Velvet, Velvet Optimizer, Spades,** Abyss, MIRA, Newbler, SGA, AllPaths, Ray, SOAPdenovo, ...\n\n\n* Meta-genome\n  * Meta Velvet, SGA, custom scripts + above\n\n\n* Transcriptome\n  * Trinity, Oases, Trans-abyss\n\n***And many, many others...***\n\n]\n\n---\n.enlarge120[\n# **Assembly Exercise #1**\n\n* We will do a simple assembly using **Velvet** in **Galaxy**\n* We can do a number of different assemblies and compare some assembly metrics.\n\n]\n&quot;,&quot;# Ecology Analysis using vegan \n{:.no_toc}\n\nIn this exercise we will look at a data matrix of 16S rRNA counts in 74 samples.\n\nThis dataset is the microbiota composition of 74 mice from 5 different mice strains. The original research aim was to define the effect that the mouse genome has on the microbiota and what the effect of living in the same cage would be. However, we found much stronger trends in the data, and these we will look at in this exercise.\n\nThe 454 data was already compiled into a matrix with genus abundance per sample in a previous step. This matrix is called a feature abundance matrix, or abundance matrix for short. We will do an ecology-oriented analysis of the data, in later steps also taking metadata (experimental, environmental or clinical data that was collected for each sample, independent of the DNA) into account. The aim of this tutorial is to get an idea of the very basic steps of ecological data analysis using the programming language R.\n\nThe gene abundance table (Genus.txt) can be found in the folder /home/VIBTrainingX/NGS/metagenomics/higherLvl folder on the server. Those who are working on their own laptop can download it [from the lotus website](http://psbweb05.psb.ugent.be/lotus/data/LotuStutorial.tar.gz).\n\n1. Set the folder with the provided files as your working directory in R using `setw`. This way required files can be easily loaded. To find out how to use this command, you can type ?setwd() to open the help. If there are other R-commands that you want to know more about, you can open the R-help for that command by entering in the R-prompt `?command`. This will be very useful when working with R, make sure to use this a lot as you can only learn more :o). \n\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 1 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to set the working directory in R \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; setwd(dir_to_data) \n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\n2. Load the provided data into the matrix M (Genus.txt, actual genus abundance data), using the read.delim command, saving the loaded table as `M`. Make sure, the row names are correctly read in. As R reads the matrix as an object of class data.frame, we convert M from a data.frame to a matrix `M=as.matrix(M)`. This is important for some of the following calculations, where we need a `matrix` class object. \n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 1 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to read in data as matrix ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # read in data as matrix\n&gt;  &gt; &gt; M = read.delim(file=\&quot;Genus.txt\&quot;,row.names=1)\n&gt;  &gt; &gt; M = as.matrix(M) \n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nThe matrix you loaded represents the number of 16S sequences assignable to each genus, which we could find in the samples. Also note that not all genera are real genera, but partly assigned unknown sequences. With these groups we do not know if this is a single genus or in fact several genera or in extreme cases even several classes, that just all fall under the same phylum tag. What are the advantages and disadvantages of keeping such undefined groups in the data?\nUse the function `edit(M)` to better view the abundance matrix.\n\n3. Lets look at some  basic features of the abundance matrix. The `summary(M)` command is a good start, but also look at total row and column counts (`colSums`, `rowSums` command). To see how the genera are distributed within each sample, we will plot a sample-wise density plot.We will be using a combination of the `density`, `lines` and `lapply` functions, to draw the densities of values found in each sample. Lets start with looking at the density of the first sample. In R you can access specific columns by writing the matrix coordinates in square brackets. For example `M[1,]` shows the first row of a matrix, `M[,7]` shows the 7th column etc:\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 3 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to estimate density of first sample ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # estimate density of first sample\n&gt;  &gt; &gt; densityOfSample1 = density(M[,1])\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\n\nLook at the object densityOfSample1 by simply entering the object name into the command prompt. Next try to visualize it with `plot(densityOfSample1)`. In this plot you see that most genera are at 0 abundance, some genera have an abundance &lt;10 and some rare genera actually occur with a higher frequency, one genus even having ~1100 16S reads assigned to it. Which genus is this?\n\nAlternatively you can also use the function `hist`, to plot a histogram of the abundances. Try to do this now.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 4 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to plot histogram of abundances ?\n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # plot histogram of abundances\n&gt;  &gt; &gt; hist(M[,1], nclass = 50)\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nWe can use the `apply` command, to apply the density command to every column of M, which will return a list of density objects. The second argument to the `apply` function is the `margin` and is set to 2, which tells the `apply` function that we want to work on columns (margin = 2) and not on rows (margin = 1). Save this into object  `S_densities`.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 5 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to estimate densities of all samples ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # estimate densities of all samples\n&gt;  &gt; &gt; S_densities = apply(M,2,density)\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\n\n\nTo plot this start with:\n```\n# open a new plot window and set range of x and y axis\nplot(1,1,type=\&quot;n\&quot;,ylim=c(0,3),xlim=c(0,5000)) \n```\n\nThis will open a new plotting window, already set to the range of x and y coordinates (xlim, ylim) we will need in this example. In this case we just want to plot a blank space, this is done with the `type=n` argument. Try to replace the argument by `type=p`, to actually see that point! S_densities is a list, so we use `lapply` (list apply), in combination with the `lines` function, try this now to plot all the density lines into the open plot window.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 6 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to plot density distributions of all samples ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # plot density distributions of all samples\n&gt;  &gt; &gt; lapply(S_densities,lines)\n&gt; &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\n\nWhat you should see now in the plot window is the density distribution of all samples. The lines function is adding new lines, while a plot function makes a completely new plot. Try to replace the `lines` with `plot` to see this (its very fast, so keep a close eye on your plot). How are these lines already telling us something about the differences between the communities of each sample?\n\n4. Maybe you noticed that the `colSums` command showed that the totals are not equal. What does this mean? In this state the data is actually not comparable among each other. One way to `correct` the data for this shortcoming is to normalize the matrix. In this step we will normalize the abundance matrix into variable M1: \n\n```\n# normalize matrix: divide each column by the total of that column\nM1 = sweep(M,2,colSums(M),\&quot;/\&quot;)\n```\n\nThe `sweep` command is extremely useful, as it will apply a simple arithmetic operation (like divide) in a matrix column- or row-wise with a vector of your choice. So it is very similar to `apply`, but takes more basic functions. In this case we will divide each column by the sum of the column, this is called normalization.\n\nNow we will compare these matrices using the `barplot` function. For this we need to open another graphical window, using the `X11` function:\n```\n# create barplot of original and normalized data\nbarplot(M)\nX11()\nbarplot(M1)\n```\n\nWhat do you notice about the sample composition? What does the graph mean? Discuss where you would want to normalize the data (and where not).\n\nClose all open plots.\n\nNow replot the sample-wise density plot (as you did in step 3), but start the plot with these adapted x and y ranges. Additionally we will this time label the x- and y-axis:\n\n```\n# open a new plot and define ranges and titles of x and y axis\nplot(1,1,type=\&quot;n\&quot;,ylim=c(0,80),xlim=c(0,1),xlab=\&quot;relative genus abundance\&quot;, ylab=\&quot;Frequency of genera\&quot;) \n``` \n\nYou will notice that the graph looks different from you previous plot. What changed due to the normalization? Are the samples more similar to each other using M or M1? \n\nIf you spot a difference in species abundance between two samples using matrix M, is this difference real, does it have scientific value?\n\nFor the next step the R-library vegan is required. It is a set of functions specifically designed for ecological data analysis. The package has been installed on the bits laptops. If you were to install the package, you could do so using the command: `install.packages(vegan)`. More details on the [vegan web site ](http://cc.oulu.fi/~jarioksa/softhelp/vegan.html). Load vegan, using the `library` command.\n\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 7 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to load the vegan package ?\n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # load vegan package\n&gt;  &gt; &gt; library(vegan)\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\n\nLets try to put the differences we observed in sample density into numbers. To do this, ecologists rely on the concept of diversity. Diversity describes the evenness of species distributions as well as the richness of species that are observed in a given ecological system. We will first calculate the Shannon diversity, using vegans `diversity` command. Try to do this per sample, using the `apply` function again. Save the result in object `div`.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 8 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to calculate Shannon diversity index for each sample using the normalized data ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # calculate Shannon diversity index for each sample using the normalized data \n&gt;  &gt; &gt; div = apply(M1,2,diversity,index=\&quot;shannon\&quot;)\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nNow we can see in action what these indices are actually doing for us. Plot the density of the sample with the lowest and highest diversity in red and blue on your previous density plot of M1, this you do by first finding out which diversity indexes are the maximum and minimum values using the `which.max` and `which.min` functions on the object `div`. Dont forget to have the last density plot still open (or replot it from step 4 on M1), than add the lowest samples as a blue line and the highest sample as a red line, using the `lines` command. \n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 9 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; Find samples with lowest and highest Shannon diversity index and add them to the density plot ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # find samples with lowest and highest Shannon diversity index and add them to the density plot\n&gt;  &gt; &gt; which.min(div) #should be bl16\n&gt;  &gt; &gt; which.max(div) #should be bl48\n&gt;  &gt; &gt; lines(density(M1[,\&quot;bl16\&quot;],adjust =0.5),col=\&quot;blue\&quot;)\n&gt;  &gt; &gt; lines(density(M1[,\&quot;bl48\&quot;],adjust =0.5),col=\&quot;red\&quot;)&amp;\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nYou can now readjust the window by changing the `ylim` and `xlim` attribute in the plot function, if necessary (tip, try to rerun using `ylim=c(0,180)`). Try to explain why the colored samples have the highest &amp; lowest diversity. What does this tell about an ecosystem (remember that these are genus abundances).\nRaise your hand if you reached this step.\n\nA different way to normalize the data is to sample exactly equal amounts of 16S rDNA for each sample in this experiment. Of course in practice this is impossible to do, but we can simulate this, by randomly selecting a subset of 16S rDNA. This is called rarefaction. Rarefy your original abundance matrix (M) into M2, using 1000 reads per sample, using the `rrarefy` function of vegan. Note that you need to transpose (command `t()`) the matrix, before giving it to `rrarefy`. Transform the matrix back and save it as `M2`.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 10 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to normalize via rarefaction ?\n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # Alternative way of normalization\n&gt;  &gt; &gt; M2 = t(rrarefy(t(M),sample=2000))  #vegan needs transformed matrix, and we need it back-transformed\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nUse `colSums(M2)` to check if the rarefaction worked. The main use of rarefaction is in calculating diversity and richness correctly, for this we will look in the following step at observed richness.\n\nThe concept of observed richness within a sample is pretty simple (but useful): richness describes the number of different species that occur at least once in a sample. This can be calculated in two steps:\n\n```\n# Species present in sample: TRUE or 1 if species is present, FALSE or 0 if species is absent\nOnceOrMoreOftenPresent = M1&gt;0\n``` \n\nThe sum of each column in this matrix will tell us how many species were detected in total within the respective sample, use the `apply` and `sum` functions , saving the result in `rich1`.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 11 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to calculate the sum of each column ?\n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # Calculate sum of each column\n&gt;  &gt; &gt; rich1 = apply(OnceOrMoreOftenPresent,2,sum)\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\n\nCompare the richness values in `rich1` to the richness obtained on the rarefied matrix `M2`, calculated with a shortened command:\n\n```\n# Calculate number of present species in each sample using the rarefied data\nrich2 = apply(M2&gt;0,2,sum)\n``` \n\nCompare rich1 and rich2 in a matrix value by value. We use the `cbind` command to bind two vectors column wise together, so we get a matrix with 2 columns. Order this matrix by the richness values in rich1, using the `order` command and accessing the vector representation with `[]` square brackets.\n\n```\n# Create new matrix with two columns: rich1 and rich2 and order rows according to rich1 values\ncbind(rich1,rich2)[order(rich1),]\n```\n\nWhat does the second part of the formula do? What happens if you change that to order(rich2)?\n\nDiscuss which richness values have the highest value to the researcher and why the order is very different between these two richness estimates. Is one way clearly wrong?\n\nWhy did we choose 1000 as cutoff for the sequences per sample? What is the maximum value we could choose? \n\nFirst samples are clustered to see underlying data structures. For this tutorial we will choose a hierarchical clustering, based on a bray-curtis distance between samples, using the function `vegdist`. Make  sure the distances are calculated between Samples and not Genera.\n\nNext, use the function `hclust` on the distance matrix, saving the output in variable `cluster`, and subsequently plot the clustering of the samples (using `plot`).\nTake a guess of how many groups there might be in this clustering?\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 11 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to cluster samples and plot results ?\n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # cluster samples and plot results\n&gt;  &gt; &gt; BCD = vegdist(t(M1), dist=\&quot;bray\&quot;)\n&gt;  &gt; &gt; cluster = hclust(BCD)\n&gt;  &gt; &gt; plot(cluster)\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nTo visualize the samples and their relatedness to each other in a two-dimensional space, we can use an ordination to visualize the data in a low dimensional space. The dimensionality of the original matrix (73 genera=73 dimensions) is reduced to two dimensions. If you know what a PCA (Principal component analysis) is, this step will use a conceptually similar, but methodologically quite different technique to perform an ordination of the data, NMDS (non-metric multidimensional scaling).\n\nStart by calculating a 2-dimensional NMDS of the data using M1, using the Bray-Curtis distance in the function `metaMDS`, saving the result to `nmds`. Again, make sure that samples are being ordinated and not Genera.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 11 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to calculate the NMDS ?\n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # calculate NMDS\n&gt;  &gt; &gt; nmds = metaMDS(t(M1),distance = \&quot;bray\&quot;) #actual NMDS command, matrix needs to be transformed to conform with vegans standards\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nTake a look at the `nmds` object and explore some of its features (e.g. type `str(nmds)` to see what variables are stored within the NMDS object). Try to find out what the `stress` of your ordination is. What does stress stand for (tip: go to the R help on metaMDS)? Next we can visualize the NMDS, similar to what you get out of PCAs, displaying samples only:\n```\n# plot NMDS\nplot(nmds,display =\&quot;sites\&quot;)\n```\n\nThe important difference of NMDS compared to PCA is, that NMDS works with any kind of distance metric, while PCA can only use Euclidean distances between samples. A second important feature of NMDS is, that this method finds non-parametric, monotonic relationships between objects; in short: it doesnt assume a specific data distribution. Why might these two features be important for ecologists? \n\nYou might have noticed that you see two clusters, similar to the hierarchical clustering of the data. We can get for each sample the identity within the two clusters using the `cutree` commands, specifying k=2 (2 clusters). This can be plotted into the NMDS with the following command:\n\n```\n# identify clusters\nmemb = cutree(cluster, k = 2)\nordispider(nmds,memb)\n```\n\nCongratulations, you have just visualized the mouse enterotypes. Next we are going to look closer at these. If you want to know the exact methods to detect enterotypes in your data visit [http://enterotype.embl.de/enterotypes.html http://enterotype.embl.de/enterotypes.html]\n\nIn the last step, we will test for all the genera in the matrix whether they show significant differences between two clusters. The scientific question we are posing here is: what are the significant differences in the gut microbiota of between enterotypes? We will use a non-parametric test (kruskal-wallis) to do the tests, as ecological data is in most cases not normally distributed. This test is very similar to the student t-test, and the interpretation works just the same way. Use the function `kruskal.test` to test the first genera (M[1,]) for significant differences between the two cluster groups (in object `memb`). Save the output of this command in variable `Kt`.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 12 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to test if there is a difference between the two clusters for the first genus ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # Test if there is a difference between the two clusters for the first genus\n&gt;  &gt; &gt; Kt = kruskal.test(M1[1,],memb)\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\n\nLook at the output of this function. This will show you a human readable summary of the test and the result. You can access elements of a list (`Kt` is a list in this case) using the `$` operator. Try to extract the p-value from the `Kt` object.\n\nOnce you know how, we can start to calculate the significance for every genus in the M1 matrix,. These p-values we will store in a newly created vector `pvals`. Lets add the first 2 p-values to the vector:\n\n```\n# Test if there is a difference between the two clusters for the first and second genera. Store p-values in a vector.\npvals = c()\npvals[1] = kruskal.test(M1[1,], memb)$p.value\npvals[2] = kruskal.test(M1[2,], memb)$p.value\n```\n\nSince doing this 73 times takes a long time, we will be using a for-loop to `loop` over the matrix and do this for us. We could as well use the apply function, but the syntax would get a little more complicated, since we are only interested in a subpart of the result, the $p.value part. Try to write a for-loop, to calculate the p-value 73 times.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 13 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to test if there is a difference between the two clusters for all genera ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # Test if there is a difference between the two clusters for all genera\n&gt;  &gt; &gt; for (i in 1:dim(M1)[1])\n&gt;  &gt; &gt; {\n&gt;  &gt; &gt;         pvals[i] = kruskal.test(M1[i,], memb)$p.value\n&gt;  &gt; &gt; }\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nAs an additional help, you can add the name of the taxa to the pvals vector using the names command (that will name a vector):\n\n```\n# Add names to the vector\nnames(pvals) = dimnames(M1)[[1]] \n```\n\nWhich taxa are significantly different?\n\nIn this case we will use the normalized M1 matrix, can you explain why we do not use the M or M2 matrix? Would either be wrong to use?\n\nIn total we were testing in 73 genera, if their p-value was below a threshold of 0.05. What is the chance of observing data with a p-value &gt;0.05 by random chance? How many genera do you expect to be below this threshold by random chance? \n\nTo avoid statistical errors of this kind, we will use a Benjamini-Hochberg multiple testing correction, implemented in the R function `p.adjust`. Save the result as `qvals`.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 14 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt;\n&gt;  &gt; How to perform multiple testing correction of p-values using Benjamini-Hochberg method ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; # Multiple testing correction of p-values using Benjamini-Hochberg method\n&gt;  &gt; &gt; qvals = p.adjust(pvals,method =\&quot;hochberg\&quot;)\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nWhat do you see in this test? What would you report on this dataset, based on these values?\n\nTry sorting the q-values to see the most significant differences first:\n```\n# Sorting q-values\nsort(qvals)\n```\n\nNow that you have finished the tutorials, you should be able to analyze any new dataset of amplicon data, using the LotuS pipeline and performing a basic analysis with R, including\n* Data normalization\n* Clustering analysis\n* Ordination\n* Univariate statistics\nYou can always expand upon these concepts, using this tutorial as starting point. Just remember that R is a very flexible language, and all these commands can be expanded for new purposes and visualizations.\n\n### Data sources\nAll the material provided in this tutorial are from metagenomic study on mice knockouts. Further analysis of the data can be found in the reference below.\n\n### Reference \n\nHildebrand, F., Nguyen, A. T. L., Brinkman, B., Yunta, R. G., Cauwe, B., Vandenabeele, P.,  Raes, J. (2013). Inflammation-associated enterotypes, host genotype, cage and inter-individual effects drive gut microbiota variation in common laboratory mice. Genome Biology, 14(1), R4. doi:10.1186/gb-2013-14-1-r4\n\n&quot;,&quot;# Manipulation of variables \n{:.no_toc}\n\n### General functions\nThe big difference between R and other programming languages is that functions in R are designed to be applied to variables rather than to individual values to avoid loops e.g. if we want to log transform a whole dataset we can do this using a single operation:\n```\n&gt; v &lt;- c(1,10,100,1000,10000)\n&gt; log10(v)\n[1] 0 1 2 3 4\n```\nThe log10() function is written in such a way that it can be applied on a vector. This is true for all functions and operators in R:\n```\n&gt; v - 1\n[1] 0     9    99   999  9999\n```\nR has built-in functions for virtually any standard mathematical task.\n \n&lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../../images/Rgeneral_functions.png\&quot; alt=\&quot;general_functions\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; Overview of built-in functions&lt;/figcaption&gt;&lt;/figure&gt;\n\nArithmetic operators can be used on variables. Provided that the variables have the same dimensions, you can do element-wise addition, subtraction, multiplication and division of two vectors or tables. Element-wise means that the calculation is performed on the equivalent positions between the two variables: first element + first element, second element + second element etc.\n\n```\n&gt; v1&lt;-c(1,2,3)\n&gt; v2&lt;-c(4,5,6)\n&gt; z&lt;-v1+v2\n&gt; z\n[1] 5 7 9\n```\n\nIf you perform operations on vectors with different lengths (not recommended) then the vector with the shorter length is recycled to the length of the longer vector so that the first element of the shorter vector is appended to the end of that vector (a way of faking that it is of equal length to the longer vector) and so forth. You will get a warning, but R does let you perform the operation:  \n\n```\n&gt; x1 &lt;- c(1,2,3)\n&gt; x2 &lt;- c(3,4)\n&gt; x3 &lt;- x1 + x2\nWarning message: \nIn x1 + x2:\n  longer object length is not aa multiple of shorter object length\n&gt; x3\n[1] 4 6 6\n```\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Operations on variables** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 13a\n&gt;\n&gt; 1. Calculate log base2 of the activity in Drug_study\n&gt; 2. Round the result to the nearest integer\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  log.act &lt;- (log2(Drug_study$activity))\n&gt;    &gt;  round(log.act)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 13b\n&gt;\n&gt; 1. Create vector v as the sum of newVector and threes using an arithmetic operator \n&gt; 2. Print the content of v\n&gt; 3. Do the same for newVector and vector x2 with elements 3,1\n&gt; 4. Join the elements of newVector and threes into 1 vector q\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  v &lt;- newVector + threes\n&gt;    &gt;  v\n&gt;    &gt;  x2 &lt;- c(3,1)\n&gt;    &gt;  newVector + x2 \n&gt;    &gt;   q &lt;- c(newVector,threes)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 13c\n&gt;\n&gt; 1. Add a column called geneDensity to genomeSize containing the number of bp per gene for every organism \n&gt; 2. Round the numbers to the nearest integer\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  dens.fl &lt;- genomeSize$size / genomeSize$geneCount\n&gt;    &gt;  genomeSize$geneDensity &lt;- round(dens.fl)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\nSome functions only work on vectors. For instance sort() will sort data from smallest to largest (arguments allow other ordering) and order() returns the indices of the sorted elements:\n```\nx\n[1] 1 3 11 1 7\nsort(x)\n[1] 1 1 3 7 11\norder(x)\n[1] 1 4 2 5 3\n```\nIn the sorted vector the first element is also the first element of the original vector, the second element of the sorted vector has index 4 in the original vector etc.\nTo sort a data frame use order() inside square brackets:\n```\nmtcars[order(mtcars$mpg),]\n```\nTo sort on two columns (first on mpg, then on cyl): \n```\nmtcars[order(mtcars$mpg,mtcars$wt),]\n```\nTo sort in descending order place a minus sign in front of the variable:\n```\nmtcars[order(mtcars$mpg,-mtcars$wt),]\n```\n\nSelect the **labels** of a vector or table using names(). For tables rownames() and colnames() can access or set the either row or the column labels. Both functions will not work on vectors. \n\nThe length() function retrieves the number of elements of a vector. Used on data frames it doesn&#39;t throw an error but returns the number of columns instead. \n\nThe same is true for match(x,y). It compares x and y and returns a vector with the same length as x containing: \n-  NA for elements of x that are not in y  \n- the index in y for elements in x that are in y\n\nOn data frames it will not do an element-wise comparison but a column-wise comparison: \n```\nmatch(D1,D2) \n```\nwill return a vector with length equal to the number of columns in D1 containing:\n- NA for columns of D1 that are not in D2\n- the index in D2 for columns in D1 that are in D2 (so the complete column has to match, not the individual elements)\n\nImportant is to see the difference between the + operator and sum(). The former works element-wise on two variables, the latter calculates the sum of all elements of one vector.\n\nThere are also functions to be used only on tables, e.g. \n- dim() returns how many rows and columns a table has, nrow() and ncol() will get these values individually\n- t() transposes matrices (exchanges rows and columns), the output is a transposed matrix: the columns are the rows of the original matrix and vice versa\n\nUse merge() to join two data frames. Let?s say D1 has a column A with values. Data frame D2 has the same values stored in column A. Merge the two data frames on the basis of this common column:\n```\nnewD &lt;- merge(D1,D2)\n```\nIf (some of) the values of the common column differ, merge() will ignore these values. Use argument *all.x* to add an extra row for every different value to the resulting data frame. All rows where the values of the two data frames don?t correspond, will be filled up with NA values.\n\nMost functions operate on numbers but there are also functions for manipulating text, e.g. \n```\npaste(x,y,sep=\&quot; \&quot;) \n```\t\nconcatenates two strings x and y (glues them together into one string) separating them by the character defined by *sep*. Arguments *x* and *y* can be strings but they can also be vectors. If they are vectors, they are concatenated element-wise to give a character vector result.\n\nFurthermore there are also functions specific for factors. For instance to select the names of the categories (levels) of a factor use levels() and table() to create a contingency table. \n```\n table(cell_phone_data$own, cell_phone_data$grade)\n```\n\n&lt;figure id=\&quot;figure-2\&quot;&gt;&lt;img src=\&quot;../../images/Rtable_function.png\&quot; alt=\&quot;table_function\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 2:&lt;/span&gt; Example of a contingency table&lt;/figcaption&gt;&lt;/figure&gt;\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 13d\n&gt;\n&gt; You repeat the plant study experiment this time having the following numbers of plants developing lesions: 1, 6, 6, 5, 4\n&gt; 1. Add these data as a third column to the data frame \n&gt; 2. Relabel columns to Day, Infected and Repeat\n&gt; 3. Use paste() to add the word ?day? to the elements of the Day column. Look at the documentation first !\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  Plant_study$repeated &lt;- c(1,6,6,5,4)\n&gt;    &gt;  names(Plant_study) &lt;- c(\&quot;Day\&quot;,\&quot;Infected\&quot;,\&quot;Repeat\&quot;)\n&gt;    &gt;  ?paste\n&gt;    &gt;  Plant_study$Day &lt;- paste(Plant_study$Day,\&quot;day\&quot;,sep=\&quot;\&quot;)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt;  ```\n&gt;    &gt;  paste(Plant_study[,\&quot;Day\&quot;],\&quot;day\&quot;,sep=\&quot;\&quot;)\n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 13e\n&gt;\n&gt; 1. Change the label of the second column of Drug_study to drug\n&gt; 2. How many rows does Drug_study contain?\n&gt; 3. Order the rows according to decreasing activity\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  colnames(Drug_study)[2] &lt;- \&quot;drug\&quot;\n&gt;    &gt;  nrow(Drug_study)\n&gt;    &gt;  Drug_study[order(Drug_study$activity,decreasing=TRUE),]\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What happens when you run this code ?\n&gt;    &gt;  ```\n&gt;    &gt;  colnames(Drug_study$ID) &lt;- \&quot;id\&quot;\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What happens when you run this code ?\n&gt;    &gt;  ```\n&gt;    &gt;  colnames(Drug_study[2]) &lt;- \&quot;blabla\&quot;\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt;  ```\n&gt;    &gt;  Drug_study[order(Drug_study$activity),\&quot;ID\&quot;]\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt;  ```\n&gt;    &gt;  n &lt;- order(Drug_study$activity,decreasing=TRUE)\n&gt;    &gt;  Drug_study[n,]\n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 13f\n&gt;\n&gt; 1. Sort the elements of z from smallest to largest\n&gt; 2. Now use order(z). What&#39;s the difference with the previous exercise?\n&gt; 3. How many elements does z contain?\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  sort(z)\n&gt;    &gt;  order(z)\n&gt;    &gt;  length(z) \n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 13g\n&gt;\n&gt; Add a new row to data frame ab containing values: 3,4,7\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  d &lt;- c(3,4,7)\n&gt;    &gt;  ab &lt;- rbind(ab,d)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 13h\n&gt;\n&gt; 1. How many rows and columns are in the built-in data frame CO2 (data on CO2 uptake by plants)\n&gt; 2. Use levels() to retrieve the names of the Treatment categories\n&gt; 3. Create a contingency table with counts (number of plants) in every category of CO2 that is defined by Type and Treatment\n&gt; 4. Use unique() to count how many plants were studied\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  dim(CO2)\n&gt;    &gt;  levels(CO2$Treatment)\n&gt;    &gt;  table(CO2$Type,CO2$Treatment)\n&gt;    &gt;  length(unique(CO2$Plant))\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n### Functions helpful for working with large data sets\nResearch in biology/medicine often generates very large data sets. When you work with very large data sets, it is often useful to show only a small part of the data set;\n- head() shows the first 6 elements (vector) or rows (table) of a variable \n- tail() prints the last 6 elements or rows\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 14a\n&gt;\n&gt; 1. View the first 6 rows of the mtcars data frame\n&gt; 2. Return TRUE if mtcars contains cars with 6 gears and FALSE if not\n&gt; 3. How many cars with 3 gears are in mtcars?\n&gt; &gt;   &gt; ### {% icon solution %} Solution\n&gt; &gt;   &gt;  ```\n&gt; &gt;   &gt;  head(mtcars)\n&gt; &gt;   &gt;  nrow(subset(mtcars,gear==6))!=0\n&gt; &gt;   &gt;  nrow(subset(mtcars,gear==3))\n&gt; &gt;   &gt;  ```\n&gt; &gt;   {: .solution}\n{: .hands_on}\n\n### Functions for finding indices of specific elements\nThere are functions that help you locate specific values, the which functions:\n```\nwhich.min(x)\nwhich.max(x)\n```\nreturn the location (index) of the minimum, maximum or a specific value of a vector x. So max() will return the highest value in the data, which.max() will return the index of the highest value in the data.\n\nThe argument of which() is a logical expression and which() will return the indices of the elements for which the logical expression is TRUE. \n```\nx &lt;- c(1,5,8,4,6)\nx\n# [1] 1 5 8 4 6\nwhich(x == 5)\n# [1] 2\nwhich(x != 5)\n# [1] 1 3 4 5\n```\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 15a\n&gt;\n&gt; Get the data of the patient with the highest activity in Drug_study\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  Drug_study[which.max(Drug_study$activity),]\n&gt;    &gt;  \n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  n &lt;- which.max(Drug_study$activity)\n&gt;    &gt;  Drug_study[n,]\n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 15b\n&gt;\n&gt; 1. Get the index of the column called cyl in mtcars\n&gt; 2. Create a data frame that contains the car with the lowest mpg for each category of cyl\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  which(names(mtcars)==\&quot;cyl\&quot;)\n&gt;    &gt;  C4m &lt;- mtcars[order(mtcars$cyl,mtcars$mpg),][1,]\n&gt;    &gt;  C6 &lt;- subset(mtcars,cyl==6)\n&gt;    &gt;  C6m &lt;- C6[which.min(C6$mpg),]\n&gt;    &gt;  C8m &lt;- mtcars[order(-mtcars$cyl,mtcars$mpg),][1,]\n&gt;    &gt;  rbind(C4m,C6m,C8m)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n### Checking and converting types of variables\nTo check the data structure of an object you can use str() and the generic class() function:\n```\nclass(c(10,12,30))\n# [1] \&quot;numeric\&quot;\nclass(c(\&quot;alana\&quot;,\&quot;britt\&quot;,\&quot;chris\&quot;))\n# [1] \&quot;character\&quot;\nclass(c(TRUE,TRUE,FALSE))\n# [1] \&quot;logical\&quot;\n```\n\nYou can also use the specific is. functions e.g. is.numeric(), is.character(), is.Date(), is.vector(), is.matrix(), is.data.frame() etc.\n\nThe is.na(x) function returns TRUE when an element of x is missing:\n```\nx &lt;- c(1,2,3,NA)\nis.na(x)\n# [1] FALSE FALSE FALSE TRUE\n```\nTo recode values to missing values you don?t need is.na(). Select the rows that contain the value you want to recode, e.g. 99, and change the value using an assignment:\n```\ndata$v1[data$v1==99] &lt;- NA\n```\nTo exclude missing values you can use is.na() but there are alternatives. The problem with missing values is that when you apply arithmetic functions on variables that contain missing values they will return missing values and you will have no result. To circumvent this problem many functions have the *na.rm* argument. If you set *na.rm=TRUE* missing values are deleted before calculations are done.\n```\nmean(x) \t\t\t\n# NA\nmean(x,na.rm=TRUE) \t\n# 2\n```\nThe function na.omit() allows to create a new vector without missing values. If you apply this function on a data frame it will remove complete rows that contain one or more NA-values.\n```\nnewdata &lt;- na.omit(x)\n```\nYou can convert the data type of an object by using the as. functions e.g. as.numeric(), as.character(), as.Date(), as.vector(), as.matrix(),\nas.data.frame() etc.\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Checking and converting data types** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 16a\n&gt;\n&gt; We created a vector containing the days of the week and loaded this into a data frame called Plant_study. If we want to replace the days of the week by real dates, how should we proceed?\n&gt; \n&gt; To create a Date object in R:\n&gt; - define the date as a string in the following format: 1970-01-01\n&gt; - transform the string into a date by using as.Date()\n&gt; 1. Replace the days of the week by the dates of this week\n&gt; 2. What type of data is Plant_study ?\n&gt; 3. Convert Plant_study into a matrix called PS\n&gt; 4. Did the conversion work? Look at the matrix to see if there is a problem. \n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  Plant_study$Days &lt;- as.Date(c(\&quot;2019-01-09\&quot;,\&quot;2019-01-10\&quot;,\&quot;2019-01-11\&quot;,\&quot;2019-01-12\&quot;,\&quot;2019-01-13\&quot;))\n&gt;    &gt;  class(Plant_study)\n&gt;    &gt;  PS &lt;- as.matrix(Plant_study)\n&gt;    &gt;  PS\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 16b\n&gt;\n&gt; 1. Check the data type of the second column of Drug_study. Retrieve the column using a comma.\n&gt; 2. Convert the second column into a vector. \n&gt; 3. What is different now? Look at the vector.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  class(Drug_study[,2])\n&gt;    &gt;  v &lt;- as.vector(Drug_study[,2])\n&gt;    &gt;  v\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 16c\n&gt;\n&gt; Instead of deleting missing values with na.omit() you can select the non-missing values.\n&gt; 1. Create a vector with a missing value \n&gt; 2. Multiply all elements with 2. What happens?\n&gt; 3. Check if the 2nd element is missing\n&gt; 4. Delete the missing value using is.na() and the strategy above\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  x &lt;- c(1,2,3,NA)\n&gt;    &gt;  x*2\n&gt;    &gt;  is.na(x[2])\n&gt;    &gt;  x[!is.na(x)]\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 16d\n&gt;\n&gt; 1. Check if z is a vector or a data frame \n&gt; 2. Check if z contains numbers or characters\n&gt; 3. Convert z into a matrix\n&gt; 4. Convert the elements of z into characters\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  is.vector(z)\n&gt;    &gt;  is.data.frame(z) \n&gt;    &gt;  is.character(z)\n&gt;    &gt;  is.numeric(z)\n&gt;    &gt;  as.matrix(z) \n&gt;    &gt;  as.character(z)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 16e\n&gt;\n&gt; 1. Create a vector called words containing Hello, Hi \n&gt; 2. Convert the words into numbers. What happens?\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  words &lt;- c(\&quot;Hello\&quot;,\&quot;Hi\&quot;)\n&gt;    &gt;  as.numeric(words) \n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\nR is smart enough to catch you if you try to do an illogical conversion, such as convert characters to numbers. It does the conversion but the data is converted to NA values.\n&quot;,&quot;# Data structures in R\n{:.no_toc}\n\nThe power of R lies not in its ability to work with simple numbers but in its ability to work with large datasets.  R has a wide variety of data structures including scalars, vectors, matrices, data frames, and lists.\n\n### Matrices\nA matrix is a table, the columns are vectors of equal length. \nAll columns in a matrix must contain the same type of data. The top row, called the header, contains column labels. Rows can also have labels. Data values are called elements. Indices are often used as column and row labels.\n\n### Creating a matrix\nTo create a matrix M use the matrix() function\n```\nM &lt;- matrix(data,nrow=r,ncol=c,byrow=FALSE))\n```\n\nIt takes a long list of arguments:\n- *data* usually is a vector of elements to will fill the matrix\n- *nrow* and *ncol*: dimensions (number of rows and columns). Only one dimension argument is needed. If there are 20 elements in the *data* vector and *ncol=4* then R will automatically calculate that there should be 5 rows. \n- *byrow*: how the matrix is filled, *byrow=TRUE* fills the matrix row by row whereas *byrow=FALSE* fills the matrix column by column\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Data creation: matrices** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 8a\n&gt;\n&gt; 1. Create a 2x2 matrix named mat containing numbers 2,3,1,5\n&gt; 2. Print the matrix\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  mat&lt;-matrix(c(2,3,1,5),nrow=2,ncol=2)\n&gt;    &gt;  mat\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 8b\n&gt;\n&gt; 1. Create a 2x3 matrix named onemat consisting of all ones\n&gt; 2. Print the matrix\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  onemat&lt;-matrix(1,nrow=2,ncol=3)\n&gt;    &gt;  onemat\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 8c\n&gt;\n&gt; 1. Create a 3x3 matrix containing numbers 1,2,3,4,5,6,7 \n&gt; 2. Retrieve all elements that are larger than 3\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  m &lt;- matrix(c(1,2,3,4,5,6,7),ncol=3) \n&gt;    &gt;  m[m &gt; 3]\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n### Data frames\nJust like a matrix, a data frame is a table where each column is a vector. But a data frame is more general than a matrix: they are used when columns contain different data types, while matrices are used when all data is of the same type. \n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; R has a number of built-in data frames like mtcars. \n{: .comment}\n\n### Creating a data frame\nTo create a data frame D use the function data.frame() with the vectors we want to use as columns:\n```\nD &lt;- data.frame(column1,column2,column3)\n```\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; The columns of a data frame are all of equal length\n{: .comment}\n\nYou can provide names (labels) for the columns:\n```\nD &lt;- data.frame(label1=column1,label2=column2,label3=column3)\n```\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; As an argument of data.frame() you use label=vector_to_add: the equals (and not the assignment) operator is used because you are naming columns not creating new variables. \nIf you don&#39;t define labels (as in the first example), the names of the vector names are used as column names. \n{: .comment}\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Data creation: data frames** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 9a\n&gt;\n&gt; Create a data frame called Plant_study containing days and Plants_with_lesions. Name the columns Days and Plants.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  Plant_study &lt;- data.frame(Days=days,Plants=Plants_with_lesions)\n&gt;    &gt;  Plant_study\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 9b\n&gt;\n&gt; Create a data frame called Drug_study consisting of three columns: ID, treatment and smoking\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  Drug_study &lt;- data.frame(ID,treatment,smoking)\n&gt;    &gt;  Drug_study\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 9c\n&gt;\n&gt; Create a data frame genomeSize containing genome sizes and print it. \n&gt; - The first column is called organism and contains Human,Mouse,Fruit Fly, Roundworm,Yeast \n&gt; - The second column size contains 3000000000,3000000000,135600000,97000000,12100000\n&gt; - The third column geneCount contains 30000,30000,13061,19099,6034\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  organism &lt;- c(\&quot;Human\&quot;,\&quot;Mouse\&quot;,\&quot;Fruit Fly\&quot;, \&quot;Roundworm\&quot;,\&quot;Yeast\&quot;)\n&gt;    &gt;  size &lt;- c(3000000000,3000000000,135600000,97000000,12100000)\n&gt;    &gt;  geneCount &lt;- c(30000,30000,13061,19099,6034) \n&gt;    &gt;  genomeSize &lt;- data.frame(organism,size,geneCount)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 9d\n&gt;\n&gt; Create a data frame ab and print it. \n&gt; - The first column is called a and contains 1,3,2,1\n&gt; - The second column is called b and contains 2,3,4,1\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  a &lt;- c(1,3,2,1)\n&gt;    &gt;  b &lt;- c(2,3,4,1)\n&gt;    &gt;  ab &lt;- data.frame(a,b)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n##### Referring to the elements of a data frame\nReferring to elements of a data frame can be done in the same way as for matrices, using row and column **indices** in between square brackets. The only difference is that in data frames you can also use the **labels** of the columns to retrieve them.\n\nTo retrieve the element on the second row, first column:\n```\nD[2,1]\n```\n\nTo select all values from one dimension leave the index blank, e.g. all elements of the first column:\n```\nD[,1]\n```\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; If you want to retrieve **all** the rows you don?t write any index before the comma inside the square brackets.\n{: .comment}\n\nYou can also use column labels for retrieving elements. Column names have to be written between quotes:\n```\nD[,\&quot;label1\&quot;]\n```\n\nYou can also use the range function to select elements:\n```\nD[2:4,1]\n```\n\nThe **$** symbol can be used to retrieve a column based on its label e.g. to retrieve column label1 from D:\n```\nD$label1\n```\n\n&gt; ### {% icon comment %} Comment\n&gt; With $ you do not have to put quotes around the column name\n{: .comment}\n\nSince the result of $ is a vector, you can address a specific element of a column using its index:\n```\nD$label1[2]\n```\nretrieves the second element of the column called label1\n\nSpecific for data frames is the **subset()** function that can be used to select columns that satisfy a logical operation:\n```\nsubset(D,select=columns to extract)\nsubset(D,logical expression,columns to extract)\n```\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Data extraction: data frames** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 10a\n&gt;\n&gt; 1. Retrieve the data for the Volvo 142E from mtcars \n&gt; 2. Retrieve the gas usage (mpg column) for the Volvo 142E \n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  mtcars[\&quot;Volvo 142E\&quot;,]\n&gt;    &gt;  mtcars[\&quot;Volvo 142E\&quot;,\&quot;mpg\&quot;]\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  mtcars[\&quot;Volvo 142E\&quot;]\n&gt;    &gt;  \n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ##### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  mtcars[Volvo 142E,]\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 10b\n&gt;\n&gt; 1. Retrieve the IDs of the smoking patients in Drug_study\n&gt; 2. Retrieve ID and treatment of the smoking patients \n&gt; 3. Retrieve the smoking behavior of all the patients\n&gt; 4. Change the treatment of the fourth patient to A\n&gt; 5. Add a column called activity with values: 4, NA, 12.1, 2.5\n&gt; 6. Use subset() to retrieve the full ID and treatment columns\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  subset(Drug_study,smoking==TRUE,ID)\n&gt;    &gt;  subset(Drug_study,smoking==TRUE,c(ID,treament))\n&gt;    &gt;  Drug_study$smoking\n&gt;    &gt;  Drug_study$treatment[4] &lt;- \&quot;A\&quot;\n&gt;    &gt;  Drug_study$activity &lt;- c(4,NA,12.1,2.5)\n&gt;    &gt;  subset(Drug_study,select=c(ID,treatment))\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  Drug_study[Drug_study$smoking==TRUE,\&quot;ID\&quot;]\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  Drug_study[Drug_study$smoking==TRUE,ID]\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  Drug_study[,\&quot;smoking\&quot;]\n&gt;    &gt;  \n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ##### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt;  ```\n&gt;    &gt;  Drug_study[4,\&quot;treatment\&quot;] &lt;- \&quot;B\&quot;\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  Drug_study[\&quot;activity\&quot;] &lt;- c(4,NA,12.1,2.5)\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  subset(Drug_study,c(ID,treatment))\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  subset(Drug_study,,c(ID,treatment))\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; The order of the arguments is important except when you specify their names. \n{: .comment}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 10c\n&gt;\n&gt; On which days did we observe more than 2 infected plants in the plant experiment? Answer this question with and without using the subset() function.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  &gt; Plant_study[Plant_study$Plants &gt; 2,\&quot;Days\&quot;]\n&gt;    &gt;  &gt; subset(Plant_study,Plants &gt; 2,Days)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  Plant_study[Plant_study[\&quot;Plants\&quot;] &gt; 2,\&quot;Days\&quot;]\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 10d\n&gt;\n&gt; 1. Create vector q by extracting the a column of data frame ab (exercise 9) with and without subset().\n&gt; 2. Retrieve the second element of column a of data frame ab\n&gt; 3. Add column c with elements 2,1,4,7 to data frame ab\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  q &lt;- ab$a\n&gt;    &gt;  subset(q,select=a)\n&gt;    &gt;  ab$a[2]\n&gt;    &gt;  ab$c &lt;- c(2,1,4,7)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n##### Removing elements from a data frame\nTo remove elements from a data frame use negative indices just as in a vector e.g. to remove the second row from data frame D use:\n```\nD &lt;- D[-2,]\n```\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; The minus sign only works with numbers not with column labels. \n{: .comment}\n\nTo remove columns based on labels assign them to NULL:\n```\nD$genome &lt;- NULL\n```\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; Setting a column to NULL is done via an assignment so the removal is permanent. \n{: .comment}\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; Insteading of removing elements you can also define the elements you want to keep.\n{: .comment}\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Data removal: data frames** section\n{: .hands_on}\n\n##### Reordering columns in a data frame\nReordering columns is a special case of retrieving columns, e.g. for a data frame that has 4 columns you can switch the position of the second and third column as follows:\n```\nD2 &lt;- D[ ,c(1,3,2,4)]\n```\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; The first comma means keep all the rows, and the 1,3,2,4 refer to column indices. \n&gt; You can use indices or labels to refer to the columns. \n{: .comment}\n\nYou can also use subset():\n```\nD2 &lt;- subset(D,select=c(1,3,2,4))\n```\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Column reordering: data frames** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 11a\n&gt;\n&gt; Switch the position of the second and the third column of Drug_study\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  Drug_study[,c(1,3,2)]\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  subset(Drug_study,select=c(1,3,2))\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n### Lists\nA list is an ordered collection of objects (of any data type: string, numbers, vectors, matrices, data frames). Lists can even contain other lists as objects! A list allows you to gather a variety of objects under one name. It is not mandatory but very useful to give each object in a list a label.\n\n##### Creating a list\nTo create a list L use the list() function:\n```\nL &lt;- list(label1=object1,label2=object2,label3=object3)\n```\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 12a\n&gt;\n&gt; 1. Create a list called myList with the following objects: 5, 6, the word seven, the matrix mat.\n&gt; 2. Print the list.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  myList&lt;-list(5,6,\&quot;seven\&quot;,mat)\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  subset(Drug_study,select=c(1,3,2))\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n##### Referring to the elements of a list\nReferring to the elements of a list can be done in exactly the same way as for data frames, using row and column **indices or labels** in between square brackets. However, since a list can contain other lists or data frames you have to use **double square brackets** [[ ]] to retrieve elements. \n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; The $ operator also works to access the objects of a list.\n{: .comment}\n&quot;,&quot;### Exercise 1: simple gene expression study\n\nIn my qPCR experiment I want to study the expression of 12 genes of interest in 8 samples of interest. I want to use 2 PCR replicates for each reaction.\n\n&gt; How many 96 well plates do I need for this experiment ?\n&gt; &gt; I have 12 genes in 8 samples which gives a total of 96 reactions (one plate). I want to perform each reaction twice (2 PCR replicates) so I need two plates. However, I need to include reference genes in my experiment, preferably more than one. I can put these reference genes on a separate plate, I do not have to include them on each plate.\nIdeally, you need to include 3 reference genes so having 8 samples and 2 replicates this gives an additional 48 reactions. Thus, I need three 96 well plates to perform this experiment.\n\n| Do I need to include IRCs (inter-run calibrators) ?                      |\n| :--------------------------------------------------- |\n| No, I can easily fit all samples of the same gene on the same plate so I don&#39;t need to include IRCs. |\n\n### Exercise 2: a large study\n\nIn my qPCR experiment I want to study the pattern of expression of 96 genes (genes of interest and reference genes) in 96 samples of interest, divided into a few groups. I want to use 2 PCR replicates for each reaction.\n\n| Do I need to include IRCs (inter-run calibrators) ?                    |\n| :------------------------------------------------------- |\n| No, I can fit all samples of the same gene on the same plate so I don&#39;t need to include IRCs. |\n\nI want to include PCR replicates.\n\n| Do I need to include IRCs when I work on a 96 well plate ?                                                                                    |\n| :-------------------------------------------------------------------------------------------------------------------------------------------- |\n| Yes, I have 192 reactions per gene so I cannot place them on the same plate. Remember that replicates have to be located on the same plate \\! |\n\n| Do I need to include IRCs when I work on a 384 well plate ?                        |\n| :--------------------------------------------------------------------------------- |\n| No, I have 192 reactions per gene so I can even place two genes on the same plate. |\n\nI want to include no template controls but I don&#39;t want to increase the\nnumber of plates.\n\n| What is the most elegant strategy to make room for including negative controls ?      |                                                      \n| :------------------------------------------------------------------------------------ |\n| This kind of study screen for expression patterns and requires statistical analysis. Since you have many samples divided over a few groups it means you have many biological replicates so you could easily do without the PCR replicates. By doing so you preserve the biological variability which is often far greater than the technical variation. |\n\n### Exercise 3: how to fill plates ?\n\nIn my qPCR experiment I want to study the pattern of expression of 5 genes (genes of interest and reference genes) in 38 samples (samples of interest and control samples). I want to use 2 PCR replicates for each reaction.\n\n| What is the minimum number of 96 well plates I need for this experiment ? |\n| :------------------------------ |\n| 5 genes * 38 samples * 2 replicates = 380 reactions.\nI need a minimum of 4 plates for this experiment.\n\n| If I use the minimum number of 96 well plates do I need to include IRCs ?                                                      |\n| :----------------------------------------------------------------------------------------------------------------------------- |\n| Yes, 5 genes spread over 4 plates with 72 reactions per gene means that at least one gene will be spread over multiple plates. |\n\n| What can I do to avoid inter-run variability ?                                                                                                                                                                                         |\n| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| I can use 5 plates and fill them with one gene each. They will not be completely filled (72 reactions) but at least I do not have to use IRCs (which are additional reactions that also cost money) and I have no inter-run variation. |\n\nSuppose there&#39;s only one 96-well plate left in your lab. You have 10 samples (samples of interest + control samples) and you want to make the most of what you have.\n\n| How many genes of interest would you measure ? |\n| :------------------------------ |\n| Since you want to make most of what you have, let&#39;s assume you are omitting PCR replicates.\nTheoretically, you could fit 9 genes on your 96-well plate. However, to avoid pipetting mistakes I would measure only 8 genes so I can work with one row / gene. This is very handy for multichannel pipets.\n\n### Exercise 4: a growing study\n\nIn my qPCR experiment I want to study the pattern of expression of 24 genes (genes of interest and reference genes) in 48 samples (samples of interest and control samples). I want to use 2 PCR replicates for each reaction.\n\n| How many genes can I analyze on one 384 well plate ? |\n| :------------------------------ |\n| 48 samples * 2 replicates = 96 reactions per gene.\nI can analyze 4 genes on each 384 well plate.\n\nEach week I receive 2 additional samples to analyze.\n\n| Do I analyze them immediately after I get them ? |\n| :------------------------------ |\n| No. Since the samples are placed on different plates as in the previous experiment, you have to use IRCs. You typically need 3 IRCs and a no template control sample. It means that if you want to analyze these 2 samples you have to include 4 additional samples for each gene. This is a lot of overhead for just 2 samples !\nTry to avoid this: it&#39;s better to wait a few weeks until you have 6 or 8 or even more samples.\n\n### Exercise 5: a diagnostic copy number screen\n\nIn diagnostic screens all samples are important: you cannot leave out samples and all measurements need to be of the highest quality possible. In my qPCR experiment I want to study copy number variation of 16 genes\n(genes of interest and reference genes) and 2 calibrator samples (samples with known copy number). Since we need high quality data we will use 4 technical replicates.\n\n| Are we going to use sample maximization ?                                   |                   \n| :------------------------------------------------------------------------- |\n| No. In contrast to gene expression studies, where we want to compare expression levels of a gene between different groups of samples, copy number analyses do compare genes. It means that in this case the sample maximization approach (placing all samples of the same gene on the same plate) is not valid. Instead we use a gene maximization approach here (placing same sample for different genes on the same plate). |\n\n| How many samples can I fit on a 384 well plate ? |\n| :------------------------------ |\n| We have 16 (genes) * 4 (replicates) = 64 reactions per sample.\nThis means that we can fit 6 samples on a 384 well plate: 4 unknowns and 2 calibrators.\n\n### Exercise 6: fix experiments with bad or missing data\n\nIn my qPCR experiment I want to study gene expression of 6 genes (3 genes of interest and 3 reference genes) in 20 samples (samples of interest and control samples). I want to use 2 technical replicates. One of my genes of interest failed completely and I want to repeat the measurements for this gene in a new run.\n\n| Do I need to include IRCs ?                                                                                |\n| :--------------------------------------------------------------------------------------------------------- |\n| No. We can put the 20 samples of the gene that failed on a single plate so we do not have to include IRCs. |\n\n| Do I need to include reference genes ?                                                                 |\n| :----------------------------------------------------------------------------------------------------- |\n| No. We just repeat all samples for the gene that failed and replace the old data with the new results. |\n\nOne of the reference genes failed completely.\n\n| What should I do ?                                                                                                                                                                                                                                                                                     |\n| :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Depending on the quality of the two remaining reference genes, you should either do nothing or do the same as in the previous example where one of your genes of interest failed. If the two remaining reference genes are stable you can do the normalization with the two remaining reference genes. |\n\nThree samples failed completely.\n\n| What&#39;s the first thing I need to do ?                                                                                                                             |\n| :---------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Since they failed completely, they are probably of low quality. Therefore, you have to prepare the samples again, check their quality and then use them for qPCR. |\n\n| Do I need to include IRCs ?                                                                                             |\n| :---------------------------------------------------------------------------------------------------------------------- |\n| Yes. If you want to compare these samples with the samples that didn&#39;t fail, you have to perform inter-run calibration. |\n\nThree samples failed for one of the genes of interest\n\n| What is the first question I need to ask ? |\n| :----------------------------------------- |\n| Is the gene expressed in these samples ?   |\n\n| Is it possible the RNA of these three samples was of low quality ?        |\n| :------------------------------------------------------------------------ |\n| Not likely, the measurements for the other genes in these samples are ok. |\n\nThree samples failed for one of the reference genes\n\n| Can I use the measurements of that reference gene in the non-failing samples for normalization ?                                         |\n| :--------------------------------------------------------------------------------------------------------------------------------------- |\n| No, qbasePLUS requires that you use the same reference genes for all samples so you have to discard all samples for that reference gene. |\n\n### Exercise 7: dilution series for calculating amplification efficiencies\n\nIn my qPCR experiment I want to study 8 new genes for which I had to design new primer pairs in 12 samples (samples of interest and control samples). I want to use 2 technical replicates and 96 well plates.\n\n| What is the first thing I need to do ?                                                        |\n| :-------------------------------------------------------------------------------------------- |\n| Perform a pilot experiment to determine the amplification efficiencies of these primer pairs. |\n\nFor this I need a dilution series of representative cDNA template.\n\n| How many dilutions would you include ?                                           |\n| :------------------------------------------------------------------------------- |\n| A dilution series with 6 dilutions for 8 genes nicely fits into a 96 well plate. |\n\nA few weeks after my initial qPCR experiment I want to test these 8 genes in a new set of samples.\n\n| Do I have to repeat the pilot experiment ?      |\n| :---------------------------------------------- |\n| No, dilution series do not need to be repeated. |&quot;,&quot;# Installation\n## Windows\n&gt; Requirements to install E-Notebook 2014: \n&gt; 1. Microsoft Windows\n&gt; 2. MS Office, Adobe Reader (or similar)\n&gt; 3. ChemBioDraw (optional - see STEP 2)\n&gt; 4. Valid VIB login credentials. Check your login and password on [https://storefront.vib.be/](https://storefront.vib.be/).\n\n**STEP 1: E-Notebook 2014**\n\n1. Browse to [https://eln.vib.be/clickonce/](https://eln.vib.be/clickonce/)\n2. Click Install and open the file\n3. After the installation, the software is automatically launched and the login window appears\n4. Log in with your VIB credentials (see requirements)\n5. Close E-Notebook after successful launch: File - Exit or &#39;X&#39; in the right upper corner\n6. Generate a shortcut on the desktop (right click - Send to - Desktop): All Programs - PerkinElmer - E-Notebook 2014 Client\n7. Install ChemBioDraw (STEP 2)\n\n**STEP 2: ChemBioDraw**\nNote: In case you only reinstall the ELN client, you don&#39;t have to reinstall the ChemBioDraw component\n1. Download the ChemBioDraw installation file from the same website as E-Notebook 2014: [https://eln.vib.be/clickonce](https://eln.vib.be/clickonce)\n2. Start the installation\n3. Install ChemBioDraw ActiveX component in suggested destination\n4. Follow the installation wizard instructions\n5. Click on Install and subsequently on \&quot;Finish\&quot;\n\n&gt; Why use ELN throught Citrix on Windows? \nSome older Windows versions cause problems with the E-Notebook 2014 Client installation.\n\n**STEP 1: Citrix Workspace app**\n1. Browse to [http://www.citrix.com www.citrix.com] \n2. Click on Download\n3. Select Citrix Workspace app from the list of possible downloads\n4. Download and install Citrix Workspace app\n\n**STEP 2: Launch ELN online**\n1. Browse to [https://storefront.vib.be](https://storefront.vib.be)\n2. Login with your VIB credentials\n3. Launch the ELN application by clicking on the icon\n4. If your browser asks to download and open an .ica file, please agree\n5. Citrix Workspace will open en launch the application\n\n## MacOS, Linux, mobile devices\n**STEP 1: Citrix Workspace app**\n1. Browse to [https://www.citrix.com www.citrix.com] \n2. Click on Download\n3. Select Citrix Workspace app from the list of possible downloads\n4. Download and install Citrix Workspace app\n5. After the installation on Linux execute the following command:\n```\nsudo cp -a /usr/share/ca-certificates/mozilla/DigiCert_Assured_ID_ Root_ CA.crt /opt/Citrix/ICAClient/keystore/cacerts/\n```\n\n**STEP 2: Launch ELN online**\n1. Browse to [https://storefront.vib.be](https://storefront.vib.be)\n2. Login with your VIB credentials\n3. Launch the ELN application by clicking on the icon\n4. If your browser asks to download and open an .ica file, please agree\n5. Citrix Workspace will open en launch the application\n\n# Support\n- Call us at +32 (0)9 248 16 15\n- Mail us at eln@vib.be&quot;,&quot;# Login\nWhen launching the application (Windows: double-click the **E-notebook 2014 client** icon  Citrix: click on the ELN 2014 icon and open the .ica file, Citrix Workspace will launch the application), you will see the following login window:\n\nIn order to login on ELN, you need a **valid VIB account**. The VIB username usually has a format like: *firstname lastname*. More information on [https://help.vib.be](https://help.vib.be) or mail eln@vib.be.  \n\nWhen clicking on **Connect** the application will retrieve your data. The **Work Offline** option is only available with the client installation and will allow you to make adjustments to the data in your Offline folder.\n\n&gt; Note: when launching the application for the first time, a download of all collections will start, this usually takes 1 or 2 minutes.\n\n# Layout\nThe layout is resembling to Microsoft Office. It has 3 main parts; the ribbon with options on top, the navigation and history area on the left and the working area on the right.\n\nThe default starting point is the Home location, this gives an overview of all data in the navigation area on the left and any modified experiments since one month on the right.\nIn the Audit Trail (bottom left) you can find the history of the object selected above. This history allow you to access previous versions of an experiment and retrieve a file in order to bring it back to the present. Every version has a timestamp and operator (= user that pressed the save button). Previous versions of an experiment can**t be modified, only the last version is adjustable.\nNavigating to your colleagues or Home can be done with the orange icons in the upper left corner. Next to the navigation buttons you find the Save button. When saving you can add annotations as well.\n# Ribbon\nThe Ribbon is where you can find the options corresponding with your selection (navigation area or section). By default, there are three tabs: Home, View and Data. Sections have specific tabs in the ribbon, e.g. Document, Image, Text, Table, Property List, etc. An example can be found below (Text):\n\n# Project, Notebook, Experiment\nThere are 3 basic levels to organize your data: Project, Notebook and Experiment (see icons below). You can see them as folders with a certain hierarchy. Only an experiment contains files. To add one of the levels click on the icon in the **Home** tab in the ribbon. \n\n# Sections\nAn experiment consists of sections, every section is a file or page. To add a section, select the icon in the **Home** tab in the ribbon. Some sections are hidden behind the **Other** button.\nYou can add sections automatically by drag and dropping them into your experiment. E-Notebook will recognize Word, Excel and PowerPoint files, PDF documents and images. GraphPad Prism files are not native to E-Notebook and will result in an Ancillary data section, this will happen with any other file type that is not native to the program.\n## General Page\nCreating a new experiment will give you a blank experiment with only one section, by default this is the General page. This is an example of a General Page:\n\nEvery lab group has a slightly different version of this General page. The universal parts of this section are the **General Information** and the **Reference to experiment** field. In the first field you have the option to enter general properties of your experiment such as start date, project, etc. Adding extra properties is available in the **Property List** tab in the ribbon.\n\nAdding a reference to your experiment can be very useful to link similar experiment to each other or make a series of experiments. This refence can be any experiment within your group. To add a reference, click on the option in the **Home** tab in the ribbon.\n\nAs last there are 3 or 4 text boxes to add keywords, aim of experiment, results, specifications or a conclusion.\n## Microsoft Office sections\nThree MS Office applications are supported in the E-Notebook software: Word, Excel and PowerPoint. All other MS Office files can be uploaded using the Ancillary Data section.\n\nFor the supported application you can add files using the corresponding section. This will initially display a (print) preview of the file, double-clicking the preview will launch the MS Office application to make adjustments. All other options are displayed in the ribbon:\n\n## Images\nUsing the Image section in E-Notebook will allow you to import one (1) image file. All common image extensions are supported, camera brand specific files (e.g. RAW or DNG) can be uploaded using a non-file-specific section. Next to the image file itself you can add a title and notes.\n\n## PDF files and Captured Image\nUsing the PDF section in E-Notebook will allow you to import 1 PDF file. Next to the PDF file itself you can add a description, date and a document name.\n\n## Ancillary Data (a.k.a. Binder)\nThis non-file-specific section will save 1 file. In order to open the file , you must double-clicking on it, this will launch the according application outside ELN. Closing the external application again (e.g. after making adjustments) will result in this window:\n\nClick **Continue** to save your changes and re-upload the new file in ELN or click **Cancel** to ignore the changes.\n## Supplementary Data Management (SDM)\nFiles imported in this section will be saved on an internal network drive linked to ELN. This means that files in SDM won**t be accessible outside of your research center or university network. Files in the SDM section are not limited to the file size limit of 30 MB. \nNext to the default list of sections, there are some lab-specific sections for PCR or Western Blot. To add one of these lab-specific sections, click on the **Other** icon and select your section.\n\n# Sharing data and linking experiments\n## Access rights for others\nTo grant a colleague access to your data, you simple select the object and click on the View tab in the ribbon. In the Properties field you click on Security. A new window will appear (left picture). The inherited privileges are default settings, youre not able to modify this. The assigned privileges on the other hand can be modified by clicking Grant.\n\nBy filtering on user group or user you can select the group/person (right picture). The type of privilege can be: read, read and write, full control. You can define this in the next window.\n\nRemoving the privilege can de done by selecting the person or group and click on Remove. For both granting or removing access privileges there is no notification system, you have to tell them yourself.\n## Experiment shortcuts\nWhen a colleague granted you access to a project/notebook/experiment you can place a link to this object in your own ELN. This makes navigating to this object easier and allows you to group all your collaborations within your own ELN hierarchy. To create such a shortcut, follow these steps:\n1. Select the object of interest\n2. Right click  Copy\n3. Navigate to your own ELN\n4. Right-click on the location you want the link to appear\n5. Select Paste Reference\n\n&gt; Note: shortcuts can be removed, the original data however is not deleted. \n## Templates\nTemplates can be created by every user and can be shared with your colleagues. To create a template, follow this procedure:\n\n1.\tnavigate to User Configuration  Templates\n2.\tcreate new experiment\n3.\tbuild your new default experiment/template by adding information/sections\n4.\tsave your template\n\nNext time you want to create a new experiment, you will have the option to create a blank or template experiment. \n## Search\nThe collection search can be used for users, projects, notebooks and experiments. No content can be found with the search box in the upper right corner.\nThe Advanced Search option can find experiment content. You can find it in Quick Links above the navigation pane.\n\n\n&quot;,&quot;You need to do inter-run calibration if you want to compare samples from different runs e.g.:\n\n  - when it is not possible to get all samples for the same gene on the same plate\n  - when you do additional runs weeks or months after your initial experiment\n\nOf course there is a lot of variability between runs on a qPCR instrument:\n\n  - thermal block is not always heating uniformously\n  - quality of the lamp, the filters and the detector decreases over time\n  - data analysis settings on the qPCR instrument (baseline correction and threshold) can be slightly different\n  - efficiency of reagents (polymerase, fluorophores) is variable\n  - optical properties of the plastic plates vary\n\nFortunately, inter-run calibration allows you to eliminate most of this variability.\n\nIn this experiment we will analyze the data from the gene expression experiment (see Analyzing gene expression data in qbase+) together with data from 2 runs (Run4 and Run5) that were done weeks after the initial gene expression experiment.\n\nBecause the data comes from two different experiments spread over time, we have included three inter-run calibrators on the plates: Sample01, Sample02 and Sample03.\n\nThe principle of the IRCs is very similar to that of the reference genes:\nIn theory, the IRCs should have the same NRQ in each run. In practice, the difference in NRQ between two runs is a measure of the inter-run variation and can be used to adjust the NRQs to remove the inter-run variation.\n\n#### Creating a new Experiment\n| Import [Run1](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run1.xls), [Run2](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run2.xls), [Run3(all three in CFX format)](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run3.xls), [Run4](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run4.xls) and [Run5 (the latter two are in qBase format)](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run5.xls).\n| :----------------------------- |\n| Since the data is in files of two different format, you have to do a separate import for each format. So first import Run1, Run2 and Run3, then import Run4 and Run5. You can find the details on how to import CFX files in [](Loading_data_into_qbase+\&quot; title=\&quot;wikilink)Loading data into qbase+.\nThe details of importing qBase files are in [](Analyzing_data_from_a_geNorm_pilot_experiment_in_qbase+\&quot; title=\&quot;wikilink)Analyzing data from a geNorm pilot experiment in qbase+\n\n#### Analyzing the data\n\n| Use assay specific amplification efficiencies.\n| :----------------------------- |\n| You can find the details on how to convert the targets in the **Taking into account amplification efficiencies** section of Analyzing gene expression data in qbase+\n\nIn Analyzing gene expression data in qbase+ we have already checked the stability of the reference genes (see **Normalization** section). We determined that Flexible did not show stable expression.\n\n| Convert Stable and Nonregulated to Reference targets.\n| :----------------------------- |\n| You can find the details on how to convert the targets in the **Normalization** section of Analyzing gene expression data in qbase+\n| Appoint Sample01, Sample02 and Sample03 as IRCs.\n| :----------------------------- |\n| Leave the Analysis wizard by clicking the **Close wizard** button in the top menu.\n\n - Expand **Intermediate results** (red) in the **Project Explorer**\n - Double click **Interrun calibration** (green)\n\nThis opens the **Interrun calibration window**:\n\n - Click the **New** button (blue) to create a IRC\n - Once the IRC is created you have to appoint samples to it: select **Sample01** in the list of **Other samples**\n - Click the **Add Sample** button (purple)\n - Remember that you cannot give IRCs the same name in different runs: the software would think that they are technical replicates spread over different plates (which is not allowed). Therefore, in Run4 and Run5 we have given Sample01 another name: Sample01_2. Select **Sample01_2** in the list of **Other samples**\n - Click the **Add Sample** button (purple)\n\nYou have appointed the first IRC (grey), now do the same for the other two IRCs.\n\nRemember that for each target the variability of the normalized\nexpression levels of the IRCs between different runs will be used to\nadjust the other normalized expression levels of that target gene. The\nadjustment is done by amplifying the normalized expression levels with a\ncalibration factor that is calculated based on the normalized expression\nlevels of the IRCs.\nSince variability between runs is the same for each IRC, you expect that\nall IRCs measure the variability between the runs to the same extent,\nhence leading to similar calibration factors.\n\n| Do these IRCs generate similar calibration factors ?\n| :----------------------------- |\n| Open the **Calibration Factors** tab (red) of the **Interrun calibration window** and look at the result for Duvel:\n\nYou see that IRC2 returns a substantially different calibration factor in Run5 (green) so the validity of this IRC should be interpreted with care.\nFor Leffe the IRCs also gives inconsistent results in Run5. Switch to the results for Leffe by selecting **Leffe** in the **Targets** list (blue)\n| Do you still see the same expression pattern for Palm as you did in the first three runs ?\n| :----------------------------- |\n| Open the target bar chart for Palm.\n\nYou see that the pattern Palm showed in the first three runs (sample01 to sample16): high expression in the odd and low expression in the even samples is reversed in the samples from Run4 and Run5 (sample17 to sample25). In the latter runs you see high expression in the even and low expression in the odd samples. However, without annotation for Run4 and Run5 (which samples are treated and which not) it&#39;s impossible to interpret the bar chart.\n\n1. [Link](http://youtu.be/OJFsuZqNUHs)&quot;,&quot;# What is Inkscape?\nInkscape is professional quality vector graphics software which runs on Windows, Mac OS X and GNU/Linux. It is used by design professionals and hobbyists worldwide, for creating a wide variety of graphics such as illustrations, icons, logos, diagrams, maps and web graphics. Inkscape uses the W3C open standard SVG (Scalable Vector Graphics) as its native format, and is free and open-source software.\nDuring this training we will use **Inkscape 0.92** on Windows. To download the most recent version, browse to the [Inkscape Download page](https://inkscape.org/en/download/). For Windows 10 S: the Inkscape app is also available in the Microsoft Store.\n## External training material\n- [Online Inkscape tutorials](https://inkscape.org/en/learn/tutorials/).\n- [Nick Saporito Inkscape tutorials for beginners](https://www.youtube.com/playlist?listPLynG8gQD-n8BMplEVZVsoYlaRgqzG1qc4 )\n- [Nick Saporito Inkscape intermediate/advanced tutorials](https://www.youtube.com/playlist?listPLynG8gQD-n8AFcLFAkvqJYnQUiBweRh1y )\n\n## User Interface\nInkscape is a single-window program. Drawing tools are on the left hand side, option docks are on the right. \nIn the central window, you have the drawing area with default an A4 page as document layout. To select another format for e.g. posters, go to **File - Document Properties**. Next to the document size, you can adjust the background colour (default: transparant).\n\n## Import Images\nYou can import scalable vector graphic files (.svg) and also GraphPad Prism graphs (.emf or .pdf format).\nInkscape is not used for editing images like GIMP. If you import bitmap images, note that they are not scalable like vector objects!\n\n## Drawing lines and objects\nYou can draw a line with the Draw Bezier tool. You can make your own shape or just draw a line or path. On top of your drawing area you can select the Mode: Regular Bezier curves, Spiro paths, straight line segments and paraxial line segments. When selecting the straight line mode, you can hold the Ctrl button to make your line snap every 15 degrees around your first/previous point.\nYou can draw shapes by using the Rectangle tool, Ellipse tool and the Create Stars and Polygons tool. On top of the drawing area you can specify your polygon and star properties, size and lock aspect ration. Here is the Crtl key useful as well for creating squares, circles or specify the position of your object.\nWhen you have an object (polygon or others) you can select a color for the stroke and inside of the object. Selecting an object using the Selection tool will give you more options on top of the view area. You have the option to rotate, flip, change dimensions and XY position (in different units). You can change the position of the selected object compared to others (move up/down). \n\n## Paths\nA path consist of lines and nodes. These lines can be straight or curved and you can make an object using paths ( closed path). When in Path mode you have several options; add or remove a node, joining or breaking nodes apart and changing the node properties. You can also change the segment (line between nodes) properties with the options on top of the screen. \nYou can convert an object into a path to gain more flexibility by selecting the object and go to **Path  Object to path**. Afterwards you can use the object tool or the path tool to manipulate the object. \n\n## Fill and stroke\nPaths, lines and objects can be given a plain color, patterns, gradient color or left blank/transparent. You can also configure the stroke style and color. Click **Object  Fill and Stroke** to see all the options. Paths/lines can be transformed into arrows using the Stroke style option **Markers**.\n\n## Text\nAt the left there is also a Text tool available. With this tool you can create and change text, it&#39;s colour, font, style and size. After entering text, youre able to manipulate it like an object. You can also attach text into a frame by selecting both objects and click on **Text  Flow into Frame**.\nYou can also align text to a path. Select both text and path and click **Text  Put on Path**. Once the text in aligned to the path it stays adaptable and can be removed from the path; **Text - Remove from Path**.\nText is an object at first. When you select **Path - Object to path** you can modify your text like any other object that is converted into a path.\n\n## Grouping, aligning and arranging object/paths\nTo group several object you must select them all (hold Shift) and select **Object  Group**. To unite several paths you must select **Path  Combine**. Both options are the same and allow you to manipulate objects/paths as one. Both actions can be reversed (Ungroup / Break Apart).\nSeveral object must be aligned before you group them, think of text inside a box. To display the options, go to **Object - Align and Distribute**. When multiple objects are selected, you can align the top, bottom, left and right edges of the objects. Aligning on the central axes is also possible, this in both horizontal as vertical direction. The aligned objects always need an anchor, this can be changed in the box on top of the toolbox (Relative to:). This anchor can be an object (first, last, smallest or biggest) or the page, a selection or the complete drawing. Distributing objects works in a similar way, but manages the space between objects. For paths you can only align the nodes.\nAligning or distributing objects allows you to manipulate the X and Y position of your objects. There is also a virtual Z axis. When you have multiple objects with different colours, you can move the one above the other. Every new object you draw will be on top of all the rest. To raise an object one step or to the top, you can use the buttons on top of your screen. The same can be done to lower an object one step or to the bottom.\n\n## Path Effects and operations\nWhen you want to distribute/multiply an object along a guideline, there is a tool called Path Effects. First draw and select the object or group of objects and past it in the clipboard (Ctrl + C). Draw or select your path (guideline) and select **Path  Path Effects**. Click on the &#39;+&#39; sign and select the effect **Pattern Along Path**. In the new box on the right: select &#39;Repeated&#39; on the option Pattern copies. Now click on &#39;Paste path&#39; to paste the object you want to multiply. Note that only the shape is pasted, not the color. When adjusting the color, it will affect the entire path. To copy the colour, use Crtl+C again on your original, select your path of objects and go to **Edit - Paste Style - Paste Style**. There are also standard patterns to distribute along a path. When clicking on the &#39;+&#39; sign to add an effect, select Gears or Hatches (rough). Each of these effects have their own options to create an effect and to adjust the pattern.\nWhen it comes to paths, you can do much more than combining them. When you want to cut one shape out of another shape, you can use the options in the Path menu; Union, Difference, Intersection, Exclusion, Division and Cut Path.\n\n## Diagrams\nTo make a diagram with objects (circles, rectangles, stars, etc.) connected by lines, there is the Diagram connector tool. First you must draw and align the objects to create your diagram. Then select the Diagram connector tool. Every object can be selected by clicking in the white box in the middle of the object. Once connected the lines will follow the object if you move it to another place. The lines can be used as a path, therefore you can also modify them to e.g. dashed lines, arrows, etc.\n\n# Exercises\n&gt; ### {% icon hands_on %} Hands-on: Exercise 1\n&gt; Image 1 PNG: [Image 1](http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/Drawing.png)\n&gt; Image 1 SVG: [Image 1 SVG](http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/Drawing.svg)\n&gt; Task: Reproduce the top strand. Afterwards, reproduce the bottom strand using the first one.\n{: .hands_on}\n&gt; ### {% icon hands_on %} Hands-on: Exercise 2\n&gt; Image 2 PNG: [Image 2](http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/Drawing2.png)\n&gt; Image 2 SVG: [Image 2 SVG ](http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/Drawing2.svg)\n&gt; Task: Reproduce one of the sets of this image. Afterwards, reproduce the others using the first set.\n{: .hands_on}\n&gt; ### {% icon hands_on %} Hands-on: Exercise 3\n&gt; Image infographic 1: [Image 1](http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/procent_bars.png)\n&gt; Image infographic 2: [Image 2](http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/circle_infographic.png)\n&gt; Image infographic 3: [Image 3](http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/flower_diagram.png)\n&gt; Task: Try to reproduce one of these images using the video tutorial series from Nick (see top of this page).\n{: .hands_on}&quot;,&quot;# Bitmap vs Vector images\n## Bitmap \n- Pixels in a grid/map\n- Resolution dependent\n- Restricted to rectangle\n- Resizing reduces visual quality\n- Easily converted\n- Minimal support for transparency\n- Popular file formats: BMP, GIF, JPEG, JPG, PNG, TIFF\n\nBit depth or color depth is the amount of data assigned to every pixel (e.g. 1-bit = black/white, 4-bit = 16 colors/shades of grey, etc.) The more data, the more realistic your image will be. More data per pixel also means larger files.\n\n## Vector\n- Scalable\n- Resolution independent\n- No background\n- Inappropriate for photo-realistic images\n- XML based text format\n- Popular file formats: SVG, AI, CGM, DXF, WMF, EMF\n\n# Pixels\nResolution = number of pixels =  how much detail an image holds\nPPI: pixel per inch\n- Screen pixel density (monitor/smartphone)\n- Tells you how large an image is\n\nDPI: dots per inch\n- Print-out dots density (inkjet/laser printer)\n- Printer settings\n\nAn image at 300 PPI will look fine on a monitor, but printing is another matter! Print it on paper and you will notice the difference between 72 DPI and 300 DPI\n\n# File formats and compression\n## JPG/JPEG\n- Supports 26 million colours (24 bit)\n- Lossy compression (information is lost from original file)\n- Small file size (compressed)\n- Photographs\n## BMP\n- Supports 8/16/24-bit\n- Uncompressed file format\n- Large file size\n## TIFF\n- Tagged Image File Format\n- All colour and data information is stored\n- Uncompressed (lossy and lossless compression is possible)\n- Very large file size\n## GIF\n- Graphics Interchange Format\n- Only 256 colours possible (8-bit)\n- Replace multiple occuring patterns into one\n- Small file size\n- Animation\n## PNG\n- Portable Network Graphics\n- 256 / 16M colours\n- 8-bit transparancy\n- Lossless compression\n## SVG\n- Scalable Vector Graphics\n- XML-based format\n- Lossless data compression\n- Creatable and editable with a text editor\n- Can contain both bitmap and vector data\n## PDF\n- Portable Document Format\n- Can contain both bitmap and vector data\n## RAW/DNG\n- Digital Negative (DNG) is a universal RAW file format\n- Raw image file (without white balance, color saturation, contrast settings, )\n- RAW files can be camera brand specific\n- Large file size\n- Multiple options without taking the picture again\n## Publication vs Presentation\nKey features for publications:\n- Raw/uncompressed image file (e.g. TIFF)\n- High quality image (300 PPI) and resolution\n- Lossless compression (e.g. PNG)\n- Compression is sometimes allowed (check journal website!)\n\nKey features for presentation:\n- Normal quality image (72 PPI) and smaller resolution (max width: 1920 pixels)\n- Compression is allowed (e.g. JPEG)\n- Smaller file size\n\n# Guidelines on image editing\nScientific accepted image manipulations are described in guidelines. VIB also has a document to guide you in what is and what isn&#39;t acceptible when adjusting your images. Some examples are:\n- No specific feature within an image may be enhanced, obscured, moved, removed or introduced\n- Adjustments of brightness, contrast or color balance are acceptable if they are applies to the whole image as long as they do not misrepresent information in the original\n- Grouping of images from different parts of the same or different gel, fields or exposures must be made explicit by the arrangement of the figure (dividing lines)\n- The original data must be available by the author when asked to provide it, otherwise acceptance of the publications may be revoked\n\nyou can find all the VIB guidelines [here](http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/VIB_guidelines.pdf).&quot;,&quot;# What is GIMP?\nGIMP is short for **GNU Image Manipulation Program**. It is a free and Open-source, cross-platform image editor available for GNU/Linux, MacOS and Windows operating systems. During this training we will use **GIMP 2.10** on Windows. To download the most recent version for your OS, browse to the [GIMP Download page](https://www.gimp.org/downloads/).\n## External training material\n- [GIMP Manual page](https://www.gimp.org/docs/).\n- [GIMP 2.10 Basics on YouTube](https://www.youtube.com/watch?v=2EPIUyFJ4ag)\n- [Nick Saporito GIMP Tutorials](https://www.youtube.com/playlist?list=PLynG8gQD-n8Dl23X0o1HFu_5PmBl79niz)\n\n## User Interface\nGIMP has a &#39;Single-window&#39; mode, this allows you to switch from multiple windows (for e.g. multiple monitors) to a single window. When the &#39;Single-window&#39; mode is disabled, you have separate windows for toolboxes, view area and dockable dialogs. When enabled you have one window with all tools, options and dockable dialogs attached to the central view area. For beginners, we would advise the &#39;Single-window&#39; enabled.\nOn the left panel you have the &#39;Toolbox&#39; (if not present: **Windows - Toolbox** or press **Ctrl + B**) and underneath the &#39;Tool Options&#39; dialog. Selecting a tool will result in a different Tool Option bar. Every tool has his own set of parameters and functions, best to keep them close to each other. \nOn the right-hand panel you can find other &#39;dockable dialogs&#39;. These are easy to move, remove and re-introduce if necessary. To get a list of all &#39;dockable dialog&#39; go to **Windows  Dockable Dialogs - ...** . If you want a full screen view of your image select **Windows  Hide Docks**. \n\n## Import data and image properties\nTo import an image: **File  Open**\nWhen you select an image (any file type) in the import window, you get a preview and information on the right side. Click **Open** and the image(s) will be displayed in the middle box at zoom level 100% (1 pixel image = 1 pixel screen) or fitted to your windows. To zoom use Ctrl + mouse scroll up or down. Multiple images in GIMP are displayed in different tabs on top of the View Area.\nBefore you export your image, make sure it has the right resolution and pixel density. **Image - Image Properties** will give you all the information your image holds. This information can be very useful when you open an image from an unknown source.\n\n## Selection\nRectangular selection has several options and shortcut keys. The first icons in the tool options are the selection modes: add to selection (Shift), subtract from selection (Ctrl) and intersect with selection (Shift+Ctrl). More options are: feathering edges, rounding of the corners, expand from center, lock aspect ratio, size and position and if necessary to highlight the selection). The Ellipse selection tool has more or less the same options.\nThere are other selection tools available: Free Selection, Select by Color, Fuzzy Selection, Scissor Selection, Foreground Selection. Those tools have different tool options and are only used in specific cases.\n\n## Transforming\nThere are several ways to transform your image or selection; rotating, scaling, shearing and flipping. You can transform a selection, a layer or the image. When using the rotation tool, you have several options in the dockable dialog below. An important option is Clipping this will change the aspect ratio of your image after rotating. \nAnother way of rotating an entire image is: **Image  Transform  ...** then you have the option to flip (horizontal/vertical) or rotate (90/180). The entire image will be rotated including the selection and image orientation. \n\n## Layers\nMake sure you have the dockable dialog Layers in your window. All options for layers can be found in the menu bar Layer. You can make a new blank layer or duplicate the current layer (e.g. copy of original image to compare or as back-up). In the dockable dialog you can hide or show a layer (eye button), rename them or move them up and down in the layer stack. If you want to link/connect two or more layers, you can use the chain button (next to the eye button).\nTo copy a selection to a new layer, perform a regular copy/past action of that selection (Ctrl+C and then Ctrl+V) and select **Layer - To New Layer**\nIf you want to merge all layers into one layer you can select **Image  Merge Visible Layers**.\n\n## Brightness and contrast\nIn the menu bar you can find **Colors** . This menu has multiple option to manipulate your image; \n- Color Balance will change the cyan, magenta and yellow color levels of your image\n- Brightness and Contrast will change brightness and contrast and you can save these settings as a favorite \n- Threshold will reduce your image to two colors by using a threshold value\n- Adjust color curve will change the gamma setting of your image\n- Posterize will change the number of colors (2-256)\n\n## Guides and cropping\nYou can split your image in different sub-images. This can be done by using &#39;Guides&#39;. To create such a break-line, go to **Image - Guides - New Guide... or (by Percent)...**. You can create a horizontal or vertical guide at the value/percentage you enter. A guide will be displayed as a blue dashed line. To chop your image in multiple parts, go to **Filters- Web- Slice** (Older versions: Image - Transform - Guillotine). The sub-images will be generates in the folder you selected.\nIf you only want a selection of your image without all the rest you can crop by clicking **Image  Crop to Selection** or use the Crop tool from the Toolbox.\n\n## Scaling and print size\nWhen you want to scale your image to a smaller resolution you can select **Image  Scale Image**. There you can scale in pixels (or another unit) and you can lock the aspect ratio (chain symbols).\nIf you want to change the print size to make your image suitable for publication you can select **Image - Print Size...**. There you can change the dimension/resolution and pixel density of your image.\n\n## Remove background color\nIf you download an image of a company or university logo, it might have a white (or any other color) background. This can be very annoying when the destination background is different. In order to remove the background color, we first have to add an alpha channel to this image: **Layer - Transparency - Add Alpha Channel** - If the Alpha channel is already present, skip this step. Now you&#39;re able to get a transparent background using the option: **Image - Color to Alpha**. In the new window you can select the color which you would like to convert to transparent pixels. You can either select by clicking the color bar or use the color picker icon.\n\n## Exporting\nSelect **File  Export as**\nIf you click on the &#39;+&#39; next to Select File Type, you have a list of all possible extensions in which you can export your image. Each of those file formats has different compression options.\n\n# Exercises on image manipulations in GIMP\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 1\n&gt; Source file: [http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/original_file.tif Image 1]\n&gt; Task: Split this image in 2 parts, one for each gel. Make sure the band are horizontal and export the 2 new images in the same file format as the original. You can adjust brightness and contrast to make all the band more visible.\n{: .hands_on}\n&gt; ### {% icon hands_on %} Hands-on: Exercise 2\n&gt; Source file: [http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/Exercise1.1.jpg Image 2]\n&gt; Task: Rotate this image 45 degrees and crop an image of 500x500 pixels out of the original. Make sure the printing resolution is set to 300 ppi and export this image as a PNG file. Adjust brightness and contrast to make this image look better.\n{: .hands_on}\n&gt; ### {% icon hands_on %} Hands-on: Exercise 3\n&gt; Source file: [http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/Exercise1.2.jpg Image 3]\n&gt; Task: Cut this image in 4 equal parts. Know that the printing width is 150 mm and the journal demands a minimum op 300 ppi for all 4 images. Also export each of them in a different file formats without losing image quality. Adjust brightness and contrast to your own opinion.\n{: .hands_on}\n&gt; ### {% icon hands_on %} Hands-on: Exercise 4\n&gt; Source file: [http://data.bits.vib.be/pub/trainingen/GIMP_Inkscape/Exercise1.3.jpg Image 4]\n&gt; Task: Adjust brightness and contract of this images and export it in a way to make the file as small as possible. Use preferably lossless compression (try lossy compression to compare file size), there is no restriction on file formats. Be sure your image is exported with at least 300 ppi.\n{: .hands_on}\n&gt; ### {% icon hands_on %} Hands-on: Exercise 5\n&gt; Source file: select from the internet\n&gt; Task: Download an image from your most favorite brand and remove the white (or other color) background. Export this new image in a format that support transparent pixels.\n{: .hands_on}&quot;,&quot;qbase+ is software to visualize and analyze qPCR data. It allows you to perform various types of analyses:\n  - statistical analysis of gene expression\n  - advanced copy number analysis\n  - miRNA profiling\n  - ChIP-qPCR analysis\n# Installation and licensing\nYou can find the installation instructions on [VIB qbase+ support page](https://www.bits.vib.be/index.php/software-overview/qbaseplus)\nVIB only offers qbase+ to VIB scientists, you need a valid VIB email address to run the software. Biogazelle (the company who has developed the software) have written a manual with instructions on how to use the software. Download [Biogazelle&#39;s user manual](https://www.biogazelle.com/system/files/manuals/qbaseplus_manual_0.pdf). Before you can download the manual you have to log on to [the qbase+ website](https://www.qbaseplus.com/) using your qbase+ account. Use your VIB email address for setting up this account.\n# Training material\n  - [slides](http://data.bits.vib.be/pub/trainingen/qbasePLUS/qbase_2018.pdf)\n  \n  **Extra**\n  - [clean log10 transformed CNRQs](http://data.bits.vib.be/pub/trainingen/qbasePLUS/Log10CNRQsClean.xlsx) for checking normality in Prism\n  - [clean untransformed CNRQs](http://data.bits.vib.be/pub/trainingen/qbasePLUS/CNRQsClean.xlsx) for visualization in Prism\n  - [R script](http://data.bits.vib.be/pub/trainingen/qbasePLUS/qPCR.R) for analysis and visualization\n  - [log10 transformed CNRQs of control samples](http://data.bits.vib.be/pub/trainingen/qbasePLUS/resultslog.csv) for analysis and visualization in R\n  - [log10 transformed CNRQs of treated samples](http://data.bits.vib.be/pub/trainingen/qbasePLUS/resultslogTreated.csv) for analysis and visualization in R\n&quot;,&quot;# OTU creation using LotuS \n{:.no_toc}\n\nIn this tutorial we will create a genus abundance table from two 454 sequencer runs using a pipeline called LotuS. A genus abundance table contains counts of different genera in a several of samples  Rows are the different genera and columns the samples. As a simple example, take a look at this table:\n\n|                     |        |       |        |       |      |\n|:--------------------|:-------|:------|:-------|:------|:-----|\n|Genus\t              | bl10   |bl11   |bl12\t|bl128\t|bl13  |\n|Bacteria             |24      |52     |39\t|63\t|181   |\n|Bacteroides\t      |169     |27     |7\t|42\t|6     |\n|Porphyromonadacea    |370     |346    |621\t|565\t|224   |\n\nThis table tells us how often we observe unclassified Bacteria, Bacteroides and unclassified Porphyromonadaceae in the 5 samples bl10, bl11, bl12, bl128 and bl13. A matrix like this will be used for the next tutorial on numerical ecology and created from raw sequence data within this tutorial.\n\n## The data\n\nIn a recent experiment, we sequenced 73 samples in two 454 runs, the raw fasta and quality files are in `/home/VIBTrainingX/metagenomics/` on the bits server. For each run we have a fasta (.fna) and quality (.qual) file. Go to this directory using the command `cd` and become aware of the files required from the experimenter (command `ls`). You can always take a look at files and their contents using viewing commands like `less`.\n\nThe sequence files were multiplexed before the experiment, that is a small nucleotide sequence  the barcode - was attached to each read, specific for each experiment. A mapping file is typically used, containing the link between a sequence barcode and the name of the experiment and is essential to demultiplex the fasta files. \n\n## The tools\n\nLotuS is actually a set of tools that were installed in the `/opt/` folder. First go to [the lotus website](http://psbweb05.psb.ugent.be/lotus/) and familiarize yourself with the basic documentation.\n\nTo start the exercises, go to the directory where Lotus is installed. \n```\ncd /opt/lotus-1.62/lotus_pipeline/\n```\n\nFrom this directory you can run all the tools. To reach all data files (e.g. input files) you have to provide the path to the files: `~/metagenomics/`\n\n## The analysis\n\n### Creation of Mapping file. \n\n[An Excel](http://data.bits.vib.be/pub/trainingen/metagenomics/Mice_experiment.xlsx) is provided, with some basic experiment annotation. The fwd primer is given as `ACTYAAAKGAATTGACGG`, but if you search for the primer sequence in the reads (in one of the .fna files) you will not find it because you need to reverse translate the primer sequence first using [http://www.bioinformatics.org/sms/rev_comp.html this tool]. So you see annotation provided by the provider is not always correct.\n \nLotus needs experiment annotation to map input files to barcodes. Based on the documentation on [http://psbweb05.psb.ugent.be/lotus/documentation.html#MapFile the Lotus website], create a mapping file for this experiment. This means that you need to replace the column headers of the Excel file to terms that are accepted by Lotus and that you have to indicate that there is a .fna and a .qual file for each run. The header line should be preceeded by a `#`. The mapping file should at least contain four columns with the following headers:\n\n* SampleID\n* BarcodeSequence\n* fnaFile\n* qualFile\n\nSave the file as a tab-delimited text file.\n\nYou can always test the validity of your mapping file with the command \n```\n./lotus.pl -check_map [your mapping file]\n```\n\nIf you have fastq files as input the fnaFile and qualFile columns would be replaced by one fastqFile column.\n\n### Changing  the data format of the input files.\n\nSometimes you need to transcribe data from one format to another. For instance we could transform the fasta files (.fna) to fastq files (.fq). This can be done with the program `sdm`, that is part of the LotuS pipeline. Take a look at the sdm help by typing `./sdm` and exploring the options, e.g.\n \n```\n./sdm -help_commands\n```\n\nThen, using command line arguments, transcribe the fasta + qual files of the Anh experiment into fastq files. Take a look at output and log files created by sdm.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 1 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt; \n&gt;  &gt; How to transform fasta + qual files into fastq files ?\n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; sudo ./sdm -i_fna ~/metagenomics/Anh.1.fna -i_qual ~/metagenomics/Anh.1.qual -o_fastq t1.fq\n&gt;  &gt; &gt; ```\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nIn the lotus_pipeline folder the fastq file t1.fq was generated, to take a look at the file use\n```\nhead t1.fq\n```\n\nDo the same for the t1.log file: you see that sdm is not only used to transform fasta into fastq files but it is also capable of doing quality filtering on the raw reads files.\n\n### Setting up a quality filter of the input sequence files.\n\nSince we want to make sure the quality filtering of the input file is strict, LotuS offers several quality filtering options. Quality settings are different for different data formats, thats why Lotus offers a file with specific settings for each platform. Since we have 454 data we will take a look at the file sdm_454.txt.\n```\nless sdm_454.txt\n``` \n\nRead the comments (line starting with #) to each option and think which quality filtering options might be important in order to create OTUs from the raw sequences. (Hint: an OTU is a clustering of similar sequences with the aim to have one cluster of sequences for each species that was originally present in the samples. Take into account that sequencing machines make errors and that PCR amplification of the 16S rDNA is similarly with errors). Think about a set of parameters, including the statistical information from step 2, and save these in your copy of sdm_options.txt for later use.\n\nCheck the sdm [quality filter settings](http://psbweb05.psb.ugent.be/lotus/documentation.html#SDMconfig). Some of the default filter settings are:\n\n* MinSeqLength=250 : Only use reads of at least 250 nt long after processing (remember we are working with long reads from 454 sequencing)\n* TruncateSequenceLength = 250 : Cut all reads after 250 nt\n* QualWindowWidth = 50 and QualWindowThreshold = 25 : Remove all reads where average quality is &lt;= 25 over a 50bp window\n* maxAccumulatedError = 0,5 : Remove all remaining bases when accumulated error score &gt;= 0,5&lt;/li&gt;\n* maxHomonucleotide = 8 : Remove all reads with a homonucleotide run (repeat of same nt) &gt;= 8\n* RejectSeqWithoutFwdPrim = TRUE : Remove all reads that do not contain the forward primer\n\n### Demultiplexing  and quality filter the input files.\n\nFor this step you will need the mapping file from Step 1 and the file with the quality filtering settings for 454 data. Use the sdm command to demultiplex and filter all input files at the same time into a local folder &#39;&#39;demultDir&#39;&#39;. First create the folder where the demultiplexed files will be written in ~/metagenomics/:\n```\nmkdir ~/metagenomics/demultDir\n```\n\nSince the mapping file contains information on all files, you have to provide an input path to the folder that contains the input files (.fna + .qual) to sdm.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 2 \n&gt;\n&gt;  &gt; ### {% icon question %} Question\n&gt;  &gt; How to demultiplex and quality filter files ? \n&gt;  &gt;\n&gt;  &gt; &gt; ### {% icon solution %} Solution\n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; ./sdm -i_path ~/metagenomics/ -o_fastq t1.fq -o_demultiplex ~/metagenomics/demultDir/ -map ~/metagenomics/map.txt -options sdm_454.txt \n&gt;  &gt; &gt; ```\n&gt;  &gt; &gt; Input is the folder containing the .fna and .qual files. The demultiplexing will fill the demultDir folder with fastq files.\n&gt;  &gt; {: .solution }\n&gt;  {: .question }\n{: .hands_on }\n\nDiscuss the output files and what each of these represents. In this experiment multiple samples were sequenced in the same lane. Two lanes were used, each containing 37 samples. After sequencing, this results in two files with reads. To know which sample a read comes from, unique bar codes are incorporated into the adapter sequences. One specific bar code for each sample. In this step reads from different samples (but from the same lane thus in the same fasta file) are split over separate fastq files, one for each sample. \n\n### Mapping file creation when sequence provider provides demultiplexed files.\n\nNow that you have demultiplexed the files into a single folder, you might be aware that sequence providers often deliver files in this format: already demultiplexed into single files. In this case slight modifications to the mapping file are enough to change the input from non-demultiplexed large file(s) to demultiplexed-many-small-files.\n\nNote that lotus has a special script that creates the mapping file for you in this case. The script is autoMap.pl. It is used to link SampleIDs to demultiplexed files. Run autoMap.\n\n```\n./autoMap.pl ~/metagenomics/demultDir/ ~/metagenomics/automap.txt 1,1\n```\n\n### Running Lotus.\n\nWe will run Lotus on the demultiplexed files. Use the mapping file you generated in Step 5 and the settings file sdm_454.txt. Use the utax taxonomy to assign a phylogeny to the derived OTUs. Run lotus from out the /opt/lotus_pipeline/ and save the output in the folder &#39;&#39;testR&#39;&#39;\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 3 \n&gt;\n&gt; &gt; ### {% icon question %} Question\n&gt; &gt; How to run lotus\n&gt; &gt;\n&gt; &gt; &gt; ### {% icon solution %} Solution\n&gt; &gt; &gt; ```\n&gt; &gt; &gt; sudo ./lotus.pl -i ~/metagenomics/demultDir/ -o ~/metagenomics/testR/ -m ~/metagenomics/automap.txt \n&gt; &gt; &gt; ```\n&gt; &gt; &gt; Input is the folder containing the .fna and .qual files. The demultiplexing will fill the demultDir folder with fastq files.\n&gt; &gt; {: .solution }\n&gt; {: .question }\n{: .hands_on }\n\nIn case you haven&#39;t done any quality filtering yet, you can still do it now. The command would then be:\n```\nsudo ./lotus.pl -i ~/metagenomics/demultDir/ -o ~/metagenomics/testR/ -m ~/metagenomics/automap.txt -s sdm_454.txt\n```\n\n* Peek at the file hiera_RDP (using `head`). The file maps eachg OTU to a genus.\n* Peek at the file OTU.txt (using `head`). The first line contains the number of reads that represent OTU_1 in each sample.\n* Peek at the file otus.fa (using `head`). It contains the reads representing each OTU. You can use this file to blast the sequences to check if they are really from the OTU they were assigned to.\n* Go to the folder higherLvl. This contains the data that we are going to use in the Ecology analysis.\n* Go to the folder LotuSLogs. This contains the settings of the analysis. For instance, peek a the file demulti.log: it shows how many reads were rejected... The file citations.txt contains the references for reporting your LotuS results. \n\n### Using a different taxonomy assignment on a finished run.\n\nIn this step we want to reassign the taxonomy to a LotuS run, but keep exactly the same OTUs. In this exercise, assign the OTUs to the Silva taxonomy. \n\nThis option is useful, if e.g. you want to keep your work on a given OTU set (as well as the phylogenetic tree), but want to try out what would have happened if you had used e.g. Silva as reference database instead of utax.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 4 \n&gt;\n&gt; &gt; ### {% icon question %} Question\n&gt; &gt; How to reassign the taxonomy with Silva as reference database? \n&gt; &gt;\n&gt; &gt; &gt; ### {% icon solution %} Solution\n&gt; &gt; &gt; ```\n&gt; &gt; &gt; sudo ./lotus.pl -i ~/metagenomics/demultDir/ -o ~/metagenomics/testR2/ -m ~/metagenomics/automap.txt -s sdm_454.txt -refDB SLV -redoTaxOnly 1\n&gt; &gt; &gt; ```\n&gt; &gt; &gt; Input is the folder containing the .fna and .qual files. The demultiplexing will fill the demultDir folder with fastq files.\n&gt; &gt; {: .solution }\n&gt; {: .question }\n{: .hands_on }\n\n### Using  a custom database.\n\nThe research of honey bee gut communities have very specific taxonomic names for already known bacteria. In order to accomodate for their naming sheme, we will use a very specific database that contains 16S sequences of bacteria mostly found in the honey bee gut. Download the [bee taxonomy in tax format](http://psbweb05.psb.ugent.be/lotus/packs/DB/beeTax/beeTax.tax) and [http://psbweb05.psb.ugent.be/lotus/packs/DB/beeTax/beeTax.fna bee taxonomy in fna format].\n\nUse the two provided files (fna, tax) to again redo the taxonomy, but this time assigning first using the honey bee DB and secondly everything with low hit should be assigned with the SILVA database. \n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 5 \n&gt;\n&gt; &gt; ### {% icon question %} Question\n&gt; &gt; Use honey bee taxonomy database ? \n&gt; &gt;\n&gt; &gt; &gt; ### {% icon solution %} Solution\n&gt; &gt; &gt; ```\n&gt; &gt; &gt; sudo ./lotus.pl -i XX -o ~/metagenomics/testR3/ -redoTaxOnly 1 \\\n&gt; &gt; &gt; -m ~/metagenomics/LASI_Spring_2_bees_barn_3_map_lts_5.txt \\\n&gt; &gt; &gt; -refDB ~/metagenomics/beeTax.fna,SLV -tax4refDB ~/metagenomics/beeTax.tax \n&gt; &gt; &gt; ```\n&gt; &gt; &gt; Input is the folder containing the .fna and .qual files. The demultiplexing will fill the demultDir folder with fastq files.\n&gt; &gt; {: .solution }\n&gt; {: .question }\n{: .hands_on }\n\n### Get  everything assigned!\n\nIn this step we want to assign every OTU sequence to a database target  and we dont care about false positive assignments! Of course this is per se wrong, but in some cases you just want to know what the best hit would be, even if it is only 90% similar to your OTU sequence. LotuS provides several options that allow tweaking towards more lenient assignments. Find all options related to this and try to create the most extreme case with these options, by reassigning the taxonomy again as in the previous step.\n\n### Try a different sequence clustering algorithm.\n\nNow rerun lotus, but try to optimize for a lot of small, hard defined OTUs (that might correspond to something like strain level). Which clustering algorithm might be suitable? Which clustering cutoffs make sense? For this specific run, use the first mapping file you created (step 1) and the non-demultiplexed input files. Save this output in the folder &#39;&#39;testR4&#39;&#39;\n\n### Your own best run.\n\nNow that you have run LotuS with various databases and options, go back and look at the output folder of the different runs, look at the statistics provided in the &#39;&#39;LotuSLogS&#39;&#39; subfolder. Based on this, tune the sdm filtering parameter file from step 3 (again), choose the database you think best suited/most interesting, and choose a clustering algorithm. With this create run the sample set again, saving the output in folder &#39;&#39;testrun1.3&#39;&#39;. This output folder you can use in the following session on numerical ecology.\n\nIf LotuS run has finished, go to the specified output folder and copy the genus.txt from the output folder to your home folder: \n```\ncp testrun1.3/ higherLvl/genus.txt ~\n```\n\n### Using Illumina data as input.\n\nIn all the analysis before we were using 2 x 454 runs from an outdated next generation sequencing technology. For the next exercise we will look at the output of an Illumina miSeq sequencing platform, that is still being used a lot nowadays.\n\nSet up the mapping file, using [http://data.bits.vib.be/pub/trainingen/metagenomics/Miseq.xlsx the provided Miseq.xlsx file]. Run LotuS, after you set up a custom sdm configuration file and using a combination of parameters you learned about in previous steps.\n\nThis run might take some time longer to finish. Be sure you set it to use all the cores of your computer and let it run over the lunch break.\n\nCongratulations, now you know how to process raw sequence files to meaningful summary tables, that can be directly analyzed in R or even Excel! In the next tutorial this matrix will be analyzed with the help of R, after the lunch break.\n\n&quot;,&quot;# Reading and writing files\n{:.no_toc}\n\n### Reading files\nEntering data in R can be done by typing the values when you create a variable. In most cases, however, you will have a file with data that was created by an instrument in your lab. How to import such a file into R? \n\nThere is a manual available in the R documentation called **R Data Import/Export**. It&#39;s accessible using help.start() and covers in detail the functionality R has to import and export data. Reading this is highly recommended. This manual covers importing data from spreadsheets, text files, and networks.\n\n### Reading text files\nMost instruments put out data in text format: tab-delimited text (.txt) or comma-separated value files (.csv). Both  can be easily opened in R. \n\nThe most convenient method to import data into R is to use the read functions, like read.table(). These functions can read data in a text file. In Notepad you can save such a file as a regular text file (extension .txt). Many spreadsheet programs can save data in this format. Reading means opening the file and storing its content into a data frame.\n```\nread.table(file,header=FALSE,sep=\&quot;\&quot;,dec=?.?,skip=0,comment.char=\&quot;#\&quot;)\n```\n\nThis function has a long list of arguments, the most important ones are:\n- *file*: path on your computer to the file e.g. D:/trainingen/Hormone.csv \n\tIf it is stored in the working directory, you can simply use its name. You can also use *file=file.choose()* to browse to the file and select it. File can be replaced by a url to load a file with data from the internet.\n- *header*: does the first line of the file contain column names?\n- *dec*: symbol used as decimal separator\n- *sep* symbol used as column separator, default is a whitespace or tab\n- *skip*: number of lines to skip in the file before starting to read data\n- *comment.char*: symbol to define lines that must be ignored during reading\n\nSee the documentation for an overview of all the arguments. The output of every read function is a data frame.\n\nThere are functions to read specific file formats like .csv or tab-delimited .txt files. In the documentation of read.table() you see that these functions are called read.csv() and read.delim().  Both functions call read.table(), but with a bunch of arguments already set.  Specifically they set up *sep* to be a tab or a comma, and they set *header=TRUE*.  \n\n```\nread.delim(file,header=TRUE,sep=\&quot;\\t\&quot;)\n```\nOn the documentation page, you see that these functions each have two variants that have different default settings for the arguments they take:\n```\nread.csv(   file,header=TRUE,sep= \&quot;,\&quot;,dec=\&quot;.\&quot;, ...)\nread.csv2(  file,header=TRUE,sep= \&quot;;\&quot;,dec=\&quot;,\&quot;, ...)\nread.delim( file,header=TRUE,sep=\&quot;\\t\&quot;,dec=\&quot;.\&quot;, ...)\nread.delim2(file,header=TRUE,sep=\&quot;\\t\&quot;,dec=\&quot;,\&quot;, ...)\n```\nOriginally the CSV format was designed to hold data values separated by commas. In .csv files that are made on American computers this is the case. However, in Europe the comma was already used as a decimal separator. This is why .csv files that are made on a European computer use the semicolon as a separator. \n\nFor instance, the file below contains a header row and three columns, separated by semicolons. It uses the comma as decimal separator.\n```\nPatient;Drug;Hormone\n1;A;58,6\n2;A;57,1\n3;B;40,6\n```\nObviously, the file is a European CSV file, to open it use read.csv2()\n\n### Reading Excel files\nTo import Excel files via a command the easiest way is to let Excel save the file in .csv or tab delimited text format and use the read functions. \n\nAn easy way to import Excel files is to use the RStudio interface although I prefer to use commands. To use the interface go to the **Environment** tab and click the **Import Dataset** button. \n\nRStudio can import 3 categories of files: text files, Excel files and files generated by other statistical software. To read .xls or .xlsx files select **From Excel**. \n\nA dialog opens with options on the import. You can import data from your computer (**Browse**) or from the internet (provide a url and click **Update**). Click **Browse**, locate the Excel file and click **Open**.\n\nThe **Data Preview** section shows what the data will look like in R.\n\nThe **Import Options** section allows you to specify the import parameters. \n- *Name*: name of the data frame that will hold the imported data. The default is the name of the file that you are opening.\n- *Skip*: number of rows at the top of the file to skip during import. Some data formats contain a number of header rows with general info like parameter settings, sample names etc. These rows are followed by the actual data. Skip allows you to skip over the header rows and import the actual data. \n- If the first row of the file contains column names, select *First Row as Names*\n- *Open data viewer* shows the data in the script editor upon import\n\nClick **Import**.\n\nBehind the scenes RStudio uses the **readxl** package that comes with the tidyverse package. You can also use the functions of this package directly in commands. \n\nCompared to other packages for reading Excel files (gdata, xlsx, xlsReadWrite) readxl has no external dependencies, so it?s easy to install and use on all operating systems. It supports the  .xls format and the .xlsx format. The easiest way to install it from CRAN is to install the whole tidyverse package but you have to load readxl explicitly, since it is not a core tidyverse package.\n\nOnce imported into RStudio the data is stored in a data frame and you can use it as input of commands. The data frame appears in the list of **Data in the Environment tab**.\n\n&lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../../images/Rfile_imported.png\&quot; alt=\&quot;file_imported\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; Inspect Variables and Data Frames in the Environment tab&lt;/figcaption&gt;&lt;/figure&gt;\n\nIf you want to view the data frame you can **click its name in the Environment** tab and it will appear in a separate tab in the script editor.\n\n&lt;figure id=\&quot;figure-2\&quot;&gt;&lt;img src=\&quot;../../images/Rview_file.png\&quot; alt=\&quot;view_file\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 2:&lt;/span&gt; View file content&lt;/figcaption&gt;&lt;/figure&gt;\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Reading files** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 17a\n&gt;\n&gt; 1. Import the file [GeneEx.csv](http://data.bits.vib.be/pub/trainingen/RIntro/GeneEx.csv) into a data frame called GeneEx\n&gt; 2. Rename the two last columns Ct1 and Ct2\n&gt; 3. Create a new column containing the average Ct: (Ct1+Ct2)/2\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  GeneEx &lt;- read.csv2(\&quot;Rdata/GeneEx.csv\&quot;)\n&gt;    &gt;  colnames(GeneEx)[c(3,4)] &lt;- c(\&quot;Ct1\&quot;,\&quot;Ct2\&quot;)\n&gt;    &gt;  GeneEx$Average_Ct &lt;- (GeneEx$Ct1 + GeneEx$Ct2)/2\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  Which of these 2 commands will work ?\n&gt;    &gt; ```\n&gt;    &gt;  GeneEx &lt;- read.csv2(\&quot;Rdata/GeneEx\&quot;)\n&gt;    &gt;  GeneEx &lt;- read.csv2(\&quot;http://data.bits.vib.be/pub/trainingen/RIntro/GeneEx.csv\&quot;)\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt; Which of these 2 commands will work ?\n&gt;    &gt;  ```\n&gt;    &gt;  names(GeneEx[c(3,4)]) &lt;- c(\&quot;Ct11\&quot;,\&quot;Ct21\&quot;)\n&gt;    &gt;  names(GeneEx)[3:4] &lt;- c(\&quot;Ct11\&quot;,\&quot;Ct21\&quot;)\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt; What&#39;s the difference in result between these 2 commands ?\n&gt;    &gt; ```\n&gt;    &gt; GeneEx$Average_Ct2 &lt;- (GeneEx$Ct1+GeneEx[4])/2\n&gt;    &gt; GeneEx[5] &lt;- (GeneEx[3]+GeneEx[4])/2\n&gt;    &gt; ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt; Can you use sum() instead of + ?\n&gt;    &gt; ```\n&gt;    &gt; sum(GeneEx$Ct1,GeneEx$Ct2)\n&gt;    &gt; (GeneEx$Ct1+GeneEx$Ct2)\n&gt;    &gt; ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt; Can you use mean() instead of +/2 ?\n&gt;    &gt; ```\n&gt;    &gt; mean(GeneEx$Ct1,GeneEx$Ct2)\n&gt;    &gt; mean(GeneEx$Ct1)\n&gt;    &gt; ```\n&gt;    {: .question}\n{: .hands_on}\n\n### Reading other files\nAlso of note is an R package called **foreign**. This package contains functionality for importing data into R that is formatted by most other statistical software packages, including SAS, SPSS, STRATA and others. \n\n### Writing files\nReversely, to write a data frame to a file you can use the generic function:\n```\nwrite.table(x,file=?name.txt?,quote=TRUE,row.names=TRUE,col.names=TRUE)\n```\nThis function has a long list of arguments, the most important ones are:\n- *x*: data frame to be written to a file\n- *file*: name or full path of the file e.g. D:/trainingen/Hormone.csv\n- *quote*: if TRUE, strings, row and column names will be surrounded by double quotes. If FALSE, nothing is quoted.\n- *sep*: column separator\n- *row.names*: boolean indicating whether the row names of x are to be written or a character vector of row names to be written\n- *col.names*: boolean indicating whether the column names of x are to be written or a character vector of column names to be written\n- *append=FALSE*: if TRUE x is **added** to the file defined by *file*\n- *eol = ?\\n?*: end-of-line character, default ?\\n? represents an enter\n- *na=?NA?*: string to use for missing values in the data\n- *dec=?.?*: decimal separator\n\nSee the help file for a full overview of all arguments. \n\nTo specifically write .csv files use write.csv() or write.csv2(). See the help file for a description of the difference between them. \n\nExcel can read .csv files but if you really want to write .xls or .xlsx files use the openxlsx package.  \n\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 17b\n&gt;\n&gt; 1. Read the file [RNASeqDE.txt](http://data.bits.vib.be/pub/trainingen/RIntro/RNASeqDE.txt) into a data frame called DE. It contains the differentially expressed genes from an RNA-Seq experiment.  \n&gt; 2. Split the table into a table of upregulated genes (log2foldchange &gt; 0) and a table of downregulated genes and store them in data frames called up and down.\n&gt; 3. How many up- and downregulated genes are there?\n&gt; 4. What is the gene with the highest log2 fold change?\n&gt; 5. What is the data of the gene with the lowest adjusted p-value (= padj)?\n&gt; 6. Write the Ensembl IDs (= row names) of the upregulated genes to a file called up.txt. You will use this file for functional enrichment analysis using online tools like ToppGene,EnrichR? These tools want a file with only Ensembl IDs as input (one per line, no double quotes, no column headers, no row names).\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  DE &lt;- read.table(\&quot;Rdata/RNASeqDE.txt\&quot;,header=TRUE)\n&gt;    &gt;  up &lt;- DE[DE$log2FoldChange &gt; 0,]\n&gt;    &gt;  down &lt;- DE[DE$log2FoldChange &lt; 0,]\n&gt;    &gt;  nrow(up) \n&gt;    &gt;  nrow(down)\n&gt;    &gt;  rownames(up[which.max(up$log2FoldChange),])\n&gt;    &gt;  DE[which.min(DE$padj),]\n&gt;    &gt;  write.table(rownames(up),file=\&quot;up.txt\&quot;,quote=FALSE,col.names=FALSE,row.names=FALSE)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt; Which of the following 2 commands will not work properly ?\n&gt;    &gt; ```\n&gt;    &gt;  DE &lt;- read.table(\&quot;Rdata/RNASeqDE.txt\&quot;)\n&gt;    &gt;  file &lt;- file.choose()\n&gt;    &gt;  DE &lt;- read.table(file,header=TRUE)\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt; Will the following command work ?\n&gt;    &gt; ```\n&gt;    &gt;  up &lt;- subset(DE,log2FoldChange &gt; 0)\n&gt;    &gt;  \n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt; What&#39;s the difference between these 2 commands ?\n&gt;    &gt;  ```\n&gt;    &gt;  which.max(up$log2FoldChange)\n&gt;    &gt;  max(up$log2FoldChange)\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt; Will this command write Ensembl IDs and log fold changes ?\n&gt;    &gt; ```\n&gt;    &gt;  toprint &lt;- as.data.frame(up$log2FoldChange)\n&gt;    &gt;  write.table(toprint,file=\&quot;up.txt\&quot;,quote=FALSE,col.names=FALSE)\n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 17c\n&gt;\n&gt; Which type of files are imported by read.delim ? \n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt; Check the documentation and look at the default for *sep* \n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 17d\n&gt;\n&gt; 1. Read the file [ALLphenoData.tsv](http://data.bits.vib.be/pub/trainingen/RIntro/ALLphenoData.tsv) into a variable called pdata using one of the read functions\n&gt; 2. What type of data structure is pdata ?\n&gt; 3. What are the names of the columns of pdata ?\n&gt; 4. How many rows and columns are in pdata ? \n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;  ```\n&gt;    &gt;  pdata &lt;- read.delim(\&quot;Rdata/ALLphenoData.tsv\&quot;)\n&gt;    &gt;  class(pdata)\n&gt;    &gt;  colnames(pdata)\n&gt;    &gt;  dim(pdata)\n&gt;    &gt;  ``` \n&gt;    {: .solution}\n{: .hands_on}\n&quot;,&quot;# Tools  \n{:.no_toc}\n\n## Lotus pipeline \nLotuS offers a lightweight complete 16S/18S/ITS pipeline to\n- Demultiplex and filter fasta or fastq sequences\n- Denoise, remove chimeric sequences and cluster sequences into very high quality OTUs that perform at a similar level to mothur / dada2\n- Determine taxonomic origin of each OTU using &gt;5 spezialized and general purpose database or statistical algorithms\n- Construct OTU, genus, family, class, order and phylum abundance tables in .txt or .biom format\n- Reconstruct OTU phylogenetic tree\n\nMore information at [LotuS home page](http://psbweb05.psb.ugent.be/lotus/downloads.html)\n\n## usearch \n\nDownload [usearch version 8](http://www.drive5.com/usearch/download.html) and copy the executable in a folder e.g. /usr.bin/tools/ which you can reach (you might to be superuser for this)\n\nMake executable:\n```\nsudo chmod +x /usr/bin/tools/usearch8.1.1861_i86linux32\n```\n\nCreate a symbolic link into the folder where Lotus will search for it:\n\n``\nsudo ln -s /usr/bin/tools/usearch8.1.1861_i86linux32 /usr/bin/tools/lotus_pipeline/bin/usearch_bin\n```\n\n## R package \n\nYou also need R with the vegan package installed.\n&quot;,&quot;#### Create a project\n\nWhen you use qbase+ for the first time, you can&#39;t do anything unless you\ncreate a project to store your experiments in.\n\n| Create a new Project |\n| :----------------------------------- |\n| When you double click the qbase+ icon, the software starts up automatically opens the Start page where you can create a new project by clicking the Create new project button : This will create a new project with a default name like Project 1 . |\n\n#### Create an experiment\n\nTo open actual data (one/more runs) in qbase+, creating a project is not sufficient. You need to create an experiment in this project to hold the run data.\n\n| Create a new Experiment called GeneExpression in the new project. |\n| :----------------------------------- |\n| Select the Create a new qbase+ experiment option  in the Start page. Type a name for th new experiment . Click the Next button at the bottom of the page . This will create the experiment.\n\nWhen you leave the **Start page**, the **Import run** page is automatically opened allowing you to import the actual qPCR data into qbase+.\n\n#### Loading the data\n\nFirst a few quick words about the data set. Well be working with data coming from 3 runs (plates in the qPCR instrument): [Run1](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run1.xls), [Run2](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run2.xls) and [Run3](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run3.xls)\n\nThe data consist of Cq values for:\n\n  - 3 reference target genes: Stable, Nonregulated, and Flexible\n  - 3 target genes of interest: Duvel, Leffe, and Palm\n\neach measured twice (= technical replicates) in 16 different samples. Half of the samples have undergone a treatment, half of them are untreated control samples.\n\nThe data set also contains a series of standard samples consisting of a four-fold dilution series of cDNA for each target gene. These measurements allow to generate a standard curve from which target-specific amplification efficiencies can be calculated. Finally, negative controls (No Template Controls) have been measured. The goal of the analysis is to identify target genes of interest that have different expression levels in the treated samples compared to the untreated control samples.\n\n| In GeneExpression load CFX run files [Run1](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run1.xls), [Run2](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run2.xls) and [Run3](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run3.xls).\n| :---------------------------- |\n|  \n* Click the **Import runs** button  to open the **Import Run** window\n* Click the **Browse** button  to go to the directory that stores the files containing the qPCR data\n\nSelect the 3 run files simultaneously by holding the **Ctrl** key on your keyboard during the selection in Windows or the command button in MacOSX.\n\nClick the **Open** button \n\nNow you go back to the **Import Run** window, click the **Next** button (purple)\n\n* \nqbase+ tries to recognize the format of the selected import files. If only one format matches the files (as in our case CFX), it is selected and the quick import option is enabled. Click the **Finish** button.\n\nIn the Imported run names area on the **Import run** page you should now see the names of the 3 run files. If these are the correct files, click the **Next** button at the bottom of the page.\n\n#### Adding annotation to the data\n\nWhen you leave the **Import run** page, you are redirected to the **Sample target list** page, which gives you an overview of the targets (= genes) and samples qbase+ detected when reading in the datafiles.\nTake a look at the data. You see that the list of samples and targets matches the description of the qPCR experiment at the top of this page. The samples in this experiment are divided into two groups: samples that received some kind of treatment and untreated control samples. This information was not included in the run files so qbase+ does not know which sample belongs to which group. However, this is relevant information: in our analysis we are going to compare the expression of our genes of interest between treated and untreated samples. This means that qbase+ needs the grouping annotation to be able to perform the analysis we want to do. So we have to give qbase+ this annotation: we can do this by adding a custom sample property. To do this we need to create a sample properties file with a specific format that is described in [the tutorial](http://data.bits.vib.be/pub/trainingen/qbasePLUS/TutorialIII.pdf). You can find the file in the qbase+ folder on the BITS laptops or you can [download the file here](http://data.bits.vib.be/pub/trainingen/qbasePLUS/Sample_Properties_file.xlsx).\n\n| How to add the grouping annotation ?\n| :---------------------------- |\n|  To import the file containing to grouping annotation:\n\n* select **Add samples and targets** \n* click **Import sample list** \n* browse to the folder that contains the samples file\n* select the file and click **Open**\n* click **Next**\n\nIn the **Importing samples** window, you have to tell qbase+ which sample annotation you want to import from the sample properties file\n\nIn our case we could import Quantities (this annnotation is available in the sample properties file) but the quantities of the standard samples were included in the run files so qbase+ has already imported this annotation from the run files during data import.\nWe definitely need to import the Custom properties since they were not a part of the run files. The Treatment property will tell qbase+ which samples belong to the group of control samples and which samples belong to the group of treated samples.\nClick the **Next** button at the bottom of the page to finish the import.\n\nAt this point you don&#39;t see the custom annotation that you have imported, you will see it later in the analysis during scaling\nLeaving the **Sample target list** page takes you to the **Run annotation** page, where you have to confirm again that the sample and gene names are ok. If this is not the case you can adjust the annotation here.\n\nClick the **Next** button at the bottom of the page\n\nOur data file contains all required annotation:\n\n  - Cq values\n  - sample and target names\n  - sample types\n  - quantities for the standard samples\n  - grouping of the samples\n\n\n\nOnce runs are imported, you can start analyzing the data. Data consist\nof Cq values for all the wells.\n\n#### Specifying the aim of the experiment\n\nOn the **Aim** page you tell the software what type of analysis you want to do. Different types of analyses require different parameters, parameter settings and different calculations. By selecting the proper analysis type, qbase+ will only show the relevant parameters and parameter settings.\n\nSince we are doing a **gene expression analysis** in this exercise, this the option we should select. Click the **Next** button on the bottom of the page to go to the **Technical quality control** page.\n\n#### Checking the quality of technical replicates and controls\n\nThe **Technical quality control** page handles the settings of the requirements that the data have to meet to be considered high quality. For instance the maximum difference between technical replicates is defined on this page. If there are technical replicates in the data set, qbase+ will detect them automatically (they have the same sample and target name) and calculate the average Cq value. In theory, technical replicates should generate more or less identical signals.\n\n| How to set the maximum difference in Cq values for technical replicates ?\n| :---------------------------- |\n|  The quality criterium that the replicates must meet to be included for further analysis is one of the parameters in qbase+. You can set it on the **Technical quality control** page:\n\nThe default maximum allowed difference in Cq values between technical replicates is 0.5\n\nAdditionally, you can do quality checks based on the data of the positive and negative controls.\n| How to set quality requirements for the control samples ?\n| :---------------------------- |\n|  On the same **Technical quality control** page you can define the minimum requirements for a well to be included in the calculations:\n\n* **Negative control threshold** : minimum allowed difference in Cq value between the sample with the highest Cq value and the negative control with the lowest Cq value: the default is 5 which means that negative controls should be more than 5 cycles away from the sample of interest.\n* **Lower and upper boundary** : allowed range of Cq values for positive controls.\n\nExcluded means that the data are ignored in the calculations.\n\n| How to check if there are wells that do not meet these criteria ?\n| :---------------------------- |\n|  You can see flagged and excluded data by ticking the **Show details** options  on the **Technical quality control** page and clicking the **Next** button (purple) at the bottom of the page.\n\nQbase+ will open the results of the quality checks for the replicates  and the controls  on two different tabs. These tabs show lists of samples that failed the quality control criteria. When you open the replicates tab  you can get an overview of the flagged  or the excluded (purple) wells. Select the **failing**  wells.\n\nWhen the difference in Cq between technical replicates exceeds 0.5, the wells end up in the flagged or failing list. They are included in calculations unless you exclude them by unticking them. You see that the two replicates of Palm in Sample05 have very different Cq values. All other bad replicates are coming from standard samples.\nIf you are finished checking the data quality, click **Next** to go to the **Amplification efficiencies** page.\n\n#### Taking into account amplification efficiencies\n\nQbase+ calculates an amplification efficiency (E) for each primer pair (= gene). Genes have different amplification efficiencies because:\n\n  - some primer pairs anneal better than others\n  - the presence of inhibitors in the reaction mix (salts, detergents) decreases the amplification efficiency\n  - inaccurate pipetting\n\nQbase+ has a parameter that allows you to specify how you want to handle amplification efficiencies on the **Amplification efficiencies** page.\n\n| How to specify the amplification efficiencies strategy you want to use ?\n| :---------------------------- |\n|  Since we have included a dilution series for creating a standard curve in our qPCR experiment, we will select\n\n* **Use assay specific amplification efficiencies**\n* **Calculate efficiencies from included standard curves**\n\nAmplification efficiencies are calculated based on the Cq values of a serial dilution of representative template, preferably a mixture of cDNAs from all your samples. Since you know the quantity of the template in each dilution, you can plot Cq values against template quantities for each primer pair. Linear regression will fit a standard curve to the data of each gene, and the slope of this curve is used to calculate the amplification efficiency.\n\n| How to check the amplification efficiencies of the genes ?\n| :---------------------------- |\n|  Once you have made this selection, qbase+ starts calculating the efficiencies and the results are immediately shown in the **calculation efficiencies** table.\n\nIn this way, one amplification efficiency (E) for each gene is calculated and used to calculate **Relative Quantities (RQ)**:\nCq is calculated for each well by subtracting the Cq of that well from the average Cq across all samples for the gene that is measured in the well. So Cq is the difference between the Cq value of a gene in a given sample and the average Cq value of that gene across all samples. Cq is subtracted from the average because in this way high expression will result in a positive Cq and low expression in a negative Cq. \n**So at this point the data set contains one RQ value for each gene in each sample.**\n\nClick **Next** to go to the **Normalization** page.\n\n#### Normalization\n\nDifferences in amplification efficiency are not the only source of variability in a qPCR experiment. Several factors are responsible for noise in qPCR experiments e.g. differences in:\n\n  - amount of template cDNA between wells\n  - RNA integrity of samples\n  - efficiency of enzymes used in the PCR or in the reverse\n    transcription\n\nNormalization will eliminate this noise as much as possible. In this way it is possible to make a distinction between genes that are really upregulated and genes with high expression levels in one group of samples simply because higher cDNA concentrations were used in these samples.\nIn qPCR analysis, normalization is done based on housekeeping genes.\n\nHousekeeping genes are measured in all samples along with the genes of interest. In theory, a housekeeping gene should have identical RQ values in all samples. In reality, noise generates variation in the expression levels of the housekeeping genes. This variation is a direct measure of the noise and is used to calculate a normalization factor for each sample.\nThese normalization factors are used to adjust the RQ values of the genes of interest accordingly so that the variability is eliminated.\n\nThese adjusted RQ values are called **Normalized Relative Quantities (NRQs)**. In qbase+ housekeeping genes are called reference genes. In our data set there are three reference genes: Stable, Non-regulated and Flexible. On the **Normalization page** we can define the normalization strategy we are going to use, appoint the reference genes and check their stability of expression.\n\n| How to specify the normalization strategy you want to use ?\n| :---------------------------- |\n|  You can specify the normalization strategy you want to use on the Normalization method page:\n\n* **Reference genes** normalization is based on the RQ values of the housekeeping genes\n* **Global mean** normalization calculates normalization factors based on the RQ values of all genes instead of only using the reference genes. This strategy is recommended for experiments with more than 50 random genes. Random means that the genes are randomly distributed over all biological pathways.\n* **Custom value** normalization is used for specific study types. This strategy allows users to provide custom normalization factors such as for example the cell count.\n* **None** means that you choose to do no normalization at all. This option should only be used for single cell qPCR.\n\nWe have incorporated 3 housekeeping genes in our experiment so we select the **Reference genes** strategy.\n\n| How to appoint reference targets ?\n| :---------------------------- |\n|  You have to indicate which targets should be used as reference genes since qbase+ treats all genes as targets of interest unless you explicitly mark them as reference genes on the Normalization method page:\n\nWe have measured 3 housekeeping genes: Stable, Flexible and Non-regulated so we tick the boxes in front of their names.\n\nIt&#39;s not because you have appointed genes as reference genes that they necessarily are **good** reference genes. They should have stable expression values over all samples in your study. Fortunately, qbase+ checks the quality of the reference genes. For each appointed reference gene, qbase+ calculates two indicators of expression stability\n\n  - **M** (geNorm expression stability value): calculated based on the pairwise variations of the reference genes.\n  - **CV** (coefficient of variation): the ratio of the standard deviation of the NRQs of a reference gene over all samples to the mean NRQ of that reference gene.\n\nIt is considered that the higher these indicators the less stable the reference gene.\n\n| Are Flexible, Stable and Nonregulated good reference targets ?\n| :---------------------------- |\n|  M and CV values of the appointed reference genes are automatically calculated by qbase+ and shown on the Normalization method page:\n\nThe default limits for M and CV were determined by checking M-values and CVs for established reference genes in a pilot experiment that was done by Biogazelle. Based on the results of this pilot experiment, the threshold for CV and M was set to 0.2 and 0.5 respectively.\nIf a reference gene does not meet these criteria it is displayed in red. As you can see the M and CV values of all our reference exceed the limits and are displayed in red.\n\nIf the quality of the reference genes is not good enough, it is advised to remove the reference gene with the worst M and CV values and re-evaluate the remaining reference genes.\n\n| Which reference target are you going to remove ?                                                                                                                                    |\n| :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Both the M-value and the CV are measures of variability. The higher these values the more variable the expression values are. So we will remove the gene with the highest M and CV. |\n\nYou can remove a reference gene simply by unticking the box in front of its name.\n\n| Are the two remaining reference genes good references ?\n| :---------------------------- |\n|  After removing Flexible as a reference gene the M and CV values of the two remaining reference genes decrease drastically to values that do meet the quality criteria. M and CV values that meet the criteria are displayed in green.\n\nThis exercise shows the importance of using a minimum of three reference genes. If one of the reference genes does not produce stable expression values as is the case for Flexible, you always have two remaining reference genes to do the normalization.\n\n[See how to select reference genes for your qPCR experiment](http://wiki.bits.vib.be/index.php/Using_GeneVestigator_to_select_candidate_reference_genes).\n\n**So after normalization you have one NRQ value for each gene in each sample.**\n\nClick **Next** to go to the **Scaling** page.\n\n#### Scaling\n\nRescaling means that you calculate NRQ values relative to a specified reference level.\n\nQbase+ allows you to rescale the NRQ values using one of the following as a reference:\n\n  - the sample with the minimal expression\n  - the average expression level of a gene across all samples\n  - the sample with the maximal expression\n  - a specific sample (e.g. untreated control)\n  - the average of a certain group (e.g. all control samples): this is\n    often how people want to visualize their results\n  - positive control: only to be used for copy number analysis\n\nAfter scaling, the expression values of the choice you make here will be set to 1 e.g. when you choose **average** the average expression level across all samples will be set to 1 and the expression levels of the individual samples will be scaled accordingly.\n\n| How to scale to the average of the untreated samples ?\n| :---------------------------- |\n|  You can specify the scaling strategy on the **Scaling** page. Select **Scale to group** and set the **Scaling group** to the **untreated** samples . This is one of the reasons why you need the grouping annotation.\n\nRescaling to the average of a group is typically used to compare results between 2 groups, e.g. treated samples against untreated controls. After rescaling, the average of the NRQs across all untreated samples is 1 and the NRQs of the treated samples are scaled accordingly.\n\nClick **Next** to go to the **Analysis** page.\n\n#### Visualization of the results\n\nOne of the things you can select to do on the **Analysis** page is viewing the relative expression levels (= scaled NRQs) of each of the genes in a bar chart per gene. It is recommended to visualize your results like this.\n\nIt is possible to view the relative expression levels of all genes of interest on the same bar chart. You can use this view to see if these genes show the same expression pattern but you cannot directly compare the heights of the different genes because each gene is independently rescaled\\!\n\n| How to visualize single gene expression bar charts ?\n| :---------------------------- |\n|  Select **Visually inspect results For individual targets** on the **Analysis** page and click **Finish**\n\n| How to visualize the expression levels of Palm in each sample ?\n| :---------------------------- |\n|  Select **Visually inspect results For individual targets** on the **Analysis** page and click **Finish**\n\nThe **Target** select box allows you to select the gene you want to view the expression levels of. Relative expression levels are shown for each sample. Error bars are shown and represent the technical variation in your experiment (variation generated by differences in amounts pipetted, efficiency of enzymes, purity of the samples...).\n\nYou see that Palm has a low expression level and a very large error bar in Sample05 because the two replicates of this sample had very different Cq values. You can group and colour the bars according to a property.\n\n| How to group the bars of Palm according to treatment (so treated at one side and untreated at the other side)\n| :---------------------------- |\n|  In the **Grouping** section you can specify the property you want to group by.\n\n| How to view average expression levels in each group ?\n| :---------------------------- |\n|  In the **Grouping** section you can choose to plot individual samples as shown above but you can also choose to **plot group average** expression levels.\n\nThe error bars that you see here represent biological variation and will be used later on in the statistical analysis. The error bars are 95% confidence intervals which means that they represent the range that will contain with 95% certainty the real average expression level in that group of samples.\nThe nice characteristic of 95% confidence intervals is the following:\n\n  - if they do not overlap you are sure that the expression levels in the two groups are significantly different, in other words the gene is differentially expressed\n  - if they do overlap you cannot say that you are sure that the expression levels are the same. You simply dont know if the gene is differentially expressed or not.\n\n| Assess the effect of switching the Y-axis to a logarithmic scale for Palm.\n| :---------------------------- |\n|  In the **Y axis** section you can specify if you want a linear or logarithmic axis.\nAs you can see you do not change the expression values, you just change the scale of the Y axis. Switching the Y-axis to a logarithmic scale can be helpful if you have large differences in NRQs between different samples\n\n| Assess the effect of switching the Y-axis to a logarithmic scale for Flexible.\n| :---------------------------- |\n|  Switch to the bar charts of Flexible. By switching the Y-axis to logarithmic you can now see more clearly the differences between samples with small NRQs.\n\n#### Statistical analysis\n\nOnce you generate target bar charts you leave the **Analysis wizard** and you go to the regular qbase+ interface. Suppose that you want to perform a statistical test to prove that the difference in expression that you see in the target chart is significant.\nAt some point, qbase+ will ask you if your data is coming from a normal distribution. If you don&#39;t know, you can select **I don&#39;t know** and qbase+ will assume the data are not coming from a normal distribution and perform a stringent non-parametric test.\nHowever, when you have **7 or more replicates per group**, you can check if the data is normally distributed using a statistical test. If it is, qbase+ will perform a regular t-test. The upside is that the t-test is less stringent than the non-parametric tests and will find more DE genes. However, you may only perform it on normally distributed data. If you perform the t-test on data that is not normally distributed you will generate false positives i.e. qbase+ will say that genes are DE while in fact they are not. Performing a non-parametric test on normally distributed data will generate false negatives i.e. you will miss DE genes.\n\nChecking if the data is normally distributed can be easily done in GraphPad Prism. To this end you have to export the data.\n| How to export the data ?\n| :---------------------------- |\n|  To export the results click **the upward pointing arrow** in the qbase+ toolbar:\nYou want to export the normalized data so select **Export Result Table (CNRQ)**:\nYou will be given the choice to export results only (CNRQs) or to include the errors (standard error of the mean) as well . We don&#39;t need the errors in Prism so we do not select this option.\nThe scale of the Result table can be linear or logarithmic (base 10) . Without user intervention, qbase+ will automatically log10 transform the CNRQs prior to doing statistics. So we need to check in Prism if the log transformed data are normally distributed.\nAdditionally, you need to tell qbase+ where to store the file containing the exported data. Click the **Browse** button for this .\n\nExporting will generate an Excel file in the location that you specified. However, the file contains the results for all samples and we need to check the two groups (treated and untreated) separately. The sample properties show that the even samples belong to the treated group and the odd samples to the untreated group.\nThis means we have to generate two files:\n\n  - [a file containing the data of the untreated samples](http://data.bits.vib.be/pub/trainingen/qbasePLUS/resultslog.csv)\n  - [a file containing the data of the treated samples](http://data.bits.vib.be/pub/trainingen/qbasePLUS/resultslogTreated.csv)\n\nNow we can open these files in Prism to check if the data is normally distributed.\n\n| How to import the data of the untreated samples in Prism ?\n| :---------------------------- |\n|  \n* Open Prism\n* Expand **File** in the top menu\n* Select **New**\n* Click **New Project File**\n* In the left menu select to create a **Column** table. Data representing different groups (in our case measurements for different genes) should always be loaded into a column table.\n* Select **Enter replicate values, stacked into columns** (this is normally the default selection) since the replicates (measurements for the same gene) are stacked in the columns.\n* Click **Create**\n\nPrism has now created a table to hold the data of the untreated samples but at this point the table is still empty. To load the data:\n\n* Expand **File** in the top menu\n* Select **Import**\n* Browse to the resultslog.csv file, select it and click **Open**\n* In the **Source** tab select **Insert data only**\n* Since this is a European csv file commas are used as decimal separators so in contrast to what its name might imply, semicolons and not commas are used to separate the columns in the csv file (you can open the file in a text editor to take a look). In American csv files dots are used as decimal separator and the comma is used to separate the columns. Prism doesn&#39;t know the format of your csv file so you have to tell him the role of the comma in your file. Select **Separate decimals**\n* Go to the **Filter** tab and specify the rows you want to import (the last rows are these of the standard and the water samples, you don&#39;t want to include them)\n* Click **Import**\n\nAs the file is opened in Prism you see that the first column containing the sample names is treated as a data column. Right click the header of the first column and select **Delete**\n\n| How to check if the data of the untreated samples comes from a normal distribution ?\n| :---------------------------- |\n|  \n* Click the **Analyze** button in the top menu\n* Select to do the **Column statistics** analysis in the **Column analyses** section of the left menu\n* In the right menu, deselect **Flexible**. It&#39;s a bad reference gene so you will not include it in the qbase+ analysis so there&#39;s no point checking its normality (it is probably not normally distributed). In that respect you could also deselect the other two reference genes since you will do the DE test on the target genes and not on the reference genes.\n* Click **OK**\n* In the **Descriptive statistics** and the **Confidence intervals** section deselect everything except **Mean, SD, SEM**. These statistics is not what we are interested in: we want to know if the data comes from a normal distribution. The only reason we select Mean, SD, SEM is because if we make no selection here Prism throws an error.\n* In the **Test if the values come from a Gaussian distribution** section select the **D&#39;agostino-Pearson omnibus test** to test if the data are drawn from a normal distribution. Although Prism offers three tests for this, the D&#39;Agostino-Pearson test is the safest option.\n* Click **OK**\n\nPrism now generates a table to hold the results of the statistical analysis: As you can see, the data for Palm are not normally distributed.\n\nSince we found that there&#39;s one group of data that does not follow a normal distribution, it&#39;s no longer necessary to check if the treated data are normally distributed but you can do it if you want to. We will now proceed with the statistical analysis in qbase+. Statistical analyses can be performed via the **Statistics wizard**.\n\n| How to open the Statistics wizard ?\n| :---------------------------- |\n|  You can open it in the **Project Explorer** (window at the left):\n\n* expand **Project1** if it&#39;s not yet expanded\n* expand the **Experiments** folder in the project if it&#39;s not yet expanded\n* expand the **GeneExpression** experiment if it&#39;s not yet expanded\n* expand the **Analysis** section if it&#39;s not yet expanded\n* expand the **Statistics** section\n* double click **Stat wizard**\n\nThis opens the **Statistics wizard** that allows you to perform various kinds of statistical analyses.\n\n| Which kind of analysis are you going to do ?                                                                                                                                                                                                                                                      |\n| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| On the **Goal** page: Select **Mean comparison** since you want to compare expression between two groups of samples so what you want to do is comparing the mean expression of each gene in the treated samples with its mean expression level in the untreated samples. Click **Next**. |\n\n| How to define the groups that you are going to compare ?\n| :---------------------------- |\n|  On the **Groups** page: specify how to define the two groups of samples that you want to compare. Select **Treatment** as the grouping variable to compare treated and untreated samples. Click **Next**.\n\n| How to define the genes that you want to analyze ?\n| :---------------------------- |\n|  On the **Targets** page: specify for which targets of interest you want to do the test. Deselect **Flexible** since you do not want to include it in the analysis. It&#39;s just a bad reference gene. Click **Next**.\n\nOn the **Settings** page you have to describe the characteristics of your data set, allowing qbase+ to choose the appropriate test for your data. \n\nThe first thing you need to tell qbase+ is whether the data was drawn from a normal or a non-normal distribution. Since we have 8 biological replicates per group we can do a test in Prism to check if the data are normally distributed.\n\n| Which gene(s) is/are differentially expressed ?\n| :---------------------------- |\n|  On the **Settings** page you describe the characteristics of your data set so that qbase+ can choose the ideal test for your data. For our data set we can use the default settings. Click **Next**. In the results **Table** you can see that the p-value for Palm is below 0.05 so Palm is differentially expressed.\n\n\n\nIn this example we will analyze data from another expression study with the following characteristics:\n\nAll samples fit in a single run: [Run7](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run7.xls)\nWe have the following samples:\n\n  - 5 control samples: control1, control2\n  - 5 treated samples: treated1, treated2\n  - 1 no template control: NTC\n\nThe expression of the following genes was measured:\n\n  - 2 reference genes: refgene1 and refgene2\n  - 2 genes of interest: gene1 and gene2\n\nThere are two technical replicates per reaction\n\n#### Creating a new experiment\n\n| Create a new Experiment called GeneExpression2 in Project1\n| :---------------------------- |\n| You can find the details on how to create a new experiment in Creating a project and an experiment\n\n#### Loading the data\n\n| Import [Run7](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run7.xls). This file is in qBase format.                    |\n| :-------------------------------------------------------------------------------------------------------------------------------------- |\n| You can find the details on how to import the data file in the **Loading the data into qbase+** section of Analyzing data from a geNorm pilot experiment in qbase+ |\n\n#### Adding sample annotation\n\nDownload the [the sample properties file](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Sample_Properties_GE2.xlsx).\n| Add a custom sample property called Treatment.\n| :---------------------------- |\n| You can find the details on how to add a custom sample property in the **Adding annotation to the data** section of Loading data into qbase+\n\n#### Analyzing the data\n\n| Choose the type of analysis you want to perform.\n| :---------------------------- |\n| \n\n| Check controls and replicates.\n| :---------------------------- |\n| First set the minimum requirements for controls and replicates  You see that 6 replicates do not meet these requirements . Select to **Show details and manually exclude bad replicates**\nAll negative controls pass the test . Positive controls were not included in this analysis. Qbase+ will now open the results for the failing replicates: as you can see the difference in Cq values between these replicates is not that big. They fail to meet the requirement just slightly.\n\n| Which amplification efficiencies strategy are you going to use ?\n| :---------------------------- |\n| You don&#39;t have data of serial dilutions of representative template to build standard curves so the only choice you have is to use the default amplification efficiency (E = 2) for all the genes.\n\n| Appoint the reference genes as reference targets.\n| :---------------------------- |\n| You can find the details on how to appoint reference targets in the **Normalization** section of Analyzing gene expression data in qbase+\n\n| Is the stability of the reference genes ok ?\n| :---------------------------- |\n| In the **Reference target stability window** the M and CV values of the reference genes are shown in green so the stability of the reference genes is ok. You can find the details on how to check reference target stability in the **Normalization** section of [](Analyzing_gene_expression_data_in_qbase+\&quot; title=\&quot;wikilink)Analyzing gene expression data in qbase+\n\n| Which scaling strategy are you going to use ?\n| :---------------------------- |\n| Since you have a treated and a **control** group, it seems logical to use the average of the control group for scaling. You can find the details on how to specify the scaling strategy in the **Scaling** section of Analyzing gene expression data in qbase+\n\nLook at the target bar charts.\n\n| In the target bar charts group the samples according to treatment.\n| :---------------------------- |\n| You can find the details on how to group the samples in the **Visualization of the results** section of Analyzing gene expression data in qbase+\n\nThe samples of each group are biological replicates so you might want to generate a plot that compares the average expression of the treated samples with the average expression of the untreated samples.\n\n| In the target bar charts plot the group averages instead of the individual samples.\n| :---------------------------- |\n| In the **Grouping** section at the bottom of the chart you can select **Plot group average**:\n\n| Are there any genes for which you see a clear difference in expression between the two groups ?\n| :---------------------------- |\n| For gene 1, the mean expression levels in the two groups are almost the same and the error bars completely overlap.\n\nWhen you look at the title of the Y-axis, you see that 95% confidence levels are used as error bars. In case of 95% confidence intervakls you can use the following rules:\n\n* if they do not overlap: you are certain that the difference between the means of the two groups is significant\n* if they do not overlap: you know nothing with certainty: the means can be different or they can be the same\n\nSo for gene 1 the means are very close but just based on the plot we may not make any conclusions with certainty. For gene 2, the mean expression levels in the two groups are very different and the error bars do not overlap. So the 95% confidence intervals do not overlap meaning that we can be certain that the difference between the means of the two groups is significant.\n\n| Use a statistical test to compare the expression levels between the two groups of samples ?\n| :---------------------------- |\n| You only have 5 replicates per group so you cannot test if the data comes from a normal distribution. Qbase+ will assume they&#39;re not normally distributed and perform a non-parametric Mann-Whitney test.\n\nThe p-value of gene2 is smaller than 0.05 so it has a statistically significant difference in expression levels in treated samples compared to untreated samples. For gene1 the p-value is 1 so we have no evidence to conclude that the expression of gene1 is different in treated compared to untreated samples. You can find the details on how to compare the means of the two groups in the **Statistical analysis** section of Analyzing gene expression data in qbase+\n&quot;,&quot;The following exercise will make you familiar with the Primer3Plus software for designing primers for PCR. Primer3Plus is the user-friendly version of Primer3, the standard software for primer design.\n\n### Criteria for qPCR primers\n\nPrimers for qPCR have to follow all the gudelines for regular primers is and an additional set of rules specific for qPCR primers:\n\n  - qPCR products are small: 80-160 bp\n  - use intron or exon-exon junction spanning primers to detect genomic DNA contamination in the RNA samples. Primers of intron spanning primer pairs are located at both sides of an intron and will therefore generate a larger product on genomic DNA (containing the intron). Primer pairs containing an exon-exon junction spanning primer will not generate a PCR product on genomic DNA since the exon-exon junction only exist in the cDNA.\n  - primer length between 9 and 30 bp with an optimum at 20 bp\n  - melting temperature (Tm) of the primers between 58 and 60C with an optimum at 59C\n  - maximum Tm difference between the primers of a pair: 2C\n  - GC content of the primers between 30 and 80% with an optimum at 50%\n  - the 5 nucleotides at the 3&#39; end of the primers should have no more than 2 G or C bases\n  - avoid runs of 4 or more identical nucleotides (especially Gs)\n  - primers must specifically target the region you want to amplify\n\nThere are many programs for designing primers, the most important ones:\n\n  - [Primer3](http://frodo.wi.mit.edu/) \\[1\\] or use it&#39;s user-friendly version: [Primer3Plus](http://primer3plus.com/cgi-bin/dev/primer3plus.cgi)\\[2\\]\n  - [PrimerBLAST](http://www.ncbi.nlm.nih.gov/tools/primer-blast/index.cgi?LINK_LOC=BlastHome)\\[3\\]\n\nThe major downside of Primer3 and Primer3Plus is the fact that you have to check the specificity of the primers yourself. Primer3 will suggest a number of primer pairs that fulfill all of the above requirements, but Primer3 will not check the specificity of the primers. So you have use BLAST to check the specificity of the suggested primer pairs. Very often, the selected primers are not specific and you have to repeat the entire Primer3 analysis.\nIf you use Primer3 and do the BLAST yourself, BLAST against Refseq sequences unless they are not available for the organism you work with or you have reasons to believe that they are not complete (i.e. they do not represent the full genome). For model organisms, you can BLASTagainst the Refseq database. Limit the database to sequences from the organism you work with.\nAdditionally, it is especially important to check that the primers are specific at the 3&#39; end because that&#39;s the site where the polymerase will attach nucleotides. So it is recommended to not use primers that contain long identical stretches (\\&gt; 15nt for primers of 20nt long) to other regions in the genome, and certainly not if these stretches comprise the last nucleotide at the 3&#39; end of the primer.\nFor these exercises we will use PrimerBLAST since [it uses the same algorithm to pick primers as Primer3](http://www.ncbi.nlm.nih.gov/tools/primer-blast/primerinfo.html) \\[4\\] and does the specificity check for you\\!\n\n## Designing qPCR primers for the fruit fly tap gene\n\n### Designing qPCR primers using PrimerBLAST\n\nThe RefSeq entry NM_079400 contains the sequence of the D. melanogaster mRNA coding for tap, the target of Poxn. Tap encodes a bHLH protein expressed in larval chemosensory organs and involved in the response to sugar and salt. We wish to amplify the region encoding the Helix-loop-helix domain. In the sequence of the RefSeq record, the domain is located between position +577 and +745.\nWe want to design qPCR primers for measuring the expression level of the hlh domain using SYBR green. Remember that it is advised to design intron/exon-exon junction spanning primers for qPCR experiments that are based on fluorescent labels to detect/avoid amplification of contaminating genomic DNA.\n\n| Check in NCBIs Gene database if the hlh domain contains any introns ? |\n| :------------------------------ |\n|To know the location of the introns, you need the genomic sequence instead of the mRNA sequence.\n\n - Go to [the NCBI RefSeq record](https://www.ncbi.nlm.nih.gov/nuccore/NM_079400).\n - In the right menu click the link to the **Gene** record\n - In the **Genomic regions, transcripts and products** secton you can see that the gene contains no introns: the transcript is not chopped up into pieces when aligned to the genome. Click [here](https://www.ncbi.nlm.nih.gov/gene/39934) for an example of a gene with introns.\n\nNext, we will design primers to measure the expression of the hlh domain.\n\n| Go to Primer BLAST by using the link in the Refseq record |\n| :------------------------------ |\n|Go back to the RefSeq mRNA record. There, you can go directly to PrimerBLAST by clicking the **Pick Primers** link in the **Analyze this sequence** section of the right menu.\n\nSince you want to measure the expression of the hlh domain you want\nprimers that are located inside the domain.\n\n| Define the range of the sequence in which you want to design primers. |\n| :------------------------------ |\n|You have to specify the range as follows:\n\n| Define the primer parameters to comply with the rules of qPCR primer design: product size and Tm. |\n| :------------------------------ |\n|To comply with the rules for qPCR primer design, you have to change the settings for PCR product size and melting temperature:\n\n| The PrimerBLAST automatically decides to check primer specificity in the Drosophila (organism ID: 7227) RefSeq mRNA database which is exactly what you want. For the qPCR you are going to use RNA samples from fruitfly. This means that the primers will only come into contact with Drosophila mRNAs so you only have to check their specifity in this database. Make sure the last 2 nucleotides are completely specific. |\n| :------------------------------ |\n|You want to ensure that the 3&#39; end of the primers really is specific:\n\nThe PrimerBLAST gives you a set of 9 primer pairs that are specific (according to the criteria that you have specified) and that fulfill all other requirements that you have defined. Look at the detailed report of the first primer pair:\nAll parameters are quite self-explanatory except for the Self complementary and Self 3&#39;complementarity scores.\n\n  - The first score represents the local alignment score when aligning a primer to itself. The scoring system gives 1.00 for a match, -1.00 for a mismatch. This means that the lower the score (the more mismatches), the less likely that the primer binds to itself.\n  - The second score represents the global alignment score when aligning a primer to itself. Here again, the lower the score, the better.\n\nThe scores are followed by information on the specificity of the primer: alignments of the two primers to all target sequences from the database that match the criteria that you specified. In these alignments dots represent matching nucleotides while letters represent mismatches. A specific primer pair will have two alignments (one for each primer): both perfect alignments (all dots) to the sequence you want to amplify.\n\n### Analyzing primer characteristics using OligoAnalyzer\n\n[OligoAnalyzer](https://eu.idtdna.com/calc/analyzer) is a tool implemented by ID\\&amp;T (who sell primers) to check the characteristics of your primers. Take the first primer that is suggested by Primer-BLAST, the pair resulting in a product of 100bp.\n\n| What&#39;s the Tm of the first primer ? |\n| :------------------------------ |\n|Copy the sequence of the first primer in the **Sequence** box, adjust the concentrations to these that are typically used in PCR (see slides) and click **Analyze**:\nAs you can see the predicted melting temperature is 63.9 C, which is slightly different from the prediction made by BLAST. There are many different methods to predict Tm and each method will give a different result. Assumed concentrations of primers and ions have an enormous impact on the Tm prediction. So don&#39;t worry about these differences: these are theoretical calculations anyway, the only way to determine Tm values is by doing actual PCR. As long as the difference in Tm between the two primers is not too large, everything is fine.\n\n| What&#39;s the Tm of the second primer ?                                                                                                                                             |\n| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Copy the sequence of the second primer in the **Sequence** box and click **Analyze**. The predicted melting temperature is also 63.9 C , the same Tm as the first primer. |\n\nRemember that the second primer had a large Self complementarity score according to PrimerBLAST.\n\n| Check the self-complementarity of the second primer in OligoAnalyzer ? |\n| :------------------------------ |\n|Click **Self-Dimer**:\n\nYou see that the highest scoring alignment indeed has 6 matches, giving a score of 6 as predicted by PrimerBLAST.\n\n| Do you expect this self-complementarity will give problems in the PCR ? |\n| :------------------------------ |\n|No, the complementarity is concentrated at the center of the primer, not at the 3&#39; end. Since polymerases add bases at the 3 end of the primer, the primer duplex cannot be extended so it will not give rise to aspecific products. [ID&amp;amp;T](https://eu.idtdna.com/pages/docs/default-source/default-document-library/idt_self-dimer_and_hetero-dimer_results_guide.pdf) recommends to avoid complementary stretches of more than 2 bp at the 3 end.\nHowever, even if the primer dimer cannot be extended, it could interfere when its formation competes with the annealing of primer and target. This is only the case when the stability of the dimer is similar to the stability of a perfectly matched primer-target duplex. The stability of the perfectly matched duplex is shown as a Maximum Delta G at the top of results. So non-extendable dimer structures that are much shorter than the intended duplex, as we have here, are not going to disrupt the PCR reaction.\nIt is advised to review all possible interactions between primers so both Self-Dimer (primers binding to themselves) and Hetero-Dimer (primers binding to each other) interactions between primers are examined.\n\n| Is it likely that the primers bind to each other ? |\n| :------------------------------ |\n|Click **Hetero-Dimer**:\n\nThis opens a text box to enter the second primer. Click **Analyze**. There is one structure (the fourth one) that looks problematic because there is a stretch of 3 matching nucleotides at the 3&#39;end of one of the primers.\n\nSo you might consider taking a look at the second pair of primers that PrimerBLAST suggests. On the other hand, this structure is has relatively high free energy (delta G). The structure with the lowest total free energy, the target-primer duplex, is most important because it will dominate in solution. Structures with higher free energy are less stable and will be present in smaller amounts in the reaction mixture.\n\nTake a look at the second primer pair that was suggested by PrimerBLAST.\n\n| Is it likely that these primers bind to each other ?                                 |\n| :----------------------------------------------------------------------------------- |\n| No these primers do not form duplex structures that could pose a problem during PCR. |\n\n## Designing qPCR primers for the human F9 gene\n\n### Designing qPCR primers using PrimerBLAST\n\nThe RefSeq entry NM_000133.3 contains the sequence of the human mRNA coding for coagulation factor F9. The gene contains 8 coding exons and gives rise to a transcript of 2780 bp encoding a protein of 461 amino acids.\nNext, we want to design primers to measure the expression of the F9 gene.\n\nGo to [the RefSeq record of this transcript](http://www.ncbi.nlm.nih.gov/nuccore/NM_000133.3) to study its structure. When you scroll down to the **features** section you see that the CDS is located from position 40 to position 1415. Since RNA degradation starts at the 5&#39;end of transcripts, we don&#39;t want to pick primers at the 5&#39;end. On the other hand, we don&#39;t want to pick primers in the long 3&#39;UTR either because it doesn&#39;t contain any introns (the exons are all coding) and we want to design exon-exon junction or intron spanning primers.\nLet&#39;s try to find exon-exon junction spanning primers between position 400 and 1600, with optimal anneal temperature = 60.\n\n| Find primers that fulfill the above defined criteria |\n| :------------------------------ |\n|Go to [PrimerBLAST](http://www.ncbi.nlm.nih.gov/tools/primer-blast/index.cgi?LINK_LOC=BlastHome) and fill in the form as follows:\n\nExclude predicted sequences in the database to search in .\n\n| Find primers that fulfill the above defined criteria |\n| :------------------------------ |\n|Go to [PrimerBLAST](http://www.ncbi.nlm.nih.gov/tools/primer-blast/index.cgi?LINK_LOC=BlastHome) and fill in the remainder of the form as follows:\n\nThe PrimerBLAST gives you a set of 10 primer pairs. Look at the detailed\nreport of the first primer pair:\n\nAs you can see the primers are not specific: they can bind to various other targets albeit with lower affinity because of the mismatches . The best option seems to be primer pair 7, which binds to both F9 transcript variants and potentially to one unintended target, but as you can see the last nucleotide at the 3&#39; end of both primers are specific.\n\n### In silico PCR in the UCSC Browser\n\nWe will proceed using the third primer pair Primer-BLAST suggests. You can visualize the PCR product (and additional annotation) in the UCSC Genome Browser using [UCSC&#39;s In Silico PCR tool](http://genome.ucsc.edu/cgi-bin/hgPcr).\nSelect the most recent version of the human genome and paste the sequences of forward and reverse primers in their respective boxes. Click **submit**\nNormally, this returns the location and the sequence of the PCR product but our primer pair doesn&#39;t return a match. When you think about this was to be expected since we are working with exon-exon junction spanning primers that are not able to match the genome sequence. So checking SNPs is not so straight-forward in the case of exon-exon junction spanning primers.\nWe will repeat the primer search now searching for intron-spanning primers to show you how to use the in silico PCR tool. Taking into account the fact that the results for the exon-exon junction spanning primers were so messy we will make the search more stringent this time:\n\n  - We will the minimum number of mismatches to 4\n  - and at least 3 mismatches in the last 3 bps at the 3&#39;end\n\n| Find intron spanning primers that fulfill the above defined criteria |\n| :------------------------------ |\n|Go back to the Primer-BLAST and fill in the form like in the previous exercise except that they should span an intron:\n\nPrimer-BLAST returns 10 primer pairs. Again the seventh primer pair is\nthe specific one.\n\n| Take the seventh suggested primer pair and check for SNPs in the UCSC Browser |\n| :------------------------------ |\n|Go to [PrimerBLAST](http://www.ncbi.nlm.nih.gov/tools/primer-blast/index.cgi?LINK_LOC=BlastHome) and paste the sequences of forward and reverse primers in their respective boxes.\nThis time the search finds a PCR product:\n\nClicking the location visualizes the PCR product in the UCSC genome browser. Remove unnecessary trancks by right clicking the box in front of them and selecting **hide**\n\nAdd tracks showing relevant annotation like position of SNPs...\n\nSetting the SNPs track from **hide** to **full** shows the SNPs in the browser. Center the forward primer by grabbing and dragging it to the center.\n\nZoom in to **base** display to see if the forward primer is matching any SNPs.\n\nAs you can see the forward primer does match two SNPs but none of them are located near the 3&#39;end of the primer.\n\n1.  &lt;http://frodo.wi.mit.edu/&gt;\n2.  &lt;http://primer3plus.com/cgi-bin/dev/primer3plus.cgi&gt;\n3.  &lt;http://www.ncbi.nlm.nih.gov/tools/primer-blast/index.cgi?LINK_LOC=BlastHome&gt;\n4.  &lt;http://www.ncbi.nlm.nih.gov/tools/primer-blast/primerinfo.html&gt;&quot;,&quot;# Data structures in R\n{:.no_toc}\n\nThe power of R lies not in its ability to work with simple numbers but in its ability to work with large datasets. R has a wide variety of data structures including scalars, vectors, matrices, data frames, and lists.\n\n### Vectors\nThe simplest data structure is the *vector*, a single row consisting of data values of the same type, e.g. all numbers, characters, Booleans... \n\n#### Creating a vector\nThe function **c()** (short for \&quot;combine values\&quot; in a vector) is used to create vectors. The only arguments that need to be passed to c() are the  values that you want to combine into a vector. \nYou can create a **numeric** (a), **character** (b) or **logical** (c) vector:\n```\na &lt;- c(1,2,5.3,6,-2,4)\nb &lt;- c(\&quot;janick\&quot;,\&quot;jasper\&quot;,\&quot;niels\&quot;)\nc &lt;- c(TRUE,TRUE,TRUE,FALSE,TRUE,FALSE)\n```\nYou can also create a vector by **joining existing vectors with the c () function:**\n```\nx1 &lt;- c(1,2,3)\nx2 &lt;- c(3,4)\nc(x1,x2)\n# [1] 1 2 3 3 4\n```\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Data Creation: vectors** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 4a\n&gt;\n&gt; You count every day how many plants of the initial set of 40 plants developed lesions as a result of a mold infection. \n&gt; \n&gt; 1. Create a vector called Plants_with_lesions containing the results of your counts: 1,3,4,2,6\n&gt; 2. Create a vector days containing the days of the week in the following format: Mon, Tues, Wednes, Thurs, Fri.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  &gt; Plants_with_lesions &lt;- c(1,3,4,2,6)\n&gt;    &gt;  &gt; days &lt;-  c(\&quot;Mon\&quot;,\&quot;Tues\&quot;,\&quot;Wednes\&quot;,\&quot;Thurs\&quot;,\&quot;Fri\&quot;)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 4b\n&gt;\n&gt; Create a vector newVector with the following elements: 2,5,5,3,3,6,2 and print its content.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  newVector &lt;- c(2,5,5,3,3,6,2)\n&gt;    &gt;  newVector\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\nIf you need a sequence of consecutive integers you can create it with the **start:end** notation, e.g. a vector with values from 5 through 9\n```\n5:9\t\n# [1] 5 6 7 8 9\n```\nYou can also define a decreasing sequence of integers:\n```\n9:5\t\n# [1] 9 8 7 6 5\n```\nYou can create the same vector with the seq() function:\n```\nseq(5,9)  \n# [1] 5 6 7 8 9\n```\n\nBut seq (short for sequence) can do a lot more: it allows to take increments other than 1. It takes four arguments:\n- *from*: the first number in the sequence\n- *to*: the last possible number in the sequence. \n- *by=increment*: increment, can be added or subtracted depending on the start and the end of the sequence. If from &gt; to then subtract increment, if from &lt; to then add increment.\n- *length.out*: alternative to end, number of elements in the vector.\n\nAs you can see, some arguments of a function have a name, e.g. the increment argument is called *by*. \n\nThe **rep()** function **repeats** a value a specified number of times.\n```\nrep(\&quot;bla\&quot;, 3)\n# [1] \&quot;bla\&quot; \&quot;bla\&quot; \&quot;bla\&quot;\n```\nYou can combine these functions with the c() function to make more complicated vectors:\n```\nc(rep(1,3), rep(2,3), rep(3,3))\n# [1] 1 1 1 2 2 2 3 3 3\n```\n\nTo generate a **random** set of **numbers** drawn from a normal distribution with a given mean and spread use the **rnorm(n, mean = 0, sd = 1)** function where:\n- *n*: how many random numbers do you want ?\n- *mean*: mean of the normal distribution\n- *sd*: standard deviation of the normal distribution\n```\nrnorm(1000, 3, 0.25)\n```\ngenerates 1000 numbers from a normal distribution with mean 3 and sd=0.25\n\nThe normal distribution implies that numbers close to the mean have a higher probability of occurring than numbers far from the mean.\n\nIf you want a set of random numbers from a uniform distribution (every number in the specified range has the same probability of being drawn) you can use the **runif(n, min=0, max=1)** function where:\n- *n*: how many random numbers do you want ?\n- *min*: lowest number of the range of numbers to choose from\n- *max*: highest number of the range of numbers to choose from\n\nThe most freedom is given by the **sample(x, size, replace = FALSE)** function: it takes a random sample of a specified size from the elements of x either with or without replacement:\n- *x*: a vector of elements from which to choose\n- *size*: how many random numbers do you want ?\n- *replace*: place sampled numbers back in set or not ?\n```\nsample(c(0,1), 100, replace=TRUE)\n```\t\ngenerates a set of 100 random zeros or ones.\n\nSuppose you want to simulate 10 rolls of a dice. Because the outcome of a single roll is a number between 1 and 6, your code looks like this:\n```\nsample(1:6, 10, replace=TRUE)\n# [1] 2 2 5 3 5 3 5 6 3 5\n```\nYou tell sample() to return 10 values, each in the range 1:6. Because every roll of dice is independent, you sample with replacement. This means that you put the element you?ve drawn back into the list of values to choose from.\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 4c\n&gt;\n&gt; For a study checking the effect of a drug on a disease, we want to store patient info. \n&gt; \n&gt; 1. Create a vector named ID containing numerical values 1,2,3,4\n&gt; 2. Create a vector named treatment containing values A, placebo, B, and a missing value.\n&gt; 3.  Use the rep() function to create a vector called smoking containing booleans true, true, true, and false. Check the documentation and the examples of usage of rep(). \n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  ID &lt;- 1:4\n&gt;    &gt;  treatment &lt;- c(\&quot;A\&quot;,\&quot;placebo\&quot;,\&quot;B\&quot;,NA)\n&gt;    &gt;  smoking &lt;- c(rep(TRUE,3),FALSE)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt;  ```\n&gt;    &gt;  smoking &lt;- c(rep(true,3),false)\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt;  ```\n&gt;    &gt;  smoking &lt;- c(rep(\&quot;true\&quot;,3),\&quot;false\&quot;)\n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 4d\n&gt;\n&gt; Create vector threes consisting of 3,3,3,3,3,3,3 and print the content of threes\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  threes&lt;-rep(3,7)\n&gt;    &gt;  threes\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 4e\n&gt;\n&gt; Print ha ha ha ha\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  rep(\&quot;ha\&quot;,4) \n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; Vectors cannot hold values of different types! R automatically converts all values to the same type so that the vector can hold them. If one of the values is a string all values will be converted to strings or in case of a mix of integers and booleans all values will be converted to integers. \n{: .comment}\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; Words used as values have to be written between quotes, words used as variable names do not! If R encounters a word without quotes it will try to find a variable with that name.\n{: .comment}\n\n#### Referring to elements of a vector\nEvery element in a vector is assigned an index (= its position in the vector) in the order in which elements were entered. This index starts with one, not zero. \n\nYou can extract elements from vectors in two ways:\n1. You directly identify specific elements using their indices\n2. You create a logical operation to select certain elements.\n\nTo refer to elements of a vector use indices or a logical operation inside square brackets []\ne.g. to retrieve the 2nd element of vector a use:\n```\na[2]\n```\nto retrieve the 2nd, 3rd and 4th element of vector a use:\n```\na[2:4]\n```\nto retrieve the 2nd and 4th element of vector a use:\n```\na[c(2,4)]\n```\nYou also see [] when you look at output in the console. The number in between the square brackets is the index of the first value on the line. \n```\nv &lt;- c(rep(5,10),rep(10,5))\n#[1] 5 5 5 5 5 5 5 5 5 5 10 10\n#[13] 10 10 10 \n```\nThere are 12 values on the first line, so on the second line of data, the first value (10) is actually on the 13th position in the vector v. So [13] refers to the index of the first element on the line.\n\nRetrieving elements using a logical operation is done as follows:\n```\nx\n#[1] 1 3 11 1 7\nx[x &lt; 4]\n#[1] 1 3 1\n```\nRetrieving data with logical operators is based on the following fact: every logical statement produces the outcome TRUE or FALSE.\n```\nx &lt; 4\n#[1]  TRUE  TRUE  FALSE  TRUE  FALSE\n```\n\nLogical operators applied to vectors will result in a vector of the same length consisting of TRUE or FALSE values depending on whether the statement is true for the particular element. If you use the outcomes of a logical operation to retrieve elements of a vector, only the elements where the outcome is TRUE will be selected. \n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Data extraction: vectors** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 5a\n&gt;\n&gt; Create a vector named x containing the numbers 20 to 2. Retrieve elements that are larger than 5 and smaller than 15.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  x &lt;- 20:2\n&gt;    &gt;  x[x &gt; 5 &amp; x &lt; 15]\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  x[15 &gt; x &gt; 5]\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  x(x &gt; 5 &amp; x &lt; 15)\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  x[x &gt; 5] &amp; x[x &lt; 15]\n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 5b\n&gt;\n&gt; 1. Retrieve the 4th and 5th elements from the days vector.\n&gt; 2. Retrieve elements from Plants_with_lesions that are larger than 2.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  days[c(4,5)]\n&gt;    &gt;  Plants_with_lesions[Plants_with_lesions &gt; 2]\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  days[4,5]\n&gt;    &gt;  \n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  days[4:5]\n&gt;    &gt;  \n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  days(4:5)\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 5c\n&gt;\n&gt; Create vector y with elements 9,2,4 and retrieve the second element of y.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  y &lt;-c (9,2,4)\n&gt;    &gt;  y[2] \n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 5d\n&gt;\n&gt; 1. Create vector z with elements 1, 2, 3, 4, 12, 31, 2, 51, 23, 1, 23, 2341, 23, 512, 32, 312, 123, 21, 3\n&gt; 2. Retrieve the 3rd, 4th, 5th, 6th and 7th element\n&gt; 3. Retrieve the 2nd and 4th element\n&gt; 4. Retrieve elements from z that are larger than 100\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  z &lt;- c(1,2,3,4,12,31,2,51,23,1,23,2341,23,512,32,312,123,21,3)\n&gt;    &gt;  z[3:7] \n&gt;    &gt;  z[c(2,4)]\n&gt;    &gt;  z[z &gt; 100] \n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Logical and arithmetic operations on variables** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 5h\n&gt;\n&gt; Retrieve elements from newVector (exercise 4b) that are larger than the corresponding elements of vector threes (exercise 4d).\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  newVector[newVector &gt; threes]\n&gt;    &gt;   \n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n#### Removing, changing or adding elements in a vector\nTo remove an element from a vector use a negative index: ?-? indicates ?NOT? followed by the index of the element you want to remove, e.g. to remove the second element of vector z use:\n```\nz &lt;- z[-2]\n```\n\nChange or add elements by assigning a new value to that element . \n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Data removal vectors** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 6a\n&gt;\n&gt; From vector x (exercise 5a) remove the first 8 elements and store the result in x2.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  x2 &lt;- x[-(1:8)]\n&gt;    &gt;  x2\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  x2 &lt;- x[-1:8]\n&gt;    &gt;  \n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 6b\n&gt;\n&gt; Retrieve the same elements from z as in exercise 5d2 but first replace the 3rd element by 7.\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  z[3] &lt;- 7\n&gt;    &gt;  z[3:7] \n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n### Factors\nYou can tell R that a variable is categorical (= text labels representing categories although sometimes numbers are also used) by making it a factor. \n\nThe difference between a categorical variable and a continuous variable is that a categorical variable represents a limited number of categories. A continuous variable is the result of a measurement and can correspond to an infinite number of values. \n\nIn most cases categorical data is used to **describe** other data, it is not used in calculations e.g. which group does a measurement belong to. Storing data as factors ensures that the graphing and statistical functions in R will treat such data correctly.\n\nThere are two types of categorical data:\n1. unranked categorical data do not have an implied order\n2. ranked categorical data do have a natural ordering\n\nR will treat factors by default as unranked but you can create ordered (ranked) factors. \n\nTo create a factor, first create a vector and then convert it to a factor using the factor() function:\n```\nv &lt;- c(1,4,4,4,3,5,4,4,5,3,2,5,4,3,1,3,1,5,3,4)\nv\n#[1] 1 4 4 4 3 5 4 4 5 3 2 5 4 3 1 3 1 5 3 4\nf &lt;- factor(v,ordered=TRUE)\nf\n#[1] 1 4 4 4 3 5 4 4 5 3 2 5 4 3 1 3 1 5 3 4\n#Levels: 1 &lt; 2 &lt; 3 &lt; 4 &lt; 5 \n```\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; The factor() function creates \&quot;Levels\&quot;: these are the labels of the categories.\n{: .comment}\n\nThe only **required argument** of the factor() function is a **vector** of values which will be factorized. Both numeric and character vectors can be made into factors but you will use factor() typically for numerical data that represents categories. \n\nWhen you create a vector containing text values in R you have to factorize it but if you store the vector as a column in a data frame, text data is automatically converted to a factor. \n\nWhen you import data into R using read.() functions, the data is automatically stored in a data frame so text will be automatically converted into a factor. \n\nSo in reality (since you mostly import data into R) you use factor() mainly to factorize **numbers** that represent categories.\n\nBy default, factor() transforms a vector into an unordered factor, as does the automated factorization of the read.() functions. Unordered means that the categories are processed in alphabetical order: High will be plotted before Low since H comes first in the alphabet. \n\nIf the categories are ranked, you have to create an ordered factor, you have to add two additional arguments: \n- Set *ordered* to TRUE to indicate that the factor is ordered\n- *levels*: a vector of category labels (as strings) in the correct order\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Data creation: factors** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 7a\n&gt;\n&gt; 1. Create a vector gender with the following elements: Male, Female, male. \n&gt; 2. Convert gender into a factor with levels: Male and Female\n&gt; 3. Print the content of the factor. What happens?\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  gender &lt;- c(\&quot;Male\&quot;,\&quot;Female\&quot;,\&quot;male\&quot;)\n&gt;    &gt;  gender &lt;- factor(gender,levels=c(\&quot;Male\&quot;,\&quot;Female\&quot;))\n&gt;    &gt;  gender\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n&quot;,&quot;# Genome assembly with Velvet: Background\n{:.no_toc}\n\nVelvet is one of a number of *de novo* assemblers that use short read sets as input (*e.g.* Illumina Reads). The assembly method is based on the manipulation of de Bruijn graphs, via the removal of errors and the simplication of repeated regions.\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; For information about Velvet, you can check its (nice) [Wikipedia page](https://en.wikipedia.org/wiki/Velvet_assembler).\n{: .comment}\n\nFor this tutorial, we have a set of reads from an imaginary *Staphylococcus aureus* bacterium with a miniature genome (197,394 bp). Our mutant strain read set was sequenced with the whole genome shotgun method, using an Illumina DNA sequencing instrument. From these reads, we would like to rebuild our imaginary *Staphylococcus aureus* bacterium via a *de novo* assembly of a short read set using the Velvet assembler.\n\n&gt; ### Agenda\n&gt;\n&gt; In this tutorial, we will deal with:\n&gt;\n&gt; 1. TOC\n&gt; {:toc}\n&gt;\n{: .agenda}\n\n# Get the data\n\nWe will now import the data that we will use for the tutorial.\n\n&gt; ### {% icon hands_on %} Hands-on: Getting the data\n&gt;\n&gt; 1. Create and name a new history for this tutorial.\n&gt; 2. Import from [Zenodo](https://doi.org/10.5281/zenodo.582600) or from the data library the files:\n&gt;    - [`mutant_R1.fastq`](https://zenodo.org/record/582600/files/mutant_R1.fastq)\n&gt;    - [`mutant_R2.fastq`](https://zenodo.org/record/582600/files/mutant_R2.fastq)\n&gt;\n&gt;    &gt; ### {% icon tip %} Tip: Importing data via links\n&gt;    &gt;\n&gt;    &gt; * Copy the link location (Right-click on the filename then \&quot;Copy Link Address\&quot;)\n&gt;    &gt; * Open the Galaxy Upload Manager\n&gt;    &gt; * Select **Paste/Fetch Data**\n&gt;    &gt; * Paste the link into the text field\n&gt;    &gt; * Change the data-type to **fastqsanger**\n&gt;    &gt; * Press **Start**\n&gt;    {: .tip}\n&gt;\n&gt; 3. Change the name of the files to `mutant_R1` and `mutant_R2`.\n&gt;\n&gt;    As a default, Galaxy uses the link as the name of the new dataset. It also does not link the dataset to a database or a reference genome.\n&gt;\n&gt;    {% include snippets/rename_dataset.md %}\n&gt;\n&gt; 4. Inspect the content of a file.\n&gt;\n&gt;    &gt; ### {% icon tip %} Tip: Inspecting the content of a dataset\n&gt;    &gt;\n&gt;    &gt; * Click on the {% icon galaxy-eye %} (eye) icon next to the relevant history entry\n&gt;    &gt; * View the content of the file in the central panel\n&gt;    {: .tip}\n&gt;\n&gt;    &gt; ### {% icon question %} Questions\n&gt;    &gt;\n&gt;    &gt; 1. What are four key features of a FASTQ file?\n&gt;    &gt; 2. What is the main difference between a FASTQ and a FASTA file?\n&gt;    &gt;\n&gt;    &gt; &gt; ### {% icon solution %} Solution\n&gt;    &gt; &gt; 1. Each sequence in a FASTQ file is represented by 4 lines: 1st line is the id, 2nd line is the sequence, 3rd line is not used, and 4th line is the quality of sequencing per nucleotide\n&gt;    &gt; &gt; 2. In a FASTQ file, not only are the sequences present, but information about the quality of sequencing is also included.\n&gt;    &gt; {: .solution }\n&gt;    {: .question}\n&gt;\n{: .hands_on}\n\nThe reads have been sequenced from an imaginary *Staphylococcus aureus* bacterium using an Illumina DNA sequencing instrument. We obtained the 2 files we imported (`mutant_R1` and `mutant_R2`)\n\n&gt; ### {% icon question %} Question\n&gt;\n&gt; Why do we have 2 files here if we only sequenced the bacteria once?\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt; 1. The bacteria has been sequenced using paired-end sequencing. The first file corresponds to forward reads and the second file to reverse reads.\n&gt; {: .solution }\n{: .question}\n\n# Evaluate the input reads\n\nBefore doing any assembly, the first questions you should ask about your input reads include:\n\n- What is the coverage of my genome?\n- How good is my read set?\n- Do I need to ask for a new sequencing run?\n- Is it suitable for the analysis I need to do?\n\nWe will evaluate the input reads using the FastQC tool. This tool runs a standard series of tests on your read set and returns a relatively easy-to-interpret report. We will use it to evaluate the quality of our FASTQ files and combine the results with MultiQC.\n\n&gt; ### {% icon hands_on %} Hands-on: FastQC on a fastq file\n&gt;\n&gt; 1. **FastQC** {% icon tool %} with the following parameters\n&gt;    - \&quot;Short read data from your current history\&quot; to (**Multiple datasets**) `mutant_R1.fastq` and `mutant_R2.fastq`\n&gt;\n&gt; 2. **MultiQC** {% icon tool %} with the following parameters\n&gt;    - \&quot;Software name\&quot; to `FastQC`\n&gt;    - \&quot;Result file\&quot; to the raw data files generated by FastQC\n&gt;\n{: .hands_on}\n\nMultiQC generates a webpage combining reports for FastQC on both datasets. It includes these graphs and tables:\n\n- General statistics\n\n    This is important in setting maximum k-mer size for an assembly.\n\n    &gt; ### {% icon comment %} Getting the length of sequences\n    &gt;\n    &gt; * Click on **Configure Columns**\n    &gt; * Check **Length**\n    &gt; * Close the window\n    {: .comment}\n\n    &gt; ### {% icon question %} Questions\n    &gt;\n    &gt; 1. How long are the sequences?\n    &gt; 2. What is the average coverage of the genome, given our imaginary *Staphylococcus aureus* bacterium has a genome of 197,394 bp?\n    &gt;\n    &gt; &gt; ### {% icon solution %} Solution\n    &gt; &gt; 1. The sequences are 150 bp long\n    &gt; &gt; 2. We have 2 x 12,480 sequences of 150 bp, so the average genome coverage is: 2 * 12480 * 150 / 197394, or approximately 19 X coverage.\n    &gt; {: .solution }\n    {: .question}\n\n- Sequence Quality Histograms\n\n    Dips in quality near the beginning, middle or end of the reads may determine the trimming/cleanup methods and parameters to be used, or may indicate technical problems with the sequencing process/machine run.\n\n    &lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../../images/fastqc_per_base_sequence_quality_plot.png\&quot; alt=\&quot;Sequence Quality Histograms with the mean quality value across each base position in the read\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; The mean quality value across each base position in the read&lt;/figcaption&gt;&lt;/figure&gt;\n\n    &gt; ### {% icon question %} Questions\n    &gt;\n    &gt; 1. What does the y-axis represent?\n    &gt; 2. Why is the quality score decreasing across the length of the reads?\n    &gt;\n    &gt; &gt; ### {% icon solution %} Solution\n    &gt; &gt; 1. The y-axis represents the quality score for each base (an estimate of the error during sequencing).\n    &gt; &gt; 2. The quality score is decreasing accross the length of the reads because the sequencing become less and less reliable at the end of the reads.\n    &gt; {: .solution }\n    {: .question}\n\n- Per Sequence GC Content\n\n    High GC organisms tend not to assemble well and may have an uneven read coverage distribution.\n\n- Per Base N Content\n\n    The presence of large numbers of Ns in reads may point to a poor quality sequencing run. You will need to trim these reads to remove Ns.\n\n- k-mer content\n\n    The presence of highly recurring k-mers may point to contamination of reads with barcodes or adapter sequences.\n\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; For a fuller discussion of FastQC outputs and warnings, see the [FastQC website link](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/), including the section on each of the output [reports](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/3%20Analysis%20Modules/), and examples of [\&quot;good\&quot;](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/good_sequence_short_fastqc.html) and [\&quot;bad\&quot;](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/bad_sequence_fastqc.html) Illumina data.\n{: .comment}\n\nWe won&#39;t be doing anything to these data to clean it up as there isn&#39;t much need. Therefore we will get on with the assembly!\n\n\n# Assemble reads with Velvet\n\nNow, we want to assemble our reads to find the sequence of our imaginary *Staphylococcus aureus* bacterium. We will perform a *de novo* assembly of the reads into long contiguous sequences using the Velvet short read assembler.\n\nThe first step of the assembler is to build a de Bruijn graph. For that, it will break our reads into k-mers, *i.e.* fragments of length *k*. Velvet requires the user to input a value of *k* (k-mer size) for the assembly process. Small k-mers will give greater connectivity, but large k-mers will give better specificity.\n\n&gt; ### {% icon hands_on %} Hands-on: Assemble the reads\n&gt;\n&gt; 1. **FASTQ interlacer** {% icon tool %} with the following parameters\n&gt;    - \&quot;Type of paired-end datasets\&quot; to `2 separate datasets`\n&gt;    - \&quot;Left-hand mates\&quot; to `mutant_R1.fastq`\n&gt;    - \&quot;Right-hand mates\&quot; to `mutant_R2.fastq`\n&gt;\n&gt;    Currently our paired-end reads are in 2 files (one with the forward reads and one with the reverse reads), but Velvet requires only one file, where each read is next to its mate read. In other words, if the reads are indexed from 0, then reads 0 and 1 are paired, 2 and 3, 4 and 5, etc. Before doing the assembly *per se*, we need to prepare the files by combining them.\n&gt;\n&gt; 2. **velveth** {% icon tool %} with the following parameters\n&gt;    - \&quot;Hash Length\&quot; to `29`\n&gt;    - \&quot;Input Files\&quot;: click on `Insert Input Files`\n&gt;    - \&quot;file format\&quot; to `fastq`\n&gt;    - \&quot;read type\&quot; to `shortPaired reads`\n&gt;    - \&quot;Dataset\&quot; to the pairs output of **FASTQ interlacer**\n&gt;\n&gt;    The tool takes our reads and break them into k-mers.\n&gt;\n&gt; 3. **velvetg** {% icon tool %} with the following parameters\n&gt;    - \&quot;Velvet Dataset\&quot; to the output of **velveth**\n&gt;    - \&quot;Using Paired Reads\&quot; to `Yes`\n&gt;\n&gt;    This last tool actually does the assembly.\n{: .hands_on}\n\nTwo files are generated:\n\n- A \&quot;Contigs\&quot; file\n\n    This file contains the sequences of the contigs longer than 2k. In the header of each contig, a bit of information is added:\n    - the k-mer length (called \&quot;length\&quot;): For the value of k chosen in the assembly, a measure of how many k-mers overlap (by 1 bp each overlap) to give this length\n    - the k-mer coverage (called \&quot;coverage\&quot;): For the value of k chosen in the assembly, a measure of how many k-mers overlap each base position (in the assembly).\n\n    ![Contigs output](../../images/image10.png)\n\n- A \&quot;Stats\&quot; file\n\n    This is a tabular file giving for each contig the k-mer lengths, k-mer coverages and other measures.\n\n    ![Contigs stats output](../../images/image11.png)\n\n# Collect some statistics on the contigs\n\n&gt; ### {% icon question %} Question\n&gt;\n&gt; 1. How many contigs have been built?\n&gt; 2. What is the mean, min and max length of the contigs?\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt; 1. 190\n&gt; &gt; 2. To compute this information, we can use the Datamash tool on the 2nd columns (length). Be careful with the first line, the header. As a result, we obtain: 597.82 as mean, 1 as min and 12904 as max. It would mean that the smallest contig has a length of 1 bp, even smaller than k. The length on the 2nd column corresponds to length of the contig in k-mers. This means that the smallest contig has a length of 1k = 29. So to obtain the real length, we need to add k-1 to the length. We then obtain a mean contig length of 625.82 bp, a min contig of 29 bp and a max contig of 12,932 bp.\n&gt; {: .solution }\n{: .question}\n\nThis table is limitted, but we will now collect more basic statistics on our assembly.\n\n&gt; ### {% icon hands_on %} Hands-on: Collect fasta statistics on our contigs\n&gt;\n&gt; 1. **Quast** {% icon tool %} with\n&gt;    - \&quot;Contigs/scaffolds output file\&quot; to the output of **velvetg**\n&gt;    - \&quot;Type of data\&quot; to `contig`\n&gt;    - \&quot;Reference File\&quot; to `wildtype.fna`\n&gt;    - \&quot;Type of organism\&quot; to `Prokaryotes`\n&gt;    - \&quot;Lower Threshold\&quot; to `500`\n&gt;    - \&quot;Thresholds\&quot; to `0,1000`\n{: .hands_on}\n\nThis tool generates 5 output files, but we will focus on the HTML report and the Icarus viewer.\n\n&gt; ### {% icon question %} Question\n&gt;\n&gt; 1. What is represented in the Icarus viewer?\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt; 1. Icarus is a novel genome visualizer for accurate assessment and analysis of genomic draft assemblies. It draws contigs ordered from longest to shortest, highlights N50, N75 (NG50, NG75) and long contigs larger than a user-specified threshold\n&gt; {: .solution }\n{: .question}\n\nThe HTML report reports many statistics computed by QUAST to assess the quality of the assembly:\n\n- Statistics about the quality of the assembly when compared to the reference (fraction of the genome, duplication ratio, etc)\n- Misassembly statistics, including the number of misassemblies\n\n    A misassembly is a position in the contigs (breakpoints) that satisfy one of the following criteria:\n    - the left flanking sequence aligns over 1 kbp away from the right flanking sequence on the reference;\n    - flanking sequences overlap on more than 1 kbp\n    - flanking sequences align to different strands or different chromosomes\n\n- Unaligned regions in the assembly\n- Mismatches compared to the reference genomes\n- Statistics about the assembly *per se*, such as the number of contigs and the length of the largest contig\n\n&gt; ### {% icon question %} Question\n&gt;\n&gt; 1. How many contigs have been constructed?\n&gt; 2. Which proportion of the reference genome do they represent?\n&gt; 3. How many misassemblies have been found?\n&gt; 4. Has the assembly introduced mismatches and indels?\n&gt; 5. What are N50 and L50?\n&gt; 6. Is there a bias in GC percentage induced by the assembly?\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt; 1. 190 contigs have been constructed, but only 47 have a length &gt; 500 bp.\n&gt; &gt; 2. The contigs represents 87.965% of the reference genome.\n&gt; &gt; 3. 1 misassembly has been found: it corresponds to a relocation, *i.e.* a misassembly event (breakpoint) where the left flanking sequence aligns over 1 kbp away from the right flanking sequence on the reference genome.\n&gt; &gt; 4. 8.06 mismatches per 100 kbp and 4.03 indels per 100 kbp are found.\n&gt; &gt; 5. N50 is the length for which the collection of all contigs of that length or longer covers at least half an assembly. In other words, if contigs were ordered from small to large, half of all the nucleotides will be in contigs this size or larger. And L50 is the number of contigs equal to or longer than N50: L50 is the minimal number of contigs that cover half the assembly.\n&gt; &gt; 6. The GC % in the assembly is 33.64%, really similar to the one of the reference genome (33.43%).\n&gt; {: .solution }\n{: .question}\n\n# Discussion\n\n&gt; ### {% icon hands_on %} (Optional) Hands-on: Rerun for values *k* ranging from 31 to 101\n&gt;\n&gt; 1. **velveth** {% icon tool %} with the same parameters as before except\n&gt;    - \&quot;Hash Length\&quot; to a value between 31 and 101\n&gt; 2. **velvetg** {% icon tool %} with the same parameters as before\n&gt; 3. **Quast** {% icon tool %} with the same parameters as before\n{: .hands_on}\n\nWe have completed an assembly on this data set for a number of k values ranging from 29 to 101. A few of the assembly metrics appear below.\n\n&lt;figure id=\&quot;figure-2\&quot;&gt;&lt;img src=\&quot;../../images/number_of_contigs.png\&quot; alt=\&quot;contigs\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 2:&lt;/span&gt; Number of contigs in the assembly for various k-mer sizes&lt;/figcaption&gt;&lt;/figure&gt;\n\n&lt;figure id=\&quot;figure-3\&quot;&gt;&lt;img src=\&quot;../../images/largest_contig.png\&quot; alt=\&quot;largest_contig\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 3:&lt;/span&gt; Largest contig in each of the assemblies by k-mer size&lt;/figcaption&gt;&lt;/figure&gt;\n\n&lt;figure id=\&quot;figure-4\&quot;&gt;&lt;img src=\&quot;../../images/total_bp.png\&quot; alt=\&quot;total_bp\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 4:&lt;/span&gt; Total number of base pairs in all the contigs for each assembly by k-mer size&lt;/figcaption&gt;&lt;/figure&gt;\n\n&lt;figure id=\&quot;figure-5\&quot;&gt;&lt;img src=\&quot;../../images/n50.png\&quot; alt=\&quot;n50\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 5:&lt;/span&gt; N50 metric for each of the assemblies by k-mer size&lt;/figcaption&gt;&lt;/figure&gt;\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; 1. Are there any distinct features in the charts?\n&gt; 2. Does it look like one assembly might be better than some of the others?\n&gt;\n{: .question}\n\nThe reasons for these patterns will be discussed in detail in the De Bruijn graph assembly slides and tutorial.\n&quot;,&quot;Since normalization of qPCR data is based on the assumption that the reference targets have the same expression level in all samples it is crucial that the expression of the chosen reference genes is stable.\nHowever, none of the so-called **housekeeping** genes is universally stably expressed.\n\n[Genevestigator](https://www.genevestigator.com/gv/), both the commercial and the free version, contains a tool, called RefGenes, that allows to identify candidate reference genes that display very stable expression in the context that you are working in, typically a certain tissue of a certain organism.\n\nGenevestigator is a platform that contains curated public microarray data from thousands of experiments/conditions.\n\nRefGenes allows you to select the conditions that are relevant for you, e.g. mouse liver, human fibroblasts, or Arabidopsis thaliana leaves. In a next step, RefGenes identifies the genes with the most stable expression in the selected conditions.\n\n## Starting the RefGenes tool\n\n| How to start the RefGenes tool ? |\n| :-------------------------------- |\n| - Open the [RefGenes page](http://www.refgenes.org/rg/).\n - Click **start GENEVESTIGATOR**\n - Click the **Install/Start** button\n - This will automatically open a Genevestigator startup page. Keep this page open during the analysis. Closing this page will close Genevestigator.\n - Login. Also for the free version you need to create an account (use your academic email for this since you will need your vib email to get access to the commercial version).\n - Genevestigator is opened automatically\n\n## The Genevestigator user interface\n\nThe Genevestigator consists of the following components:\n  - **Sample Selection** panel: to choose the experimental conditions you&#39;re interested in (green)\n  - **Gene Selection** panel: to choose the genes you&#39;re interested in (blue)\n  - Center panel shows an overview of all available tools (purple). Once you have selected a tool, the panel will show the results of the analysis that is done by the tool.\n  - **Home** button (red) allows to return to the overview of the tools at any time. The text next to the home button indicates the toolset that you have selected.\n\nClick the **RefGenes** tool at the bottom.\n\n## Using the RefGenes tool to find reference genes\n\n### STEP 1: Choose samples from a biological context similar to those in your qPCR expriment\n\n| How to choose the samples you want to analyze ? |\n| :-------------------------------- |\n|\n - Click the **New** button in the **Sample Selection** panel. The selection of samples defines which data are used for the analysis.\n - Select the organism you&#39;re interested in (in this example: human)\n - Select the array type you want to analyze (in this example: human 133_2).\nFor most organisms Genevestigator contains expression data from multiple types of microarrays, e.g. different generations of Affymetrix GeneChips. On these arrays, genes are sometimes represented by different sets of probes. To keep the analysis results easily interpretable, data from different array types are not mixed.\n - Click the **Select particular conditions** button to select all samples with a certain annotation, e.g. all data from a certain tissue type.\n - Select the type of conditions (red) you want to base your selection on (in this example: Anatomy). For each type (anatomy, neoplasms, perturbations, development...) you can browse the corresponding ontologies and select the desired condition(s) (green) (in this example: cardiac muscle).\n - Click **OK**\n\nNote that you can select multiple tissues.\nWhen you select samples for use in the RefGenes tool, you have to focus on microarrays from samples that were collected in conditions similar to those in your qPCR experiment. Don&#39;t make a too general selection, e.g. all human samples: you might end up with genes that are stable in most conditions but not in yours. Don&#39;t make a very specific selection either, e.g. human heart samples from patients taking the same medication as yours. If you want to broaden your study later on with samples from other patients, your reference genes might not be valid anymore. It is recommended to select reference genes in the same organism and the same / a similar tissue type as the one that you used in your experiments.\n\n### STEP 2: Select the gene(s) you want to measure in your qPCR experiment\n\nThis step is not essential, but it helps you to see whether your target gene(s) is (are) strongly or weakly expressed in the conditions of interest selected in STEP1. This allows you to search for candidate reference genes in a similar range of expression.\n\n| How to choose the genes you want to analyze ? |\n| :-------------------------------- |\n|\n - Click the **New** button in the **Gene Selection** panel.\n - Enter the name of your target gene in the text area (in this example: GOT1) and click **OK**\n - Open the RefGenes tool (if you haven&#39;t done that already). A red box plot representing the distribution of the expression levels of GOT1 in the 68 selected human heart samples appears in the center panel. As you can see, this gene is highly expressed in heart.\n\n\n\n\n### STEP 3: Find candidate reference genes\n\nThe reference genes that are suggested by GeneVestigator have the\nfollowing characteristics:\n\n  - They have the most stable expression levels across all selected samples (a small boxplot)\n  - Their overall expression level is similar to that of the target gene(s) of your qPCR experiment\n| How to find the candidate reference genes ? |\n| :-------------------------------- |\n|Click the **Run** button in the RefGenes tool. RefGenes will show the top 20 most stable genes with similar expression levels:\n\n\n\n## Exercises\n\n### Finding candidate reference genes in the free version of Genevestigator\n\nNow we will make a more elaborate exercise on finding candidate reference genes. We will do the analysis in the free version of RefGenes but the analysis in the commercial version is very similar.\nSuppose we want to compare the expression stability of the 4 commonly used reference genes for qPCR on mouse liver samples (ACTB, GAPDH, HPRT and TUBB4B) to that of 4 reference genes that are suggested by Genevestigator.\nTo this end we open the RefGenes tool and select the liver samples of the mouse 430_2 arrays.\n\n| Check the expression stability of the 4 commonly used reference genes ? |\n| :-------------------------------- |\n|\n - Click the **New** button in the **Gene Selection** panel to create a new selection. The selection of samples defines which data are used for the analysis.\n - Enter the name of your target gene in the text area (for example: ACTB) and click **OK**\n\nWhen you are using the commercial version, you may enter multiple genes at the same time, in the free version you have to enter them one by one. This means that you have to add the first gene as described above and then add the next gene by clicking the **Add** button and so on...\n\nFinally you end up with an expandable list of the genes you asked for and you can tick or untick them to control the display of their expression data in the main window. When you tick the 4 commonly used reference genes you can see how stable they are expressed in the 651 mouse liver samples that are stored in Genevestigator:\n\nAs you can see, the expression levels of the commonly used reference genes in the selected mouse liver samples is pretty variable which is also confirmed by their relatively high SD values.\nOften there are multiple probe sets for the same gene. When you use the free version you may only choose one probe set per gene so you have to make a choice. How to make that choice ?\nAffymetrix probe set IDs have a certain meaning: what comes after the underscore tells you something about the quality of the probes:\n\n  - **_at** means that all the probes of the probe set hit one known transcript. This is what you want: probes specifically targeting one transcript of one gene\n  - **_a_at** means that all the probes in the probe set hit alternate transcripts from the same gene. This is still ok the probes bind to multiple transcripts but at least the transcripts come from the same gene (splice variants)\n  - **_x_at** means that some of the probes hit transcripts from different genes. This is still not what you want: the expression level is based on a combination of signals of all the probes in a probe set so also probes that cross-hybridize\n  - **_s_at** means that all the probes in the probe set hit transcripts from different genes. This is definitely not what you want: if the probes bind to multiple genes you have no idea whose expression you have measured on the array\n\nSo I always ignore probe sets with s or x. If you have two specific probe sets for a gene, they should more or less give similar signals. If this is not the case, I base my choice upon the expression level that I expect for that gene based on previous qPCR results.\n\nAs you can see, each of these 4 commonly used reference genes has a high expression level. Most genes do not have such high expression levels. In most qPCR experiments your genes of interest will have low or medium expression levels, so these reference genes will not be representative for the genes of interest.\n\nReference genes should ideally have similar expression levels as the genes of interest. Therefore, we will select the four most stably expressed genes with a medium expression level (between 8 and 12) according to the RefGenes tool.\n\n| Select the 4 most stably expressed candidate reference gene with medium expression levels. |\n| :-------------------------------- |\n|\n - Untick all target genes.\n - Click the **Run** button at the top of the main window and check if the range is set correctly\n\nSelect the 4 candidates with the lowest SD: Then, we performed qPCR on a representative set of 16 of our liver samples to measure the expression of these 8 candidate reference genes and analyzed the data ([See how to select the best reference genes using geNorm in qbase+](http://wiki.bits.vib.be/index.php/Analyzing_data_from_a_geNorm_pilot_experiment_in_qbase%2B)).\n\n\n### Finding candidate reference genes in the commercial version of Genevestigator\n\nWe will do the same exercise as above in the commercial version of Genevestigator. The difference between the free and commercial version of RefGenes is the number of target genes you can select. In the free version you have to select one gene and then gradually add all other genes one at a time. The commercial version allows you to load as many target genes as you want simultaneously. As a consequence, you can select multiple probe sets for the same gene.\nAll VIB scientists have free access to the commercial version of Genevestigator via their VIB email address. If you don&#39;t know your VIB email address, check [the Who&#39;s Who of VIB](http://www.vib.be/en/whoiswho/Pages/default.aspx).\n\n  - Open a browser and go to the [Genevestigator website](https://www.genevestigator.com/)\n  - If it&#39;s your **first time to access Genevestigator**, create an account by clicking **join now** button. You will be redirected to a new window in which you will give some personal information including a valid VIB email address. Click **Register** and check your email to activate your new account. Go back to the [GeneVestigator website](https://www.genevestigator.com/)\n  - Choose the research field you want to investigate: **pharma/biomediacal** or **plant biology** by clicking the corresponding button\n  - Click **Start**\n  - Use your VIB email address and password to login to Genevestigator.\n  - This will automatically open a Genevestigator startup page in your browser. Keep this page open during the analysis. Closing this page will close Genevestigator.\n  - Genevestigator is opened automatically\n\nOpen the RefGenes tool by clicking its icon in the **Further tools** secion and select the liver samples of the mouse 430_2 arrays [as explained in the previous exercise](http://wiki.bits.vib.be/index.php/Using_GeneVestigator_to_select_candidate_reference_genes#STEP_1:_Choose_samples_from_a_biological_context_similar_to_those_in_your_qPCR_expriment).\n| Check the expression stability of the 4 commonly used reference genes ? |\n| :-------------------------------- |\n| - Click the **New** button in the **Gene Selection** panel to create a new selection. The selection of samples defines which data are used for the analysis.\n - Enter the names of the 4 commercial reference genes in the text area and click **OK**\n\nI still remove probe sets with an _s or _x since they do not specifically bind to one single gene:\nFinally you end up with an expandable list of the genes you asked for and you can tick or untick them to control the display of their expression data in the main window. By default all probe sets are ticked so you can see how stable the commonly used reference genes are expressed in the 651 mouse liver samples that are stored in Genevestigator:\nAs you can see, the expression levels of the commonly used reference genes in the selected mouse liver samples is pretty variable which is also confirmed by their relatively high SD values.\n\nThe next step of selecting the 4 most stable candidate reference genes with medium expression levels is exactly the same as described above for the free version of RefGenes.\n\n| Create a new gene selection with 20 found candidate reference genes and call it mouse_references. |\n| :-------------------------------- |\n|Click the **New** button at the top of the main window to create a new selection.\n\nTo change the name of the selection right click the name in the **Gene selection** panel and select **Rename**\n\n| Identify perturbations where the mouse_references genes show more than 1,5 fold differential expression using the Condition perturbations tool. |\n| :-------------------------------- |\n|Click the **Home** button at the top to go back to the tools overview page.\n\nClick the **Perturbations** tool in the **Condition Search tools** section\n\n\nMake a **New Sample selection** including all mouse 430_2 arrays.\nUntick all genes except for the first one and filter the long heatmap for at least 1.5 fold change differential expression:\n\n\nYou now get a list of mouse samples in which the gene is not stably expressed so you can check if any of these samples is related to the samples in your study. Hover your mouse over the name of a sample to see more details about the sample.\nYou can do this for each of the candidate reference genes and select the ones that best fit your needs\n\n[Exercise on selecting reference genes for metacaspases in Arabidopsis thaliana](http://wiki.bits.vib.be/index.php/GV_Exercise.1).\n\n\nIn a geNorm pilot experiment you analyze a set of candidate reference genes in a representative set of samples that you want to test in your final experiment. Based on the M-values and CVs that are calculated by qbase+, you can choose the genes that most satisfy the criteria for a good reference gene.\n\n### Exercise 1: reference genes for mouse liver\n\nWe come back on the 8 candidate reference genes that we selected for mouse liver:\n\n  - 4 commonly used reference genes: ACTB, TUBB4B, GAPDH and HPRT\n  - 4 candidate reference genes with very stable medium expression levels selected based on expression data coming from more than 600 microarrays of mouse liver samples using Genevestigator: Gm16845, MUSK, OTOP3, EDN3\n\nWe have measured their expression in a represetative set of 16 of our mouse liver samples, each in triplicate. We will now analyze the stability of these candidate reference genes in our samples.\n\n#### Creating a new Experiment\n\n| Create a new Experiment called GeNormMouse in Project1 |\n| :------------------------------------------- |\n| Open qbase+ or, if the software is already open, click the Launch Wizard button.\n\nYou can find the details on how to create a new experiment in Creating a project and an experiment\n\n#### Loading the data into qbase+\n\nThe data is stored in [the RefGenes folder](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/RefGenes.zip). It consists of 8 Excel files, one file for each candidate reference gene. If you are not working on a BITS laptop, download and unzip the folder.\n\n| Import the data. This files are in qBase format. |\n| :------------------------------------------- |\n| You can find the details on how to start the data import in Loading data into qbase+\n\nUnlike the previous exercise, qbase+ does not allow you to do a quick import this time. In the Import Run window Manual import is selected:\nMake sure that Upload file to Biogazelle support for further analysis is NOT selected and click Next\nMake sure the correct File type is selected (qBase) and click Finish.\nThis file contains the data of the geNorm pilot experiment. In the pilot experiment, 8 candidate reference genes were measured in 16 representative mouse liver samples.\n#### Analyzing the geNorm pilot data\n\n| Specify the aim of the experiment. |\n| :------------------------------------------- |\n| In this experiment we want to select the ideal reference genes for our next experiments so we choose selection of reference genes (geNorm)\n\n| Check the quality of the replicates (use default parameter settings). |\n| :------------------------------------------- |\n| You can find the details on how to check the quality of the replicates in the Checking the quality of technical replicates and controls section of Analyzing gene expression data in qbase+\n\nWe haven&#39;t included any positive or negative controls so you don&#39;t need to show their details.\n\n| Select the Amplification efficiencies strategy you want to use. |\n| :------------------------------------------- |\n| You can find the details on how to select the Amplification effciencies strategy in the Taking into account amplification efficiencies section of Analyzing gene expression data in qbase+\n\nWe haven&#39;t included dilution series nor do we have data from previous qPCR experiments regarding the amplification efficiencies so we choose to use the same efficiency for all genes.\nIt is of course better to include a dilution series for each gene to have an idea of the amplification efficiencies of each primer pair.\n\n| Convert all genes to Reference genes. |\n| :------------------------------------------- |\n| You can convert all the genes simultaneously by selecting Use all targets as candidate reference genes\n\nClick Finish.\n\n| Which genes are you going to use as reference targets in further experiments ? |\n| :------------------------------------------- |\n| Upon clicking Finish, the geNorm window containing the analysis results is automatically opened. The geNorm window consists of three tabs. The tabs are located at the bottom of the window: geNorm M, geNorm V and Interpretation.\nThe first tab, geNorm M, shows a ranking of candidate genes according to their stability, expressed in M values, from the most unstable genes at the left (highest M value) to the best reference genes at the right (lowest M value):\nThe second tab, geNorm V, shows a bar chart that helps determining the optimal number of reference genes to be used in subsequent analyses:\n\nThe number of reference genes is a trade-off between practical considerations and accuracy. It is a waste of resources to quantify more genes than necessary if all candidate reference genes are relatively stably expressed and if normalization factors do not significantly change when more genes are included. However, Biogazelle recommends the minimal use of 3 reference genes and stepwise inclusion of more reference genes until the next gene has no significant contribution to the normalization factors.\nTo determine the need of including more than 3 genes for normalization, pairwise variations Vn/n+1 are calculated between two sequential normalization factors. Simply stated: V is measure of the added value of adding a next reference gene to the analysis. A large variation means that the added gene has a significant effect and should be included.\nIn normal experiments like the Gene expression experiment (see Analyzing gene expression data in qbase+), we only have 3 reference genes so we will see only 1 bar here. But in this geNorm pilot experiment, we analyzed 8 candidate reference genes, so we see 6 bars.\nAll pairwise variations are very low, so even the inclusion of a third gene has no significant effect. Based on a preliminary experiment that was done by Biogazelle, 0.15 is taken as a cut-off value for V, below which the inclusion of an additional reference gene is not required. Normally this threshold is indicated by a green line on the geNorm V bar chart. However since all V-values fall below the threshold in this geNorm pilot experiment, you dont see this line on the bar chart.\nSo, these results mean that for all subsequent experiments on these samples, two reference genes, EDN3 and MUSK, would be sufficient. However, as stated before, Biogazelle recommends to always include at least three reference genes in case something goes wrong with one of the reference genes (so also include Gm16845). |\nThese are artificial data. But when you read [the paper by Hruz et al., 2011](http://www.biomedcentral.com/1471-2164/12/156/abstract) you see that the genes that are selected by Genevestigator are often outperforming the commonly used reference genes.\n\n### Exercise 2: reference genes for human heart\n\n#### Creating a new Experiment\n\n| Create a new Experiment called GeNormHuman in Project1        |\n| :------------------------------------------------------------ |\n| You can find the details on how to create a new experiment in Creating a project and an experiment |\n\n#### Loading the data into qbase+\n| Import [Run6](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Run6.xls) . This file is in qBase format. |\n| :------------------------------------------- |\n| You can find the details on how to start the data import in Loading data into qbase+. Unlike the previous exercise, qbase+ does not allow you to do a quick import this time. In the Import Run window Manual import is selected:\n\nMake sure that Upload file to Biogazelle support for further analysis is NOT selected and click Next. Select the correct File type (qBase) and click Finish. This file contains the data of the geNorm pilot experiment. In the pilot experiment, 10 candidate reference genes were measured in 20 representative samples.\n\n#### Analyzing the geNorm pilot data\n\n| Specify the aim of the experiment.        |\n| :---------------------------------------- |\n| In this experiment we want to select the ideal reference genes for our next experiments so we choose selection of reference genes (geNorm) |\n\n| Check the quality of the replicates and the controls (use default parameter settings). |\n| :------------------------------------------- |\n| You can find the details on how to check the quality of the replicates in the Checking the quality of technical replicates and controls section of Analyzing gene expression data in qbase+\n\nAll replicates and controls have met the quality criteria so there&#39;s no need to inspect them further. |\n| Select the Amplification efficiencies strategy you want to use. |\n| :------------------------------------------- |\n| You can find the details on how to select the Amplification effciencies strategy in the Taking into account amplification efficiencies section of Analyzing gene expression data in qbase+. We haven&#39;t included dilution series nor do we have data from previous qPCR experiments regarding the amplification efficiencies so we choose to use the same efficiency (E=2) for all genes. |\n\nIt is of course better to include a dilution series for each gene to have an idea of the amplification efficiencies of each primer pair.\n| Convert all genes to Reference genes.                                                                         |\n| :------------------------------------------------------------------------------------------------------------ |\n| You can convert all the genes simultaneously by selecting Use all targets as candidate reference genes |\n\nClick Finish.\n\n| Which genes are you going to use as reference targets in further experiments ? |\n| :------------------------------------------- |\n| Upon clicking Finish, the geNorm window containing the analysis results is automatically opened. The geNorm window consists of three tabs. The tabs are located at the bottom of the window: geNorm M, geNorm V and Interpretation.\nThe first tab, geNorm M, shows a ranking of candidate genes according to their stability, expressed in M values, from the most unstable genes at the left (highest M value) to the best reference genes at the right (lowest M value):\nThe second tab, geNorm V, shows a bar chart that helps determining the optimal number of reference genes to be used in subsequent analyses:\n\nThe number of reference genes is a trade-off between practical considerations and accuracy. It is a waste of resources to quantify more genes than necessary if all candidate reference genes are relatively stably expressed and if normalization factors do not significantly change when more genes are included. However, Biogazelle recommends the minimal use of the 3 most stable candidate reference genes and stepwise inclusion of more reference genes until the next gene has no significant contribution to the normalization factors.\nTo determine the need of including more than 3 genes for normalization, pairwise variations Vn/n+1 are calculated between two sequential normalization factors. Simply stated: V is measure of the added value of adding a next reference gene to the analysis. A large variation means that the added gene has a significant effect and should be included.\nIn normal experiments like the Gene expression experiment, see Analyzing_gene_expression_data_in_qbase+, we only have 3 reference genes so we will see only 1 bar here. But in this geNorm pilot experiment, we analyzed 10 candidate reference genes, so we see 8 bars.\nAll pairwise variations are very low, so even the inclusion of a third gene has no significant effect. Based on a preliminary experiment that was done by Biogazelle, 0.15 is taken as a cut-off value for V, below which the inclusion of an additional reference gene is not required. Normally this threshold is indicated by a green line on the geNorm V bar chart. However since all V-values fall below the threshold in this geNorm pilot experiment, you dont see this line on the bar chart.\nSo, these results mean that for all subsequent experiments on these samples, two reference genes, HPRT1 and GADP, would be sufficient. However, as stated before, Biogazelle recommends to always include at least three reference genes in case something goes wrong with one of the reference genes (so also include YHWAZ). \n\n\n\nIn this example we will analyze data from an artificial expression study containing the following samples:\n  - 6 treated samples: treated1, treated2, ... treated6\n  - 6 control samples: control1, control2, ... control6\n\nIn this study, the expression of the following genes was measured:\n  - 4 commonly used reference genes: ACTB, HPRT, GAPDH, and TUBB4. We have seen in [the previous exercise](http://wiki.bits.vib.be/index.php/Analyzing_data_from_a_geNorm_pilot_experiment_in_qbase%2B#Exercise_1:_reference_genes_for_mouse_liver) that the expression of these reference genes in mouse liver samples is not as stable as generally thought.\n  - 3 genes of interest:\n      - Low: a gene with low expression levels\n      - Medium: a gene with moderate expression levels\n      - HighVar: a gene with low and very noisy expression\n\nIn general, the lower the expression level, the more noisy the qPCR results will become. For each of the genes of interest we have included a run in which a 2-fold difference in expression between control and treated samples was created (Low1, Medium1 and HighVar1) and a run with a 4-fold difference in expression (Low2, Medium2 and HighVar2).\nThere are three technical replicates per reaction. In a second experiment we used [the reference genes that were obtained via Genevestigator](http://wiki.bits.vib.be/index.php/Using_GeneVestigator_to_select_candidate_reference_genes#Finding_candidate_reference_genes_in_the_free_version_of_Genevestigator) and that proved to be [more stably expressed in mouse liver samples than the commonly used references](http://wiki.bits.vib.be/index.php/Analyzing_data_from_a_geNorm_pilot_experiment_in_qbase%2B#Exercise_1:_reference_genes_for_mouse_liver).\nThe data can be found in the NormGenes folder on the BITS laptops or can be downloaded: [from our website](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/NormGenes.zip).\n\n#### Creating a new experiment\n\n| Create a new Experiment called NormGenes1 in Project1 |\n| :---------------------------------------------------- |\n| You can find the details on how to create a new experiment in Creating a project and an experiment |\n\n#### Loading the data\n\n| Import Run1 to Run5. These files are in qBase format. |\n| :---------------------------------------------------- |\n| You can find the details on how to import the data file in the Loading the data into qbase+ section of Analyzing data from a geNorm pilot experiment in qbase+ |\n\nWe are going to compare expression in treated versus untreated samples so we need to tell qbase+ which samples are treated and which not. To this end, we have constructed [a sample properties file](http://data.bits.vib.be/pub/trainingen/qbasePLUS/DataTraining/Sample_Properties_Norm.xlsx) in Excel containing the grouping annotation as a custom property called Treatment.\n\n| Import the Sample Properties file. |\n| :---------------------------------------------------- |\n| You can find the details on how to import the data file in the Adding annotation to the data section of Loading data into qbase+.\n\n| Select to import the custom property. |\n| :---------------------------------------------------- |\n| So as you can see we have 6 treated and 6 untreated samples and we have measured the expression of the 4 commonly used reference genes and 6 genes of interest:\n\n#### Analyzing the data\n\n| Which amplification efficiencies strategy are you going to use ?     |\n| :------------------------------------------------------------------- |\n| You don&#39;t have data of serial dilutions of representative template to build standard curves so the only choice you have is to use the default amplification efficiency (E = 2) for all the genes. |\n\n| Appoint the reference genes. |ACTB, GAPDH, HPRT and TUBB4B are the reference genes:\nYou can find the details on how to appoint reference targets in the Normalization section of Analyzing gene expression data in qbase+ |\n\n| Is the stability of the reference genes ok ?                                                                 |\n| :----------------------------------------------------------------------------------------------------------- |\n| The M and CV values of the reference genes are shown in green so the stability of the reference genes is ok. |\n\n| Which scaling strategy are you going to use ? |Since you have a treated and a control group, it seems logical to use the average of the control group for scaling.\n\nYou can find the details on how to specify the scaling strategy in the Scaling section of Analyzing gene expression data in qbase+\nLook at the target bar charts.\n\n| In the target bar charts plot the average expression level of each group. |In the Grouping section at the bottom of the chart you can select Plot group average: Now do exactly the same for the second experiment with the same genes of interest but with other reference genes. This means that you have to return to the Analysis wizard. To this end, click the Launch wizard button a the top of the page:\n\n| Create a new Experiment called NormGenes2 in Project1 |\n| :---------------------------------------------------- |\n| You can find the details on how to create a new experiment in Creating a project and an experiment |\n\n| Import Run5 to Run9. These files are in qBase format. |\n| :---------------------------------------------------- |\n| You can find the details on how to import the data file in the Loading the data into qbase+ section of Analyzing data from a geNorm pilot experiment in qbase+ |\n\n| Import the Sample Properties file.                    |\n| :---------------------------------------------------- |\n| You can find the details on how to import the data file in the Adding annotation to the data section of Loading data into qbase+. Select to import the custom property. |\n\nSo as you can see we have 6 treated and 6 untreated samples and we have measured the expression of the 4 new reference genes and 6 genes of interest:\n| Appoint the reference genes. |EDN3, Gm16835, MUSK and OTOP3 are the reference genes:\n| :---------------------------------------------------- |\n| You can find the details on how to appoint reference targets in the Normalization section of Analyzing gene expression data in qbase+ |\n\n| Is the stability of the reference genes ok ?                                                                 |\n| :----------------------------------------------------------------------------------------------------------- |\n| The M and CV values of the reference genes are shown in green so the stability of the reference genes is ok. |\n\nAs you can see the M and CV values of these reference genes is much lower than these of the 4 commonly used reference genes pointing to the fact that genes are more stably expressed. It&#39;s not that the commonly used reference genes are bad references. Then qbase+ would not display them in green. It&#39;s just that the other reference genes are more stable. But this can have a big impact on the results of your analysis...\n\n| Use the average of the control group for scaling |You can find the details on how to specify the scaling strategy in the Scaling section of Analyzing gene expression data in qbase+\n\nPlot the average expression level of each group. Now we will compare the target bar charts of the second and the first experiment to assess the influence of the stability of the reference targets on the analysis results.\n\n| How to display the target bar charts of the second and the first experiment next to each other ? |You can display the bar charts next to each other by clicking the tab of the bar chart of the second experiment. Drag the tab to the right while you hold down the mouse button until you see and arrow at the right side of the qbase+ window and a dark grey box in the right half of qbase+ window. Release the mouse button when you see the arrow and the box. Now the two bar charts should be next to each other. Some laptop screens are too small to nicely display the two bar charts next to other. If this is the case switch to full screen mode by double clicking the tab of the first experiment. |\n\nNow you can compare the expression of each gene in the first and in the second experiment.\n\nWhen we do this for HighVar1 for instance, you see that the average expression levels of both groups are the same in the first and the second experiment (check the scales of the Yaxis\\!). Both experiments detect the two-fold difference in expression level between the groups. However, the error bars are much larger in the first experiment than in the second. The variability of the reference genes does have a strong influence on the errors and the size of the error bars will influence the outcome of the statistical test to determine if a gene is differentially expressed or not. The larger the error bars the smaller the less likely it is that the test will say that the groups differ.\n\nRemember that the error bars represent 95% confidence intervals:\n  - if the error bars of the two groups do not overlap: you are certain that the difference between the means of the two groups is significant\n  - if they do not overlap: you know nothing with certainty: the means can be different or they can be the same. Of course the more they overlap the smaller the chance that there is a significant difference between the groups.\n\nCheck out the results of HighVar2. Here, you clearly see the influence of the reference genes. Again, the fourfold difference in expression is detected by both experiments but:\n\n  - the least stable reference genes (experiment 1) give large overlapping error bars\n  - the most stable reference (experiment 2) give smaller, barely overlapping error bars\n\nThis means that in experiment 2, a statistical test will probably declare that HighVar2 is differentially expressed while in experiment 1 this will not be the case. We will test this assumption by performing a statistical test.\n\n#### Statistical analysis of differential expression\n\n| Use a non-parametric test to identify DE genes in experiment 1 ? |\n| :---------------------------------------------------- |\n| You can find full details on statistical analyses in qbase+ in the statistical analysis section of analyzing gene expression data in qbase+. In brief, you need to perform the following steps:\n\nOpen the Statistical wizard\n\nThe goal of this analysis is to compare the mean expression levels of our genes of interest in treated and untreated samples\n\nUse the Treatment property to identify treated and untreated samples\n\nAnalyze all genes of interest\n\nUse the default settings to perform the non-parametric Mann-Whitney test\n\nAs you can see, none of the genes is considered DE by the very conservative non-parametric test. Additionally most genes have the same p-value. That&#39;s normal when you don&#39;t have many replicates. In our case, we have 6 replicates. Non-parametric tests are based on a ranking of the data values and there are not so many ways to rank 6 data points. This is why you see the same p-values for many genes.\nAs said before, the non-parametric test is very stringent. If the data do come from a normal distribution, the test will generate false positives. Some of the genes might have have been labeled not DE while in fact they are DE so you might have missed some differential expression. The choice of statistical test with 6 biological replicates depends on what you prefer: false negatives or false positives. Most people will choose false negatives since they don&#39;t want to invest time and money in research on a genes that was labeled DE while in fact it is not DE.\n\nSuppose I don&#39;t mind false positives but I don&#39;t want to miss any potential DE genes. In that case, it&#39;s better to go for a t-test. Let&#39;s repeat the test n ow choosing a parametric t-test.\n| Use a t-test to identify DE genes in experiment 1 ? |\n| :---------------------------------------------------- |\n| You can find full details on statistical analyses in qbase+ in the statistical analysis section of analyzing gene expression data in qbase+.\nIn brief, you need to perform the following steps:\nOpen the Statistical wizard\nThe goal of this analysis is to compare the mean expression levels of our genes of interest in treated and untreated samples\nUse the Treatment property to identify treated and untreated samples\nAnalyze all genes of interest\nDescribe the data set as log-normally distributed\n\nStill none of the genes is considered DE but you do see that the p-values of the t-test are lower than these of the Mann-Whitney test.\n\n| Use a non parametric test to identify DE genes in experiment 2 ? |\n| :---------------------------------------------------- |\n| You can find full details on statistical analyses in qbase+ in the statistical analysis section of analyzing gene expression data in qbase+.\nIn brief, you need to perform the following steps:\n\nOpen the Statistical wizard\nThe goal of this analysis is to compare the mean expression levels of our genes of interest in treated and untreated samples\nUse the Treatment property to identify treated and untreated samples\nAnalyze all genes of interest\nUse default settings\n\nNow you see that 4 out of the 6 genes are considered DE. This is also what we expected since 3 of our genes of interst have a 4-fold difference in expression level between the two groups. It&#39;s understandable that it&#39;s hard to detect 2-fold differences in expression especially when the expression of the gene is somewhat variable as is the case for Low1 and HighVar1 but a 4-fold difference is a difference that you would like to detect.\n| Use a t-test to identify DE genes in experiment 2 ? |\n| :---------------------------------------------------- |\n| You can find full details on statistical analyses in qbase+ in the statistical analysis section of analyzing gene expression data in qbase+.\nIn brief, you need to perform the following steps:\n\nOpen the Statistical wizard\nThe goal of this analysis is to compare the mean expression levels of our genes of interest in treated and untreated samples\nUse the Treatment property to identify treated and untreated samples\nAnalyze all genes of interest\nDescribe the data as log normally distributed\n\nAgain the t-test generates lower p-values than the Mann-Whitney test but realize that choosing the t-test when the data is not normally distributed will generate false positives \\!&quot;,&quot;## What&#39;s the biology behind a list of genes ?\n\nOmics experiments typically generate lists of hundreds of interesting genes: \n- up- or downregulated genes identified in an RNA-Seq experiment\n- somatically mutated genes in a tumor identified by exome sequencing\n- proteins that interact with a bait identified in a proteomics experiment\n- ...\n\n### Over-representation analysis\n\nSince it&#39;s impossible to evaluate each gene individually, the most meaningful approach is to see what functional annotations the genes in the list have in common e.g. are many of them involved in the same pathway ?\n\nFunctional characterization of a gene list involves the following steps:\n1. Add functional annotations to the genes in the list\n2. Define a background: typically the full set of all genes in the genome\n3. Perform a  statistical test to identify **enriched** functions, diseases, pathways\n\nEnriched means over-represented, occurring more frequently in the list than expected by chance based on the background data. \n\nIt is recommended to **characterize up- and downregulated genes separately**.\n\n!! Thousands of pathways are tested for enrichment, this could lead to false positives. **Multiple testing correction** is used to correct the p-values from the individual enrichment tests to reduce the chance of false positives !!\n\n#### ToppGene: most up-to-date but only human, mouse and rat\n[ToppGene](https://toppgene.cchmc.org/) is the most up-to-date portal for gene list functional enrichment. See [this overview](https://toppgene.cchmc.org/navigation/database.jsp) of their resources of functional annotations and their last update date. \n\nThe **ToppFun** tool returns enriched terms from GO, phenotypes, pathways, protein interactions, domains, transcription factor binding sites, miRNA-target genes, disease associations, drug-gene interactions compiled from various data sources...\n\nIt supports gene symbols, Ensembl, Entrez, RefSeq and UniProt IDs from human. However, since gene symbols for human, mouse and rat are identical the tool can also be used for mouse and rat. \n\n&gt; ### {% icon hands_on %} Exercise ToppGene\n&gt;  How to do functional enrichment analysis with ToppFun ?\n&gt;    &gt; ### {% icon solution %} answer\n&gt;    &gt; - On the [ToppGene](https://toppgene.cchmc.org/) page click the first link **[ToppFun](https://toppgene.cchmc.org/enrichment.jsp): Transcriptome, ontology, phenotype, proteome...**\n&gt;    &gt; - Enter gene symbols or Ensembl IDs in the box **Training Gene Set**\n&gt;    &gt; - Click **Submit Query**\n&gt;    &gt; - If the gene list contains non-approved symbols or duplicates, they are listed under **Genes Not found**. \n&gt;    &gt; \n&gt;    &gt; ![ToppGene_Not_Found](../../images/FunTopp_NF.png)\n&gt;    &gt; - In the section **Calculations** select the functional annotation types you want to test (all in our case) and select the multiple correction method (default FDR is ok) and the significance cut-off level (default 0.05 is ok)\n&gt;    &gt; - Click **Start**\n&gt;    &gt; - **Input Parameters** summarizes the input parameters of the search. Click the **Show Detail** (red) link to see them. \n&gt;    &gt; - **Training results** contains the enrichment analysis results. **Download all** (blue) will download the analysis results as a text file.\n&gt;    &gt; - Click the **Display chart** (green) link to visualize the results\n&gt;    &gt; \n&gt;    &gt; ![ToppGene_Results](../../images/FunTopp_Results.png)\n&gt;    &gt; - If you want to see which genes from your list belong to a certain annotation click the number in the **Genes from innput** column\n&gt;    &gt; \n&gt;    {: .solution}\n{: .hands_on}\n\n#### Enrichr: longest list of resources but not so up-to-date\n\n[Enrichr](http://amp.pharm.mssm.edu/Enrichr/) use a respectable number of [resources](http://amp.pharm.mssm.edu/Enrichr/index.html#stats) to compute enrichment but they are not as regularly updated as those of ToppGene. To learn more about Enrich, see their [FAQ page](http://amp.pharm.mssm.edu/Enrichr/#help).\n\nEnrichr uses a list of gene symbols as input (one per line). It only supports human, mouse and rat. You can upload the list by selecting a text file or by simply pasting the list of gene symbols into the text box. \n\n&gt; ### {% icon hands_on %} Exercise 1 Enrichr\n&gt;  How to perform functional enrichment analysis in Enrichr ?\n&gt;  \n&gt;  Browse to [Enrichr submission page](http://amp.pharm.mssm.edu/Enrichr/index.html) and click the **Submit** button\n{: .hands_on}\n\nThe results page consists of multiple tabs, each tab giving an overview of a specific type of annotation (Transcription, Pathways, Ontologies...), e.g. \n\n&gt; ### {% icon hands_on %} Exercise 2 Enrichr\n&gt;  How to visualize the results for KEGG pathways as a bar chart ?\n&gt;    &gt; ### {% icon solution %} answer\n&gt;    &gt; Go to the **Pathways** tab and expand the results for **KEGG** as a bar chart.\n&gt;    {: .solution}\n{: .hands_on}\n\nThe bar charts are interactive: hover your mouse over the bars to see the enrichment scores. Clicking the bars will order the terms according to different scores.\n\nThe length of the bar represents the significance of that specific term. In addition, the brighter the color, the more significant that term is.\n\nEnrichr implements three approaches to compute enrichment scores:\n- The **p-value** comes from a test implemented in most enrichment analysis tools: the hypergeometric test\n- The **q-score** is the adjusted p-value using the Benjamini-Hochberg method for correction for multiple hypotheses testing.\n- EnrichR computes enrichment using the hypergeometric test for many random gene sets to compute mean and standard deviation of the expected rank for each annotation. Then it computes an **odds ratio** reflecting the deviation of the actual rank from this expected rank.\n- They combine the p-value of the hypergeometric test with the odds ratio into a **combined score**\n \n&gt; ### {% icon hands_on %} Exercise 3 Enrichr\n&gt; How to obtain the table containing the actual scores ?\n&gt; Sort the terms according to adjusted p-value\n&gt;    &gt; ### {% icon solution %} answer\n&gt;    &gt; - If you want to see the actual scores click the **Table** tab\n&gt;    &gt; - Click the name of the column you want to use for sorting\n&gt;    &gt; \n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Exercise 4 Enrichr\n&gt; Look at the results for GO Biological processes, OMIM disease, and TargetScan miRNAs\n&gt; \n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Exercise 5 Enrichr\n&gt;  How to visualize enriched Transfac and Jaspar TFBS as a network ?\n&gt;    &gt; ### {% icon solution %} answer\n&gt;    &gt; - Go to the **Transcription** tab and click **TRANSFAC and JASPAR PWMs**\n&gt;    &gt; - Visualize the results as a network by clicking then **Network** tab \n&gt;    &gt; \n&gt;    {: .solution}\n{: .hands_on}\n\nEach node in the network represents a term (in this case a Transcription Factor) and a link between two nodes means that the 2 transcription factors have some genes from the list in common. the genes are linked to both transcription factors. Since these transcription factors share target genes from the list they might interact to regulate the process you&#39;re studying.\n\n#### Webgestalt: all organisms but one resource at a time\n\nThis tool largely overlaps in data-sources with Enrichr but updates them more regularly.\n\n[WebGestalt](http://www.webgestalt.org/) accepts many ID types and supports 12 different model organisms. For other organisms it allows to upload your own functional annotation database (see section 3.1 of the [manual](http://www.webgestalt.org/WebGestalt_2019_Manual.pdf) of this tool).\n\n&gt; ### {% icon hands_on %} Exercise 1 WebGestalt\n&gt;  How to calculate enrichment of KEGG pathways in a list of genes ?\n&gt;    &gt; ### {% icon solution %} answer\n&gt;    &gt; - In the **Organism** box select the correct organism\n&gt;    &gt; - In the **Method** box select **Over-Representation Analysis**\n&gt;    &gt; - In the **Functional Database** boxes select **pathway** and **KEGG**\n&gt;    &gt; - In the **Gene ID type** box select the correct ID type\n&gt;    &gt; - Upload the list of IDs\n&gt;    &gt; - In the **Select Reference Set** box select the correct background, for lists generated by RNA-Seq experiments **genome, protein-coding** is a good choice because that is what you have measured\n&gt;    &gt; - Click the **Submit** button\n&gt;    &gt; \n&gt;    {: .solution}\n{: .hands_on}\n\nThe **Enrichment results** can be visualized as a table, a bar chart or a Volcano plot. Dark blue bars are considered significantly enriched. \n\n![WebGestalt_Results](../../images/FunWebG_Results1.png)\n\nClicking a bar shows the details on the bottom half of the page: \n- **FDR** is the corrected p-value (blue)\n-**Mapped input** represents your gene list\n- **gene set** is the total group of genes in the genome with this annotation\n- **overlap** is the number of genes from your list with this annotation. They are listed in the table.\n\n![WebGestalt_Results](../../images/FunWebG_Results2.png)\n\n&gt; ### {% icon hands_on %} Exercise 2 WebGestalt\n&gt; Repeat the enrichment analysis on Wiki pathways\n{: .hands_on}\n\nAgain, many more tables can be generated in WebGestalt and you should choose the type of enrichment that fits your experimental needs. Data can be saved back to disk for further use.\n\n### g:Profiler: many organisms but limited resources\n[g:Profiler](https://biit.cs.ut.ee/gprofiler/) supports a [long list of organisms but has less resources](https://biit.cs.ut.ee/gprofiler/page/organism-list) than the other tools since it retrieves functional annotations from Ensembl representing GO terms, pathways, networks, regulatory motifs, and disease phenotypes. \n\nIt is very [regularly updated](https://biit.cs.ut.ee/gprofiler/page/news).\n\n&gt; ### {% icon hands_on %} Exercise 1 g:Profiler\n&gt;  How to calculate enrichment in a list of genes ?\n&gt;    &gt; ### {% icon solution %} answer\n&gt;    &gt; - For Enrichment analysis you need to use the **g:GOSt** tool.\n&gt;    &gt; - **Upload query**: a file with gene IDs (in this example Ensembl IDs - one per line). \n&gt;    &gt; - In the **Functional Database** boxes select **pathway** and **KEGG**\n&gt;    &gt; - In the **Gene ID type** box select the correct ID type\n&gt;    &gt; - Select the **Organism** you need\n&gt;    &gt; - Click the **Run query** button\n&gt;    &gt; \n&gt;    &gt; ![g:Profiler_Interface](../../images/FungP_Interface.png)\n&gt;    &gt; \n&gt;    {: .solution}\n{: .hands_on}\n\nThis tool produces visually attractive results. Every dot in the graph represents a functional annotation. Hover your mouse over a dot to show details like the name of the annotation and the corrected p-value. \n\n![g:Profiler_Results](../../images/FungP_Results.png)\n\nAlso the detailed results are very visual. \n\n### Gene set enrichment analysis\nSome omics experiments generate a ranked list of genes:\n- genes ranked by differential expression score from a RNA-Seq experiment\n- genes ranked by sensitivity in a genome-wide CRISPR screen\n- mutated genes ranked by a score from a cancer driver prediction method\n- ...\n\nTo analyze these lists, the following steps are taken\n1. The genes are divided into groups based on functional annotation (gene sets)\n2. For every group enrichment of high or low scores is calculated\n\nGroups of related genes are called gene sets: a *pathway gene set* includes all genes in a pathway. \n\nThis is why this type of analysis is called GSEA, Gene Set Enrichment Analysis. It assumes a whole-genome ranked list as input. \n\n\n#### GSEA\nGSEA is most often done in R or via software that you install on your computer like  [GSEA](http://software.broadinstitute.org/gsea/) from the Broad Institute. \n\nGSEA is recommended when ranks are available for all or most of the genes in the genome (e.g. RNA-Seq data). It is not suitable when only a small portion of genes have ranks available (e.g. an experiment that identifies mutated cancer genes).\n\n#### g:Profiler\nIf you only have scores for a subset of the genome you should analyze the data using [g:Profiler](https://biit.cs.ut.ee/gprofiler/)with the **Ordered query** option.\n\n![gProfiler_Ranked](../../images/FungP_Ranked.png)\n\nYour list should now consist of gene IDS ordered according to decreasing importance (in this case increasing corrected p-value for differential expression). \n\ng:Profiler performs enrichment analysis with increasingly larger numbers of genes starting from the top of the list. This procedure identifies functional annotations that associate to the most dramatic changes, as well as broader terms that characterise the gene set as a whole.\n\n&gt; ### {% icon hands_on %} Exercise 2 g:Profiler\n&gt; Repeat the enrichment analysis with the ranked gene list\n{: .hands_on}\n\n### Resources of functional annotation\nFunctional annotations can be very diverse: molecular functions, pathways (genes that work together to carry out a biological process), interactions, gene regulation, involvement in disease... \n\nOnline enrichment analysis tools often have functional annotation built-in for a limited set of organisms but some tools like WebGestallt also allow to upload your own annotation. \n\n[Pathguide](http://www.pathguide.org/) contains info about hundreds of pathway and molecular interaction related resources. It allows organism-based searches to find resources that contain functional info on the organism you work on. \n\nGene sets based on GO, pathways,omics studies, sequence motifs, chromosomal position, oncogenic and immunological expression\nsignatures, and various computational analyses maintained by the GSEA team of [MSigDB](http://www.msigdb.org).\n\n### Choosing the right background\nFunctional enrichment methods require the definition of background genes for comparison. **All annotated protein-coding genes** are often used as default. This leads to false-positive results if the experiment measured only a subset of all genes. For example, setting a custom background is important in analyzing data from targeted sequencing or phosphoproteomics experiments. The appropriate **custom background** in this example would include all genes in the sequencing panel or all known or all phosphoproteins.\n&quot;,&quot;# Introduction\n{:.no_toc}\n\n&lt;!-- This is a comment. --&gt;\n\nThe goal of homology modeling is to predict the 3D structure of a protein that comes close to what would be achieved experimentally with X-Ray experiments.\n\nMain principles of homology modeling\n\n- We predict the structure of a protein sequence on the basis of the structure of another protein with a similar sequence (the template)\n- If the sequences are similar, the structures will have a similar fold\n- Structure is more conserved than sequence\n\n&gt; ### Agenda\n&gt;\n&gt; In this tutorial, we will cover:\n&gt;\n&gt; 1. TOC\n&gt; {:toc}\n&gt;\n{: .agenda}\n\n# Main ingredients for homology modelling \n\n## The sequence\n\nLast week my colleague sequenced a plant protein. He is not a bioinformatician. Yet, he would like to know what the structure might look like to do some rounds of rational mutagenesis. Let&#39;s try to address the problem for him.\n \nHe came up with this sequence:\n\n```\nSVCCPSLVARTNYNVCRLPGTEAALCATFTGCIIIPGATCGGDYAN\n```\n\n## Searching for the template structure\n\nActually, the first step is to check whether the PDB already contains the structure of this sequence. That would be easy so we don&#39;t have to model anything. We will use Blast again to search with the sequence.\n\n**TODO: add hands-on area with Blast search on PDB page**\n\n&gt; ### {% icon hands_on %} Hands-on: Data upload\n&gt;\n&gt; 1. Create a new history for this tutorial\n&gt; 2. Import the files from [Zenodo]() or from the shared data library\n&gt;\n&gt;    ```\n&gt; \n&gt;    ```\n&gt;    ***TODO***: *Add the files by the ones on Zenodo here (if not added)*\n&gt;\n&gt;    ***TODO***: *Remove the useless files (if added)*\n&gt;\n&gt;    {% include snippets/import_via_link.md %}\n&gt;    {% include snippets/import_from_data_library.md %}\n&gt;\n&gt; 3. Rename the datasets\n&gt; 4. Check that the datatype\n&gt;\n&gt;    {% include snippets/change_datatype.md datatype=\&quot;datatypes\&quot; %}\n&gt;\n&gt; 5. Add to each database a tag corresponding to ...\n&gt;\n&gt;    {% include snippets/add_tag.md %}\n&gt;\n{: .hands_on}\n\nA suitable template structure to make a high quality model should have following properties:\n\n- The highest possible sequence identity from all structures in the PDB when aligned to the target sequence\n- A good resolution (and R-factor): if many identical template structures exist with the same sequence, filter by resolution\n- Is solved by X-RAY, not NMR\n\n&gt; ### {% icon hands_on %} Hands-on: Data upload\n&gt;\n&gt; 1. Create a new history for this tutorial\n&gt; 2. Import the files from [Zenodo]() or from the shared data library\n&gt;\n&gt;    ```\n&gt; \n&gt;    ```\n&gt;    ***TODO***: *Add the files by the ones on Zenodo here (if not added)*\n&gt;\n&gt;    ***TODO***: *Remove the useless files (if added)*\n&gt;\n&gt;    {% include snippets/import_via_link.md %}\n&gt;    {% include snippets/import_from_data_library.md %}\n&gt;\n&gt; 3. Rename the datasets\n&gt; 4. Check that the datatype\n&gt;\n&gt;    {% include snippets/change_datatype.md datatype=\&quot;datatypes\&quot; %}\n&gt;\n&gt; 5. Add to each database a tag corresponding to ...\n&gt;\n&gt;    {% include snippets/add_tag.md %}\n&gt;\n{: .hands_on}\n\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; 1. Is there a difference in the number of identities, positives and gaps between the two remaining x-ray structures? \n&gt; 2. What is the PDB ID with the highest resolution, does not have insertions or deletions and should thus be the better template structure? \n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; 1. **TODO** \n&gt; &gt; 2. **TODO** \n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\n\n## Aligning target and template sequence and template selection\n\nThe alignment is the most crucial part of homology modeling. We will not explain what an alignment is and how you make it, this should be known. In an alignment, we put homologous sequences on top of each other in a text file. The point is that amino acids that are on top of each other in the same column are assumed to have the equivalent position in the 3D structure. So if the template sequence has an Ala at position 3, where the target sequence has a Phe, homology modelling tools will use the backbone of the template structure and replace the sidechain at position 3 from Ala to Phe.\n\n&gt; ### {% icon hands_on %} Hands-on: Data upload\n&gt;\n&gt; 1. Create a new history for this tutorial\n&gt; 2. Import the files from [Zenodo]() or from the shared data library\n&gt;\n&gt;    ```\n&gt; \n&gt;    ```\n&gt;    ***TODO***: *Add the files by the ones on Zenodo here (if not added)*\n&gt;\n&gt;    ***TODO***: *Remove the useless files (if added)*\n&gt;\n&gt;    {% include snippets/import_via_link.md %}\n&gt;    {% include snippets/import_from_data_library.md %}\n&gt;\n&gt; 3. Rename the datasets\n&gt; 4. Check that the datatype\n&gt;\n&gt;    {% include snippets/change_datatype.md datatype=\&quot;datatypes\&quot; %}\n&gt;\n&gt; 5. Add to each database a tag corresponding to ...\n&gt;\n&gt;    {% include snippets/add_tag.md %}\n&gt;\n{: .hands_on}\n\n\nTo extract the sequence from the template structure, display the FASTA sequence of the template structure and paste it into the text editor on the first line.\n\n&lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../../images/image_name\&quot; alt=\&quot;Alternative text\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; Legend of the image&lt;/figcaption&gt;&lt;/figure&gt;\n\nThe idea is to keep the theory description before quite simple to focus more on the practical part.\n\n&lt;figure id=\&quot;figure-2\&quot;&gt;&lt;img src=\&quot;../../images/image_name\&quot; alt=\&quot;Alternative text\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 2:&lt;/span&gt; Legend of the image&lt;/figcaption&gt;&lt;/figure&gt;\n\n\n# Building the homology model with Swiss Model \n\nOur current request for homology modelling is a rather safe one, so we can use an automatic server for homology modelling. There are many automatic tools available and many of them compete in regular competitions like lastly, the 12th Community Wide Experiment on the Critical Assessment of Techniques for Protein Structure Prediction (CASP12) - [1].\n\nIn our example, we take the [Swiss Model server](https://swissmodel.expasy.org/interactive). SWISS-MODEL is a fully automated protein structure homology-modelling server, accessible via the ExPASy web server, or from the program DeepView (Swiss Pdb-Viewer). The purpose of this server is to make Protein Modelling accessible to all biochemists and molecular biologists worldwide.\n\n&gt; ### {% icon hands_on %} Hands-on: Template selection step with Swiss Model \n&gt;\n&gt; 1. Browse to the [Swiss Model server](https://swissmodel.expasy.org/interactive) \n&gt; 2. On the first page, paste the sequence of our unknown protein in the field &#39;Target Sequence&#39; and give the project a name. \n&gt; &lt;figure id=\&quot;figure-3\&quot;&gt;&lt;img src=\&quot;../../images/Modelling_sequence_template_step1.png\&quot; alt=\&quot;Swiss Model Start page\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 3:&lt;/span&gt; Start page of Swiss Model&lt;/figcaption&gt;&lt;/figure&gt;\n&gt; 3. Click &#39;Search templates&#39; to initiate the first step. \n&gt;    Thereafter, the server identifies structural template(s) and gives an overview list of hits \n&gt;    which you can select the templates from.\n&gt;\n{: .hands_on}\n\n&gt; ### {% icon question %} Question\n&gt;\n&gt; Which of the 10 (at the time of writing) possible template structures would you select as template for the model building process? \n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; **TODO: add link with 10 template** \n&gt; &gt; We suggest as template **1jxx.1.A** given that it is an X-ray structure with high resolution and a very high \n&gt; &gt; sequence identity (X-ray, 0.9 , 78.26 %).\n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\n\n&gt; ### {% icon hands_on %} Hands-on: Model Building Step and Visualisation \n&gt;\n&gt; 1. Once you have selected the template, hit &#39;Build Model&#39; to start the homology modelling procedure. \n&gt;    The server will alignment of target sequence and template structure(s), build a model and evaluate it. \n&gt;    These steps require specialized software and integrate up-to-date protein sequence and structure databases. \n&gt;    Each of the above steps can be repeated interactively until a satisfying modelling result is achieved. \n&gt;\n&gt; 2. Once the model has been built, you can download it.\n&gt; 3. If the Swiss Model server is too busy at the moment you execute the request, you can download the model from\n&gt;    [here](https://zenodo.org/record/3551850#.Xdqs4ehKiUk).\n&gt; 4. Load the created model into YASARA. \n&gt;    Perform a structural superposition with your reference e.g. 1CRN \n&gt;    try to detect the differences through manipulating the visualisations.\n&gt;    &lt;figure id=\&quot;figure-4\&quot;&gt;&lt;img src=\&quot; \&quot; alt=\&quot;superposition\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 4:&lt;/span&gt; Superposition of 1CRN with the obtained model&lt;/figcaption&gt;&lt;/figure&gt;\n&gt;\n{: .hands_on}\n\n\n# Conclusion\n{:.no_toc}\n\nHomology modelling evolved over the years and many online tools for homology modelling are available. You have used the Swiss Model service with a reasonable simple modelling request. Often, in research projects, homology modelling can be rather difficult and needs expert knowledge depending on the actual situation (sequence conservation, available templates, etc.).\n&quot;,&quot;# Introduction\n{:.no_toc}\n\n&lt;!-- This is a comment. --&gt;\n\nMutations in proteins can have various origins. Natural occurring mutations are random and can have any kind of effect on the protein structure and/or function. Mutations can have no effect at all, be stabilizing of destabilizing. In the last two cases, these can lead to diseases.\n\nBut we can also make mutations in the wet lab to study the effect of a single residue position on protein stability, interaction with a peptide ligand etc ... Such site-directed mutagenesis in the wet lab is hard labour and costs money, I don&#39;t have to explain that to you. So wouldn&#39;t it be easier, cheaper and more rational if you could predict the effect of some mutations first with bioinformatics and then test the really interesting ones in the lab?\n\nFoldX is a molecular modeling tool that can quantitatively predict the change in free energy (kcal/mol) upon mutation. These values approach experimental determined values. FoldX is a non-interactive command line program. In other words, not user friendly. But the bright news is that I recently developed a YASARA plugin for FoldX, so that all predictions are just a few clicks away. And the nice thing is, it&#39;s all free!\n\n&gt;\n&gt; In this tutorial, we will cover:\n&gt;\n&gt; 1. TOC\n&gt; {:toc}\n&gt;\n{: .agenda}\n\n# P53 as example protein \n\nIn this section we will let the FoldX plugin loose on some real world examples and give you step-by-step instructions on how to proceed and analyze the results. We will use the P53 tumor suppressor protein as our example molecule. In a first exercise you will make a point mutation with FoldX and determine if the mutation is stabilizing or destabilizing for the P53 structure. In a second exercise you will design a mutation in the P53 structure at the DNA binding interface and determine how the mutation affects the interaction energy of P53 with the DNA strand.\n\n## Get data\n\n&gt; ### {% icon hands_on %} Hands-on: Data upload\n&gt;\n&gt; Download the file [2AC0.sce](https://zenodo.org/record/3551686/files/2AC0.sce?download=1).\n&gt;\n{: .hands_on}\n\n# What do FoldX energies mean?\n\n\nBefore we start, some basic information about FoldX energies is necessary.\n\nFirst of all, FoldX energies are expressed in kcal/mol.\n\nThe main focus of FoldX is the prediction of free energy changes, e.g. what happens to the free energy of the protein when we mutate an Asp to a Tyr? FoldX will then calculate the free energy of the wild type (WT) and the mutant (MT) and make the difference:\n\n```\nddG(change) = dG(MT) - dG(WT)\n```\n\nFoldX is trained to make ddG(change) approach experimental values. It is important to realize that dG(WT) and dG(MT) are meaningless numbers as such. These do not correlate with experimental values. Only ddG(change) does.\n\nAs a rule of thumb we use:\n\n```\nddG(change) &gt; 0 : the mutation is destabilizing\n\nddG(change) &lt; 0 : the mutation is stabilizing\n```\n\nThe error margin of FoldX is approximately 0.5 kcal/mol, so changes in that range are insignificant. \n\n# How to minimize the structure with FoldX\n\nFoldX assumes that the starting structure has been energy minimized. Although crystal structures with high resolution represent the form with a low energy, FoldX performs best when we minimize it just before we do the predictions. This FoldX procedure is called RepairPDB and should be done on each structure you want to perform calculations on.\n\nOpen the YASARA scene 2AC0.sce in YASARA. This is a part of a tetrameric complex of the transcription factor P53 bound to DNA. I removed 3 of the 4 P53 structures for simplicity and visualized some nice features.\n\nLoad the scene with:\n\n```\nFile &gt; Load &gt; YASARA Scene\n```\n&lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../../images/Training_1.png\&quot; alt=\&quot;monomer bound to DNA -80width\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; P53 monomer bound to DNA&lt;/figcaption&gt;&lt;/figure&gt;\n\nTo Repair (or minimize) the structure with FoldX go to:\n```\nAnalyse &gt; FoldX &gt; Repair object \n```\n\n&lt;figure id=\&quot;figure-2\&quot;&gt;&lt;img src=\&quot;../../images/Training_2.png\&quot; alt=\&quot;Select the object for repairing\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 2:&lt;/span&gt; Select the object for repairing&lt;/figcaption&gt;&lt;/figure&gt;\n\nAnd select the only object in the list.\n\nWhen the Repair is finished, the Repaired Object is placed in Object 2 (see top right corner) and superposed with the original Object 1. Take a look at the sidechains and see what FoldX has done while Repairing.\n\nIf you feel the repair takes too long (more than 10 minutes) due to a slow computer, download and open this YASARA Scene with the [Repaired Object](https://zenodo.org/record/3551686/files/2AC0_Repaired.sce?download=1).\n\nBecause we will continue working with this Repaired Object, we can now hide the entire Object 1 by toggling the Visibility column in the top right corner head-up display (HUD).\n\n# How to analyze a mutation \n\nFoldX has mutated the Ala to Trp and the structure with the Trp mutation has been loaded in the next Object (3) and is superposed with the wild type (WT, Object 2). We selected an option to show the VdW clashes in WT and mutant. The atoms that give rise to steric clashes are colored in red. Toggle the Visibility of Object 2 (WT) and Object 3 (mutant) and see how many clashes we introduced by mutating the Ala to Trp.\n\n\n&lt;figure id=\&quot;figure-3\&quot;&gt;&lt;img src=\&quot;../../images/Training_7.png\&quot; alt=\&quot;Zoomed-in-view on the original Ala159, no Vander Waals clashes here\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 3:&lt;/span&gt; Zoomed-in-view on the original Ala159, no Vander Waals clashes here&lt;/figcaption&gt;&lt;/figure&gt;\n\n&lt;figure id=\&quot;figure-4\&quot;&gt;&lt;img src=\&quot;../../images/Training_8.png\&quot; alt=\&quot;Zoomed-in-view on the mutated Ala159Trp, lots of red Vander Waals clashes here\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 4:&lt;/span&gt; Zoomed-in-view on the mutated Ala159Trp, lots of red Vander Waals clashes here&lt;/figcaption&gt;&lt;/figure&gt;\n\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; Van der Waals clashes are red colored atoms. \n&gt; Do you see a difference around the mutation site between WT and mutant? \n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; Toggle the Visibility of WT and mutant to see the differences. \n&gt; &gt; Open the Console by pressing the spacebar twice and see the free energy change of the mutation. \n&gt; &gt; Anything above a change of +0.5kcal/mol is already assumed to be destabilizing.\n&gt; &gt; In the console - to open press spacebar twice - we see an energy change of +29 kcal/mol.\n&gt; &gt; This is clearly a destabilizing mutation.\n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\n&lt;figure id=\&quot;figure-5\&quot;&gt;&lt;img src=\&quot;../../images/Training_9.png\&quot; alt=\&quot;In the console - to open press spacebar twice - we see an energy change of +29 kcal/mol.\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 5:&lt;/span&gt; Open the console to explore the situation.&lt;/figcaption&gt;&lt;/figure&gt;\n\n# Study the effect of a second mutation \n\nHide Object 3 by toggling its Visibility so that only Object 2 (the repaired WT) is visible.\nFirst turn on all atoms in the molecules G and H (DNA) again as you did previously, because the FoldX run has hidden it (it rearranged the view to show the VdW clashes).\n\nShow the sidechain of Arg273 of Object 2 by searching for it in the sequence selector, then right-click on it and go to:\n\n\n```\nShow atoms &gt; Sidechain and CA and zoom in on Arg273\n```\n\nNotice how the positively charged Arginine is making an electrostatic interaction with the negative phosphate from the DNA backbone.\n\n&lt;figure id=\&quot;figure-6\&quot;&gt;&lt;img src=\&quot;../../images/Training_10.png\&quot; alt=\&quot;R273 makes an electrostatic interaction with the DNA phosphate groups.\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 6:&lt;/span&gt; R273 makes an electrostatic interaction with the DNA phosphate groups.&lt;/figcaption&gt;&lt;/figure&gt;\n\nLet&#39;s see what would happen to the interaction energy between the DNA and P53 when we mutate this Arginine to Alanine.\n\nRight-click on this Arg273 in the sequence selector and go to:\n\n```\nFoldX &gt; Mutate residue\n```\n\nA number of menus is now presented and here is what you need to do in each menu:\n\n1. Select Calculate interaction energy change\n2. Select Ala\n3. &#39;Move neighbours&#39; and &#39;Show disrupted and new hydrogen bonds&#39;\n4. Don&#39;t change any numerical options in the last menu\n\n&lt;figure id=\&quot;figure-7\&quot;&gt;&lt;img src=\&quot;../../images/Training_11.png\&quot; alt=\&quot;View of the first options menu with &#39;Show new and disrupted hydrogen bondsxi&#39; selected.\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 7:&lt;/span&gt; View of the first options menu with &#39;Show new and disrupted hydrogen bonds&#39; selected.&lt;/figcaption&gt;&lt;/figure&gt;\n\n&gt; ### {% icon question %} Questions\n&gt; \n&gt; 1. What is the change in interaction energy is between P53 and DNA chain G upon mutation?\n&gt;    And what is the reason?\n&gt; 2. Why doesn&#39;t the mutation affect the interaction with DNA chain H?\n&gt;\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; 1. Toggle the Visibility between this mutant and the WT structure and see how the hydrogen bonding changes and check the output in the Console. \n&gt; &gt;    &lt;figure id=\&quot;figure-8\&quot;&gt;&lt;img src=\&quot;../../images/Training_12.png\&quot; alt=\&quot;Mutation\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 8:&lt;/span&gt; Change in interaction energy&lt;/figcaption&gt;&lt;/figure&gt;\n&gt; &gt;    We see that the mutation decreases the interaction with DNA strand G by approximately 1 kcal/mol\n&gt; &gt;    since we lost 1 hydrogen bond.\n&gt; &gt;\n&gt; &gt; 2. ***TODO***  \n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\n# Conclusion\n{:.no_toc}\n\nInstead of DNA-protein, FoldX can of course also calculate interaction energy changes in protein-protein or peptide-protein complexes.\n\n&quot;,&quot;&gt; ### Agenda\n&gt;\n&gt; In this tutorial, we will deal with:\n&gt;\n&gt; 1. TOC\n&gt; {:toc}\n&gt;\n{: .agenda}\n\n# Search for a structure\n#### Via [UniProt](http://www.uniprot.org/)\nThe way of searching for a specific protein structure depends on the data you already have. You might already have the PDB ID (a unique identifier), that&#39;s an easy one. But mostly you have the protein name or you just have a sequence. In the last cases I recommend to start from the UniProt website at &lt;http://www.uniprot.org&gt;, which is the best annotated protein database in the world. Our first model protein will be the molecular chaperone DnaK from *E. coli*. Below is an image of the UniProt search box where you can start your search for proteins.\n\n&lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../../images/uniprotsearchbox.png\&quot; alt=\&quot;uniprotsearchbox.png\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; Search box&lt;/figcaption&gt;&lt;/figure&gt;\n\n&gt; ### {% icon hands_on %} Explore a PDB structure on the Uniprot web site\n&gt;\n&gt; 1. Go to the UniProt website and search for the DnaK protein\n&gt; - The UniProt search engine returns a list of DnaK protein sequences from a variety of organisms. An entry with accession code **P0A6Y8** and entry name **DNAK_ECOLI** should be near the top of this list.\n&gt; 2. Click on the *accession code* (column Entry) to view the protein page of this DnaK from the model organism *Escherichia coli*.\n&gt; 3. Click on *Structure* in the left-side menu and then look at the *3D structure databases* table.\n{: .hands_on }\n\n&gt; ### {% icon question %} Guidelines which PDB structures to select\n&gt;\n&gt; Which structures (give the 4-character PDB ID) of the C-terminal domain of DnaK should preferentially be use for analysis and why?\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt; Usually, the recommended selection criteria are using an X-ray structure with low resolution and low Rfree factor. Furthermore, the PDB database has pre-calculated a validation report for all of the structures.\n&gt; &gt; As an example, have a look at https://www.ebi.ac.uk/pdbe/entry/pdb/4EZX under the section &#39;Experiments and Validation&#39;. For many PDB structures, there is also a re-done structure available with a vast amount of informaton on the quality of the X-ray structure and suggested &#39;better&#39; models e.g. (https://pdb-redo.eu/db/4ezx). In our case, we could opt for the structures 1DKX and 4EZX.\n&gt; &gt;\n&gt; &gt; This is a difficult example since there are so many high resolution structures available. So, it is recommended to study the articles and compare the available structures to find your favorite structure for further analysis.\n&gt; &gt;\n&gt; {: .solution}\n{: .question }\n\n\n#### Via the Protein Data Bank by PDB ID\n\n&lt;iframe src=\&quot;https://h5p.org/h5p/embed/577970\&quot; width=\&quot;699\&quot; height=\&quot;418\&quot; frameborder=\&quot;0\&quot; allowfullscreen=\&quot;allowfullscreen\&quot;&gt;&lt;/iframe&gt;\n&lt;script src=\&quot;https://h5p.org/sites/all/modules/h5p/library/js/h5p-resizer.js\&quot; charset=\&quot;UTF-8\&quot;&gt;&lt;/script&gt;\n\n&lt;iframe src=\&quot; https://docs.google.com/presentation/d/1lgEeigU8M45xF2BjQgPumgxalzfiHZeD/preview\&quot; width=\&quot;640\&quot; height=\&quot;480\&quot;&gt;&lt;/iframe&gt; \n\n\nYou can find structural information directly at the PDB database. The web site of the PDB consortium is located at &lt;http://www.wwpdb.org&gt;. This web site provides links to all members of the PDB (left side). It is a question of taste which resource you start off with. For X-ray structures, it is currently PDBe, RCSB PDB, PDBj. For NMR structres, you find the BMRB. In today&#39;s course, we focus on the PDB resources only.\n\nBelow is an image of the RCSB search box &lt;http://www.rcsb.org/pdb/home/home.do&gt; where you can start your search for structures.\n\n![Pdbsearchbox_RCSB.png](../../images/Pdbsearchbox_RCSB.png)\n\nThe PDB file with ID **1DKX** contains the atomic coordinates of the molecular chaperone (DnaK) from *E. coli*.\n\n&gt; ### {% icon hands_on %} Search a structure on the RCSB web site\n&gt;\n&gt; 1. Go to the PDB website and type 1DKX in the search box\n{: .hands_on }\n\n\nThis will lead you to the same page we got earlier through UniProt.\n\n#### Via the Protein Data Bank by sequence\n\nIn lots of cases we only have a sequence of which we would like to find out if there is structural information. The PDB can be searched using a sequence as input. Here is the sequence of the C-terminal substrate binding domain of DnaK:\n```\n    DVKDVLLLDVTPLSLGIETMGGVMTTLIAKNTTIPTKHSQVFSTAEDNQSAVTIHVLQGE\n    RKRAADNKSLGQFNLDGINPAPRGMPQIEVTFDIDADGILHVSAKDKNSGKEQKITIKAS\n    SGLNEDEIQKMVRDAEANAEADRKFEELVQTRNQGDHLLHSTRKQVEEAGDKLPADDKTA\n    IESALTALETALKGEDKAAIEAKMQELAQVSQKLMEIAQQQHAQQQTAGADASANNAKDD\n    DVVDAEFEEVKDKK\n```\nThe PDB allows sequence searches through the same search box we used before.\n\n![Pdbsearchbox_RCSB.png](../../images/Pdbsearchbox_RCSB.png)\n\nThere is also an Advanced Search section, with a Blast/Fasta option in the Sequence Features section.\n\n![Blastpdb.png](../../images/Blastpdb.png)\n\n&gt; ### {% icon hands_on %} Hands-on: BLAST search for PDB structure\n&gt;\n&gt; 1. Go to the Advanced Search section\n&gt; 2. Please select &#39;Sequence BLAST/PSI-BLAST&#39; in the Query type drop down.\n&gt;    This method allows you to change some parameters for the search.\n&gt; 3. Copy and paste the sequence in the &#39;&#39;Sequence&#39;&#39; field\n&gt; 4. Press &#39;&#39;Submit query&#39;&#39;.\n&gt; 5. You should see the same structures popping up as you saw in the UniProt page of DnaK.\n{: .hands_on}\n\n# The PDB file\n\n## Introduction\n\nA PDB (Protein Data Bank) file is a plain text file that contains the\natom coordinates of a solved 3D structure of a protein or even DNA. Such\ncoordinate files can be obtained at the Protein Data Bank at\n&lt;http://www.rcsb.org/pdb&gt;. Each PDB file has a unique identifier (ID)\nconsisting of 4 characters, the first one is always a number. Note: It\nhas been announced that the 4 character code will change in the future\n&lt;https://www.wwpdb.org/news/news?year=2017\\#5910c8d8d3b1d333029d4ea8&gt;.\n\nThe PDB file with ID **1DKX** contains the atomic coordinates of the\nmolecular chaperone (DnaK) from *E coli*.\n\n&gt; ### {% icon hands_on %} Hands-on: BLAST search for PDB structure\n&gt;\n&gt; 1. Go to the PDB website at &lt;http://www.rcsb.org/pdb&gt;\n&gt; 2. Type 1DKX in the search and try to answer the following questions.\n{: .hands_on}\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; 1. How many molecules were solved in this PDB file? What kind of molecules are these (proteins, peptides, DNA, ...)?\n&gt; 2. Does the structure represent the full protein? If not, how many residues are missing? Hint: Click on the UniProt KB link in the Sequence tab to see the full sequence.\n&gt; 3. Was this structure solved by X-Ray or NMR?\n&gt; 4. What is the atomic resolution and R-factor?\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt; 1. Two, called polymers or chains: they are polypeptides ![Type](../../images/Mol_desc_1DKX.png)\n&gt; &gt; 2. To answer this question you can go to the sequence tab at the top:\n&gt; &gt;    - ![Uniprot view](../../images/Pdb_firstresiduesmissing_1dkx.png)\n&gt; &gt;    - Summary: a large chunk of the N-terminus is missing from the structure, the C-terminus is virtually complete.\n&gt; &gt; 3. X-RAY diffraction, as shown by Experimental Details\n&gt; &gt; 4. Atomic resolution: 2.00 ngstrom and R-factor of 0.206\n&gt; {: .solution }\n{: .question}\n\n\n## Downloading the structure\n\nThe file that holds the 3D coordinates can be downloaded by clicking on\n*Download files* in the top right corner and then choosing *PDB file (text)*.\nFor convenience, save this file on your desktop. The filename is the\n4-character unique PDB ID.\n\n![Pdbdownloadfile1.png](../../images/Pdbdownloadfile1.png)\n\n&gt; ### {% icon hands_on %} Hands-on: Open downloaded PDB file in an editor\n&gt; 1.   Open this file with a text editor, e.g. WordPad is an excellent tool for that.\n&gt; 2. Do you see the different sections in the PDB file? Analyse some ATOM lines and try to explain what kind of data is in each column.\n{: .hands_on}\n\nAdditional exercises on searching PDB can be found on [the basic bioinformatics exercises page](http://wiki.bits.vib.be/index.php/Exercises_on_Protein_Structure).\n&quot;,&quot;# Introduction\n{:.no_toc}\n\n&lt;!-- This is a comment. --&gt;\n\nThe goal of this exercise is appreciate how protein interactions can be studied through visual inspection and other software tools. Protein interactions can be classified into different groups regarding the molecular properties and functions of the interacting partners. (These groups are intertwined in several cases.) Some examples include:\n\n- the interactions of proteins with other proteins, small molecules, carbohydrates, lipids or nucleic acids;\n- Receptor-ligand interactions;\n- Antigen-antibody interactions;\n- Enzymatic interactions, enzyme-inhibitor interactions.\n\n&gt; ### Agenda\n&gt;\n&gt; In this tutorial, we will cover:\n&gt;\n&gt; 1. TOC\n&gt; {:toc}\n&gt;\n{: .agenda}\n\n# Exploring the structure of a nanobody-stabilized active state of the 2 adrenoceptor - the ligand \n\nWe will start with exploring one crystal structure of the 2 adrenoceptor. Together with the Steyaert lab from VIB, Kobilka published several crystal structures of the 2 adrenoceptor in its various activation states (Rasmussen et al. Nature 2011, 477)\n\n\n&gt; ### {% icon hands_on %} Get the structure\n&gt;\n&gt; 1. Download the crystal structure 3P0G from the PDB into YASARA. \n&gt;\n&gt;    ```\n&gt;    File - Load - PDB file from internet    \n&gt;    ```\n&gt;    As you can immediately appreciate, it is a bigger crystal structure with more than one molecule. \n&gt;\n{: .hands_on}\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; 1. How many molecules are present in the crystallized structures? \n&gt; 2. And how many chain identifiers are used? \n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; 1. Answer for question1\n&gt; &gt; 2. Answer for question2\n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\nSome software routines need seperate chain identifiers for molecular entities to work correctly, so we suggest to rename the small molecule to chain L.\n\n\n&gt; ### {% icon hands_on %}  \n&gt;\n&gt; 1. Activate the Head-up display\n&gt; 2. Select Rename\n&gt; 3. Enter &#39;L&#39; to proceed with the renaming. \n&gt;\n{: .hands_on}\n\nWe first have a look whether we can find out if there are specific interactions of the small molecule ligand with the adrenoreceptor.\n\nIn order to do so, we first have to add Hydrogens to all present molecules.\n\n&gt; ### {% icon hands_on %}  \n&gt;\n&gt; 1. Edit - Add - hydrogens to : All \n&gt; 2. Change the display of the ligand to Sticks\n&gt; 3. Select the amino acids of the binding pocket i.e. a sphere of 10 Angstrom around the ligand\n&gt;    ```\n&gt;    Select  in sphere around  Residue and drag with the mouse until the display says 10 \n&gt;    ``` \n&gt; 4. ```\n&gt;    View  show interactions  hydrogen bonds of - Residues\n&gt;    ```\n&gt;    select &#39;Selected&#39; in the panel Belongs to or has\n&gt;    and press OK in the subsequent window\n&gt;\n{: .hands_on}\n\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; Between which amino acids and the ligand do you see hydrogen bonds?\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; 1. Answer for question1\n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\n\nGiven that hydrogen bonding is dependent on the definition of a hydrogen bond in the program, it is not a bad idea to use other tools to compare the analysis. There are many options to do this online if you look at published crystal structures. Next to the tools which are directly linked out from the web site of the crystal structure at the PDB database you can use the [ProteinPlus server](http://proteinsplus.zbh.uni-hamburg.de/)\n\nGo to the web site of ProteinPlus and enter the PDB code 3P0G into the search box. After clicking on Go, you should be presented with on overview of tools the ProteinPlus server provides.\n\nWe do not go into great detail on all the tools but only mention PoseView. With this tool, you can prepare an automatic sketch of the small molecule-protein interactions.\n\n&lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../../images/ProteinPlusPoseView.png\&quot; alt=\&quot;Protein Plus Server\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; Overview of 3P0G&lt;/figcaption&gt;&lt;/figure&gt;\n&lt;figure id=\&quot;figure-2\&quot;&gt;&lt;img src=\&quot;../../images/3P0G_A_PoseView_Input.png\&quot; alt=\&quot;Zoom on ligand of 3P0G\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 2:&lt;/span&gt; Zoom on ligand co-crystallized with 3P0G&lt;/figcaption&gt;&lt;/figure&gt;\n\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; Between which amino acids and the ligand do you see hydrogen bonds? \n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; 1. According to PoseView, between which amino acids and the ligand do you see hydrogen bonds?\n&gt; &gt; 2. What other interactions are presented in the sketch? \n&gt; &gt; 3. Inspect the visualisation in Yasara: Do you see the interactions in Yasara as well? \n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\n\n# Exploring the structure of a nanobody-stabilized active state of the 2 adrenoceptor - the nanobody \n\nIn order to estimate the binding energy between the nanobody and the 2 adrenoceptor, we can use the FoldX tool AnalyseComplex. It is recommended to calculate these binding energies on energy-minimized structures. To illustrate the effect of the energy minimization, we compare the interaction energy of the current crystal structure and its minimized structure.\n\n\n## Use the tool FoldX tool AnalyseComplex \n\n&gt; ### {% icon hands_on %} \n&gt;\n&gt; 1. Given that energy-minimization takes a while for this rather large complex,\n&gt;     please download the Yasara scene [here](http://data.bits.vib.be/pub/trainingen/PSA/3P0G_1.sce)  \n&gt;    \n&gt;    Calculate the interaction energies between the chain A and B of the object 3P0G \n&gt;    and the RepairObj1, respectively. \n&gt;\n&gt;    ```\n&gt;    Analyze - FoldX - Interaction energy of molecules\n&gt;    ```\n{: .hands_on}\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; 1. What is the dG in the two cases? \n&gt; 2. Any idea why the difference is rather hugh?\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; 1. Answer for question1\n&gt; &gt; 2. Answer for question2\n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\nThis command also creates a list of residues forming the interface of the two proteins. Hit space to see the list of residues in the interface.\n\nTip: This list can also be useful if you want to make visualisations of the interaction site.\n\n\n# Comparing the active and the inactive conformation of the 2 adrenoceptor \n\nIn case, there is still time, I would recommend to try to use some of your capabilities you learned today and create a superposition of the inactive and active conformation of the 2 adrenoceptor. We take one of crystal structures which are available: 3SN6\n\n**TODO: add remark that we use the first chain A from 3P0G as target**\n\n```\nFile - Load - PDB file from Internet\n```\n\nYou will be kind of overwhelmed once the structure is loaded into Yasara. In order to get a first quick overview, click on the &#39;Center&#39; buttom in the menu of Yasara (5th buttom from the left). Then, it is time to look at the PDB entry of 3SN6 in the PDB database to have a first idea on what molecules are in the PDB file.\n\nAs you see on the website [3SN6](http://www.rcsb.org/pdb/explore/explore.do?structureId=3SN6i), the chain R consists of 2 molecules, the 2 adrenoceptor and lysozyme. \nIn the corresponding article, it is stated that &#39;the unstructured amino terminus of the 2AR is replaced with T4 lysozyme (T4L)&#39;.\n\nSince this is an extra molecule in the crystal structure which disturbes our view, we will delete it.\n\nAfter the manipulation, the overall picture should look roughly like this.\n\n&lt;figure id=\&quot;figure-3\&quot;&gt;&lt;img src=\&quot;../../images/3SN6_withoutLysozyme.png\&quot; alt=\&quot;Superposition\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 3:&lt;/span&gt; Overview of 3SN6 without lysozyme&lt;/figcaption&gt;&lt;/figure&gt;\n\nIn the following step, we superimpose only the receptors. The rest of the structures will move along.\n\n```\nAnalyze - Align - Pairwise, based on structure - Molecules with MUSTANG\n\nFirst, select the first chain R from 3SN6 and second, the first chain A from 3P0G as target\n\n```\n\n&lt;figure id=\&quot;figure-4\&quot;&gt;&lt;img src=\&quot;../../images/image_name\&quot; alt=\&quot;Alternative text\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 4:&lt;/span&gt; Legend of the image&lt;/figcaption&gt;&lt;/figure&gt;\n\n# Conclusion\n{:.no_toc}\n\nSum up the tutorial and the key takeaways here. We encourage adding an overview image of the\npipeline used.\n&quot;,&quot;&lt;!--\n# Introduction\n{:.no_toc}\n\n&lt;!-- This is a comment. --&gt;\n\nGeneral introduction about the topic and then an introduction of the\ntutorial (the questions and the objectives). It is nice also to have a\nscheme to sum up the pipeline used during the tutorial. The idea is to\ngive to trainees insight into the content of the tutorial and the (theoretical\nand technical) key concepts they will learn.\n--&gt;\n\n&gt; ### Agenda\n&gt;\n&gt; In this tutorial, we will cover:\n&gt;\n&gt; 1. TOC\n&gt; {:toc}\n&gt;\n{: .agenda}\n\n## Install Python and PovRay\n\nPython and PovRay should be installed already, so you can skip this part.\n\nThe programming language Python must be installed to use some very useful YASARA features. Simply start YASARA as administrator. Right click the YASARA icon on the desktop and choose \&quot;Run as administrator\&quot;. Once the program is opened, click\n\n```\nHelp &gt; Install program &gt; Python\n```\n\nPovRay is used to make high quality publication-ready images and should be downloaded first with:\n\n```\nHelp &gt; Install program &gt; PovRay\n```\n\n## Tutorial movie\n\nPlay the movie \&quot;Working with YASARA\&quot;:\n\n```\nHelp &gt; Play help movie &gt; General: Working with YASARA\n\n```\n\n## Scene styles\n\nOpen the PDB with code 1TRZ in YASARA.\n```\nFile &gt; Load &gt; PDB file from Internet\n```\nIf this option is not there, it means you haven&#39;t installed Python yet. Please check above.\n\nThe molecule will be loaded and presented in the ball style. Different scene styles exist to rapidly change the view:\n\n* F1: Ball\n* F2: Ball &amp; Stick\n* F3: Stick\n* F4: C-alpha\n* F5: Tube\n* F6: Ribbon\n* F7: Cartoon\n* F8: Toggle sidechains on/off (press multiple times and see what happens)\n\n**Be careful!** If you have just made a nice close-up of e.g. an active site where you show some residues and hide others, and put some atoms in balls while others are in sticks, you will lose everything when you press one of the F-keys!!! The F-keys change the viewing style without asking.\n\nTry all the different scene styles!\n\n## Showing and hiding residues\n\nThe function keys F1-F3 show all atoms and residues by default. The keys F4-F7 do not explicitly show atoms and residues but are merely a impressionistic representation of the structure. The F8 keys does, to a certain extent, show atoms, but only of side chains, not main chain atoms.\nMostly to do structure analysis, we want to show only the most interesting residues, the ones we want to analyze, and hide all the others.\n\nThe structure of insulin was crystallized together with some water molecules. In many cases, it is no problem to permanently delete those waters. To visualize the waters, select an atom view such as F1, F2 or F3. See the red water (oxygen) atoms floating around the surface?\n```\nEdit &gt; Delete &gt; Waters\n```\n\nThen select the base scene style without any explicit atoms, e.g. tube style (F5). Press F5. This is our representation of the backbone.\n\nThere are several ways to show the residues of interest:\n\n1. From the menu\n```\n   View &gt; Show atoms in &gt; Residue\n```\n   Select Cys7 from Molecule **A** and press OK\n2. From the sequence selector &lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../images/Seqselector.png\&quot; alt=\&quot;seqselector.png\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; Seqselector.png&lt;/figcaption&gt;&lt;/figure&gt;\n   Hover the mouse on the bottom of the screen, you will see the sequence selector opening. Open it permanently by pressing the blue nailpin on the left side of it. Search for Cys7 from Molecule **B**, right-click and select:  \n```\n   Show &gt; Residue\n```\n\nNow show the atoms of His5 in Molecule B using a method of choice.\n\nAnd now that we&#39;re on it, what is special about the two cysteines we just visualized?\n\n**Hiding** individual atoms or residues works in the same way as showing them, only now you should go to **Hide atoms** in the menus.\n\n## Showing and hiding secondary structure\n\nMost published molecular images show a detailed active site and all the\nrest is hidden for clarity. From the previous exercise we show the atoms\nof 3 residues (let&#39;s assume this is our active site). Now secondary\nstructure of the rest of the molecule is also still visible. To hide all\nthat, we do not have to hide atoms, but hide the secondary structure\n(the F5 tube view) from the rest of the structure. Atoms and residues in\nYASARA are not the same as the term &#39;secondary structure&#39;. Atoms and\nresidues are balls and sticks, &#39;secondary structure&#39; is an artistic\nimpression of the structure (beta sheet arrows, helix ribbons, ...). If\nyou get this concept, you are a YASARA master.\n\nSo let&#39;s hide many of the secondary structure, but keep just a few\nstretches around our active site. Our active site is Cys7 (A), Cys7 (B)\nand His 5 (B). This can be done in several ways. Since we would have to\nhide almost everything, I propose to hide first everything and then show\nagain those stretches that we want. But if you have a better idea, I\nwould like to hear it.\n\nHide all secondary structure:\n```\n   View &gt; Hide secondary structure of &gt; All\n```\n\nThen show stretches of residues 2-10 in Mol B and residues 4-10 in Mol A\nin tube view as:\n```\n    View &gt; Show secondary structure &gt; Tube through &gt; Residue\n```\nThen select the correct stretches of residues by keeping the CTRL key\npressed to select multiple residues.\n\nThere are still some metal-bound histidines flying around that weren&#39;t\nhidden because they are metal bound (a YASARA specific thing). Hide\nthose histidines by clicking on one of the sidechain atoms, then\nright-click and select:\n\n```\n   Hide atoms &gt; Residue\n```\n\nThe nasty dative bonds and metals can be removed simply by deleting all\nof them:\n```\n   Edit &gt; Delete &gt; Residue &gt; Name\n```\n\nIn the name column select all the metals and ions you can find.\n\nEt voil, a publication ready image!\n\n&lt;figure id=\&quot;figure-2\&quot;&gt;&lt;img src=\&quot;/home/albot/all-images-wiki/Insulin_hires.jpg\&quot; alt=\&quot;center\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 2:&lt;/span&gt; Insuline&lt;/figcaption&gt;&lt;/figure&gt;\n\n## Labels\n\nYou can put labels on the residues you want to highlight by going to the\nmain menu or selecting an atom from a residue and right-click. In the\nlatter case you select:\n```\n   Label &gt; Residue\n```\nNote that *residue name* and *residue number* is automatically selected.\nChange the height to 0.5 or so and select a nice color for the label.\nPresto\\!\n\n## Colors\n\nYou can color on all levels: atoms, residues, molecules and objects. So\nbe careful, if you color a residue, all of its atoms will get that\ncolor. If you color a molecule, all atoms in that molecule will get that\ncolor.\n\nLet&#39;s color the secondary structure (the backbone in our case) of our\nactive site in orange. But the sidechains should keep their Element\ncolors. So we shouldn&#39;t color entire residues, but only a selected atom\nset. Therefore our selection will be at the atom level, not the residue\nlevel. Go to:\n\n    View &gt; Color &gt; Atom &gt; Belongs to or has &gt; Backbone\n\nThen select the orange color (color code 150) and select &#39;Apply unique\ncolor&#39;.\n\nBeautiful, isn&#39;t it?\n\n## Saving all the beautiful work\n\nIt would be a pitty that you spent hours creating fancy molecular\ngraphics for that next Nature paper while you can&#39;t continue on the work\nthe next day. That&#39;s why YASARA can save the entire Scene including\norientations, colors, views, everything. To save the current scene, go\nto:\n\n    File &gt; Save as &gt; YASARA Scene\n\n    Choose a filename such as MyInsulin.sce\n\nTo load the work again in YASARA go to:\n\n    File &gt; Load &gt; YASARA Scene\n\n    Careful: loading a Scene will erase everything else!\n\n## Creating high quality images\n\nTo save the current view to a high quality publication ready image file,\ngo to:\n\n    File &gt; Save as &gt; Ray-traced hires screenshot\n\nThis requires that the PovRay program has been installed. See the first\nitem on this page.\n\nUsually, you prefer to have a transparent background, so check the\nrespective box.\n\n## Distances\n\n**Distances** between atoms are calculated as follows:\n\n  - select the first atom\n  - keep CTRL pressed and select the second atom.\n  - left of the screen indicates the &#39;Marked Distance&#39; in Angstrom.\n\n&lt;!-- end list --&gt;\n\n    What is the distance between the C-alpha (CA) atoms of Tyr19 and Leu16?\n\nTo solve the question you need to select a view that shows you atoms\nincluding C-alphas. Possible views or scene styles that show these atoms\ncan be F1 (ball), F2 (stick), F3 (ball\\&amp;stick) and F4 (C-alpha). The\nviews F5-F8 won&#39;t show you any CA&#39;s explicitly. Try it.\n\n    So you&#39;ve probably noticed that pressing the CTRL button allows you to select multiple atoms. This is important for the next exercise.\n\n## Hydrogen bonds\n\nTo show hydrogen bonds, YASARA needs the actual hydrogens to be present.\nIn NMR structures these are normally there. But in X-Ray structures\nhydrogens are missing. Luckily YASARA can add the hydrogens for you.\n\n    Select tube view (F5) and toggle on the sidechains with F8.\n\nAdd hydrogens with:\n\n    Edit &gt; Add &gt; Hydrogens to all\n\nThen show the hydrogen-bonds:\n\n    View &gt; Show interactions &gt; Hydrogen bonds of&gt; All &gt; OK\n\nIf the view is to chaotic for you, toggle off the sidechains with F8\n(press untill the sidechains are hidden).\n\nDo you see the typical helix and beta sheet pattern?\n\n    Arg22 from Molecule/Chain B is making an hydrogen bonded electrostatic interaction (salt bridge) with another residue. Which residue?\n\nTo remove the hydrogen bonds, you have multiple choices:\n\n    View &gt; Hide hydrogen bonds of &gt; All\n\nor just delete all hydrogens (this will also delete all hydrogen bonds):\n\n    Edit &gt; Delete &gt; Hydrogens\n\n## Surfaces\n\nIt can be very useful and informative to show the molecular surface of a\nprotein. you can visualize cavities, ligand binding sites, etc ... To\nshow the molecular surface of one monomer of dimeric insulin, go to:\n\n    View &gt; Show surface of &gt; Molecule\n\nSelect in the *Name* column A and B (these are the two chains in 1\nsubunit). Press *Continue with surface color* and make sure Alpha is\n100. Any number lower than 100 will create transparency in the surface\n(could be nice as well).\n\n## Molecular graphics exercise\n\nTry to reproduce the following image of the 1TRZ insulin structure\n(hints below):\n\n[image:insulin.png](image:insulin.png \&quot;wikilink\&quot;)\n\nHints:\n\n  - choose the proper secondary structure scene style (F6 was used here)\n  - find the correct orientation first\n  - color all backbone atoms in gray\n  - find the residue numbers of the 2 colored helices\n  - color those residues magenta\n  - show the sidechain atoms and the CA of the two histidines and the\n    glutamate\n  - color the sidechain atoms of all residues in the Element color\n  - label the histidines and the glutamate\n  - if you need some help how to change the parameters for the label,\n    please have a look at Help -\\&gt; Show user manual and search in\n    Commands / Index\n\n## More coloring\n\nDownload GroEL via PDB code 1WE3 in YASARA.\n\nTry to reproduce (approximately) the following image (hints below):\n\n[image:groel.png](image:groel.png \&quot;wikilink\&quot;)\n\nHints:\n\n  - load the PDB as File \\&gt; Load \\&gt; PDB file from internet\n  - zoom out and find the correct orientation\n  - delete the ADP, DMS and Mg molecules (are treated as residues in\n    YASARA). So Edit \\&gt; Delete \\&gt; Residue \\&gt; Adp ...\n  - color by molecule (every molecule will get another color) and color\n    by gradient (now you need to specify 2 colors, the begin and end\n    color).\n  - choose a first color (eg. color with code 0)\n  - choose a second color (eg. color with code 300, so you go over the\n    entire color wheel spectrum)\n\nMore exercises can be found on the [basic bioinformatics exercises\npage](http://wiki.bits.vib.be/index.php/Exercises_on_Protein_Structure).\n\n\n## Get data\n\n&gt; ### {% icon hands_on %} Hands-on: Data upload\n&gt;\n&gt; 1. Create a new history for this tutorial\n&gt; 2. Import the files from [Zenodo]() or from the shared data library\n&gt;\n&gt;    ```\n&gt;    \n&gt;    ```\n&gt;    ***TODO***: *Add the files by the ones on Zenodo here (if not added)*\n&gt;\n&gt;    ***TODO***: *Remove the useless files (if added)*\n&gt;\n&gt;    {% include snippets/import_via_link.md %}\n&gt;    {% include snippets/import_from_data_library.md %}\n&gt;\n&gt; 3. Rename the datasets\n&gt; 4. Check that the datatype\n&gt;\n&gt;    {% include snippets/change_datatype.md datatype=\&quot;datatypes\&quot; %}\n&gt;\n&gt; 5. Add to each database a tag corresponding to ...\n&gt;\n&gt;    {% include snippets/add_tag.md %}\n&gt;\n{: .hands_on}\n\n# Title of the section usually corresponding to a big step in the analysis\n\nIt comes first a description of the step: some background and some theory.\nSome image can be added there to support the theory explanation:\n\n&lt;figure id=\&quot;figure-3\&quot;&gt;&lt;img src=\&quot;../../images/image_name\&quot; alt=\&quot;Alternative text\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 3:&lt;/span&gt; Legend of the image&lt;/figcaption&gt;&lt;/figure&gt;\n\nThe idea is to keep the theory description before quite simple to focus more on the practical part.\n\n***TODO***: *Consider adding a detail box to expand the theory*\n\n&gt; ### {% icon details %} More details about the theory\n&gt;\n&gt; But to describe more details, it is possible to use the detail boxes which are expandable\n&gt;\n{: .details}\n\nA big step can have several subsections or sub steps:\n\n\n## Sub-step with **My Tool**\n\n&gt; ### {% icon hands_on %} Hands-on: Task description\n&gt;\n&gt; 1. **My Tool** {% icon tool %} with the following parameters:\n&gt;    - {% icon param-file %} *\&quot;Input file\&quot;*: File\n&gt;    - *\&quot;Parameter\&quot;*: `a value`\n&gt;\n&gt;    ***TODO***: *Check parameter descriptions*\n&gt;\n&gt;    ***TODO***: *Consider adding a comment or tip box*\n&gt;\n&gt;    &gt; ### {% icon comment %} Comment\n&gt;    &gt;\n&gt;    &gt; A comment about the tool or something else. This box can also be in the main text\n&gt;    {: .comment}\n&gt;\n{: .hands_on}\n\n***TODO***: *Consider adding a question to test the learners understanding of the previous exercise*\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; 1. Question1?\n&gt; 2. Question2?\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; 1. Answer for question1\n&gt; &gt; 2. Answer for question2\n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\n\n## Re-arrange\n\nTo create the template, each step of the workflow had its own subsection.\n\n***TODO***: *Re-arrange the generated subsections into sections or other subsections.\nConsider merging some hands-on boxes to have a meaningful flow of the analyses*\n\n# Conclusion\n{:.no_toc}\n\nSum up the tutorial and the key takeaways here. We encourage adding an overview image of the\npipeline used.\n&quot;,&quot;&gt; ### Agenda\n&gt;\n&gt; In this tutorial, we will cover:\n&gt;\n&gt; 1. TOC\n&gt; {:toc}\n&gt;\n{: .agenda}\n\n# Structural comparison and RMDD \nWe compare structures by superposing (or structurally align) them on top of each other. That is, we\n superpose structurally equivalent atoms. For now, we will only superpose CA atoms, so backbones. B\nut Yasara also can superpose on any type of atom you want. You always need to specify:\n\n-  source object(s): the structure(s) that needs to be rotated and translated to superpose on anoth\ner structure\n-  target object: the structure to superpose on\n\nAn optimal superposition is found when the root-mean-square deviation (RMSD) is at a minimum. The R\nMSD is given as:\n&lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../../images/RMSD.gif\&quot; alt=\&quot;RMSD\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; calculation of RMSD&lt;/figcaption&gt;&lt;/figure&gt;\nwhere R is the distance between two structurally equivalent atom pairs (CA in our case) and n is th\ne total number of atom pairs.Get data\n\n&gt; ### {% icon hands_on %} Hands-on: Data download\n&gt;\n&gt; 1. Download the following adapted PDB files from [Zenodo](https://zenodo.org/record/3550492#.XdeNL1dKiUk) \n&gt;\n&gt;    ```\n&gt;     1DKX_1.pdb 1DKY_1.pdb 1DKZ_1.pdb 3DPO_1.pdb 3DPP_1.pdb \n&gt;    ```\n&gt;\n{: .hands_on}\n\n# Superimposing multiple structures using YASARA \n\nNow load all of them in YASARA:\n\n```\nFile &gt; Load &gt; PDB File\n```\n\nand select the CA (C-alpha) view (F4) and superpose with the MUSTANG algorithm:\n\n\n```\nAnalyze &gt; Align &gt; Objects with MUSTANG\n```\n\n\nIn the first window you have to select the source objects that will be repositioned. Select Objects 2 till 5. In the second window you select the target Object to superpose on. That would then be the first object.\n\nNotice that YASARA prints the RMSD of every superposition in the lower Console. Open the Console by pressing the spacebar once or twice to extend it.\n\nColor the atoms by their B-factor:\n\n```\nView &gt; Color &gt; Atom &gt; Belongs to or has &gt; All\nThen choose BFactor in the next window and press &#39;Apply unique color&#39;.\n```\n\nHigh BFactors are yellow, low BFactors are blue.\n\n\n&gt; ### {% icon question %} Questions\n&gt;\n&gt; Question: Do you see a correlation between the BFactors and the variability in the structure?\n&gt;\n&gt; &gt; ### {% icon solution %} Solution\n&gt; &gt;\n&gt; &gt; 1. Yes, add explanation here\n&gt; &gt; **TODO**: add image\n&gt; &gt;\n&gt; {: .solution}\n&gt;\n{: .question}\n\n\n# Conclusion\n{:.no_toc}\n\nSuperimposition of related structures is a very efficient approach to spot similarities and differences of structutally related proteins.\n&quot;,&quot;# What is R ?\n{:.no_toc}\n\nR is many things: a project, a language... \nAs a **project**, R is part of the [GNU free software project](http://www.gnu.org). The development of R is done under the philosophy that software should be free of charge. This is good for the user, although there are some disadvantages: R comes with ABSOLUTELY NO WARRANTY. This statement comes up on the screen every time you start R. There is no company regulating R as a product. The R project is largely an academic endeavor, and most of the contributors are statisticians, hence the sometimes incomprehensible documentation. \nAs a **computer language** it was created to allow manipulation of data, statistical analysis and visualization. It is not easy to learn the language if you haven&#39;t done any programming before but it is worth taking the time as it can be a very useful tool.  An enormous variety of statistical analyses are available and R allows you to produce graphs exactly as you want them with publication quality. \n\n### Good things about R\n- It&#39;s free\n- It works on Windows, Mac and Linux\n- It can deal with very large datasets (compared to Excel)\n- A lot of freedom: graphs can be produced to your own taste\n- Supports all statistical analyses: from basic to very complex\n\n### Bad things about R\n- It can struggle with extremely large datasets\n- Difficult if you don&#39;t have any programming experience \n- Open source: many people contribute thus consistency can be low\n- Open source: documentation can be poor or written by/for experts\n- Can contain  bugs and errors: packages that are widely used are probably correct, niche packages can contain errors, there is no central team assessing the quality of the code\n\n# Installing R\nR is available on the [CRAN website](https://cran.r-project.org/) (Comprehensive R Archive Network]. \nIt can be installed on Linux, Mac and Windows. On the top of the CRAN page is a section with **Precompiled Binary Distribution**: R versions you can download as an .exe file (for Windows users) and are easy to install. What you download is the basic R installation: it contains the base package and other packages considered essential enough to include in the main installation. Exact content may vary with different versions of R.\nAs R is constantly being updated and new versions are constantly released, it is recommended to regularly install the newest version of R. \n\n# Installing RStudio\nAlthough you can work directly in the R editor, most people find it easier to use [RStudio](https://www.rstudio.com/)  on top of R. RStudio is free and available for Windows, Mac and Linux. You need to have R installed to run Rstudio. \n\n# RStudio user interface\nWatch this [video tutorial](https://www.youtube.com/watch?v=5YmcEYTSN7k) on the different components of the RStudio user interface and this [video tutorial](https://www.youtube.com/watch?v=o0Y478jOjGk) on how to use the RStudio user interface.\n\n### The script editor\nA script is a text file that contains all the commands you want to run. You can write and run scripts and you can also save them so next time you need to do a similar analysis you can change and re-run the script with minimal effort. An R project can contain multiple scripts. \nThe script editor highlights syntax in scripts making it easy to find and prevent errors. It has many features that will help you write scripts e.g. autocompletion, find/replace, commenting. \n\n### Autocompletion\nIt supports the automatic completion of code, e.g. if you have an object named relfreq in your workspace, type rel in the script editor and it will show a list of possibilities to complete the name.\n\n&lt;figure id=\&quot;figure-1\&quot;&gt;&lt;img src=\&quot;../../images/Rautocompletion.png\&quot; alt=\&quot;autocompletion\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 1:&lt;/span&gt; Example for autocompletion&lt;/figcaption&gt;&lt;/figure&gt;\n\n### Find and replace\nFind and replace can be opened using Ctrl+F.\n\n### Adding comments to scripts\nIn scripts you must include comments to help you remember or tell collaborators what you did. Comments are lines that start with a # symbol. This symbol tells R to ignore  this line. Comments are displayed in green.\nYou can comment and uncomment large selections of code using: **Comment/Uncomment Lines**\n\n&lt;figure id=\&quot;figure-2\&quot;&gt;&lt;img src=\&quot;../../images/Rcomment_uncomment.png\&quot; alt=\&quot;comment_uncomment\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 2:&lt;/span&gt; Menu Comment/Uncomment Lines&lt;/figcaption&gt;&lt;/figure&gt;\n\n### Adding section headings to scripts\nAdd section headings to your scripts using the following format: #Heading Name####\n\n&lt;figure id=\&quot;figure-3\&quot;&gt;&lt;img src=\&quot;../../images/Rsection_headings.png\&quot; alt=\&quot;section_headings\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 3:&lt;/span&gt; Define section headings&lt;/figcaption&gt;&lt;/figure&gt;\n\nAt the bottom of the script editor you can quickly navigate to sections in your script. Especially in long scripts this is very useful.\n\n### Creating a new script\nClick **File** in the top menu and select **New File &gt; R Script**.\n\n&lt;figure id=\&quot;figure-4\&quot;&gt;&lt;img src=\&quot;../../images/Rnew_script.png\&quot; alt=\&quot;new_script\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 4:&lt;/span&gt; File Menu / New File&lt;/figcaption&gt;&lt;/figure&gt;\n\nBesides a simple R script, there are many other file types you can create: \n- [R markdown](http://rmarkdown.rstudio.com/) file: incorporate R-code and its results in a report \n- R Notebook: R Markdown file with chunks of code that can be executed interactively, with output visible beneath the code\n- R Sweave file: incorporate R-code and its results in a Latex report\n\n### Opening an existing script\nClick **File** in the top menu and select **Open File**.\n\nScripts are opened as a tab in the script editor. You can open several scripts at the same time in RStudio. \n\n### Running a script\nTo run a script you select the code that you want to execute in the script editor and click the **Run** button at the top right of the script editor. \n\n![run_script](../../images/Rrun_script.png)\n\nThe code will be executed in the console.\n\n### Saving a script\n\nIf there are unsaved changes in a script, the name of the script will be red and followed by an asterisk. To save the script click the **Save** button: ![save_script](../../images/Rsave_script.png)\n\nR scripts should have the extension .R \nOnce it is saved the asterisk disappears and the name becomes black.\n\n### The console\nThe  &gt; symbol in the console shows that R is ready to execute code \ne.g. type 10+3 and press return\n```\n&gt; 10 + 3\n[1] 13\n&gt;\n```\nThe result is printed in the console. \n\nIt is recommended to write commands in a script rather than typing them directly into the console. Creating a script makes it easier to reproduce, repeat and describe the analysis. If you select commands in the script editor and press the **Run** button, you will see the commands appearing in the console as they are executed. \n\nIf the &gt; symbol does not reappear upon execution of a command it means that R has crashed or is still calculating. To terminate a command press Esc.\n\nThe console also has many [features that make life easier](https://support.rstudio.com/hc/en-us/articles/200404846-Working-in-the-Console) like autocompletion, retrieving previous commands.\n\n### Environment\nA list of all variables (numbers, vectors, plots, models...) that have been imported or generated. The variables that R creates and manipulates are called *objects*. \nTo remove all variables that have been generated in the RStudio session:\n```\n&gt; rm(list=ls())\n```\nls() lists the objects in the current workspace and rm() removes them.\n\n### History\nAn overview of the last 500 commands that were run in the console: see [how to use the history](https://support.rstudio.com/hc/en-us/articles/200526217-Command-History).\n\n### Connections\nAn interface to easily [connect to databases](http://db.rstudio.com/) in R. \n\n### Files\nThe list of files and folders in the working directory. RStudio has a default working directory, typically your home folder.\n\n### Changing the working directory\n Often you want to work in the folder that contains the data. In that case you can change the working directory. \n Check which folder R is using as a working directory:\n```\n&gt; getwd()\n```\nChange the working directory:\n```\n&gt; setwd(\&quot;D:/trainingen/zelfgegeven/R/\&quot;)\n```\n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; You need to use / or \\\\ in paths. Either will work but \\ will not since R sees it as the character that represents a division. \n{: .comment}\n\nChanging your working directory will make relative file references in your code invalid so you type this in the console **at the start of the analysis**.\n\nAlternatively you can change the working directory in the **Files** tab, expand **More** and select **Set As Working Directory**.\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; 1. Download the demo script for this lesson and open it in RStudio\n&gt; [`Demo_1.R`](http://data.bits.vib.be/pub/trainingen/RIntro/Demo_1.R)\n&gt; 2. From the demo script run the **Set working directory** section\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 1\n&gt;\n&gt; Set the working directory to the folder that contains the demo script that you have downloaded and check if it was changed. \n{: .hands_on}\n\nTo list the files in the working directory:\n```\n&gt; list.files() \n```\n\n### Plots\nPlots that are generated by the code you run will appear here.\nTo save a plot click the **Export** button: ![export_plot](../../images/Rexport_plot.png)\n\n### Packages\nR is popular because of the enormous diversity of packages. R is essentially a modular environment and you install and load the modules (packages) you need. Packages are available at the [CRAN](https://cran.r-project.org/web/packages/available_packages_by_name.html) and [Bioconductor](http://www.bioconductor.org/packages/release/BiocViews.html) websites. \nInstalling a package means that a copy of the package is downloaded and unzipped on your computer. If you want to know in what directory R stores the packages, type:\n\n```\n&gt;.libPaths()\n[1] \&quot;D:/R-3.6.0/library\&quot;\n&gt;\n```\nto see the default path where R stores packages. If you want to change this folder use the *destdir* argument of the install.packages() function:\n\n```\n&gt; install.packages(\&quot;car\&quot;,destdir=\&quot;C:/Users/Janick/R\&quot;)\n```\nYou only need to install a package once, as it is saved on your computer.\n\n### Installing R packages\nWatch this [video tutorial](https://www.youtube.com/watch?v=u1r5XTqrCTQ ) on how to install CRAN packages. \nWhen you have made changes to the right side of the Rstudio user interface (packages, files tab...), R is sometimes slow to show these changes. In that case hit the refresh button: ![refresh_button](../../images/Rrefresh_button.png)\n\nSome packages are not available on the CRAN site. Download in compressed format (as a .zip or .tar.gz file) from the source site. To install: select **Install from Package Archive File (.zip; .tar.gz)** in the **Install Packages** window and R will put it in the appropriate directory. \n\n&lt;figure id=\&quot;figure-5\&quot;&gt;&lt;img src=\&quot;../../images/Rinstall_zip.png\&quot; alt=\&quot;install_zip\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 5:&lt;/span&gt; Installing packages downloaded from their source site&lt;/figcaption&gt;&lt;/figure&gt;\n\n### Installing Bioconductor packages\nBioconductor is a set of R packages that provides tools for the analysis of high-throughput data, e.g. NGS data.\nMake sure you have the BiocManager package installed:\n```\n&gt; if (!requireNamespace(\&quot;BiocManager\&quot;)) \ninstall.packages(\&quot;BiocManager\&quot;) \n```\nThe if statement is checking if you already have the BiocManager package installed, if not then install.packages() will install it. BiocManager is a package to install and update Bioconductor packages. Once BiocManager is installed, you can install the Bioconductor core packages:\n```\n&gt; BiocManager::install()\n```\nTo install additional Bioconductor packages e.g. **GenomicFeatures** you type the following command:\n```\n&gt; BiocManager::install(\&quot;GenomicFeatures\&quot;)\n```\nOverview of all available Bioconductor [packages](https://www.bioconductor.org/packages/release/BiocViews.html#___Software) and [workflows](https://www.bioconductor.org/packages/release/BiocViews.html#___Workflow).\n\n### Installing packages from GitHub\nGit is a free and open source version control system. Version control helps software developers manage changes to code by keeping track of every change in a special database. If a mistake is made, the developer can turn back the clock and compare earlier versions of the code to fix the mistake. \nThere is an install_github() function in the devtools packageto install R packages hosted on GitHub:\n```\n&gt; install.packages(\&quot;devtools\&quot;) \n&gt; library(devtools)\n&gt; devtools::install_github(\&quot;statOmics/MSqRob&amp;copy;MSqRob0.7.6\&quot;)\n```\n\n### Loading packages\n Each time you want to use a package you have to load it (activate its functions). Loading a package is done by selecting it in the list of installed packages or by typing the following command:\n```\n&gt; library(\&quot;name_of_package\&quot;)\n```\nIf R responds:\n```\nError in library(car) : there is no package called &#39;car&#39;\n```\nor similar, it means that the car package needs to be installed first.\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; Run commands of the **Installation** section of the demo script\n{: .hands_on}\n\n### Help\nYou can find a lot of documentation online: e.g. the [getting help section](https://www.r-project.org/help.html) of the R website. R documentation is not easily accessible nor well-structured  so it can be a challenge to consult the help files of R packages online. By far the most user-friendly interface for searching the R documentation is the [Rdocumentation website](https://www.rdocumentation.org/).\nAdditional useful links:\n- [Documentation of RStudio](https://support.rstudio.com/hc/en-us/categories/200035113-Documentation) \n- [Quick R by DataCamp](https://www.statmethods.net/about/sitemap.html): loads of basic and advanced tutorials\n- [R-bloggers](https://www.r-bloggers.com/): R-news and tutorials contributed by bloggers\n- [Rseek](https://rseek.org/): Google specifically for R.\n- [Google&#39;s R style guide](https://google.github.io/styleguide/Rguide.xml): Programming rules for R designed in collaboration with the entire R user community at Google to make R code easier to read, share, and verify.\n\nAccess the R documentation in RStudio using commands: help() or ?\n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Get help** section\n{: .hands_on}\n\n### Viewer\nViews HTML files that are located on your computer.\n\n[All RStudio keyboard shortcuts](https://support.rstudio.com/hc/en-us/articles/200711853-Keyboard-Shortcuts)\n\n# Expressions in R\nR can handle any kind of data: numerical, character, logical... \n\n### Character data\nCharacter data like \&quot;green\&quot;, \&quot;cytoplasm\&quot; must be typed in between **single or double quotes**:\n```\n&gt; x &lt;- \&quot;Hello\&quot;\n```\nTo use quotes in the text escape the quotes:\n```\n&gt; x &lt;- \&quot;say \\\&quot;Hello\\\&quot;\&quot;\n```\nNames of packages, files, paths on your computer, urls are all text data and need to be typed in between quotes. Names of variables do not. \n\n### Booleans\nBoolean values are **TRUE** and **FALSE** without quotes because they are Booleans not text. \n\n&gt; ### {% icon comment %} Comment\n&gt;\n&gt; R is case sensitive: true and false are not recognized as Booleans. They have to be written in capitals.\n{: .comment}\n\n### Missing values\nMissing values are represented by **NA** (Not Available) without quotes. \nImpossible values (e.g., dividing by zero) are represented by the symbol NaN (Not A Number).\n\n### Arithmetic operators\n\n&lt;figure id=\&quot;figure-6\&quot;&gt;&lt;img src=\&quot;../../images/Rarithmetic_operators.png\&quot; alt=\&quot;arithmetic_operators\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 6:&lt;/span&gt; Overview of arithmetic operators&lt;/figcaption&gt;&lt;/figure&gt;\n\nArithmetic operators follow the standard **order of priority**, with exponentiation the highest and addition and subtraction the lowest priority, but you can control the order with **parentheses**. Do not use brackets as these are for other purposes in R. \n\n### Logical operators\nLogical operators can be used to selectively execute code based on certain conditions. They allow to create logical expressions (comparisons) that return TRUE or FALSE. \n\n&lt;figure id=\&quot;figure-7\&quot;&gt;&lt;img src=\&quot;../../images/Rlogic_operators.png\&quot; alt=\&quot;logic_operators\&quot;&gt;&lt;figcaption&gt;&lt;span class=\&quot;figcaption-prefix\&quot;&gt;Figure 7:&lt;/span&gt; Overview of logical operators&lt;/figcaption&gt;&lt;/figure&gt;\n\nLogical expressions may be combined using logical operators. The NOT operator (!) can be used to assess whether something is NOT the case. \n\n```\n&gt; x = 1\n&gt; y = 2   \n&gt; z = x &gt; y      \t\tis x larger than y? \n&gt; z              \t\t\tFALSE \n&gt; u = TRUE\n&gt; v = FALSE \n&gt; u &amp; v          \t\t\tu AND v: FALSE \n&gt; u | v          \t\t\tu OR v: TRUE \n&gt; !u             \t\t\tNOT u: FALSE\n```\n&gt; ### {% icon hands_on %} Hands-on: Exercise 2a\n&gt;\n&gt;    &gt; ### {% icon question %} Question \n&gt;    &gt; What&#39;s the difference between x=2 and x==2 ? \n&gt;    &gt;\n&gt;    &gt; &gt; ### {% icon solution %} Solution\n&gt;    &gt; &gt;  The = operator attributes a value to a variable (see next section), x becomes 2. \n&gt;    &gt; &gt;  The == is a logical operator, testing whether the logical expression x equals 2 is TRUE or FALSE.\n&gt;    &gt; {: .solution }\n&gt;    {: .question }\n&gt;\n{: .hands_on }\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 2b\n&gt;\n&gt; Check if the words UseR and user are equal. \n{: .hands_on}\n\n&gt; ### {% icon comment %} R is case sensitive\n&gt;\n&gt; As exercise 2b showed R is indeed case sensitive.\n{: .comment}\n\n# Assigning variables\nA variable allows you to save a value or an object (a plot, a table, a list of values) in R. \nA value or object is assigned to a variable by the assignment operator **&lt;-**\nIt consists of the two characters &lt; (less than) and - (minus): \n```\n&gt; v &lt;- 4\tnow the value of variable v is 4\n````\nIn most contexts the = operator can be used as an alternative:\n```\n&gt; v &lt;- 4 \n&gt; v = 4 \ngive the same result: a variable called v with value 4\n```\nAfter R has performed the assignment you will not see any output, as the value 4 has been saved to variable v. You can access and use this variable at any time and print its value in the console by running its name:\n```\n&gt; v\n[1] 4\n```\nYou can now use v in expressions instead of 4\n```\n&gt; v * v\n[1] 16\n```\nYou can re-assign a new value to a variable at any time: \n```\n&gt; v &lt;- \&quot;a cool variable\&quot;\n&gt; v\n[1] \&quot;a cool variable\&quot;\n```\n\nR is not very fussy as far as syntax goes. Variable names can be anything, though they cannot begin with a number or symbol. Informative names often involve using more than one word. Providing there are **no spaces** between these words you can join them using dots, underscores and capital letters though the Google R style guide recommends that names are joined with a dot. \n\n### Using operators to create variables\nYou can combine variables into a new one using operators (like + or /).\n\n### Using functions to create variables\nA function is a piece of code that performs a specific task. \nFunctions are called by another line of code that sends a request to the function to do something or return a variable. The call may pass *arguments* (inputs) to the function. In other words a function allows you to combine variables (arguments) into a new variable (returned variable).\nThere are lots of built in functions in R and you can also write your own. Even the base package supplies a large number of pre-written functions to use. Other packages are filled with additional functions for related tasks.\nCalling a function in R has a certain syntax:\n**output &lt;- function(list of arguments)** \nFor example: \n```\n&gt; p &lt;-  ggplot(mtcars,(aes(wt,mpg))\n```\nIn this example **ggplot()** is the **function**. The brackets () are always needed. Before a function can start the actions and calculations  it encodes, it needs prior information: **input** data and parameter settings. These are called the **arguments** of the function. In this example the arguments are:\n- **mtcars**: a table containing the input data\n- **aes(wt,mpg)**: defines the two columns of the table you want to plot: weight (wt) along the X-axis and miles/gallon (mpg) along the Y-axis.\n\nTo see the arguments of a function you can use **?** or **help()**:\n```\n&gt; ? ggplot \n&gt; help(ggplot)\n```\nThis opens the documentation of the function in the **Help** tab including an overview of the arguments of the function. At the bottom of the documentation page you find examples on how to use the function.\nThe function generates a plot so the plot **p** is the **output** of the function.  \n\n&gt; ### {% icon hands_on %} Hands-on: Demo\n&gt;\n&gt; From the demo script run the **Assigning variables** section\n{: .hands_on}\n\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 3a\n&gt;\n&gt; 1. Create a variable called patients with value 42\n&gt; 2. Print the value of patients divided by 2\n&gt; 3. Create a variable called patients_gr2 with value 24\n&gt; 4. Print the total number of patients\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  &gt; ```\n&gt;    &gt;  &gt; patients &lt;- 42\n&gt;    &gt;  &gt; patients/2\n&gt;    &gt;  &gt; patients_gr2 &lt;- 24\n&gt;    &gt;  &gt; total_patients &lt;- patients + patients_gr2\n&gt;    &gt;  &gt; total_patients\n&gt;    &gt;  &gt;```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  What will happen when you run this code ?\n&gt;    &gt; ```\n&gt;    &gt;  \&quot;patients\&quot; &lt;- 42\n&gt;    &gt;  \&quot;patients\&quot;/2\n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 3b\n&gt;\n&gt; Check the arguments of the mean() function. \n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  ?mean\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\nThe mean() function has many arguments and each argument has a default value. To use the default values simply do not specify these arguments in the function call. You only have to specify the arguments for which you want to use a value other than the default.\nTo show the **examples** section instead of the full documentation page:\n```\n&gt; example(min) \n```\n\n&gt; ### {% icon hands_on %} Hands-on: Exercise 3c\n&gt;\n&gt; Calculate and print the sum of patients and patients_gr2 using the sum() function.\n&gt;    &gt; ### {% icon solution %} solution: answer\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  sum(patients,patients_gr2)\n&gt;    &gt;  ```\n&gt;    {: .solution}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  Replace the sum() function with the mean() function. What happens ?\n&gt;    &gt;    &gt; ### {% icon solution %} solution: answer\n&gt;    &gt;    &gt;  Look at the help of the sum() function. What&#39;s the first argument ? \n&gt;    &gt;    &gt;  Compare with the first argument of the mean() function\n&gt;    &gt;   {: .solution}\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  Will the code below work ?\n&gt;    &gt;  ```\n&gt;    &gt;  sum (patients,patients_gr2)\n&gt;    &gt;  ```\n&gt;    {: .question}\n&gt;    &gt; ### {% icon question %} Question\n&gt;    &gt;\n&gt;    &gt;  Will the code below work ?\n&gt;    &gt;  ```\n&gt;    &gt;  sum ( patients , patients_gr2 )\n&gt;    &gt;  ```\n&gt;    {: .question}\n{: .hands_on}\n\nSometimes functions from different packages have the same name. In that case use **package::function** to specify the package you want to use, e.g. ggplot2::ggplot() where ggplot2 is the name of the package and ggplot() is the name of the function.\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 3d\n&gt;\n&gt; Create a variable patients_gr3 with value \&quot;twenty\&quot; and print the total number of patients\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  patients_gr3 &lt;- \&quot;twenty\&quot;\n&gt;    &gt;  patients + patients_gr3\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 3e\n&gt;\n&gt; 1. Create variable x with value 5\n&gt; 2. Create variable y with value 2\n&gt; 3. Create variable z as the sum of x and y and print the value of z\n&gt; 4. Print x - y\n&gt; 5. Print the product of x and y and add 2 to it\n&gt;    &gt; ### {% icon solution %} Solution\n&gt;    &gt;\n&gt;    &gt;  ```\n&gt;    &gt;  x &lt;- 5\n&gt;    &gt;  y &lt;- 2\n&gt;    &gt;  z &lt;- x+y\n&gt;    &gt;  z\n&gt;    &gt;  x-y\n&gt;    &gt;  x*y+2\n&gt;    &gt;  ```\n&gt;    {: .solution}\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 3f\n&gt;\n&gt; What is the difference between \n&gt; correctLogic &lt;- TRUE  \n&gt; incorrectLogic &lt;- \&quot;TRUE\&quot;\n{: .hands_on}\n\n&gt; ### {% icon hands_on %} Hands-on: Extra exercise 3g\n&gt;\n&gt; Is there a difference between \n&gt; name &lt;- \&quot;Janick\&quot; \n&gt; name &lt;- &#39;Janick&#39;\n&gt; name &lt;- Janick\n{: .hands_on}\n&quot;,&quot;&lt;?xml version=\&quot;1.0\&quot; encoding=\&quot;UTF-8\&quot;?&gt;\n{% if page.xsl %}&lt;?xml-stylesheet type=\&quot;text/xsl\&quot; href=\&quot;{{ \&quot;/sitemap.xsl\&quot; | absolute_url }}\&quot;?&gt;\n{% endif %}&lt;urlset xmlns:xsi=\&quot;http://www.w3.org/2001/XMLSchema-instance\&quot; xsi:schemaLocation=\&quot;http://www.sitemaps.org/schemas/sitemap/0.9 http://www.sitemaps.org/schemas/sitemap/0.9/sitemap.xsd\&quot; xmlns=\&quot;http://www.sitemaps.org/schemas/sitemap/0.9\&quot;&gt;\n{% assign collections = site.collections | where_exp:&#39;collection&#39;,&#39;collection.output != false&#39; %}{% for collection in collections %}{% assign docs = collection.docs | where_exp:&#39;doc&#39;,&#39;doc.sitemap != false&#39; %}{% for doc in docs %}&lt;url&gt;\n&lt;loc&gt;{{ doc.url | replace:&#39;/index.html&#39;,&#39;/&#39; | absolute_url | xml_escape }}&lt;/loc&gt;\n{% if doc.last_modified_at or doc.date %}&lt;lastmod&gt;{{ doc.last_modified_at | default: doc.date | date_to_xmlschema }}&lt;/lastmod&gt;\n{% endif %}&lt;/url&gt;\n{% endfor %}{% endfor %}{% assign pages = site.html_pages | where_exp:&#39;doc&#39;,&#39;doc.sitemap != false&#39; | where_exp:&#39;doc&#39;,&#39;doc.url != \&quot;/404.html\&quot;&#39; %}{% for page in pages %}&lt;url&gt;\n&lt;loc&gt;{{ page.url | replace:&#39;/index.html&#39;,&#39;/&#39; | absolute_url | xml_escape }}&lt;/loc&gt;\n{% if page.last_modified_at %}&lt;lastmod&gt;{{ page.last_modified_at | date_to_xmlschema }}&lt;/lastmod&gt;\n{% endif %}&lt;/url&gt;\n{% endfor %}{% assign static_files = page.static_files | where_exp:&#39;page&#39;,&#39;page.sitemap != false&#39; | where_exp:&#39;page&#39;,&#39;page.name != \&quot;404.html\&quot;&#39; %}{% for file in static_files %}&lt;url&gt;\n&lt;loc&gt;{{ file.path | replace:&#39;/index.html&#39;,&#39;/&#39; | absolute_url | xml_escape }}&lt;/loc&gt;\n&lt;lastmod&gt;{{ file.modified_time | date_to_xmlschema }}&lt;/lastmod&gt;\n&lt;/url&gt;\n{% endfor %}&lt;/urlset&gt;\n&quot;,&quot;Sitemap: {{ \&quot;sitemap.xml\&quot; | absolute_url }}\n&quot;],&quot;source&quot;:&quot;.&quot;,&quot;destination&quot;:&quot;./_site&quot;,&quot;collections_dir&quot;:&quot;&quot;,&quot;cache_dir&quot;:&quot;.jekyll-cache&quot;,&quot;plugins_dir&quot;:&quot;_plugins&quot;,&quot;layouts_dir&quot;:&quot;_layouts&quot;,&quot;data_dir&quot;:&quot;metadata&quot;,&quot;includes_dir&quot;:&quot;.&quot;,&quot;safe&quot;:false,&quot;include&quot;:[&quot;.nojekyll&quot;],&quot;exclude&quot;:[&quot;shared/font-awesome/src/&quot;,&quot;Gemfile&quot;,&quot;Gemfile.lock&quot;,&quot;package.json&quot;,&quot;package-lock.json&quot;,&quot;CONTRIBUTING.md&quot;,&quot;CONTRIBUTORS.yaml&quot;,&quot;LICENSE.md&quot;,&quot;README.md&quot;,&quot;Makefile&quot;,&quot;miniconda.sh&quot;,&quot;**/README.md&quot;,&quot;**/*.yaml&quot;,&quot;**/*.yml&quot;,&quot;**/*.sh&quot;,&quot;bin/&quot;,&quot;metadata/&quot;,&quot;templates/&quot;,&quot;vendor/&quot;,&quot;node_modules/&quot;,&quot;.sass-cache&quot;,&quot;.jekyll-cache&quot;,&quot;gemfiles&quot;,&quot;node_modules&quot;,&quot;vendor/bundle/&quot;,&quot;vendor/cache/&quot;,&quot;vendor/gems/&quot;,&quot;vendor/ruby/&quot;],&quot;keep_files&quot;:[&quot;.git&quot;,&quot;.svn&quot;],&quot;encoding&quot;:&quot;utf-8&quot;,&quot;markdown_ext&quot;:&quot;markdown,mkdown,mkdn,mkd,md&quot;,&quot;strict_front_matter&quot;:false,&quot;show_drafts&quot;:null,&quot;limit_posts&quot;:0,&quot;future&quot;:true,&quot;unpublished&quot;:false,&quot;whitelist&quot;:[],&quot;plugins&quot;:[&quot;jekyll-feed&quot;,&quot;jekyll-environment-variables&quot;,&quot;jekyll-github-metadata&quot;,&quot;jekyll-scholar&quot;,&quot;jekyll-sitemap&quot;],&quot;markdown&quot;:&quot;kramdown&quot;,&quot;highlighter&quot;:&quot;rouge&quot;,&quot;lsi&quot;:false,&quot;excerpt_separator&quot;:&quot;\n\n&quot;,&quot;incremental&quot;:false,&quot;detach&quot;:false,&quot;port&quot;:&quot;4000&quot;,&quot;host&quot;:&quot;127.0.0.1&quot;,&quot;baseurl&quot;:&quot;&quot;,&quot;show_dir_listing&quot;:false,&quot;permalink&quot;:&quot;date&quot;,&quot;paginate_path&quot;:&quot;/page:num&quot;,&quot;timezone&quot;:null,&quot;quiet&quot;:false,&quot;verbose&quot;:false,&quot;defaults&quot;:[],&quot;liquid&quot;:{&quot;error_mode&quot;:&quot;warn&quot;,&quot;strict_filters&quot;:false,&quot;strict_variables&quot;:false},&quot;kramdown&quot;:{&quot;auto_ids&quot;:true,&quot;toc_levels&quot;:&quot;1..2&quot;,&quot;entity_output&quot;:&quot;as_char&quot;,&quot;smart_quotes&quot;:&quot;lsquo,rsquo,ldquo,rdquo&quot;,&quot;input&quot;:&quot;GFM&quot;,&quot;hard_wrap&quot;:false,&quot;guess_lang&quot;:true,&quot;footnote_nr&quot;:1,&quot;show_warnings&quot;:false,&quot;syntax_highlighter&quot;:&quot;rouge&quot;,&quot;syntax_highlighter_opts&quot;:{&quot;guess_lang&quot;:true},&quot;coderay&quot;:{}},&quot;title&quot;:&quot;VIB Bioinformatics Core&quot;,&quot;email&quot;:&quot;bits@vib.be&quot;,&quot;description&quot;:&quot;A collection of tutorials generated and maintained by VIB Bioinformatics Core&quot;,&quot;url&quot;:&quot;https://vibbits.github.io/&quot;,&quot;repository&quot;:&quot;vibbits/training-material&quot;,&quot;repository_branch&quot;:&quot;master&quot;,&quot;logo&quot;:&quot;assets/images/logo.svg&quot;,&quot;small_logo&quot;:&quot;assets/images/bioinformatics_core_rgb_neg.png&quot;,&quot;help_url&quot;:&quot;https://www.bits.vib.be&quot;,&quot;other_languages&quot;:&quot;fr, ja, es, pt, ar&quot;,&quot;figurify&quot;:{&quot;skip_empty&quot;:true,&quot;skip_layouts&quot;:[&quot;introduction_slides&quot;,&quot;tutorial_slides&quot;,&quot;base_slides&quot;],&quot;skip_titles&quot;:[&quot;Example of an image with a caption&quot;]},&quot;scholar&quot;:{&quot;style&quot;:&quot;_layouts/g3.csl&quot;,&quot;locale&quot;:&quot;en&quot;,&quot;sort_by&quot;:&quot;year,month&quot;,&quot;order&quot;:&quot;ascending&quot;,&quot;group_by&quot;:&quot;none&quot;,&quot;group_order&quot;:&quot;ascending&quot;,&quot;bibliography_group_tag&quot;:&quot;h2,h3,h4,h5&quot;,&quot;bibliography_list_tag&quot;:&quot;ol&quot;,&quot;bibliography_item_tag&quot;:&quot;li&quot;,&quot;bibliography_list_attributes&quot;:{},&quot;bibliography_item_attributes&quot;:{},&quot;source&quot;:&quot;topics/&quot;,&quot;bibliography&quot;:&quot;**/*.bib&quot;,&quot;repository&quot;:null,&quot;repository_file_delimiter&quot;:&quot;.&quot;,&quot;bibtex_options&quot;:{&quot;strip&quot;:false,&quot;parse_months&quot;:true},&quot;bibtex_filters&quot;:[&quot;smallcaps&quot;,&quot;superscript&quot;,&quot;italics&quot;,&quot;textit&quot;,&quot;lowercase&quot;,&quot;textregistered&quot;,&quot;tiny&quot;,&quot;latex&quot;],&quot;bibtex_skip_fields&quot;:[&quot;abstract&quot;,&quot;month_numeric&quot;],&quot;bibtex_quotes&quot;:[&quot;{&quot;,&quot;}&quot;],&quot;replace_strings&quot;:true,&quot;join_strings&quot;:true,&quot;remove_duplicates&quot;:false,&quot;details_dir&quot;:&quot;bibliography&quot;,&quot;details_layout&quot;:&quot;bibtex.html&quot;,&quot;details_link&quot;:&quot;Details&quot;,&quot;details_permalink&quot;:&quot;/:details_dir/:key:extension&quot;,&quot;bibliography_class&quot;:&quot;bibliography&quot;,&quot;bibliography_template&quot;:&quot;bibtemplate&quot;,&quot;reference_tagname&quot;:&quot;span&quot;,&quot;missing_reference&quot;:&quot;(missing reference)&quot;,&quot;details_link_class&quot;:&quot;details&quot;,&quot;query&quot;:&quot;@*&quot;,&quot;cite_class&quot;:&quot;citation&quot;,&quot;type_names&quot;:{&quot;article&quot;:&quot;Journal Articles&quot;,&quot;book&quot;:&quot;Books&quot;,&quot;incollection&quot;:&quot;Book Chapters&quot;,&quot;inproceedings&quot;:&quot;Conference Articles&quot;,&quot;thesis&quot;:&quot;Theses&quot;,&quot;mastersthesis&quot;:&quot;Master&#39;s Theses&quot;,&quot;phdthesis&quot;:&quot;PhD Theses&quot;,&quot;manual&quot;:&quot;Manuals&quot;,&quot;techreport&quot;:&quot;Technical Reports&quot;,&quot;misc&quot;:&quot;Miscellaneous&quot;,&quot;unpublished&quot;:&quot;Unpublished&quot;},&quot;type_aliases&quot;:{&quot;phdthesis&quot;:&quot;thesis&quot;,&quot;mastersthesis&quot;:&quot;thesis&quot;},&quot;type_order&quot;:[],&quot;month_names&quot;:null},&quot;icon-tag&quot;:{&quot;question&quot;:&quot;fa-question-circle&quot;,&quot;solution&quot;:&quot;fa-eye&quot;,&quot;hands_on&quot;:&quot;fa-pencil&quot;,&quot;comment&quot;:&quot;fa-commenting-o&quot;,&quot;tip&quot;:&quot;fa-lightbulb-o&quot;,&quot;objectives&quot;:&quot;fa-bullseye&quot;,&quot;requirements&quot;:&quot;fa-check-circle&quot;,&quot;time&quot;:&quot;fa-hourglass-end&quot;,&quot;keypoints&quot;:&quot;fa-key&quot;,&quot;tool&quot;:&quot;fa-wrench&quot;,&quot;workflow&quot;:&quot;fa-share-alt&quot;,&quot;feedback&quot;:&quot;fa-comments-o&quot;,&quot;congratulations&quot;:&quot;fa-thumbs-up&quot;,&quot;trophy&quot;:&quot;fa-trophy&quot;,&quot;warning&quot;:&quot;fa-warning&quot;,&quot;details&quot;:&quot;fa-info-circle&quot;,&quot;exchange&quot;:&quot;fa-exchange&quot;,&quot;param-file&quot;:&quot;fa-file-o&quot;,&quot;param-files&quot;:&quot;fa-files-o&quot;,&quot;param-collection&quot;:&quot;fa-folder-o&quot;,&quot;param-text&quot;:&quot;fa-pencil&quot;,&quot;param-check&quot;:&quot;fa-check-square-o&quot;,&quot;param-select&quot;:&quot;fa-filter&quot;,&quot;param-repeat&quot;:&quot;fa-plus-square-o&quot;,&quot;galaxy-eye&quot;:&quot;fa-eye&quot;,&quot;galaxy-gear&quot;:&quot;fa-cog&quot;,&quot;galaxy-history&quot;:&quot;fa-archive&quot;,&quot;galaxy-library&quot;:&quot;fa-folder&quot;,&quot;galaxy-pencil&quot;:&quot;fa-pencil&quot;,&quot;galaxy-refresh&quot;:&quot;fa-refresh&quot;,&quot;galaxy-barchart&quot;:&quot;fa-bar-chart&quot;,&quot;galaxy-cross&quot;:&quot;fa-times&quot;,&quot;galaxy-columns&quot;:&quot;fa-columns&quot;,&quot;galaxy-tags&quot;:&quot;fa-tags&quot;,&quot;galaxy-selector&quot;:&quot;fa-check-square-o&quot;,&quot;galaxy-upload&quot;:&quot;fa fa-upload&quot;,&quot;galaxy-chart-select-data&quot;:&quot;fa fa-database&quot;,&quot;galaxy-save&quot;:&quot;fa fa-save&quot;,&quot;galaxy-scratchbook&quot;:&quot;fa fa-th&quot;,&quot;galaxy-dropdown&quot;:&quot;fa-caret-down&quot;,&quot;zenodo_link&quot;:&quot;fa-files-o&quot;,&quot;tutorial&quot;:&quot;fa-laptop&quot;,&quot;slides&quot;:&quot;fa-slideshare&quot;,&quot;interactive_tour&quot;:&quot;fa-magic&quot;,&quot;topic&quot;:&quot;fa-folder-o&quot;,&quot;instances&quot;:&quot;fa-cog&quot;,&quot;docker_image&quot;:&quot;fa-ship&quot;,&quot;galaxy_instance&quot;:&quot;fa-external-link&quot;,&quot;references&quot;:&quot;fa-bookmark&quot;,&quot;gitter&quot;:&quot;fa-comments&quot;,&quot;help&quot;:&quot;fa-life-ring&quot;,&quot;github&quot;:&quot;fa-github&quot;,&quot;email&quot;:&quot;fa-envelope-o&quot;,&quot;twitter&quot;:&quot;fa-twitter&quot;,&quot;linkedin&quot;:&quot;fa-linkedin&quot;,&quot;orcid&quot;:&quot;ai-orcid&quot;,&quot;curriculum&quot;:&quot;fa-graduation-cap&quot;,&quot;level&quot;:&quot;fa-graduation-cap&quot;,&quot;hall-of-fame&quot;:&quot;fa-users&quot;},&quot;serving&quot;:false,&quot;env&quot;:{&quot;DRAFTS&quot;:&quot;false&quot;,&quot;HOSTNAME&quot;:&quot;3641a53bceb4&quot;,&quot;LANGUAGE&quot;:&quot;en_US&quot;,&quot;JEKYLL_VERSION&quot;:&quot;4.0.0&quot;,&quot;RUBY_DOWNLOAD_SHA256&quot;:&quot;d5d6da717fd48524596f9b78ac5a2eeb9691753da5c06923a6c31190abe01a62&quot;,&quot;JEKYLL_BIN&quot;:&quot;/usr/jekyll/bin&quot;,&quot;JEKYLL_DOCKER_NAME&quot;:&quot;builder&quot;,&quot;JEKYLL_ENV&quot;:&quot;production&quot;,&quot;RUBY_VERSION&quot;:&quot;2.6.5&quot;,&quot;PWD&quot;:&quot;/srv/jekyll&quot;,&quot;BUNDLE_APP_CONFIG&quot;:&quot;/usr/local/bundle&quot;,&quot;RUBY_MAJOR&quot;:&quot;2.6&quot;,&quot;TZ&quot;:&quot;America/Chicago&quot;,&quot;HOME&quot;:&quot;/home/jekyll&quot;,&quot;JEKYLL_GID&quot;:&quot;1000&quot;,&quot;LANG&quot;:&quot;en_US.UTF-8&quot;,&quot;BUNDLE_SILENCE_ROOT_WARNING&quot;:&quot;1&quot;,&quot;BUNDLE_HOME&quot;:&quot;/usr/local/bundle&quot;,&quot;JEKYLL_DOCKER_COMMIT&quot;:&quot;0d12d4bc90b266ae4a38dfce9a511c52dd6f0311&quot;,&quot;GEM_HOME&quot;:&quot;/usr/local/bundle&quot;,&quot;BUNDLE_BIN&quot;:&quot;/usr/local/bundle/bin&quot;,&quot;SHLVL&quot;:&quot;1&quot;,&quot;FORCE_POLLING&quot;:&quot;false&quot;,&quot;JEKYLL_DOCKER_TAG&quot;:&quot;4.0.0&quot;,&quot;JEKYLL_UID&quot;:&quot;1000&quot;,&quot;BUNDLE_PATH&quot;:&quot;/usr/local/bundle&quot;,&quot;LC_ALL&quot;:&quot;en_US.UTF-8&quot;,&quot;JEKYLL_VAR_DIR&quot;:&quot;/var/jekyll&quot;,&quot;PATH&quot;:&quot;/usr/local/bundle/bin:/usr/jekyll/bin:/usr/local/bundle/gems/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;,&quot;JEKYLL_DATA_DIR&quot;:&quot;/srv/jekyll&quot;,&quot;GEM_BIN&quot;:&quot;/usr/gem/bin&quot;,&quot;VERBOSE&quot;:&quot;false&quot;,&quot;BUNDLER_ORIG_BUNDLE_BIN_PATH&quot;:&quot;BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL&quot;,&quot;BUNDLER_ORIG_BUNDLE_GEMFILE&quot;:&quot;BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL&quot;,&quot;BUNDLER_ORIG_BUNDLER_ORIG_MANPATH&quot;:&quot;BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL&quot;,&quot;BUNDLER_ORIG_BUNDLER_VERSION&quot;:&quot;BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL&quot;,&quot;BUNDLER_ORIG_GEM_HOME&quot;:&quot;/usr/gem&quot;,&quot;BUNDLER_ORIG_GEM_PATH&quot;:&quot;BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL&quot;,&quot;BUNDLER_ORIG_MANPATH&quot;:&quot;BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL&quot;,&quot;BUNDLER_ORIG_PATH&quot;:&quot;/usr/jekyll/bin:/usr/local/bundle/bin:/usr/local/bundle/gems/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;,&quot;BUNDLER_ORIG_RB_USER_INSTALL&quot;:&quot;BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL&quot;,&quot;BUNDLER_ORIG_RUBYLIB&quot;:&quot;BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL&quot;,&quot;BUNDLER_ORIG_RUBYOPT&quot;:&quot;BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL&quot;,&quot;BUNDLE_BIN_PATH&quot;:&quot;/usr/local/lib/ruby/gems/2.6.0/gems/bundler-2.0.2/exe/bundle&quot;,&quot;BUNDLE_GEMFILE&quot;:&quot;/srv/jekyll/Gemfile&quot;,&quot;BUNDLER_VERSION&quot;:&quot;2.0.2&quot;,&quot;RUBYOPT&quot;:&quot;-rbundler/setup&quot;,&quot;RUBYLIB&quot;:&quot;/usr/local/lib/ruby/gems/2.6.0/gems/bundler-2.0.2/lib&quot;,&quot;GEM_PATH&quot;:&quot;&quot;,&quot;MANPATH&quot;:&quot;/usr/local/bundle/gems/kramdown-2.1.0/man&quot;,&quot;JEKYLL_NO_BUNDLER_REQUIRE&quot;:&quot;true&quot;},&quot;github&quot;:{&quot;environment&quot;:&quot;dotcom&quot;,&quot;hostname&quot;:&quot;github.com&quot;,&quot;pages_env&quot;:&quot;dotcom&quot;,&quot;pages_hostname&quot;:&quot;github.io&quot;,&quot;api_url&quot;:&quot;https://api.github.com&quot;,&quot;help_url&quot;:&quot;https://help.github.com&quot;,&quot;versions&quot;:{},&quot;public_repositories&quot;:[{&quot;id&quot;:160538640,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxNjA1Mzg2NDA=&quot;,&quot;name&quot;:&quot;bigdatasurvey&quot;,&quot;full_name&quot;:&quot;vibbits/bigdatasurvey&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/bigdatasurvey&quot;,&quot;description&quot;:&quot;A survey of open-source big data platforms, centering around the Hadoop ecosystem.&quot;,&quot;fork&quot;:true,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/bigdatasurvey/deployments&quot;,&quot;created_at&quot;:&quot;2018-12-05 15:27:29 UTC&quot;,&quot;updated_at&quot;:&quot;2018-12-05 15:31:44 UTC&quot;,&quot;pushed_at&quot;:&quot;2015-10-28 20:33:50 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/bigdatasurvey.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/bigdatasurvey.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/bigdatasurvey.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/bigdatasurvey&quot;,&quot;homepage&quot;:null,&quot;size&quot;:524,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:&quot;JavaScript&quot;,&quot;has_issues&quot;:false,&quot;has_projects&quot;:false,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:false,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:null,&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;gh-pages&quot;},{&quot;id&quot;:136517018,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxMzY1MTcwMTg=&quot;,&quot;name&quot;:&quot;bioconda-recipes&quot;,&quot;full_name&quot;:&quot;vibbits/bioconda-recipes&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/bioconda-recipes&quot;,&quot;description&quot;:&quot;Conda recipes for the bioconda channel.&quot;,&quot;fork&quot;:true,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/bioconda-recipes/deployments&quot;,&quot;created_at&quot;:&quot;2018-06-07 18:36:07 UTC&quot;,&quot;updated_at&quot;:&quot;2018-10-11 09:37:21 UTC&quot;,&quot;pushed_at&quot;:&quot;2019-01-21 17:01:17 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/bioconda-recipes.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/bioconda-recipes.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/bioconda-recipes.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/bioconda-recipes&quot;,&quot;homepage&quot;:&quot;https://bioconda.github.io&quot;,&quot;size&quot;:167593,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:&quot;Shell&quot;,&quot;has_issues&quot;:false,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:null,&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:170295072,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxNzAyOTUwNzI=&quot;,&quot;name&quot;:&quot;CAMEL&quot;,&quot;full_name&quot;:&quot;vibbits/CAMEL&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/CAMEL&quot;,&quot;description&quot;:&quot; The CAMEL platform, an online compendium of Adaptive Microbial Experiments in the Lab.&quot;,&quot;fork&quot;:false,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/CAMEL/deployments&quot;,&quot;created_at&quot;:&quot;2019-02-12 10:03:23 UTC&quot;,&quot;updated_at&quot;:&quot;2019-10-11 15:18:26 UTC&quot;,&quot;pushed_at&quot;:&quot;2019-10-11 15:18:25 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/CAMEL.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/CAMEL.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/CAMEL.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/CAMEL&quot;,&quot;homepage&quot;:&quot;https://cameldatabase.com&quot;,&quot;size&quot;:2352,&quot;stargazers_count&quot;:1,&quot;watchers_count&quot;:1,&quot;language&quot;:&quot;HTML&quot;,&quot;has_issues&quot;:true,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:1,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:7,&quot;license&quot;:{&quot;key&quot;:&quot;agpl-3.0&quot;,&quot;name&quot;:&quot;GNU Affero General Public License v3.0&quot;,&quot;spdx_id&quot;:&quot;AGPL-3.0&quot;,&quot;url&quot;:&quot;https://api.github.com/licenses/agpl-3.0&quot;,&quot;node_id&quot;:&quot;MDc6TGljZW5zZTE=&quot;},&quot;forks&quot;:1,&quot;open_issues&quot;:7,&quot;watchers&quot;:1,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:173921762,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxNzM5MjE3NjI=&quot;,&quot;name&quot;:&quot;cytokit&quot;,&quot;full_name&quot;:&quot;vibbits/cytokit&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/cytokit&quot;,&quot;description&quot;:&quot;Microscopy Image Cytometry Toolkit&quot;,&quot;fork&quot;:true,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/cytokit/deployments&quot;,&quot;created_at&quot;:&quot;2019-03-05 10:04:08 UTC&quot;,&quot;updated_at&quot;:&quot;2019-03-05 15:37:40 UTC&quot;,&quot;pushed_at&quot;:&quot;2019-03-05 15:37:38 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/cytokit.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/cytokit.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/cytokit.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/cytokit&quot;,&quot;homepage&quot;:&quot;&quot;,&quot;size&quot;:174062,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:&quot;Jupyter Notebook&quot;,&quot;has_issues&quot;:false,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:{&quot;key&quot;:&quot;apache-2.0&quot;,&quot;name&quot;:&quot;Apache License 2.0&quot;,&quot;spdx_id&quot;:&quot;Apache-2.0&quot;,&quot;url&quot;:&quot;https://api.github.com/licenses/apache-2.0&quot;,&quot;node_id&quot;:&quot;MDc6TGljZW5zZTI=&quot;},&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:135151492,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxMzUxNTE0OTI=&quot;,&quot;name&quot;:&quot;DataIntegrationFlows&quot;,&quot;full_name&quot;:&quot;vibbits/DataIntegrationFlows&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/DataIntegrationFlows&quot;,&quot;description&quot;:&quot;This is a docker image to set up the atmosphere for running several data integration workflows&quot;,&quot;fork&quot;:false,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/DataIntegrationFlows/deployments&quot;,&quot;created_at&quot;:&quot;2018-05-28 11:24:02 UTC&quot;,&quot;updated_at&quot;:&quot;2018-10-11 09:37:21 UTC&quot;,&quot;pushed_at&quot;:&quot;2018-05-28 12:05:05 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/DataIntegrationFlows.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/DataIntegrationFlows.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/DataIntegrationFlows.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/DataIntegrationFlows&quot;,&quot;homepage&quot;:null,&quot;size&quot;:2,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:null,&quot;has_issues&quot;:true,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:null,&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:153103893,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxNTMxMDM4OTM=&quot;,&quot;name&quot;:&quot;EMDenoising&quot;,&quot;full_name&quot;:&quot;vibbits/EMDenoising&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/EMDenoising&quot;,&quot;description&quot;:null,&quot;fork&quot;:false,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/EMDenoising/deployments&quot;,&quot;created_at&quot;:&quot;2018-10-15 11:49:08 UTC&quot;,&quot;updated_at&quot;:&quot;2019-10-03 11:12:05 UTC&quot;,&quot;pushed_at&quot;:&quot;2019-10-03 11:12:03 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/EMDenoising.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/EMDenoising.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/EMDenoising.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/EMDenoising&quot;,&quot;homepage&quot;:null,&quot;size&quot;:3855,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:&quot;Java&quot;,&quot;has_issues&quot;:true,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:1,&quot;license&quot;:{&quot;key&quot;:&quot;gpl-3.0&quot;,&quot;name&quot;:&quot;GNU General Public License v3.0&quot;,&quot;spdx_id&quot;:&quot;GPL-3.0&quot;,&quot;url&quot;:&quot;https://api.github.com/licenses/gpl-3.0&quot;,&quot;node_id&quot;:&quot;MDc6TGljZW5zZTk=&quot;},&quot;forks&quot;:0,&quot;open_issues&quot;:1,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:223176463,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkyMjMxNzY0NjM=&quot;,&quot;name&quot;:&quot;herodotus&quot;,&quot;full_name&quot;:&quot;vibbits/herodotus&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/herodotus&quot;,&quot;description&quot;:&quot;Your friendly neighbourhood Slack historian (bot).&quot;,&quot;fork&quot;:false,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/herodotus/deployments&quot;,&quot;created_at&quot;:&quot;2019-11-21 13:08:27 UTC&quot;,&quot;updated_at&quot;:&quot;2019-11-21 14:02:20 UTC&quot;,&quot;pushed_at&quot;:&quot;2019-11-21 14:02:18 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/herodotus.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/herodotus.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/herodotus.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/herodotus&quot;,&quot;homepage&quot;:null,&quot;size&quot;:24,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:&quot;Clojure&quot;,&quot;has_issues&quot;:true,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:{&quot;key&quot;:&quot;epl-2.0&quot;,&quot;name&quot;:&quot;Eclipse Public License 2.0&quot;,&quot;spdx_id&quot;:&quot;EPL-2.0&quot;,&quot;url&quot;:&quot;https://api.github.com/licenses/epl-2.0&quot;,&quot;node_id&quot;:&quot;MDc6TGljZW5zZTMy&quot;},&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:224546543,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkyMjQ1NDY1NDM=&quot;,&quot;name&quot;:&quot;ilastik&quot;,&quot;full_name&quot;:&quot;vibbits/ilastik&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/ilastik&quot;,&quot;description&quot;:&quot;ilastik-shell, applets, and workflows to string them together.&quot;,&quot;fork&quot;:true,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/ilastik/deployments&quot;,&quot;created_at&quot;:&quot;2019-11-28 01:29:56 UTC&quot;,&quot;updated_at&quot;:&quot;2019-11-28 01:29:58 UTC&quot;,&quot;pushed_at&quot;:&quot;2019-11-25 14:26:41 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/ilastik.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/ilastik.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/ilastik.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/ilastik&quot;,&quot;homepage&quot;:null,&quot;size&quot;:105466,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:null,&quot;has_issues&quot;:false,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:{&quot;key&quot;:&quot;other&quot;,&quot;name&quot;:&quot;Other&quot;,&quot;spdx_id&quot;:&quot;NOASSERTION&quot;,&quot;url&quot;:null,&quot;node_id&quot;:&quot;MDc6TGljZW5zZTA=&quot;},&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:169587916,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxNjk1ODc5MTY=&quot;,&quot;name&quot;:&quot;incubator-echarts&quot;,&quot;full_name&quot;:&quot;vibbits/incubator-echarts&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/incubator-echarts&quot;,&quot;description&quot;:&quot;A powerful, interactive charting and visualization library for browser&quot;,&quot;fork&quot;:true,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/incubator-echarts/deployments&quot;,&quot;created_at&quot;:&quot;2019-02-07 14:50:26 UTC&quot;,&quot;updated_at&quot;:&quot;2019-02-07 14:50:32 UTC&quot;,&quot;pushed_at&quot;:&quot;2019-02-07 13:03:45 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/incubator-echarts.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/incubator-echarts.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/incubator-echarts.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/incubator-echarts&quot;,&quot;homepage&quot;:&quot;http://echarts.apache.org/&quot;,&quot;size&quot;:151893,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:&quot;JavaScript&quot;,&quot;has_issues&quot;:false,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:{&quot;key&quot;:&quot;apache-2.0&quot;,&quot;name&quot;:&quot;Apache License 2.0&quot;,&quot;spdx_id&quot;:&quot;Apache-2.0&quot;,&quot;url&quot;:&quot;https://api.github.com/licenses/apache-2.0&quot;,&quot;node_id&quot;:&quot;MDc6TGljZW5zZTI=&quot;},&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:153101025,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxNTMxMDEwMjU=&quot;,&quot;name&quot;:&quot;JavaQuasarBridge&quot;,&quot;full_name&quot;:&quot;vibbits/JavaQuasarBridge&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/JavaQuasarBridge&quot;,&quot;description&quot;:null,&quot;fork&quot;:false,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/JavaQuasarBridge/deployments&quot;,&quot;created_at&quot;:&quot;2018-10-15 11:24:09 UTC&quot;,&quot;updated_at&quot;:&quot;2019-10-02 15:58:35 UTC&quot;,&quot;pushed_at&quot;:&quot;2019-10-02 15:52:05 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/JavaQuasarBridge.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/JavaQuasarBridge.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/JavaQuasarBridge.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/JavaQuasarBridge&quot;,&quot;homepage&quot;:null,&quot;size&quot;:132,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:&quot;C++&quot;,&quot;has_issues&quot;:true,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:{&quot;key&quot;:&quot;gpl-3.0&quot;,&quot;name&quot;:&quot;GNU General Public License v3.0&quot;,&quot;spdx_id&quot;:&quot;GPL-3.0&quot;,&quot;url&quot;:&quot;https://api.github.com/licenses/gpl-3.0&quot;,&quot;node_id&quot;:&quot;MDc6TGljZW5zZTk=&quot;},&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:224546595,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkyMjQ1NDY1OTU=&quot;,&quot;name&quot;:&quot;lazyflow&quot;,&quot;full_name&quot;:&quot;vibbits/lazyflow&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/lazyflow&quot;,&quot;description&quot;:&quot;lazy parallel ondemand  zero copy numpy array data flows with caching and dirty propagation&quot;,&quot;fork&quot;:true,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/lazyflow/deployments&quot;,&quot;created_at&quot;:&quot;2019-11-28 01:30:24 UTC&quot;,&quot;updated_at&quot;:&quot;2019-11-28 01:30:26 UTC&quot;,&quot;pushed_at&quot;:&quot;2019-10-24 14:48:48 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/lazyflow.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/lazyflow.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/lazyflow.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/lazyflow&quot;,&quot;homepage&quot;:&quot;&quot;,&quot;size&quot;:17459,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:null,&quot;has_issues&quot;:false,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:{&quot;key&quot;:&quot;other&quot;,&quot;name&quot;:&quot;Other&quot;,&quot;spdx_id&quot;:&quot;NOASSERTION&quot;,&quot;url&quot;:null,&quot;node_id&quot;:&quot;MDc6TGljZW5zZTA=&quot;},&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:118458037,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxMTg0NTgwMzc=&quot;,&quot;name&quot;:&quot;modules-4-GenePattern&quot;,&quot;full_name&quot;:&quot;vibbits/modules-4-GenePattern&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/modules-4-GenePattern&quot;,&quot;description&quot;:&quot;modules for integrating under GenePattern some extra tools for NGS analysis&quot;,&quot;fork&quot;:false,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/modules-4-GenePattern/deployments&quot;,&quot;created_at&quot;:&quot;2018-01-22 13:04:16 UTC&quot;,&quot;updated_at&quot;:&quot;2018-10-11 09:37:21 UTC&quot;,&quot;pushed_at&quot;:&quot;2018-07-03 14:14:58 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/modules-4-GenePattern.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/modules-4-GenePattern.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/modules-4-GenePattern.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/modules-4-GenePattern&quot;,&quot;homepage&quot;:null,&quot;size&quot;:1927,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:null,&quot;has_issues&quot;:true,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:null,&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:136658710,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxMzY2NTg3MTA=&quot;,&quot;name&quot;:&quot;MOFA&quot;,&quot;full_name&quot;:&quot;vibbits/MOFA&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/MOFA&quot;,&quot;description&quot;:&quot;Multi-Omics Factor Analysis&quot;,&quot;fork&quot;:true,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/MOFA/deployments&quot;,&quot;created_at&quot;:&quot;2018-06-08 19:31:44 UTC&quot;,&quot;updated_at&quot;:&quot;2018-10-11 09:37:21 UTC&quot;,&quot;pushed_at&quot;:&quot;2018-06-23 20:50:58 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/MOFA.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/MOFA.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/MOFA.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/MOFA&quot;,&quot;homepage&quot;:&quot;&quot;,&quot;size&quot;:110522,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:&quot;HTML&quot;,&quot;has_issues&quot;:false,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:null,&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:157213851,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxNTcyMTM4NTE=&quot;,&quot;name&quot;:&quot;NextFlow_pipelines&quot;,&quot;full_name&quot;:&quot;vibbits/NextFlow_pipelines&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/NextFlow_pipelines&quot;,&quot;description&quot;:&quot;Tricks and tips for designing a NextFlow pipeline&quot;,&quot;fork&quot;:false,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/NextFlow_pipelines/deployments&quot;,&quot;created_at&quot;:&quot;2018-11-12 12:57:24 UTC&quot;,&quot;updated_at&quot;:&quot;2019-02-25 13:20:35 UTC&quot;,&quot;pushed_at&quot;:&quot;2019-02-25 13:20:34 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/NextFlow_pipelines.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/NextFlow_pipelines.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/NextFlow_pipelines.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/NextFlow_pipelines&quot;,&quot;homepage&quot;:null,&quot;size&quot;:1578,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:&quot;Nextflow&quot;,&quot;has_issues&quot;:true,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:null,&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:207801732,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkyMDc4MDE3MzI=&quot;,&quot;name&quot;:&quot;OMeta-Public&quot;,&quot;full_name&quot;:&quot;vibbits/OMeta-Public&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/OMeta-Public&quot;,&quot;description&quot;:&quot;OMeta-Public&quot;,&quot;fork&quot;:true,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/OMeta-Public/deployments&quot;,&quot;created_at&quot;:&quot;2019-09-11 12:00:36 UTC&quot;,&quot;updated_at&quot;:&quot;2019-09-11 12:00:37 UTC&quot;,&quot;pushed_at&quot;:&quot;2019-08-29 10:37:03 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/OMeta-Public.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/OMeta-Public.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/OMeta-Public.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/OMeta-Public&quot;,&quot;homepage&quot;:null,&quot;size&quot;:331121,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:null,&quot;has_issues&quot;:false,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:null,&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:186219236,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxODYyMTkyMzY=&quot;,&quot;name&quot;:&quot;OpenRefineTrainingData&quot;,&quot;full_name&quot;:&quot;vibbits/OpenRefineTrainingData&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/OpenRefineTrainingData&quot;,&quot;description&quot;:null,&quot;fork&quot;:false,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/OpenRefineTrainingData/deployments&quot;,&quot;created_at&quot;:&quot;2019-05-12 06:19:18 UTC&quot;,&quot;updated_at&quot;:&quot;2019-05-18 14:15:38 UTC&quot;,&quot;pushed_at&quot;:&quot;2019-05-18 14:15:36 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/OpenRefineTrainingData.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/OpenRefineTrainingData.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/OpenRefineTrainingData.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/OpenRefineTrainingData&quot;,&quot;homepage&quot;:null,&quot;size&quot;:7919,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:null,&quot;has_issues&quot;:true,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:{&quot;key&quot;:&quot;mit&quot;,&quot;name&quot;:&quot;MIT License&quot;,&quot;spdx_id&quot;:&quot;MIT&quot;,&quot;url&quot;:&quot;https://api.github.com/licenses/mit&quot;,&quot;node_id&quot;:&quot;MDc6TGljZW5zZTEz&quot;},&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:71230827,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnk3MTIzMDgyNw==&quot;,&quot;name&quot;:&quot;phyd3&quot;,&quot;full_name&quot;:&quot;vibbits/phyd3&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/phyd3&quot;,&quot;description&quot;:&quot;Phylogenetic tree viewer based on D3.js&quot;,&quot;fork&quot;:false,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/phyd3/deployments&quot;,&quot;created_at&quot;:&quot;2016-10-18 09:19:54 UTC&quot;,&quot;updated_at&quot;:&quot;2019-01-03 04:05:38 UTC&quot;,&quot;pushed_at&quot;:&quot;2018-05-29 06:46:30 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/phyd3.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/phyd3.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/phyd3.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/phyd3&quot;,&quot;homepage&quot;:null,&quot;size&quot;:2992,&quot;stargazers_count&quot;:29,&quot;watchers_count&quot;:29,&quot;language&quot;:&quot;JavaScript&quot;,&quot;has_issues&quot;:true,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:8,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:3,&quot;license&quot;:{&quot;key&quot;:&quot;gpl-3.0&quot;,&quot;name&quot;:&quot;GNU General Public License v3.0&quot;,&quot;spdx_id&quot;:&quot;GPL-3.0&quot;,&quot;url&quot;:&quot;https://api.github.com/licenses/gpl-3.0&quot;,&quot;node_id&quot;:&quot;MDc6TGljZW5zZTk=&quot;},&quot;forks&quot;:8,&quot;open_issues&quot;:3,&quot;watchers&quot;:29,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:138773305,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxMzg3NzMzMDU=&quot;,&quot;name&quot;:&quot;presentation&quot;,&quot;full_name&quot;:&quot;vibbits/presentation&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/presentation&quot;,&quot;description&quot;:&quot;20180907 presentation community meeting&quot;,&quot;fork&quot;:false,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/presentation&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/presentation/deployments&quot;,&quot;created_at&quot;:&quot;2018-06-26 17:49:03 UTC&quot;,&quot;updated_at&quot;:&quot;2019-01-25 06:43:04 UTC&quot;,&quot;pushed_at&quot;:&quot;2019-01-25 06:43:03 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/presentation.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/presentation.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/presentation.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/presentation&quot;,&quot;homepage&quot;:&quot;&quot;,&quot;size&quot;:33,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:null,&quot;has_issues&quot;:true,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:2,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:1,&quot;license&quot;:null,&quot;forks&quot;:2,&quot;open_issues&quot;:1,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:186428088,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxODY0MjgwODg=&quot;,&quot;name&quot;:&quot;qupath&quot;,&quot;full_name&quot;:&quot;vibbits/qupath&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/qupath&quot;,&quot;description&quot;:&quot;QuPath - Open Source Digital Pathology&quot;,&quot;fork&quot;:true,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/qupath&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/qupath/deployments&quot;,&quot;created_at&quot;:&quot;2019-05-13 13:45:18 UTC&quot;,&quot;updated_at&quot;:&quot;2019-05-15 09:48:35 UTC&quot;,&quot;pushed_at&quot;:&quot;2019-05-15 09:48:33 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/qupath.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/qupath.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/qupath.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/qupath&quot;,&quot;homepage&quot;:&quot;https://qupath.github.io&quot;,&quot;size&quot;:83357,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:&quot;Java&quot;,&quot;has_issues&quot;:false,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:{&quot;key&quot;:&quot;gpl-3.0&quot;,&quot;name&quot;:&quot;GNU General Public License v3.0&quot;,&quot;spdx_id&quot;:&quot;GPL-3.0&quot;,&quot;url&quot;:&quot;https://api.github.com/licenses/gpl-3.0&quot;,&quot;node_id&quot;:&quot;MDc6TGljZW5zZTk=&quot;},&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:133400916,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxMzM0MDA5MTY=&quot;,&quot;name&quot;:&quot;rocker_conda_data_integration&quot;,&quot;full_name&quot;:&quot;vibbits/rocker_conda_data_integration&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/rocker_conda_data_integration&quot;,&quot;description&quot;:&quot;Docker container based on rocker/tidyverse with miniconda3 to run various integration tools for Omics&quot;,&quot;fork&quot;:false,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_data_integration/deployments&quot;,&quot;created_at&quot;:&quot;2018-05-14 17:53:42 UTC&quot;,&quot;updated_at&quot;:&quot;2019-07-31 15:35:10 UTC&quot;,&quot;pushed_at&quot;:&quot;2019-01-13 08:51:00 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/rocker_conda_data_integration.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/rocker_conda_data_integration.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/rocker_conda_data_integration.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/rocker_conda_data_integration&quot;,&quot;homepage&quot;:&quot;&quot;,&quot;size&quot;:50406,&quot;stargazers_count&quot;:3,&quot;watchers_count&quot;:3,&quot;language&quot;:&quot;R&quot;,&quot;has_issues&quot;:true,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:3,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:{&quot;key&quot;:&quot;gpl-2.0&quot;,&quot;name&quot;:&quot;GNU General Public License v2.0&quot;,&quot;spdx_id&quot;:&quot;GPL-2.0&quot;,&quot;url&quot;:&quot;https://api.github.com/licenses/gpl-2.0&quot;,&quot;node_id&quot;:&quot;MDc6TGljZW5zZTg=&quot;},&quot;forks&quot;:3,&quot;open_issues&quot;:0,&quot;watchers&quot;:3,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:131875427,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxMzE4NzU0Mjc=&quot;,&quot;name&quot;:&quot;rocker_conda_mofa&quot;,&quot;full_name&quot;:&quot;vibbits/rocker_conda_mofa&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/rocker_conda_mofa&quot;,&quot;description&quot;:&quot;Docker container on rocker/tidyverse with miniconda3 to run MOFA tool https://github.com/bioFAM/MOFA&quot;,&quot;fork&quot;:false,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/rocker_conda_mofa/deployments&quot;,&quot;created_at&quot;:&quot;2018-05-02 16:08:04 UTC&quot;,&quot;updated_at&quot;:&quot;2018-10-11 09:37:21 UTC&quot;,&quot;pushed_at&quot;:&quot;2018-05-02 18:07:02 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/rocker_conda_mofa.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/rocker_conda_mofa.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/rocker_conda_mofa.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/rocker_conda_mofa&quot;,&quot;homepage&quot;:null,&quot;size&quot;:17,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:null,&quot;has_issues&quot;:true,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:{&quot;key&quot;:&quot;gpl-2.0&quot;,&quot;name&quot;:&quot;GNU General Public License v2.0&quot;,&quot;spdx_id&quot;:&quot;GPL-2.0&quot;,&quot;url&quot;:&quot;https://api.github.com/licenses/gpl-2.0&quot;,&quot;node_id&quot;:&quot;MDc6TGljZW5zZTg=&quot;},&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:113286207,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxMTMyODYyMDc=&quot;,&quot;name&quot;:&quot;scop3d&quot;,&quot;full_name&quot;:&quot;vibbits/scop3d&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/scop3d&quot;,&quot;description&quot;:&quot;Sequence conservation of protein on 3D structure.&quot;,&quot;fork&quot;:true,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/scop3d/deployments&quot;,&quot;created_at&quot;:&quot;2017-12-06 07:56:32 UTC&quot;,&quot;updated_at&quot;:&quot;2019-06-04 20:25:31 UTC&quot;,&quot;pushed_at&quot;:&quot;2019-06-04 20:25:30 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/scop3d.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/scop3d.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/scop3d.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/scop3d&quot;,&quot;homepage&quot;:&quot;&quot;,&quot;size&quot;:26190,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:&quot;Python&quot;,&quot;has_issues&quot;:false,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:false,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:{&quot;key&quot;:&quot;gpl-3.0&quot;,&quot;name&quot;:&quot;GNU General Public License v3.0&quot;,&quot;spdx_id&quot;:&quot;GPL-3.0&quot;,&quot;url&quot;:&quot;https://api.github.com/licenses/gpl-3.0&quot;,&quot;node_id&quot;:&quot;MDc6TGljZW5zZTk=&quot;},&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:104596713,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxMDQ1OTY3MTM=&quot;,&quot;name&quot;:&quot;scRNA-Seq-TCC-prep&quot;,&quot;full_name&quot;:&quot;vibbits/scRNA-Seq-TCC-prep&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/scRNA-Seq-TCC-prep&quot;,&quot;description&quot;:&quot;Preprocessing of single-cell RNA-Seq data for input to kallisto&quot;,&quot;fork&quot;:true,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-Seq-TCC-prep/deployments&quot;,&quot;created_at&quot;:&quot;2017-09-23 20:22:54 UTC&quot;,&quot;updated_at&quot;:&quot;2018-10-11 09:37:22 UTC&quot;,&quot;pushed_at&quot;:&quot;2016-12-01 02:04:26 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/scRNA-Seq-TCC-prep.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/scRNA-Seq-TCC-prep.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/scRNA-Seq-TCC-prep.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/scRNA-Seq-TCC-prep&quot;,&quot;homepage&quot;:null,&quot;size&quot;:8740,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:&quot;Jupyter Notebook&quot;,&quot;has_issues&quot;:false,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:{&quot;key&quot;:&quot;gpl-3.0&quot;,&quot;name&quot;:&quot;GNU General Public License v3.0&quot;,&quot;spdx_id&quot;:&quot;GPL-3.0&quot;,&quot;url&quot;:&quot;https://api.github.com/licenses/gpl-3.0&quot;,&quot;node_id&quot;:&quot;MDc6TGljZW5zZTk=&quot;},&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:137523231,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxMzc1MjMyMzE=&quot;,&quot;name&quot;:&quot;scRNA-tools&quot;,&quot;full_name&quot;:&quot;vibbits/scRNA-tools&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/scRNA-tools&quot;,&quot;description&quot;:&quot;Table of software for the analysis of single-cell RNA-seq data.&quot;,&quot;fork&quot;:true,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/scRNA-tools/deployments&quot;,&quot;created_at&quot;:&quot;2018-06-15 19:10:39 UTC&quot;,&quot;updated_at&quot;:&quot;2018-10-11 09:37:22 UTC&quot;,&quot;pushed_at&quot;:&quot;2018-06-15 19:31:56 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/scRNA-tools.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/scRNA-tools.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/scRNA-tools.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/scRNA-tools&quot;,&quot;homepage&quot;:null,&quot;size&quot;:3835,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:&quot;R&quot;,&quot;has_issues&quot;:false,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:{&quot;key&quot;:&quot;mit&quot;,&quot;name&quot;:&quot;MIT License&quot;,&quot;spdx_id&quot;:&quot;MIT&quot;,&quot;url&quot;:&quot;https://api.github.com/licenses/mit&quot;,&quot;node_id&quot;:&quot;MDc6TGljZW5zZTEz&quot;},&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:100585992,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxMDA1ODU5OTI=&quot;,&quot;name&quot;:&quot;sc_read_kallisto_wrapper&quot;,&quot;full_name&quot;:&quot;vibbits/sc_read_kallisto_wrapper&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/sc_read_kallisto_wrapper&quot;,&quot;description&quot;:&quot;wrapper for single cell transcriptomics pipeline with kallisto&quot;,&quot;fork&quot;:false,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/sc_read_kallisto_wrapper/deployments&quot;,&quot;created_at&quot;:&quot;2017-08-17 09:24:32 UTC&quot;,&quot;updated_at&quot;:&quot;2018-10-11 09:37:22 UTC&quot;,&quot;pushed_at&quot;:&quot;2018-02-09 09:22:40 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/sc_read_kallisto_wrapper.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/sc_read_kallisto_wrapper.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/sc_read_kallisto_wrapper.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/sc_read_kallisto_wrapper&quot;,&quot;homepage&quot;:null,&quot;size&quot;:84,&quot;stargazers_count&quot;:6,&quot;watchers_count&quot;:6,&quot;language&quot;:&quot;HTML&quot;,&quot;has_issues&quot;:true,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:2,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:{&quot;key&quot;:&quot;gpl-3.0&quot;,&quot;name&quot;:&quot;GNU General Public License v3.0&quot;,&quot;spdx_id&quot;:&quot;GPL-3.0&quot;,&quot;url&quot;:&quot;https://api.github.com/licenses/gpl-3.0&quot;,&quot;node_id&quot;:&quot;MDc6TGljZW5zZTk=&quot;},&quot;forks&quot;:2,&quot;open_issues&quot;:0,&quot;watchers&quot;:6,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:224546875,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkyMjQ1NDY4NzU=&quot;,&quot;name&quot;:&quot;volumina&quot;,&quot;full_name&quot;:&quot;vibbits/volumina&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/volumina&quot;,&quot;description&quot;:&quot;Volume Slicing and Editing&quot;,&quot;fork&quot;:true,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/volumina&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/volumina/deployments&quot;,&quot;created_at&quot;:&quot;2019-11-28 01:32:38 UTC&quot;,&quot;updated_at&quot;:&quot;2019-11-28 01:32:40 UTC&quot;,&quot;pushed_at&quot;:&quot;2019-11-22 15:53:44 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/volumina.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/volumina.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/volumina.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/volumina&quot;,&quot;homepage&quot;:&quot;http://ilastik.org&quot;,&quot;size&quot;:5774,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:null,&quot;has_issues&quot;:false,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:{&quot;key&quot;:&quot;other&quot;,&quot;name&quot;:&quot;Other&quot;,&quot;spdx_id&quot;:&quot;NOASSERTION&quot;,&quot;url&quot;:null,&quot;node_id&quot;:&quot;MDc6TGljZW5zZTA=&quot;},&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;},{&quot;id&quot;:153169091,&quot;node_id&quot;:&quot;MDEwOlJlcG9zaXRvcnkxNTMxNjkwOTE=&quot;,&quot;name&quot;:&quot;WaaS-Finnish-Cloud&quot;,&quot;full_name&quot;:&quot;vibbits/WaaS-Finnish-Cloud&quot;,&quot;private&quot;:false,&quot;owner&quot;:{&quot;login&quot;:&quot;vibbits&quot;,&quot;id&quot;:22908438,&quot;node_id&quot;:&quot;MDEyOk9yZ2FuaXphdGlvbjIyOTA4NDM4&quot;,&quot;avatar_url&quot;:&quot;https://avatars1.githubusercontent.com/u/22908438?v=4&quot;,&quot;gravatar_id&quot;:&quot;&quot;,&quot;url&quot;:&quot;https://api.github.com/users/vibbits&quot;,&quot;html_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;followers_url&quot;:&quot;https://api.github.com/users/vibbits/followers&quot;,&quot;following_url&quot;:&quot;https://api.github.com/users/vibbits/following{/other_user}&quot;,&quot;gists_url&quot;:&quot;https://api.github.com/users/vibbits/gists{/gist_id}&quot;,&quot;starred_url&quot;:&quot;https://api.github.com/users/vibbits/starred{/owner}{/repo}&quot;,&quot;subscriptions_url&quot;:&quot;https://api.github.com/users/vibbits/subscriptions&quot;,&quot;organizations_url&quot;:&quot;https://api.github.com/users/vibbits/orgs&quot;,&quot;repos_url&quot;:&quot;https://api.github.com/users/vibbits/repos&quot;,&quot;events_url&quot;:&quot;https://api.github.com/users/vibbits/events{/privacy}&quot;,&quot;received_events_url&quot;:&quot;https://api.github.com/users/vibbits/received_events&quot;,&quot;type&quot;:&quot;Organization&quot;,&quot;site_admin&quot;:false},&quot;html_url&quot;:&quot;https://github.com/vibbits/WaaS-Finnish-Cloud&quot;,&quot;description&quot;:null,&quot;fork&quot;:false,&quot;url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud&quot;,&quot;forks_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/forks&quot;,&quot;keys_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/keys{/key_id}&quot;,&quot;collaborators_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/collaborators{/collaborator}&quot;,&quot;teams_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/teams&quot;,&quot;hooks_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/hooks&quot;,&quot;issue_events_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/issues/events{/number}&quot;,&quot;events_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/events&quot;,&quot;assignees_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/assignees{/user}&quot;,&quot;branches_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/branches{/branch}&quot;,&quot;tags_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/tags&quot;,&quot;blobs_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/git/blobs{/sha}&quot;,&quot;git_tags_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/git/tags{/sha}&quot;,&quot;git_refs_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/git/refs{/sha}&quot;,&quot;trees_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/git/trees{/sha}&quot;,&quot;statuses_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/statuses/{sha}&quot;,&quot;languages_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/languages&quot;,&quot;stargazers_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/stargazers&quot;,&quot;contributors_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/contributors&quot;,&quot;subscribers_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/subscribers&quot;,&quot;subscription_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/subscription&quot;,&quot;commits_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/commits{/sha}&quot;,&quot;git_commits_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/git/commits{/sha}&quot;,&quot;comments_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/comments{/number}&quot;,&quot;issue_comment_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/issues/comments{/number}&quot;,&quot;contents_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/contents/{+path}&quot;,&quot;compare_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/compare/{base}...{head}&quot;,&quot;merges_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/merges&quot;,&quot;archive_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/{archive_format}{/ref}&quot;,&quot;downloads_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/downloads&quot;,&quot;issues_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/issues{/number}&quot;,&quot;pulls_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/pulls{/number}&quot;,&quot;milestones_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/milestones{/number}&quot;,&quot;notifications_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/notifications{?since,all,participating}&quot;,&quot;labels_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/labels{/name}&quot;,&quot;releases_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/releases{/id}&quot;,&quot;deployments_url&quot;:&quot;https://api.github.com/repos/vibbits/WaaS-Finnish-Cloud/deployments&quot;,&quot;created_at&quot;:&quot;2018-10-15 19:20:17 UTC&quot;,&quot;updated_at&quot;:&quot;2019-03-27 05:45:56 UTC&quot;,&quot;pushed_at&quot;:&quot;2019-03-27 05:44:56 UTC&quot;,&quot;git_url&quot;:&quot;git://github.com/vibbits/WaaS-Finnish-Cloud.git&quot;,&quot;ssh_url&quot;:&quot;git@github.com:vibbits/WaaS-Finnish-Cloud.git&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/WaaS-Finnish-Cloud.git&quot;,&quot;svn_url&quot;:&quot;https://github.com/vibbits/WaaS-Finnish-Cloud&quot;,&quot;homepage&quot;:null,&quot;size&quot;:3,&quot;stargazers_count&quot;:0,&quot;watchers_count&quot;:0,&quot;language&quot;:null,&quot;has_issues&quot;:true,&quot;has_projects&quot;:true,&quot;has_downloads&quot;:true,&quot;has_wiki&quot;:true,&quot;has_pages&quot;:false,&quot;forks_count&quot;:0,&quot;mirror_url&quot;:null,&quot;archived&quot;:false,&quot;disabled&quot;:false,&quot;open_issues_count&quot;:0,&quot;license&quot;:null,&quot;forks&quot;:0,&quot;open_issues&quot;:0,&quot;watchers&quot;:0,&quot;default_branch&quot;:&quot;master&quot;}],&quot;organization_members&quot;:[],&quot;build_revision&quot;:&quot;9f43f18a411de65222f7c941bcf4b7671aaeed5e&quot;,&quot;project_title&quot;:&quot;training-material&quot;,&quot;project_tagline&quot;:null,&quot;owner_name&quot;:&quot;vibbits&quot;,&quot;owner_url&quot;:&quot;https://github.com/vibbits&quot;,&quot;owner_gravatar_url&quot;:&quot;https://github.com/vibbits.png&quot;,&quot;repository_url&quot;:&quot;https://github.com/vibbits/training-material&quot;,&quot;repository_nwo&quot;:&quot;vibbits/training-material&quot;,&quot;repository_name&quot;:&quot;training-material&quot;,&quot;zip_url&quot;:&quot;https://github.com/vibbits/training-material/zipball/gh-pages&quot;,&quot;tar_url&quot;:&quot;https://github.com/vibbits/training-material/tarball/gh-pages&quot;,&quot;clone_url&quot;:&quot;https://github.com/vibbits/training-material.git&quot;,&quot;releases_url&quot;:&quot;https://github.com/vibbits/training-material/releases&quot;,&quot;issues_url&quot;:null,&quot;wiki_url&quot;:null,&quot;language&quot;:null,&quot;is_user_page&quot;:false,&quot;is_project_page&quot;:true,&quot;show_downloads&quot;:false,&quot;url&quot;:&quot;http://vibbits.github.io/training-material&quot;,&quot;contributors&quot;:false,&quot;releases&quot;:false}}
              page: {&quot;layout&quot;:&quot;introduction_slides&quot;,&quot;logo&quot;:&quot;GTN&quot;,&quot;title&quot;:&quot;Protein Structure Analysis&quot;,&quot;type&quot;:&quot;introduction&quot;,&quot;contributors&quot;:[&quot;abotzki&quot;,&quot;jvdurme&quot;,&quot;janick-bits&quot;],&quot;topic_name&quot;:&quot;protein-structure-analysis&quot;,&quot;tutorial_name&quot;:&quot;introduction&quot;,&quot;content&quot;:&quot;### Protein Structure Analysis ###\n\n- Sequences, structures and databases\n- Experimental methods (X-rays, electrons and NMR)\n- Finding and visualising structures from the  Protein Data Bank\n- Comparing structures\n- Modelling mutations\n- Creating homology models\n\n---\n### Sequences and Structures ###\n\nadd one slide over transcription / translation / \n\n---\n\n### Amino acids and peptide structure\n\n![](/topics/protein-structure-analysis/images/amino-acids.png)\n\n---\n\n### The Structure-Function Connection ###\n\n.pull-left[\n- Folded proteins provide a well-defined 3D arrangement of functional groups, creating microenvironments and active sites.\n- Structural changes  are often involved in functional  mechanisms  (motor proteins, ...)\n]\n.image-90[![](/topics/protein-structure-analysis/images/hemoglobin.png)]\n\n\n---\n\n### Databases\n\n.pull-left[\n**Uniprot** approx. 1100,000 sequences\n\n- mainly determined by large-scale DNA sequencing of individual genes or whole genomes\n- increasingly automated annotation\n\n**Protein Data Bank** approx. 141,000 \nexperimentally determined structures\n\n- Mainly determined by X-ray crystallography and high-resolution NMR spectroscopy\n- Automation is increasing, but there are still significant limitations in the rate of solving new structures\n]\n\n\n]\n.pull-right[ .image-50[![](/topics/protein-structure-analysis/images/uniprot-logo.png)]\n             .image-50[![](/topics/protein-structure-analysis/images/pdb-logo.png)]\n]\n\n---\n\n### X-Ray Crystallography ###\n\n![](/topics/protein-structure-analysis/images/xray-tech-setup.png)\n\n.pull-left[\n\n.left[In a crystal, a large number  of macromolecules are  packed together in a regular grid, with consistent  orientations and relative  distances. \nWhen exposed  to an X-ray beam, this  arrangement gives rise to\ndiffracted rays in specific directions,  resulting in discrete spots on the planar\ndetector. By rotating the crystal, a series  of images is obtained. From these, the\nintensities of all the diffracted rays of the  crystal can be derived.]\n\n]\n.pull-right[ .image-90[![](/topics/protein-structure-analysis/images/diffraction-pattern.png)]\n]\n\n\n---\n\n### X-Ray Crystallography ###\n\n.pull-left[\n.image-50[![](/topics/protein-structure-analysis/images/diffraction-pattern.png)]\n]\n.pull-right[.image-50[![](/topics/protein-structure-analysis/images/electron-density.png)]]\n\n|              |          |               |\n|:-------------|:--------:|--------------:|\n| Diffraction Spot Intensities and Phases $$F_{obs}(h,k,l)$$ and $$\\phi_{obs}(h,k,l)$$ | $$R_{cryst} = \\frac{\\sum_{h,k,l}F_{obs}-F_{calc}}{\\sum_{h,k,l}F_{obs}}$$ | Electron density $$\\rho(x,y,z)$$ |\n\n\n---\n\n### The Protein Databank ###\n\n.pull-left[ .image-80[![](/topics/protein-structure-analysis/images/wwpdb-welcome-page.png)] \n\n\n.pull-right[ \n.left[ [http://www.wwpdb.org](http://www.wwpdb.org) ]\n- contains structures of  proteins, nucleic acids  and complexes,  determined by X-ray  crystallography, NMR  spectroscopy\n- No purely theoretical  or ab initio models  (since 2006)\n- Also stores supporting  experimental data\n- Full deposition now  required by all peer-reviewed journals\n]\n]\n\n---\n\n### Exercise 1: Search the PDB ###\n\n- Use the UniProt site to search for dnak.  \n- Use the PDB site to search for dnak.\n - Compare the UniProt and PDB result lists.\n- Use the sequence search function to see if there are structures with sequences similar to that of the  DnaK C-terminal domain.\n- Look at the summary pages of a number of  structures and note some interesting properties.\n- Select a number of structures and create a report  page.\n\n---\n\n### PDB File Format ###\n\n![](/topics/protein-structure-analysis/images/pdb-file-format.png)\n\n---\n\n### Occupancy ###\n\n![](/topics/protein-structure-analysis/images/occupancy.png)\n\n\n---\n\n### Related Web sites ###\n\n- Nucleic Acid Database: DNA and RNA structures\n\n.left[[http://ndbserver.rutgers.edu/](http://ndbserver.rutgers.edu/)]\n\n- PDB-REDO: automatically re-refined deposited  structures, using the latest methods\n\n.left[[http://www.cmbi.ru.nl/pdb_redo/](http://www.cmbi.ru.nl/pdb_redo)]\n\n- EBI: many online tools for structure analysis\n\n[http://www.ebi.ac.uk/Tools/structure/](http://www.ebi.ac.uk/Tools/structure/).left[]]\n\n- Replaced Electron Density Server: convenient overview of  quality parameters for crystal structures\n\n.left[[http://www.ebi.ac.uk/pdbe/litemol](http://www.ebi.ac.uk/pdbe/litemol)]\n\n---\n\n### High-Resolution NMR Spectrometry ###\n\n.left[Many atomic nuclei, including the ubiquitous hydrogen nuclei,  resonate at specific radio frequencies when placed in a  strong, uniform magnetic field. The chemical environment of each individual atom slightly modulates its exact resonance  frequency.]\n\n.image-80[![](/topics/protein-structure-analysis/images/nmr-peaks-to-structure.png)]\n\n.left[In macromolecules with thousands of atoms, many different  effects combine to generate an extremely complicated pattern of chemical shifts, \nwhich therefore more or less uniquely  identify each atom. Multidimensional spectra allow these  frequencies to be assigned to specific atoms.]\n---\n\n### High-Resolution NMR Spectroscopy ###\n\n.left[When two atoms are near each other in 3D space, they can exchange magnetization, giving rise to crosspeaks at the  intersection of their respective frequencies.]\n\n.image-50[![](/topics/protein-structure-analysis/images/nmr-noe.jpg)]\n\n.left[This nuclear Overhauser effect (NOE) is used to effectively measure the distances between pairs of atoms, at least  qualitatively.]\n\n---\n\n### High-Resolution NMR Spectroscopy ###\n\n.left[After identification of the atoms by means of their unique chemical shifts, distance restraints are derived from the  Overhauser crosspeaks. An extended model of the protein  is  generated,  \nand  then  condensed  into  a  shape  that  is consistent with as many of distance restraints as possible.]\n\n.image-50[![](/topics/protein-structure-analysis/images/nmr-model-example.png)]\n\n---\n\n### Other methods ###\n\n\n- Electron microscopy (and especially Cryo-electron microscopy): Electron crystallography and single particle reconstruction\r\n-Small-angle X-ray and neutron scattering (SAXS and SANS)\n\n\n.image-80[![](/topics/protein-structure-analysis/images/saxs.png)]\n\n---\n\n### Related Web sites ###\n\n- BioMagResBank: experimental data for NMR-  derived structures (lists of distance restraints  and other experimentally derived properties)\n\n.left[[http://www.bmrb.wisc.edu/](http://www.bmrb.wisc.edu/)]\n\n- BioIsis: database of SAXS-derived structures\n\n.left[[http://www.bioisis.net](http://www.bioisis.net)]\n\n- EMBL database of SAXS-derived structures\n\n.left[[http://www.sasbdb.org](http://www.sasbdb.org)]\n\n- EM Databank for cryo-EM structures\n\n[http://www.emdatabank.org](http://www.emdatabank.org.left[)]\n\n---\n\n### Assessing Structure Quality ###\n\nGeneral geometric properties (bond lengths and angles, Ramachandran distribution, ): MolProbity  [Link](http://molprobity.biochem.duke.edu/)\n\n.left[ **Crystal Structures** ]\n- Diffraction data resolution and completeness (PDB)\n- Final $$ R_{cryst} $$ and $$ R_{free} $$ factors (PDB)\n- Local correspondence to electron density (EDS)\n\n.left[**NMR Structures**]\n- Number of distance restraints and additional experimental data sources (BMRB)\n- Local restraint density (on-line NMR constraint analyser)\n[link](http://molsim.sci.univr.it/bioinfo/tools/constraint/index.html)\n\n.left[**Other techniques**]\n- Difficult to generalise: carefully read and consider the  published protocol\n\n---\n\n### Molecular Graphics Software ###\n\n- [PyMOL](http://www.pymol.org/): high-quality output,  good examples on [Wiki](http://www.pymolwiki.org/)\n- [Chimera](http://www.cgl.ucsf.edu/chimera/): good  documentation on website\n- [VMD](http://www.ks.uiuc.edu/Research/vmd/):  excellent for the analysis of MD trajectories\n- [Yasara](http://www.yasara.org)  \n- [SwissPDBViewer](http://spdbv.vital-it.ch/)\n\n---\n\n### YASARA ###\n\n.left[\nYasara View is freely available and provides  basic visualisation functions.\n\nYasara Model, Dynamics and Structure provide  additional functionality.\n\nAn add-on module for NMR structures is  available.\n\nThe program can be combined with the WHAT-  IF program for structure validation, and with  FoldX for energy calculations.]\n\n---\n\n### Exercise 2: show a structure ###\n\n.left[\nLoad PDB entry 1TRZ using the File menu.\n\nCompare the default representations (F1-F8)  and use the various controls to change the view  of the protein.\n\nExplore the Edit and View menus to change  various aspects of the graphical representation  of the structure.\n\nExamine the hydrogen bonding patterns.  Display a molecular surface.\n\nCreate an interesting view of the molecule and  save it as a high-resolution image.\n]\n---\n\n### Protein folds are the structures of domains ###\n\n.left[\nSimilarities in assembly of secondary structure elements\n\nSo not based on sequence like motifs but on 3D structure\n\nFolds represent the shapes of protein domains!\n]\n\nExamples: TODO (add images e.g. alpha solenoid, DNA clamp, thioredoxin fold)\n\n---\n\n### Databases of protein folds ###\n\n- SCOP (http://scop.mrc-lmb.cam.ac.uk/scop/)\n- CATH (http://www.cathdb.info/)\n\n\n---\n\n### check on slides from course Wim Vranken ###\n\nsee also (http://www.ii.uib.no/~slars/bioinfocourse/PDFs/structpred_tutorial.pdf)\n\n---\n\n### Structure Superposition ###\n\n.left[\nStructures can be superimposed to achieve the best  possible match between corresponding atoms. It is  possible to consider all atoms, or only a subset  (such as the C atoms).\n\nWhen the structures are very similar, determining  which atoms should be matched to each other is  trivial. When there are larger differences, it takes  more preparation.\n\nDifferent algorithms use different combinations of  sequence- and secondary of tertiary structure-based information.\n]\n\n---\n\n### Exercise 3: Compare Structures ###\n\n.left[\nDownload the five provided PDB files and open  them in Yasara.\n\nUse the `Analyze|Align|Objects` with MUSTANG  function to align the four last objects with the first one.\n\nUse the space bar to open the text console and  see the reported root mean square deviations as well as the number of residues matched.\n]\n\n$$ rmsd = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}R_{i}^{2}} $$ \n\n.left[\nColor all structures by B factor and compare the  distribution to the local variability of the structures.\n]\n---\n\n### PDB File Surprises ###\n\n- Missing atoms, residues and loops  \n- Multiple molecules in the asymmetric unit\n- Incomplete oligomers due to coincident crystal and  oligomer symmetry\n- C-only models  lternate conformations\n- Multiple models, especially for NMR ensembles\n- Use of B factors to represent other properties  ther non-standard extensions (PDBQT, ...)\n\n---\n\n### Force Fields ###\n\n- Energy terms representing physical interactions\n\n - Covalent bond lengths and angles\n - Dihedral angles and van der Waals forces (steric effects)\n - Electrostatic interactions and hydrogen bonds\n\n\n- Energy can be minimized, and forces can literally be derived from the potential function.\n\n- Consistency and careful consideration of the  properties to be simulated are essential.\n\n---\n\n### Force Field Terms ###\n\n.left[Each energy term has a functional form, which includes one or more parameters:]\n\n- Covalent bond energy term\n To do: add formula\n- Van der Waals contact energy term\n\n.left[The parameters are collectively optimized to  reproduce a chosen set of experimentally observed parameters.\n\nA given force field should be used as a  consistent system, and can only be used to predict properties that are covered by the  training set.\n]\n\n---\n\n### FoldX ###\n\n\n.left[\nIs designed for quantitative modelling of the contribution of structural interactions to the stability of proteins and protein complexes. It also supports  protein/DNA complexes.\n\nThe force field describes the different interactions in a  protein structure or complex in analytical terms. It has  been calibrated using a set of experimentally determined  stabilities.\n\nApplications include the optimisation of structures, the calculation of the stability of complexes, and predicting  the effect of amino-acid or base-pair mutations on these  properties.\n]\n\n---\n\n### The FoldX Plugin for Yasara\t###\n\n.left[\nIn order to make FoldX more accessible and  integrate its functions into Yasara, dr. Joost van  Durme (SWITCH laboratory) made a Yasara plugin  module that can apply FoldX functions to structures  that are loaded as Yasara objects.\n\nThis greatly simplifies the use of FoldX, and allows  for a quick visual analysis of the resulting changes  in the structures.\n\nMore information can be found at [wiki](http://foldxyasara.switchlab.org/index.php/) [FoldX](http://foldxsuite.crg.eu/)\n]\n\n---\n\n### Exercise 4a: Repair a PDB File ###\n\n- Load the 1CRN PDB file.\n- Use the Repair object option in the Analysis |  FoldX menu to activate the corresponding FoldX  function.\n- Select the object to repair.\n\n.left[This exports the object as a temporary PDB file,  starts FoldX with the appropriate options, and loads  the repaired PDB file as a new object in Yasara.]\n\n- Compare the original and repaired objects.  \n- Describe the changes that were introduced.\n\n---\n\n### Exercise 4b: Model a Mutation ###\n\n- Load the 2AC0.sce Yasara scene file.\n- Set an appropriate structure representation.\n- Locate residue Ala159 using the sequence view,  and right-click to access the `FoldX|Mutate` residue function. Change it to a Trp residue.\n- Look at the effect of the substitution on the  structure, and use the space bar to open the text  console and read the output of the FoldX  calculation.\n- Mutate Arg273 to an alanine side chain. Discuss  the effects of this substitution.\n\n---\n\n### Homology Modelling ###\n\n- When a structure is available for a protein with a  similar sequences, it is possible to predict the  structure of a new sequence with varying degrees of  confidence.\n- Use PSI-BLAST/DELTA-BLAST to detect sequences with similar structures.\n- All homology modelling procedures start from an  alignment of the template and target sequences.  The quality of this alignment will have a major  impact on the resulting model.\n- Available applications include stand-alone programs  (Modeller, FoldX, ) and web-based services (such as SwissModel).\n\n \n\n---\n\n### Exercise 5: Make a Homology  Model using Swiss Model ###\n\nsee []()\n\n---\n\n### Predict protein structures by fold recognition ###\n\n1. Search SCOP/CATH for protein with same fold and known 3D structure\n2. Align each amino acid of query sequence to a position in the template structure\n3. Evaluate how well the sequence fits the fold and select best-fit fold\n4. Build structural model of query based on alignment with selected fold\n\n- Phyre (http://www.sbg.bio.ic.ac.uk/phyre2/html/page.cgi?id=index)\n- HHpred (http://toolkit.lmb.uni-muenchen.de/hhpred)\n- DescFold (http://202.112.170.199/DescFold/)\n\n.left[Works because:\n- Number of different folds in nature is fairly small (approximately 1300)\n- 90% of new submissions in PDB have similar folds to those already in PDB\n- Not always accurate\n]\n\n---\n\n### Guidelines to improve fold recognition results ###\n\n- Run as many methods as you can\n- Run each method on many sequences from your homologous protein family\n- After all of these runs, build up a consensus picture of the likely fold\n- Compare function of your protein to function of the proteins with the likely fold\n- Compare secondary structure of your protein to that of the likely fold\n\n\n---\n\n### Similarity searches based on 3D structure ###\n\n.left[\nSimilarity on structural level: aligning 3D structures\n\nStructure of query protein is known and aligned to PDB structures\n- VAST+ (https://www.ncbi.nlm.nih.gov/Structure/vastplus/vastplus.cgi)\n- DALI (http://ekhidna.biocenter.helsinki.fi/dali_server/)\n\nCompare proteins with low sequence similarity:\nsimilar structure implies homology -&gt; same function\n\nCan help to find active sites\n]\n\n---\n\n### Exercise 6: Study Protein-Ligand Interactions ###\n\nsee []()\n\n---\n\n### On-Line References ###\n\n- Crystallography 101 (Bernhard Rupp):  (http://www.ruppweb.org/Xray/101index.html)\n- Protein NMR, A Practical Guide (Vicky Higman) (http://www.protein-nmr.org.uk/)\n- Model validation course  (http://xray.bmc.uu.se/gerard/embo2001/modval/index.html)\n- Assessing model quality (http://spdbv.vital-it.ch/TheMolecularLevel/ModQual/)\n\n- Lectures by Burkhard Rost on protein structure  prediction (https://www.youtube.com/channel/UCU6j8BG4RbEtTgyIZJ6Vpow)\n\n---\n&quot;,&quot;dir&quot;:&quot;/topics/protein-structure-analysis/slides/&quot;,&quot;name&quot;:&quot;introduction.html&quot;,&quot;path&quot;:&quot;topics/protein-structure-analysis/slides/introduction.html&quot;,&quot;url&quot;:&quot;/topics/protein-structure-analysis/slides/introduction.html&quot;}
              topic: {&quot;name&quot;:&quot;protein-structure-analysis&quot;,&quot;type&quot;:&quot;basics&quot;,&quot;category&quot;:&quot;basics&quot;,&quot;title&quot;:&quot;Protein Structure Analysis&quot;,&quot;summary&quot;:&quot;Analyzing the protein structure of your protein-of-interest can be advantageous in multiple ways. It can help you discover regions which are good candidates to interact with other proteins. It can help you discover new domains. It can help with identifying differences with homologuous proteins and a lot more.&quot;,&quot;extra&quot;:&quot;protein_analysis&quot;,&quot;requirements&quot;:null,&quot;maintainers&quot;:[&quot;abotzki&quot;],&quot;references&quot;:[{&quot;authors&quot;:&quot;Switchlab&quot;,&quot;title&quot;:&quot;Home of FoldX plugin&quot;,&quot;link&quot;:&quot;http://foldxyasara.switchlab.org/&quot;,&quot;summary&quot;:&quot;More information about FoldX plugin and troubleshooting&quot;},{&quot;authors&quot;:&quot;Wikipedia&quot;,&quot;title&quot;:&quot;Wiki page about PDB&quot;,&quot;link&quot;:&quot;https://en.wikipedia.org/wiki/Protein_Data_Bank&quot;,&quot;summary&quot;:&quot;wiki page explaining information on PDB&quot;},{&quot;authors&quot;:&quot;YASARA developers&quot;,&quot;title&quot;:&quot;Working with YASARA&quot;,&quot;link&quot;:&quot;http://www.yasara.org/movies.htm&quot;,&quot;summary&quot;:&quot;Movie tutorials on YASARA&quot;}]}
              material: {&quot;layout&quot;:&quot;introduction_slides&quot;,&quot;logo&quot;:&quot;GTN&quot;,&quot;title&quot;:&quot;Protein Structure Analysis&quot;,&quot;type&quot;:&quot;introduction&quot;,&quot;contributors&quot;:[&quot;abotzki&quot;,&quot;jvdurme&quot;,&quot;janick-bits&quot;],&quot;topic_name&quot;:&quot;protein-structure-analysis&quot;,&quot;tutorial_name&quot;:&quot;introduction&quot;,&quot;content&quot;:&quot;### Protein Structure Analysis ###\n\n- Sequences, structures and databases\n- Experimental methods (X-rays, electrons and NMR)\n- Finding and visualising structures from the  Protein Data Bank\n- Comparing structures\n- Modelling mutations\n- Creating homology models\n\n---\n### Sequences and Structures ###\n\nadd one slide over transcription / translation / \n\n---\n\n### Amino acids and peptide structure\n\n![](/topics/protein-structure-analysis/images/amino-acids.png)\n\n---\n\n### The Structure-Function Connection ###\n\n.pull-left[\n- Folded proteins provide a well-defined 3D arrangement of functional groups, creating microenvironments and active sites.\n- Structural changes  are often involved in functional  mechanisms  (motor proteins, ...)\n]\n.image-90[![](/topics/protein-structure-analysis/images/hemoglobin.png)]\n\n\n---\n\n### Databases\n\n.pull-left[\n**Uniprot** approx. 1100,000 sequences\n\n- mainly determined by large-scale DNA sequencing of individual genes or whole genomes\n- increasingly automated annotation\n\n**Protein Data Bank** approx. 141,000 \nexperimentally determined structures\n\n- Mainly determined by X-ray crystallography and high-resolution NMR spectroscopy\n- Automation is increasing, but there are still significant limitations in the rate of solving new structures\n]\n\n\n]\n.pull-right[ .image-50[![](/topics/protein-structure-analysis/images/uniprot-logo.png)]\n             .image-50[![](/topics/protein-structure-analysis/images/pdb-logo.png)]\n]\n\n---\n\n### X-Ray Crystallography ###\n\n![](/topics/protein-structure-analysis/images/xray-tech-setup.png)\n\n.pull-left[\n\n.left[In a crystal, a large number  of macromolecules are  packed together in a regular grid, with consistent  orientations and relative  distances. \nWhen exposed  to an X-ray beam, this  arrangement gives rise to\ndiffracted rays in specific directions,  resulting in discrete spots on the planar\ndetector. By rotating the crystal, a series  of images is obtained. From these, the\nintensities of all the diffracted rays of the  crystal can be derived.]\n\n]\n.pull-right[ .image-90[![](/topics/protein-structure-analysis/images/diffraction-pattern.png)]\n]\n\n\n---\n\n### X-Ray Crystallography ###\n\n.pull-left[\n.image-50[![](/topics/protein-structure-analysis/images/diffraction-pattern.png)]\n]\n.pull-right[.image-50[![](/topics/protein-structure-analysis/images/electron-density.png)]]\n\n|              |          |               |\n|:-------------|:--------:|--------------:|\n| Diffraction Spot Intensities and Phases $$F_{obs}(h,k,l)$$ and $$\\phi_{obs}(h,k,l)$$ | $$R_{cryst} = \\frac{\\sum_{h,k,l}F_{obs}-F_{calc}}{\\sum_{h,k,l}F_{obs}}$$ | Electron density $$\\rho(x,y,z)$$ |\n\n\n---\n\n### The Protein Databank ###\n\n.pull-left[ .image-80[![](/topics/protein-structure-analysis/images/wwpdb-welcome-page.png)] \n\n\n.pull-right[ \n.left[ [http://www.wwpdb.org](http://www.wwpdb.org) ]\n- contains structures of  proteins, nucleic acids  and complexes,  determined by X-ray  crystallography, NMR  spectroscopy\n- No purely theoretical  or ab initio models  (since 2006)\n- Also stores supporting  experimental data\n- Full deposition now  required by all peer-reviewed journals\n]\n]\n\n---\n\n### Exercise 1: Search the PDB ###\n\n- Use the UniProt site to search for dnak.  \n- Use the PDB site to search for dnak.\n - Compare the UniProt and PDB result lists.\n- Use the sequence search function to see if there are structures with sequences similar to that of the  DnaK C-terminal domain.\n- Look at the summary pages of a number of  structures and note some interesting properties.\n- Select a number of structures and create a report  page.\n\n---\n\n### PDB File Format ###\n\n![](/topics/protein-structure-analysis/images/pdb-file-format.png)\n\n---\n\n### Occupancy ###\n\n![](/topics/protein-structure-analysis/images/occupancy.png)\n\n\n---\n\n### Related Web sites ###\n\n- Nucleic Acid Database: DNA and RNA structures\n\n.left[[http://ndbserver.rutgers.edu/](http://ndbserver.rutgers.edu/)]\n\n- PDB-REDO: automatically re-refined deposited  structures, using the latest methods\n\n.left[[http://www.cmbi.ru.nl/pdb_redo/](http://www.cmbi.ru.nl/pdb_redo)]\n\n- EBI: many online tools for structure analysis\n\n[http://www.ebi.ac.uk/Tools/structure/](http://www.ebi.ac.uk/Tools/structure/).left[]]\n\n- Replaced Electron Density Server: convenient overview of  quality parameters for crystal structures\n\n.left[[http://www.ebi.ac.uk/pdbe/litemol](http://www.ebi.ac.uk/pdbe/litemol)]\n\n---\n\n### High-Resolution NMR Spectrometry ###\n\n.left[Many atomic nuclei, including the ubiquitous hydrogen nuclei,  resonate at specific radio frequencies when placed in a  strong, uniform magnetic field. The chemical environment of each individual atom slightly modulates its exact resonance  frequency.]\n\n.image-80[![](/topics/protein-structure-analysis/images/nmr-peaks-to-structure.png)]\n\n.left[In macromolecules with thousands of atoms, many different  effects combine to generate an extremely complicated pattern of chemical shifts, \nwhich therefore more or less uniquely  identify each atom. Multidimensional spectra allow these  frequencies to be assigned to specific atoms.]\n---\n\n### High-Resolution NMR Spectroscopy ###\n\n.left[When two atoms are near each other in 3D space, they can exchange magnetization, giving rise to crosspeaks at the  intersection of their respective frequencies.]\n\n.image-50[![](/topics/protein-structure-analysis/images/nmr-noe.jpg)]\n\n.left[This nuclear Overhauser effect (NOE) is used to effectively measure the distances between pairs of atoms, at least  qualitatively.]\n\n---\n\n### High-Resolution NMR Spectroscopy ###\n\n.left[After identification of the atoms by means of their unique chemical shifts, distance restraints are derived from the  Overhauser crosspeaks. An extended model of the protein  is  generated,  \nand  then  condensed  into  a  shape  that  is consistent with as many of distance restraints as possible.]\n\n.image-50[![](/topics/protein-structure-analysis/images/nmr-model-example.png)]\n\n---\n\n### Other methods ###\n\n\n- Electron microscopy (and especially Cryo-electron microscopy): Electron crystallography and single particle reconstruction\r\n-Small-angle X-ray and neutron scattering (SAXS and SANS)\n\n\n.image-80[![](/topics/protein-structure-analysis/images/saxs.png)]\n\n---\n\n### Related Web sites ###\n\n- BioMagResBank: experimental data for NMR-  derived structures (lists of distance restraints  and other experimentally derived properties)\n\n.left[[http://www.bmrb.wisc.edu/](http://www.bmrb.wisc.edu/)]\n\n- BioIsis: database of SAXS-derived structures\n\n.left[[http://www.bioisis.net](http://www.bioisis.net)]\n\n- EMBL database of SAXS-derived structures\n\n.left[[http://www.sasbdb.org](http://www.sasbdb.org)]\n\n- EM Databank for cryo-EM structures\n\n[http://www.emdatabank.org](http://www.emdatabank.org.left[)]\n\n---\n\n### Assessing Structure Quality ###\n\nGeneral geometric properties (bond lengths and angles, Ramachandran distribution, ): MolProbity  [Link](http://molprobity.biochem.duke.edu/)\n\n.left[ **Crystal Structures** ]\n- Diffraction data resolution and completeness (PDB)\n- Final $$ R_{cryst} $$ and $$ R_{free} $$ factors (PDB)\n- Local correspondence to electron density (EDS)\n\n.left[**NMR Structures**]\n- Number of distance restraints and additional experimental data sources (BMRB)\n- Local restraint density (on-line NMR constraint analyser)\n[link](http://molsim.sci.univr.it/bioinfo/tools/constraint/index.html)\n\n.left[**Other techniques**]\n- Difficult to generalise: carefully read and consider the  published protocol\n\n---\n\n### Molecular Graphics Software ###\n\n- [PyMOL](http://www.pymol.org/): high-quality output,  good examples on [Wiki](http://www.pymolwiki.org/)\n- [Chimera](http://www.cgl.ucsf.edu/chimera/): good  documentation on website\n- [VMD](http://www.ks.uiuc.edu/Research/vmd/):  excellent for the analysis of MD trajectories\n- [Yasara](http://www.yasara.org)  \n- [SwissPDBViewer](http://spdbv.vital-it.ch/)\n\n---\n\n### YASARA ###\n\n.left[\nYasara View is freely available and provides  basic visualisation functions.\n\nYasara Model, Dynamics and Structure provide  additional functionality.\n\nAn add-on module for NMR structures is  available.\n\nThe program can be combined with the WHAT-  IF program for structure validation, and with  FoldX for energy calculations.]\n\n---\n\n### Exercise 2: show a structure ###\n\n.left[\nLoad PDB entry 1TRZ using the File menu.\n\nCompare the default representations (F1-F8)  and use the various controls to change the view  of the protein.\n\nExplore the Edit and View menus to change  various aspects of the graphical representation  of the structure.\n\nExamine the hydrogen bonding patterns.  Display a molecular surface.\n\nCreate an interesting view of the molecule and  save it as a high-resolution image.\n]\n---\n\n### Protein folds are the structures of domains ###\n\n.left[\nSimilarities in assembly of secondary structure elements\n\nSo not based on sequence like motifs but on 3D structure\n\nFolds represent the shapes of protein domains!\n]\n\nExamples: TODO (add images e.g. alpha solenoid, DNA clamp, thioredoxin fold)\n\n---\n\n### Databases of protein folds ###\n\n- SCOP (http://scop.mrc-lmb.cam.ac.uk/scop/)\n- CATH (http://www.cathdb.info/)\n\n\n---\n\n### check on slides from course Wim Vranken ###\n\nsee also (http://www.ii.uib.no/~slars/bioinfocourse/PDFs/structpred_tutorial.pdf)\n\n---\n\n### Structure Superposition ###\n\n.left[\nStructures can be superimposed to achieve the best  possible match between corresponding atoms. It is  possible to consider all atoms, or only a subset  (such as the C atoms).\n\nWhen the structures are very similar, determining  which atoms should be matched to each other is  trivial. When there are larger differences, it takes  more preparation.\n\nDifferent algorithms use different combinations of  sequence- and secondary of tertiary structure-based information.\n]\n\n---\n\n### Exercise 3: Compare Structures ###\n\n.left[\nDownload the five provided PDB files and open  them in Yasara.\n\nUse the `Analyze|Align|Objects` with MUSTANG  function to align the four last objects with the first one.\n\nUse the space bar to open the text console and  see the reported root mean square deviations as well as the number of residues matched.\n]\n\n$$ rmsd = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}R_{i}^{2}} $$ \n\n.left[\nColor all structures by B factor and compare the  distribution to the local variability of the structures.\n]\n---\n\n### PDB File Surprises ###\n\n- Missing atoms, residues and loops  \n- Multiple molecules in the asymmetric unit\n- Incomplete oligomers due to coincident crystal and  oligomer symmetry\n- C-only models  lternate conformations\n- Multiple models, especially for NMR ensembles\n- Use of B factors to represent other properties  ther non-standard extensions (PDBQT, ...)\n\n---\n\n### Force Fields ###\n\n- Energy terms representing physical interactions\n\n - Covalent bond lengths and angles\n - Dihedral angles and van der Waals forces (steric effects)\n - Electrostatic interactions and hydrogen bonds\n\n\n- Energy can be minimized, and forces can literally be derived from the potential function.\n\n- Consistency and careful consideration of the  properties to be simulated are essential.\n\n---\n\n### Force Field Terms ###\n\n.left[Each energy term has a functional form, which includes one or more parameters:]\n\n- Covalent bond energy term\n To do: add formula\n- Van der Waals contact energy term\n\n.left[The parameters are collectively optimized to  reproduce a chosen set of experimentally observed parameters.\n\nA given force field should be used as a  consistent system, and can only be used to predict properties that are covered by the  training set.\n]\n\n---\n\n### FoldX ###\n\n\n.left[\nIs designed for quantitative modelling of the contribution of structural interactions to the stability of proteins and protein complexes. It also supports  protein/DNA complexes.\n\nThe force field describes the different interactions in a  protein structure or complex in analytical terms. It has  been calibrated using a set of experimentally determined  stabilities.\n\nApplications include the optimisation of structures, the calculation of the stability of complexes, and predicting  the effect of amino-acid or base-pair mutations on these  properties.\n]\n\n---\n\n### The FoldX Plugin for Yasara\t###\n\n.left[\nIn order to make FoldX more accessible and  integrate its functions into Yasara, dr. Joost van  Durme (SWITCH laboratory) made a Yasara plugin  module that can apply FoldX functions to structures  that are loaded as Yasara objects.\n\nThis greatly simplifies the use of FoldX, and allows  for a quick visual analysis of the resulting changes  in the structures.\n\nMore information can be found at [wiki](http://foldxyasara.switchlab.org/index.php/) [FoldX](http://foldxsuite.crg.eu/)\n]\n\n---\n\n### Exercise 4a: Repair a PDB File ###\n\n- Load the 1CRN PDB file.\n- Use the Repair object option in the Analysis |  FoldX menu to activate the corresponding FoldX  function.\n- Select the object to repair.\n\n.left[This exports the object as a temporary PDB file,  starts FoldX with the appropriate options, and loads  the repaired PDB file as a new object in Yasara.]\n\n- Compare the original and repaired objects.  \n- Describe the changes that were introduced.\n\n---\n\n### Exercise 4b: Model a Mutation ###\n\n- Load the 2AC0.sce Yasara scene file.\n- Set an appropriate structure representation.\n- Locate residue Ala159 using the sequence view,  and right-click to access the `FoldX|Mutate` residue function. Change it to a Trp residue.\n- Look at the effect of the substitution on the  structure, and use the space bar to open the text  console and read the output of the FoldX  calculation.\n- Mutate Arg273 to an alanine side chain. Discuss  the effects of this substitution.\n\n---\n\n### Homology Modelling ###\n\n- When a structure is available for a protein with a  similar sequences, it is possible to predict the  structure of a new sequence with varying degrees of  confidence.\n- Use PSI-BLAST/DELTA-BLAST to detect sequences with similar structures.\n- All homology modelling procedures start from an  alignment of the template and target sequences.  The quality of this alignment will have a major  impact on the resulting model.\n- Available applications include stand-alone programs  (Modeller, FoldX, ) and web-based services (such as SwissModel).\n\n \n\n---\n\n### Exercise 5: Make a Homology  Model using Swiss Model ###\n\nsee []()\n\n---\n\n### Predict protein structures by fold recognition ###\n\n1. Search SCOP/CATH for protein with same fold and known 3D structure\n2. Align each amino acid of query sequence to a position in the template structure\n3. Evaluate how well the sequence fits the fold and select best-fit fold\n4. Build structural model of query based on alignment with selected fold\n\n- Phyre (http://www.sbg.bio.ic.ac.uk/phyre2/html/page.cgi?id=index)\n- HHpred (http://toolkit.lmb.uni-muenchen.de/hhpred)\n- DescFold (http://202.112.170.199/DescFold/)\n\n.left[Works because:\n- Number of different folds in nature is fairly small (approximately 1300)\n- 90% of new submissions in PDB have similar folds to those already in PDB\n- Not always accurate\n]\n\n---\n\n### Guidelines to improve fold recognition results ###\n\n- Run as many methods as you can\n- Run each method on many sequences from your homologous protein family\n- After all of these runs, build up a consensus picture of the likely fold\n- Compare function of your protein to function of the proteins with the likely fold\n- Compare secondary structure of your protein to that of the likely fold\n\n\n---\n\n### Similarity searches based on 3D structure ###\n\n.left[\nSimilarity on structural level: aligning 3D structures\n\nStructure of query protein is known and aligned to PDB structures\n- VAST+ (https://www.ncbi.nlm.nih.gov/Structure/vastplus/vastplus.cgi)\n- DALI (http://ekhidna.biocenter.helsinki.fi/dali_server/)\n\nCompare proteins with low sequence similarity:\nsimilar structure implies homology -&gt; same function\n\nCan help to find active sites\n]\n\n---\n\n### Exercise 6: Study Protein-Ligand Interactions ###\n\nsee []()\n\n---\n\n### On-Line References ###\n\n- Crystallography 101 (Bernhard Rupp):  (http://www.ruppweb.org/Xray/101index.html)\n- Protein NMR, A Practical Guide (Vicky Higman) (http://www.protein-nmr.org.uk/)\n- Model validation course  (http://xray.bmc.uu.se/gerard/embo2001/modval/index.html)\n- Assessing model quality (http://spdbv.vital-it.ch/TheMolecularLevel/ModQual/)\n\n- Lectures by Burkhard Rost on protein structure  prediction (https://www.youtube.com/channel/UCU6j8BG4RbEtTgyIZJ6Vpow)\n\n---\n&quot;,&quot;dir&quot;:&quot;/topics/protein-structure-analysis/slides/&quot;,&quot;name&quot;:&quot;introduction.html&quot;,&quot;path&quot;:&quot;topics/protein-structure-analysis/slides/introduction.html&quot;,&quot;url&quot;:&quot;/topics/protein-structure-analysis/slides/introduction.html&quot;}
        </pre>
    <textarea id="source">
name: inverse
layout: true
class: center, middle, inverse

<div class="my-header"><span>
<a href="/topics/protein-structure-analysis" title="Return to topic page" ><i class="fa fa-level-up" aria-hidden="true"></i></a>

<a class="nav-link" href="https://github.com/vibbits/training-material/edit/master/topics/protein-structure-analysis/slides/introduction.html"><i class="fa fa-pencil" aria-hidden="true"></i></a>

</span></div>

<div class="my-footer"><span>

<img src="/assets/images/bioinformatics_core_rgb_neg.png" alt="VIB Bioinformatics Core" style="height: 40px;"/>

</span></div>

---

# Protein Structure Analysis



---

### Protein Structure Analysis ###

- Sequences, structures and databases
- Experimental methods (X-rays, electrons and NMR)
- Finding and visualising structures from the  Protein Data Bank
- Comparing structures
- Modelling mutations
- Creating homology models

---
### Sequences and Structures ###

add one slide over transcription / translation / 

---

### Amino acids and peptide structure

![](/topics/protein-structure-analysis/images/amino-acids.png)

---

### The Structure-Function Connection ###

.pull-left[
- Folded proteins provide a well-defined 3D arrangement of functional groups, creating microenvironments and active sites.
- Structural changes  are often involved in functional  mechanisms  (motor proteins, ...)
]
.image-90[![](/topics/protein-structure-analysis/images/hemoglobin.png)]


---

### Databases

.pull-left[
**Uniprot** approx. 1100,000 sequences

- mainly determined by large-scale DNA sequencing of individual genes or whole genomes
- increasingly automated annotation

**Protein Data Bank** approx. 141,000 
experimentally determined structures

- Mainly determined by X-ray crystallography and high-resolution NMR spectroscopy
- Automation is increasing, but there are still significant limitations in the rate of solving new structures
]


]
.pull-right[ .image-50[![](/topics/protein-structure-analysis/images/uniprot-logo.png)]
             .image-50[![](/topics/protein-structure-analysis/images/pdb-logo.png)]
]

---

### X-Ray Crystallography ###

![](/topics/protein-structure-analysis/images/xray-tech-setup.png)

.pull-left[

.left[In a crystal, a large number  of macromolecules are  packed together in a regular grid, with consistent  orientations and relative  distances. 
When exposed  to an X-ray beam, this  arrangement gives rise to
diffracted rays in specific directions,  resulting in discrete spots on the planar
detector. By rotating the crystal, a series  of images is obtained. From these, the
intensities of all the diffracted rays of the  crystal can be derived.]

]
.pull-right[ .image-90[![](/topics/protein-structure-analysis/images/diffraction-pattern.png)]
]


---

### X-Ray Crystallography ###

.pull-left[
.image-50[![](/topics/protein-structure-analysis/images/diffraction-pattern.png)]
]
.pull-right[.image-50[![](/topics/protein-structure-analysis/images/electron-density.png)]]

|              |          |               |
|:-------------|:--------:|--------------:|
| Diffraction Spot Intensities and Phases $$F_{obs}(h,k,l)$$ and $$\phi_{obs}(h,k,l)$$ | $$R_{cryst} = \frac{\sum_{h,k,l}F_{obs}-F_{calc}}{\sum_{h,k,l}F_{obs}}$$ | Electron density $$\rho(x,y,z)$$ |


---

### The Protein Databank ###

.pull-left[ .image-80[![](/topics/protein-structure-analysis/images/wwpdb-welcome-page.png)] 


.pull-right[ 
.left[ [http://www.wwpdb.org](http://www.wwpdb.org) ]
- contains structures of  proteins, nucleic acids  and complexes,  determined by X-ray  crystallography, NMR  spectroscopy
- No purely theoretical  or ab initio models  (since 2006)
- Also stores supporting  experimental data
- Full deposition now  required by all peer-reviewed journals
]
]

---

### Exercise 1: Search the PDB ###

- Use the UniProt site to search for dnak.  
- Use the PDB site to search for dnak.
 - Compare the UniProt and PDB result lists.
- Use the sequence search function to see if there are structures with sequences similar to that of the  DnaK C-terminal domain.
- Look at the summary pages of a number of  structures and note some interesting properties.
- Select a number of structures and create a report  page.

---

### PDB File Format ###

![](/topics/protein-structure-analysis/images/pdb-file-format.png)

---

### Occupancy ###

![](/topics/protein-structure-analysis/images/occupancy.png)


---

### Related Web sites ###

- Nucleic Acid Database: DNA and RNA structures

.left[[http://ndbserver.rutgers.edu/](http://ndbserver.rutgers.edu/)]

- PDB-REDO: automatically re-refined deposited  structures, using the latest methods

.left[[http://www.cmbi.ru.nl/pdb_redo/](http://www.cmbi.ru.nl/pdb_redo)]

- EBI: many online tools for structure analysis

[http://www.ebi.ac.uk/Tools/structure/](http://www.ebi.ac.uk/Tools/structure/).left[]]

- Replaced Electron Density Server: convenient overview of  quality parameters for crystal structures

.left[[http://www.ebi.ac.uk/pdbe/litemol](http://www.ebi.ac.uk/pdbe/litemol)]

---

### High-Resolution NMR Spectrometry ###

.left[Many atomic nuclei, including the ubiquitous hydrogen nuclei,  resonate at specific radio frequencies when placed in a  strong, uniform magnetic field. The chemical environment of each individual atom slightly modulates its exact resonance  frequency.]

.image-80[![](/topics/protein-structure-analysis/images/nmr-peaks-to-structure.png)]

.left[In macromolecules with thousands of atoms, many different  effects combine to generate an extremely complicated pattern of chemical shifts, 
which therefore more or less uniquely  identify each atom. Multidimensional spectra allow these  frequencies to be assigned to specific atoms.]
---

### High-Resolution NMR Spectroscopy ###

.left[When two atoms are near each other in 3D space, they can exchange magnetization, giving rise to crosspeaks at the  intersection of their respective frequencies.]

.image-50[![](/topics/protein-structure-analysis/images/nmr-noe.jpg)]

.left[This nuclear Overhauser effect (NOE) is used to effectively measure the distances between pairs of atoms, at least  qualitatively.]

---

### High-Resolution NMR Spectroscopy ###

.left[After identification of the atoms by means of their unique chemical shifts, distance restraints are derived from the  Overhauser crosspeaks. An extended model of the protein  is  generated,  
and  then  condensed  into  a  shape  that  is consistent with as many of distance restraints as possible.]

.image-50[![](/topics/protein-structure-analysis/images/nmr-model-example.png)]

---

### Other methods ###


- Electron microscopy (and especially Cryo-electron microscopy): Electron crystallography and single particle reconstruction
-Small-angle X-ray and neutron scattering (SAXS and SANS)


.image-80[![](/topics/protein-structure-analysis/images/saxs.png)]

---

### Related Web sites ###

- BioMagResBank: experimental data for NMR-  derived structures (lists of distance restraints  and other experimentally derived properties)

.left[[http://www.bmrb.wisc.edu/](http://www.bmrb.wisc.edu/)]

- BioIsis: database of SAXS-derived structures

.left[[http://www.bioisis.net](http://www.bioisis.net)]

- EMBL database of SAXS-derived structures

.left[[http://www.sasbdb.org](http://www.sasbdb.org)]

- EM Databank for cryo-EM structures

[http://www.emdatabank.org](http://www.emdatabank.org.left[)]

---

### Assessing Structure Quality ###

General geometric properties (bond lengths and angles, Ramachandran distribution, ): MolProbity  [Link](http://molprobity.biochem.duke.edu/)

.left[ **Crystal Structures** ]
- Diffraction data resolution and completeness (PDB)
- Final $$ R_{cryst} $$ and $$ R_{free} $$ factors (PDB)
- Local correspondence to electron density (EDS)

.left[**NMR Structures**]
- Number of distance restraints and additional experimental data sources (BMRB)
- Local restraint density (on-line NMR constraint analyser)
[link](http://molsim.sci.univr.it/bioinfo/tools/constraint/index.html)

.left[**Other techniques**]
- Difficult to generalise: carefully read and consider the  published protocol

---

### Molecular Graphics Software ###

- [PyMOL](http://www.pymol.org/): high-quality output,  good examples on [Wiki](http://www.pymolwiki.org/)
- [Chimera](http://www.cgl.ucsf.edu/chimera/): good  documentation on website
- [VMD](http://www.ks.uiuc.edu/Research/vmd/):  excellent for the analysis of MD trajectories
- [Yasara](http://www.yasara.org)  
- [SwissPDBViewer](http://spdbv.vital-it.ch/)

---

### YASARA ###

.left[
Yasara View is freely available and provides  basic visualisation functions.

Yasara Model, Dynamics and Structure provide  additional functionality.

An add-on module for NMR structures is  available.

The program can be combined with the WHAT-  IF program for structure validation, and with  FoldX for energy calculations.]

---

### Exercise 2: show a structure ###

.left[
Load PDB entry 1TRZ using the File menu.

Compare the default representations (F1-F8)  and use the various controls to change the view  of the protein.

Explore the Edit and View menus to change  various aspects of the graphical representation  of the structure.

Examine the hydrogen bonding patterns.  Display a molecular surface.

Create an interesting view of the molecule and  save it as a high-resolution image.
]
---

### Protein folds are the structures of domains ###

.left[
Similarities in assembly of secondary structure elements

So not based on sequence like motifs but on 3D structure

Folds represent the shapes of protein domains!
]

Examples: TODO (add images e.g. alpha solenoid, DNA clamp, thioredoxin fold)

---

### Databases of protein folds ###

- SCOP (http://scop.mrc-lmb.cam.ac.uk/scop/)
- CATH (http://www.cathdb.info/)


---

### check on slides from course Wim Vranken ###

see also (http://www.ii.uib.no/~slars/bioinfocourse/PDFs/structpred_tutorial.pdf)

---

### Structure Superposition ###

.left[
Structures can be superimposed to achieve the best  possible match between corresponding atoms. It is  possible to consider all atoms, or only a subset  (such as the C atoms).

When the structures are very similar, determining  which atoms should be matched to each other is  trivial. When there are larger differences, it takes  more preparation.

Different algorithms use different combinations of  sequence- and secondary of tertiary structure-based information.
]

---

### Exercise 3: Compare Structures ###

.left[
Download the five provided PDB files and open  them in Yasara.

Use the `Analyze|Align|Objects` with MUSTANG  function to align the four last objects with the first one.

Use the space bar to open the text console and  see the reported root mean square deviations as well as the number of residues matched.
]

$$ rmsd = \sqrt{\frac{1}{N}\sum_{i=1}^{N}R_{i}^{2}} $$ 

.left[
Color all structures by B factor and compare the  distribution to the local variability of the structures.
]
---

### PDB File Surprises ###

- Missing atoms, residues and loops  
- Multiple molecules in the asymmetric unit
- Incomplete oligomers due to coincident crystal and  oligomer symmetry
- C-only models  lternate conformations
- Multiple models, especially for NMR ensembles
- Use of B factors to represent other properties  ther non-standard extensions (PDBQT, ...)

---

### Force Fields ###

- Energy terms representing physical interactions

 - Covalent bond lengths and angles
 - Dihedral angles and van der Waals forces (steric effects)
 - Electrostatic interactions and hydrogen bonds


- Energy can be minimized, and forces can literally be derived from the potential function.

- Consistency and careful consideration of the  properties to be simulated are essential.

---

### Force Field Terms ###

.left[Each energy term has a functional form, which includes one or more parameters:]

- Covalent bond energy term
 To do: add formula
- Van der Waals contact energy term

.left[The parameters are collectively optimized to  reproduce a chosen set of experimentally observed parameters.

A given force field should be used as a  consistent system, and can only be used to predict properties that are covered by the  training set.
]

---

### FoldX ###


.left[
Is designed for quantitative modelling of the contribution of structural interactions to the stability of proteins and protein complexes. It also supports  protein/DNA complexes.

The force field describes the different interactions in a  protein structure or complex in analytical terms. It has  been calibrated using a set of experimentally determined  stabilities.

Applications include the optimisation of structures, the calculation of the stability of complexes, and predicting  the effect of amino-acid or base-pair mutations on these  properties.
]

---

### The FoldX Plugin for Yasara	###

.left[
In order to make FoldX more accessible and  integrate its functions into Yasara, dr. Joost van  Durme (SWITCH laboratory) made a Yasara plugin  module that can apply FoldX functions to structures  that are loaded as Yasara objects.

This greatly simplifies the use of FoldX, and allows  for a quick visual analysis of the resulting changes  in the structures.

More information can be found at [wiki](http://foldxyasara.switchlab.org/index.php/) [FoldX](http://foldxsuite.crg.eu/)
]

---

### Exercise 4a: Repair a PDB File ###

- Load the 1CRN PDB file.
- Use the Repair object option in the Analysis |  FoldX menu to activate the corresponding FoldX  function.
- Select the object to repair.

.left[This exports the object as a temporary PDB file,  starts FoldX with the appropriate options, and loads  the repaired PDB file as a new object in Yasara.]

- Compare the original and repaired objects.  
- Describe the changes that were introduced.

---

### Exercise 4b: Model a Mutation ###

- Load the 2AC0.sce Yasara scene file.
- Set an appropriate structure representation.
- Locate residue Ala159 using the sequence view,  and right-click to access the `FoldX|Mutate` residue function. Change it to a Trp residue.
- Look at the effect of the substitution on the  structure, and use the space bar to open the text  console and read the output of the FoldX  calculation.
- Mutate Arg273 to an alanine side chain. Discuss  the effects of this substitution.

---

### Homology Modelling ###

- When a structure is available for a protein with a  similar sequences, it is possible to predict the  structure of a new sequence with varying degrees of  confidence.
- Use PSI-BLAST/DELTA-BLAST to detect sequences with similar structures.
- All homology modelling procedures start from an  alignment of the template and target sequences.  The quality of this alignment will have a major  impact on the resulting model.
- Available applications include stand-alone programs  (Modeller, FoldX, ) and web-based services (such as SwissModel).

 

---

### Exercise 5: Make a Homology  Model using Swiss Model ###

see []()

---

### Predict protein structures by fold recognition ###

1. Search SCOP/CATH for protein with same fold and known 3D structure
2. Align each amino acid of query sequence to a position in the template structure
3. Evaluate how well the sequence fits the fold and select best-fit fold
4. Build structural model of query based on alignment with selected fold

- Phyre (http://www.sbg.bio.ic.ac.uk/phyre2/html/page.cgi?id=index)
- HHpred (http://toolkit.lmb.uni-muenchen.de/hhpred)
- DescFold (http://202.112.170.199/DescFold/)

.left[Works because:
- Number of different folds in nature is fairly small (approximately 1300)
- 90% of new submissions in PDB have similar folds to those already in PDB
- Not always accurate
]

---

### Guidelines to improve fold recognition results ###

- Run as many methods as you can
- Run each method on many sequences from your homologous protein family
- After all of these runs, build up a consensus picture of the likely fold
- Compare function of your protein to function of the proteins with the likely fold
- Compare secondary structure of your protein to that of the likely fold


---

### Similarity searches based on 3D structure ###

.left[
Similarity on structural level: aligning 3D structures

Structure of query protein is known and aligned to PDB structures
- VAST+ (https://www.ncbi.nlm.nih.gov/Structure/vastplus/vastplus.cgi)
- DALI (http://ekhidna.biocenter.helsinki.fi/dali_server/)

Compare proteins with low sequence similarity:
similar structure implies homology -&gt; same function

Can help to find active sites
]

---

### Exercise 6: Study Protein-Ligand Interactions ###

see []()

---

### On-Line References ###

- Crystallography 101 (Bernhard Rupp):  (http://www.ruppweb.org/Xray/101index.html)
- Protein NMR, A Practical Guide (Vicky Higman) (http://www.protein-nmr.org.uk/)
- Model validation course  (http://xray.bmc.uu.se/gerard/embo2001/modval/index.html)
- Assessing model quality (http://spdbv.vital-it.ch/TheMolecularLevel/ModQual/)

- Lectures by Burkhard Rost on protein structure  prediction (https://www.youtube.com/channel/UCU6j8BG4RbEtTgyIZJ6Vpow)

---


---




## Related tutorials


    

    
        
    

    
        
    

    
        
    

    
        
    

    
        
    

    
        
    



---

## Thank you!

This material is the result of a collaborative work. Thanks the colleagues of the VIB Bioinformatics Core and all the contributors!


<div class="contributors-line">


<a href="/hall-of-fame#abotzki" class="contributor-badge">Alexander Botzki</a>
, <a href="/hall-of-fame#jvdurme" class="contributor-badge">Joost Van Durme</a>
, <a href="/hall-of-fame#janick-bits" class="contributor-badge">Janick Mathys</a>



</div>



<img src="/assets/images/logo.svg" alt="Galaxy Training Network" style="height: 100px;"/>



    </textarea>
    <script src="/assets/js/remark-latest.min.js" type="text/javascript">
    </script>
    <script type="text/javascript">
      var slideshow = remark.create({navigation: {scroll: false,}});
      var hljs = remark.highlighter.engine;
    </script>
  </body>
</html>
